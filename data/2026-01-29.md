<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations](https://arxiv.org/abs/2509.26331)
*Berdymyrat Ovezmyradov*

Main category: cs.AI

TL;DR: 该研究提出了一个新的商业游戏基准来评估大型语言模型（LLMs）在长期战略商业决策方面的能力，并对五个领先的LLMs进行了评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估LLMs的长期决策能力方面存在不足，而LLMs在商业决策领域的应用潜力巨大，因此需要新的评估框架。

Method: 研究人员开发了一个可复现、开放访问的管理模拟器，该模拟器基于一个商业游戏，让五个领先的LLMs（Gemini, ChatGPT, Meta AI, Mistral AI, Grok）为一家模拟零售公司做出决策。在为期十二个月的模拟中，LLMs根据上一期的业务报告制定定价、订单量、营销预算、人员增减、贷款、培训、研发、销售预测和收入预测等战略决策。

Result: 评估指标包括利润、收入和市场份额等量化指标，同时分析了LLMs决策的战略一致性、市场适应性以及决策理由，以超越简单的性能指标评估。

Conclusion: 该研究提出了一个新的LLM基准，并为研究界提供了一个管理模拟器，用于评估和改进LLMs在长期战略商业决策方面的能力。

Abstract: The rapid advancement of LLMs sparked significant interest in their potential to augment or automate managerial functions. One of the most recent trends in AI benchmarking is performance of Large Language Models (LLMs) over longer time horizons. While LLMs excel at tasks involving natural language and pattern recognition, their capabilities in multi-step, strategic business decision-making remain largely unexplored. Few studies demonstrated how results can be different from benchmarks in short-term tasks, as Vending-Bench revealed. Meanwhile, there is a shortage of alternative benchmarks for long-term coherence. This research analyses a novel benchmark using a business game for the decision making in business. The research contributes to the recent literature on AI by proposing a reproducible, open-access management simulator to the research community for LLM benchmarking. This novel framework is used for evaluating the performance of five leading LLMs available in free online interface: Gemini, ChatGPT, Meta AI, Mistral AI, and Grok. LLM makes decisions for a simulated retail company. A dynamic, month-by-month management simulation provides transparently in spreadsheet model as experimental environment. In each of twelve months, the LLMs are provided with a structured prompt containing a full business report from the previous period and are tasked with making key strategic decisions: pricing, order size, marketing budget, hiring, dismissal, loans, training expense, R&D expense, sales forecast, income forecast The methodology is designed to compare the LLMs on quantitative metrics: profit, revenue, and market share, and other KPIs. LLM decisions are analyzed in their strategic coherence, adaptability to market changes, and the rationale provided for their decisions. This approach allows to move beyond simple performance metrics for assessment of the long-term decision-making.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [2] [RelServe: Fast LLM Inference Serving on Relational Data](https://arxiv.org/abs/2601.11546)
*Xin Zhang,Shihong Gao,Yanyan Shen,Haoyang Li,Lei Chen*

Main category: cs.DB

TL;DR: RelServe通过动态优先级更新和自适应批处理来优化LLM引擎，以降低relQuery服务的延迟。


<details>
  <summary>Details</summary>
Motivation: 随着AI驱动的电子表格等应用中relQuery服务的普及，在并发查询负载下快速响应的需求日益增长。然而，当前的LLM引擎面临着严重的延迟瓶颈，包括等待、核心运行和尾部运行三个阶段的Head-of-Line（HoL）阻塞。

Method: RelServe提出了一种动态优先级更新器，可以通过统计近似来持续调整优先级并最小化开销，以及一种自适应批处理安排器，可以量化评估候选预填充和解码批处理，以最小化预期的平均延迟。

Result: 在四种真实世界数据集和13B到70B参数的LLM上进行的广泛实验表明，RelServe与vLLM相比，平均服务延迟降低了高达3.1倍。

Conclusion: RelServe是一种为低延迟relQuery服务而优化的LLM引擎，通过其创新的动态优先级更新和自适应批处理技术，显著解决了现有LLM引擎的HoL阻塞问题。

Abstract: The use of Large Language Models (LLMs) for querying relational data has given rise to relQuery, a workload pattern that applies templated LLM calls to structured tables. As relQuery services become more widely adopted in applications such as AI-powered spreadsheets, fast response times under concurrent query loads are increasingly important. Unfortunately, current LLM engines face severe latency bottlenecks from Head-of-Line (HoL) blocking across three comparable inference phases: waiting, core running, and tail running. Existing static priority scheduling methods only address HoL blocking during the waiting phase, leaving two critical problems unsolved. First, the absence of a priority update mechanism causes inaccurate prioritization and continued HoL blocking during core execution. Second, suboptimal prefill-decode batching exacerbates HoL blocking in tail execution and worsens latency trade-offs between running and waiting relQueries. To address these problems, we propose RelServe, an optimized LLM engine for low-latency relQuery serving. RelServe features two core innovations: a Dynamic Priority Updater that continuously adjusts priorities while minimizing overhead via statistical approximations, and an Adaptive Batch Arranger that quantitatively evaluates candidate prefill and decode batches to minimize projected average latency. Extensive experiments on four real-world datasets using LLMs ranging from 13B to 70B parameters show that RelServe reduces average serving latency by up to 3.1x compared to vLLM.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [3] [BookReconciler: An Open-Source Tool for Metadata Enrichment and Work-Level Clustering](https://arxiv.org/abs/2512.10165)
*Matt Miller,Dan Sinykin,Melanie Walsh*

Main category: cs.DL

TL;DR: BookReconciler是一个开源工具，用于增强和聚类图书数据，通过添加ISBN等标识符并聚类同一作品的不同版本，从而方便大规模分析和集合相关图书。该工具作为OpenRefine的扩展，连接多个文献服务，并允许用户通过交互界面手动评估匹配和定义作品的范围。BookReconciler在处理美国图书数据时准确率接近完美，但在处理全球文学数据时准确率较低，这反映了非英语和全球文学在文献基础设施方面的结构性弱点。该工具支持跨领域和应用的文献数据重用，为数字图书馆和数字人文领域做出贡献。


<details>
  <summary>Details</summary>
Motivation: 自动增强和聚类图书元数据，以实现大规模分析和集合相关图书。

Method: BookReconciler作为OpenRefine的扩展，连接到主要的文献服务（如国会图书馆、VIAF、OCLC、HathiTrust、Google图书和Wikidata），自动添加ISBN等持久标识符，并聚类同一作品的不同表达形式（如不同翻译或版本）。该工具通过交互界面支持用户手动评估匹配并定义作品的范围。

Result: BookReconciler在处理美国获奖图书和当代世界小说的数据集时，对美国图书数据实现了近乎完美的准确率，但对全球文学数据的处理准确率较低，这反映了非英语和全球文学在文献基础设施方面的结构性弱点。

Conclusion: BookReconciler通过自动增强和聚类图书数据，支持文献数据的重用，促进了数字图书馆和数字人文领域的工作。尽管在处理全球文学数据方面存在挑战，但该工具仍能有效改善图书数据的可用性和分析能力。

Abstract: We present BookReconciler, an open-source tool for enhancing and clustering book data. BookReconciler allows users to take spreadsheets with minimal metadata, such as book title and author, and automatically 1) add authoritative, persistent identifiers like ISBNs 2) and cluster related Expressions and Manifestations of the same Work, e.g., different translations or editions. This enhancement makes it easier to combine related collections and analyze books at scale. The tool is currently designed as an extension for OpenRefine -- a popular software application -- and connects to major bibliographic services including the Library of Congress, VIAF, OCLC, HathiTrust, Google Books, and Wikidata. Our approach prioritizes human judgment. Through an interactive interface, users can manually evaluate matches and define the contours of a Work (e.g., to include translations or not). We evaluate reconciliation performance on datasets of U.S. prize-winning books and contemporary world fiction. BookReconciler achieves near-perfect accuracy for U.S. works but lower performance for global texts, reflecting structural weaknesses in bibliographic infrastructures for non-English and global literature. Overall, BookReconciler supports the reuse of bibliographic data across domains and applications, contributing to ongoing work in digital libraries and digital humanities.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [4] [The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows](https://arxiv.org/abs/2509.26557)
*Litao Yan,Andrew Head,Ken Milne,Vu Le,Sumit Gulwani,Chris Parnin,Emerson Murphy-Hill*

Main category: cs.HC

TL;DR: InvisibleMentor通过分析屏幕录制来识别Excel等工具中的低效工作流程，并提供基于行为的替代建议，优于基于提示的助手。


<details>
  <summary>Details</summary>
Motivation: 现有AI助手需要用户主动描述问题，存在费力且不精确的问题。而用户在功能丰富的工具中，常常无法注意到更高效的工作流程。

Method: InvisibleMentor将屏幕录制转化为对任务的视觉化反思。它利用两阶段流程：首先，视觉-语言模型重建操作和上下文；然后，语言模型生成结构化、高保真的建议。该系统直接在屏幕录制上运行，不依赖日志、API或用户提示。

Result: InvisibleMentor能够准确识别低效工作流程。在评估中，参与者认为其建议比基于提示的电子表格助手更具可操作性、更具针对性，并且更有助于学习和改进。

Conclusion: InvisibleMentor能够有效识别低效工作流程，并提供比现有方法更优的改进建议，尤其在用户难以主动发现更优操作时，其优势更为明显。

Abstract: Many users struggle to notice when a more efficient workflow exists in feature-rich tools like Excel. Existing AI assistants offer help only after users describe their goals or problems, which can be effortful and imprecise. We present InvisibleMentor, a system that turns screen recordings of task completion into vision-grounded reflections on tasks. It detects issues such as repetitive edits and recommends more efficient alternatives based on observed behavior. Unlike prior systems that rely on logs, APIs, or user prompts, InvisibleMentor operates directly on screen recordings. It uses a two-stage pipeline: a vision-language model reconstructs actions and context, and a language model generates structured, high-fidelity suggestions. In evaluation, InvisibleMentor accurately identified inefficient workflows, and participants found its suggestions more actionable, tailored, and more helpful for learning and improvement compared to a prompt-based spreadsheet assistant.

</details>
