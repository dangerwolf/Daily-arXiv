{"id": "2506.05587", "title": "MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark", "url": "https://arxiv.org/abs/2506.05587", "pdf": "https://arxiv.org/pdf/2506.05587", "abs": "https://arxiv.org/abs/2506.05587", "authors": ["Junjie Xing", "Yeye He", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Lingjiao Chen", "Dongmei Zhang", "Surajit Chaudhuri", "H. V. Jagadish"], "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "comment": "Accepted at NeurIPS 2025; Code and data available at https://github.com/MMTU-Benchmark/MMTU and https://huggingface.co/datasets/MMTU-benchmark/MMTU", "summary": "Tables and table-based use cases play a crucial role in many important real-world applications, such as spreadsheets, databases, and computational notebooks, which traditionally require expert-level users like data engineers, data analysts, and database administrators to operate. Although LLMs have shown remarkable progress in working with tables (e.g., in spreadsheet and database copilot scenarios), comprehensive benchmarking of such capabilities remains limited. In contrast to an extensive and growing list of NLP benchmarks, evaluations of table-related tasks are scarce, and narrowly focus on tasks like NL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks that professional users face. This gap limits our understanding and model progress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 28K questions across 25 real-world table tasks, designed to comprehensively evaluate models ability to understand, reason, and manipulate real tables at the expert-level. These tasks are drawn from decades' worth of computer science research on tabular data, with a focus on complex table tasks faced by professional users. We show that MMTU require a combination of skills -- including table understanding, reasoning, and coding -- that remain challenging for today's frontier models, where even frontier reasoning models like OpenAI GPT-5 and DeepSeek R1 score only around 69\\% and 57\\% respectively, suggesting significant room for improvement. We highlight key findings in our evaluation using MMTU and hope that this benchmark drives further advances in understanding and developing foundation models for structured data processing and analysis.\n  Our code and data are available at https://github.com/MMTU-Benchmark/MMTU and https://huggingface.co/datasets/MMTU-benchmark/MMTU.", "AI": {"tldr": "MMTU: A new benchmark for evaluating LLMs on real-world table tasks.", "motivation": "Existing benchmarks for table-related tasks are limited, failing to capture the complexity of real-world tasks faced by expert users.", "method": "Introduces MMTU, a large-scale benchmark with 28K questions across 25 real-world table tasks.", "result": "Even frontier models like GPT-5 and DeepSeek R1 score only around 69% and 57% respectively on MMTU, indicating significant room for improvement.", "conclusion": "MMTU highlights the challenges LLMs face in understanding and manipulating real tables and aims to drive further advances in this area."}}
{"id": "2511.06973", "title": "Oh That Looks Familiar: A Novel Similarity Measure for Spreadsheet Template Discovery", "url": "https://arxiv.org/abs/2511.06973", "pdf": "https://arxiv.org/pdf/2511.06973", "abs": "https://arxiv.org/abs/2511.06973", "authors": ["Anand Krishnakumar", "Vengadesh Ravikumaran"], "categories": ["cs.LG", "cs.CV"], "comment": "5 pages, 2 figures, Accepted to EurIPS'25: AI for Tabular Data Workshop", "summary": "Traditional methods for identifying structurally similar spreadsheets fail to capture the spatial layouts and type patterns defining templates. To quantify spreadsheet similarity, we introduce a hybrid distance metric that combines semantic embeddings, data type information, and spatial positioning. In order to calculate spreadsheet similarity, our method converts spreadsheets into cell-level embeddings and then uses aggregation techniques like Chamfer and Hausdorff distances. Experiments across template families demonstrate superior unsupervised clustering performance compared to the graph-based Mondrian baseline, achieving perfect template reconstruction (Adjusted Rand Index of 1.00 versus 0.90) on the FUSTE dataset. Our approach facilitates large-scale automated template discovery, which in turn enables downstream applications such as retrieval-augmented generation over tabular collections, model training, and bulk data cleaning.", "AI": {"tldr": "This paper introduces a new method for identifying structurally similar spreadsheets by considering spatial layouts and type patterns, outperforming existing methods.", "motivation": "Traditional methods fail to capture spatial layouts and type patterns in spreadsheets.", "method": "The method converts spreadsheets into cell-level embeddings and uses Chamfer and Hausdorff distances to quantify similarity.", "result": "The method achieves superior unsupervised clustering performance, with a perfect Adjusted Rand Index of 1.00 on the FUSTE dataset.", "conclusion": "The approach enables large-scale automated template discovery and facilitates downstream applications like retrieval-augmented generation, model training, and bulk data cleaning."}}
{"id": "2507.13558", "title": "Why Isn't Relational Learning Taking Over the World?", "url": "https://arxiv.org/abs/2507.13558", "pdf": "https://arxiv.org/pdf/2507.13558", "abs": "https://arxiv.org/abs/2507.13558", "authors": ["David Poole"], "categories": ["cs.AI", "cs.DB", "cs.LG"], "comment": "10 pages (6 pages + references + appendices). To appear AAAI-2026", "summary": "Artificial intelligence seems to be taking over the world with systems that model pixels, words, and phonemes. The world is arguably made up, not of pixels, words, and phonemes but of entities (objects, things, including events) with properties and relations among them. Surely we should model these, not the perception or description of them. You might suspect that concentrating on modeling words and pixels is because all of the (valuable) data in the world is in terms of text and images. If you look into almost any company you will find their most valuable data is in spreadsheets, databases and other relational formats. These are not the form that are studied in introductory machine learning, but are full of product numbers, student numbers, transaction numbers and other identifiers that can't be interpreted naively as numbers. The field that studies this sort of data has various names including relational learning, statistical relational AI, and many others. This paper explains why relational learning is not taking over the world -- except in a few cases with restricted relations -- and what needs to be done to bring it to it's rightful prominence.", "AI": {"tldr": "This paper discusses why relational learning has not become more prominent in the field of AI, despite the prevalence of relational data in real-world applications.", "motivation": "The motivation is to address the discrepancy between the focus on modeling pixels, words, and phonemes in AI, and the abundance of relational data (entities, properties, and relations) in valuable datasets.", "method": "The paper explains the reasons behind the limited adoption of relational learning and suggests what needs to be done to increase its prominence.", "result": "The paper identifies the factors hindering the widespread use of relational learning.", "conclusion": "The paper concludes by outlining the steps required to bring relational learning to its rightful prominence in the AI field."}}
{"id": "2209.14457", "title": "Consensus-Free Spreadsheet Integration", "url": "https://arxiv.org/abs/2209.14457", "pdf": "https://arxiv.org/pdf/2209.14457", "abs": "https://arxiv.org/abs/2209.14457", "authors": ["Brandon Baylor", "Eric Daimler", "James Hansen", "Esteban Montero", "Ryan Wisnesky"], "categories": ["cs.DB", "cs.SE"], "comment": null, "summary": "We describe a method for merging multiple spreadsheets into one sheet, and/or exchanging data among the sheets, by expressing each sheet's formulae as an algebraic (equational) theory and each sheet's values as a model of its theory, expressing the overlap between the sheets as theory and model morphisms, and then performing colimit, lifting, and Kan-extension constructions from category theory to compute a canonically universal integrated theory and model, which can then be expressed as a spreadsheet. Our motivation is to find methods of merging engineering models that do not require consensus (agreement) among the authors of the models being merged, a condition fulfilled by our method because theory and model morphisms are semantics-preserving. We describe a case study of this methodology on a real-world oil and gas calculation at a major energy company, describing the theories and models that arise when integrating two different casing pressure test (MASP) calculation spreadsheets constructed by two non-interacting engineers. We also describe the automated theorem proving burden associated with both verifying the semantics preservation of the overlap mappings as well as verifying the conservativity/consistency of the resulting integrated sheet. We conclude with thoughts on how to apply the methodology to scale engineering efforts across the enterprise.", "AI": {"tldr": "This paper introduces a method for merging spreadsheets by using category theory to represent spreadsheets as algebraic theories and models, and then integrating them using colimit, lifting, and Kan-extension.", "motivation": "The motivation is to merge engineering models without requiring consensus among the authors.", "method": "The method involves expressing each sheet's formulae as an algebraic theory and each sheet's values as a model, expressing the overlap between the sheets as theory and model morphisms, and then performing colimit, lifting, and Kan-extension constructions from category theory.", "result": "A case study was conducted on a real-world oil and gas calculation at a major energy company, integrating two different casing pressure test calculation spreadsheets.", "conclusion": "The paper concludes with thoughts on how to apply the methodology to scale engineering efforts across the enterprise."}}
{"id": "2503.12345", "title": "General Table Question Answering via Answer-Formula Joint Generation", "url": "https://arxiv.org/abs/2503.12345", "pdf": "https://arxiv.org/pdf/2503.12345", "abs": "https://arxiv.org/abs/2503.12345", "authors": ["Zhongyuan Wang", "Richong Zhang", "Zhijie Nie", "Hangyu Mao"], "categories": ["cs.CL", "cs.AI"], "comment": "work in progress", "summary": "Advanced table question answering (TableQA) methods prompt large language models (LLMs) to generate answer text, SQL query, Python code, or custom operation, which impressively improve the complex reasoning problems in the TableQA task. However, these methods lack the versatility to cope with specific question types or table structures. In contrast, the Spreadsheet Formula, the widely used and well-defined operation language for tabular data, has not been thoroughly explored to solve TableQA. In this paper, we first attempt to use the Formula as the executable representation for solving complex reasoning on tables with different structures. Specifically, we construct \\texttt{FromulaQA}, a large Formula-annotated TableQA dataset from existing datasets. In addition, we propose \\texttt{TabAF}, a general table answering framework to solve multiple types of tasks over multiple types of tables simultaneously, which decodes answers and Formulas with a single LLM backbone. Extensive experiments demonstrate the versatility and generalization of \\texttt{TabAF}. Under the same model size, \\texttt{TabAF} achieves new state-of-the-art performance on the WikiTableQuestion, HiTab, and TabFact.", "AI": {"tldr": "This paper introduces FormulaQA, a new TableQA dataset, and TabAF, a general table answering framework that uses spreadsheet formulas as an executable representation for complex reasoning on tables. TabAF achieves state-of-the-art performance on multiple TableQA datasets.", "motivation": "Existing TableQA methods lack versatility in handling specific question types or table structures. Spreadsheet formulas, a well-defined operation language for tabular data, have not been thoroughly explored.", "method": "The authors construct FormulaQA, a large Formula-annotated TableQA dataset. They also propose TabAF, a table answering framework that decodes answers and Formulas with a single LLM backbone.", "result": "TabAF achieves new state-of-the-art performance on WikiTableQuestion, HiTab, and TabFact datasets.", "conclusion": "The versatility and generalization of TabAF are demonstrated through extensive experiments."}}
{"id": "2502.09787", "title": "TableTalk: Scaffolding Spreadsheet Development with a Language Agent", "url": "https://arxiv.org/abs/2502.09787", "pdf": "https://arxiv.org/pdf/2502.09787", "abs": "https://arxiv.org/abs/2502.09787", "authors": ["Jenny T. Liang", "Aayush Kumar", "Yasharth Bajpai", "Sumit Gulwani", "Vu Le", "Chris Parnin", "Arjun Radhakrishna", "Ashish Tiwari", "Emerson Murphy-Hill", "Guastavo Soares"], "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": null, "summary": "Spreadsheet programming is challenging. Programmers use spreadsheet programming knowledge (e.g., formulas) and problem-solving skills to combine actions into complex tasks. Advancements in large language models have introduced language agents that observe, plan, and perform tasks, showing promise for spreadsheet creation. We present TableTalk, a spreadsheet programming agent embodying three design principles -- scaffolding, flexibility, and incrementality -- derived from studies with seven spreadsheet programmers and 85 Excel templates. TableTalk guides programmers through structured plans based on professional workflows, generating three potential next steps to adapt plans to programmer needs. It uses pre-defined tools to generate spreadsheet components and incrementally build spreadsheets. In a study with 20 programmers, TableTalk produced higher-quality spreadsheets 2.3 times more likely to be preferred than the baseline. It reduced cognitive load and thinking time by 12.6%. From this, we derive design guidelines for agentic spreadsheet programming tools and discuss implications on spreadsheet programming, end-user programming, AI-assisted programming, and human-agent collaboration.", "AI": {"tldr": "This paper introduces TableTalk, a spreadsheet programming agent designed with scaffolding, flexibility, and incrementality in mind, which assists programmers in creating higher-quality spreadsheets with reduced cognitive load.", "motivation": "The motivation is to address the challenges of spreadsheet programming by leveraging advancements in large language models to create intelligent agents that can assist programmers.", "method": "The method involves designing TableTalk with three key principles: scaffolding, flexibility, and incrementality. It guides programmers through structured plans, offers multiple next steps, and uses pre-defined tools to generate spreadsheet components incrementally.", "result": "TableTalk produced higher-quality spreadsheets 2.3 times more likely to be preferred than the baseline and reduced cognitive load and thinking time by 12.6% in a study with 20 programmers.", "conclusion": "The paper derives design guidelines for agentic spreadsheet programming tools and discusses implications on spreadsheet programming, end-user programming, AI-assisted programming, and human-agent collaboration based on the results of the TableTalk experiment."}}
{"id": "2507.22391", "title": "Knowledge engineering for open science: Building and deploying knowledge bases for metadata standards", "url": "https://arxiv.org/abs/2507.22391", "pdf": "https://arxiv.org/pdf/2507.22391", "abs": "https://arxiv.org/abs/2507.22391", "authors": ["Mark A. Musen", "Martin J. O'Connor", "Josef Hardi", "Marcos Martinez-Romero"], "categories": ["cs.DL"], "comment": "22 pages, 7 figures", "summary": "Scientists strive to make their datasets available in open repositories, with the goal that they be findable, accessible, interoperable, and reusable (FAIR). Although it is hard for most investigators to remember all the guiding principles associated with FAIR data, there is one overarching requirement: The data need to be annotated with rich, discipline-specific, standardized metadata. The Center for Expanded Data Annotation and Retrieval (CEDAR) builds technology that enables scientists to encode metadata standards as templates that enumerate the attributes of different kinds of experiments. These metadata templates capture preferences regarding how data should be described and what a third party needs to know to make sense of the datasets. CEDAR templates describing community metadata preferences have been used to standardize metadata for a variety of scientific consortia. They have been used as the basis for data-annotation systems that acquire metadata through Web forms or through spreadsheets, and they can help correct metadata to ensure adherence to standards. Like the declarative knowledge bases that underpinned intelligent systems decades ago, CEDAR templates capture the knowledge in symbolic form, and they allow that knowledge to be applied in a variety of settings. They provide a mechanism for scientific communities to create shared metadata standards and to encode their preferences for the application of those standards, and for deploying those standards in a range of intelligent systems to promote open science.", "AI": {"tldr": "CEDAR builds technology that enables scientists to encode metadata standards as templates", "motivation": "Scientists strive to make their datasets available in open repositories, with the goal that they be findable, accessible, interoperable, and reusable (FAIR).", "method": "CEDAR templates describing community metadata preferences have been used to standardize metadata for a variety of scientific consortia. They have been used as the basis for data-annotation systems that acquire metadata through Web forms or through spreadsheets, and they can help correct metadata to ensure adherence to standards.", "result": "They provide a mechanism for scientific communities to create shared metadata standards and to encode their preferences for the application of those standards", "conclusion": "CEDAR templates capture the knowledge in symbolic form, and they allow that knowledge to be applied in a variety of settings to promote open science."}}
{"id": "2408.08068", "title": "The Paradox of Spreadsheet Self-Efficacy: Social Incentives for Informal Knowledge Sharing in End-User Programming", "url": "https://arxiv.org/abs/2408.08068", "pdf": "https://arxiv.org/pdf/2408.08068", "abs": "https://arxiv.org/abs/2408.08068", "authors": ["Qing", "Xia", "Advait Sarkar", "Duncan P. Brumby", "Anna Cox"], "categories": ["cs.HC"], "comment": "8 pages", "summary": "Informal Knowledge Sharing (KS) is vital for end-user programmers to gain expertise. To better understand how personal (self-efficacy), social (reputational gains, trust between colleagues), and software-related (codification effort) variables influence spreadsheet KS intention, we conducted a multiple regressions analysis based on survey data from spreadsheet users (n=100) in administrative and finance roles. We found that high levels of spreadsheet self-efficacy and a perception that sharing would result in reputational gains predicted higher KS intention, but individuals who found knowledge codification effortful showed lower KS intention. We also observed that regardless of occupation, users tended to report a lower sense of self-efficacy in their general spreadsheet proficiency, despite also reporting high self-efficacy in spreadsheet use for job-related contexts. Our findings suggest that acknowledging and designing for these social and personal variables can help avoid situations where experienced individuals refrain unnecessarily from sharing, with implications for spreadsheet design.", "AI": {"tldr": "This study investigates the factors influencing knowledge sharing (KS) intention among spreadsheet users.", "motivation": "To understand how personal, social, and software-related variables impact spreadsheet KS intention.", "method": "Multiple regressions analysis based on survey data from 100 spreadsheet users.", "result": "Spreadsheet self-efficacy and reputational gains positively predict KS intention, while knowledge codification effort has a negative impact. Users reported lower general spreadsheet self-efficacy.", "conclusion": "Acknowledging social and personal variables can encourage knowledge sharing and has implications for spreadsheet design."}}
{"id": "2409.05735", "title": "A System and Benchmark for LLM-based Q&A on Heterogeneous Data", "url": "https://arxiv.org/abs/2409.05735", "pdf": "https://arxiv.org/pdf/2409.05735", "abs": "https://arxiv.org/abs/2409.05735", "authors": ["Achille Fokoue", "Srideepika Jayaraman", "Elham Khabiri", "Jeffrey O. Kephart", "Yingjie Li", "Dhruv Shah", "Youssef Drissi", "Fenno F. Heath", "Anu Bhamidipaty", "Fateh A. Tipu", "Robert J. Baseman"], "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "In many industrial settings, users wish to ask questions whose answers may be found in structured data sources such as a spreadsheets, databases, APIs, or combinations thereof. Often, the user doesn't know how to identify or access the right data source. This problem is compounded even further if multiple (and potentially siloed) data sources must be assembled to derive the answer. Recently, various Text-to-SQL applications that leverage Large Language Models (LLMs) have addressed some of these problems by enabling users to ask questions in natural language. However, these applications remain impractical in realistic industrial settings because they fail to cope with the data source heterogeneity that typifies such environments. In this paper, we address heterogeneity by introducing the siwarex platform, which enables seamless natural language access to both databases and APIs. To demonstrate the effectiveness of siwarex, we extend the popular Spider dataset and benchmark by replacing some of its tables by data retrieval APIs. We find that siwarex does a good job of coping with data source heterogeneity. Our modified Spider benchmark will soon be available to the research community", "AI": {"tldr": "The paper introduces siwarex, a platform that enables natural language access to both databases and APIs, addressing data source heterogeneity in industrial settings.", "motivation": "Existing Text-to-SQL applications using LLMs are impractical in industrial settings due to their failure to cope with data source heterogeneity.", "method": "The authors introduce the siwarex platform and extend the Spider dataset by replacing some tables with data retrieval APIs.", "result": "siwarex effectively copes with data source heterogeneity.", "conclusion": "The siwarex platform demonstrates good performance in handling data source heterogeneity, and the modified Spider benchmark will be made available for research."}}
{"id": "2409.01517", "title": "Auditable and reusable crosswalks for fast, scaled integration of scattered tabular data", "url": "https://arxiv.org/abs/2409.01517", "pdf": "https://arxiv.org/pdf/2409.01517", "abs": "https://arxiv.org/abs/2409.01517", "authors": ["Gavin Chait"], "categories": ["cs.DB"], "comment": "14 pages, 12 colour figures", "summary": "This paper presents an open-source curatorial toolkit intended to produce well-structured and interoperable data. Curation is divided into discrete components, with a schema-centric focus for auditable restructuring of complex and scattered tabular data to conform to a destination schema. Task separation allows development of software and analysis without source data being present. Transformations are captured as high-level sequential scripts describing schema-to-schema mappings, reducing complexity and resource requirements. Ultimately, data are transformed, but the objective is that any data meeting a schema definition can be restructured using a crosswalk. The toolkit is available both as a Python package, and as a 'no-code' visual web application. A visual example is presented, derived from a longitudinal study where scattered source data from hundreds of local councils are integrated into a single database.", "AI": {"tldr": "This paper introduces an open-source curatorial toolkit for producing well-structured and interoperable data by restructuring complex tabular data to conform to a destination schema.", "motivation": "The motivation is to provide a tool for auditable restructuring of complex and scattered tabular data, enabling software and analysis development without needing source data.", "method": "The method involves dividing curation into discrete components with a schema-centric focus and capturing transformations as high-level sequential scripts describing schema-to-schema mappings. The toolkit is available as a Python package and a visual web application.", "result": "The result is a toolkit that transforms data, allowing any data meeting a schema definition to be restructured using a crosswalk.", "conclusion": "The conclusion is demonstrated through a visual example derived from a longitudinal study integrating scattered source data from hundreds of local councils into a single database."}}
{"id": "2409.12976", "title": "Excel: Automated Ledger or Analytics IDE?", "url": "https://arxiv.org/abs/2409.12976", "pdf": "https://arxiv.org/pdf/2409.12976", "abs": "https://arxiv.org/abs/2409.12976", "authors": ["Andrew Kumiega"], "categories": ["cs.CY"], "comment": "9 pages, one table", "summary": "Since the inception of VisiCalc over four decades ago, spreadsheets have undergone a gradual transformation, evolving from simple ledger automation tools to the current state of Excel, which can be described as an Integrated Development Environment (IDE) for analytics. The slow evolution of Excel from an automation tool for ledgers to an IDE for analytics explains why many people have not noticed that Excel includes a fully functional database, an OLAP Engine, multiple statistical programming languages, multiple third-party software libraries, dynamic charts, and real time data connectors. The simplicity of accessing these multiple tools is a low-code framework controlled from the Excel tool that is effectively an IDE. Once we acknowledge Excel's shift from a desk top application to an IDE for analytics, the importance of establishing a comprehensive risk framework for managing this distinctive development environment becomes clear. In this paper we will explain how the current risk framework for spreadsheets needs to be expanded to manage the growing risks of using Excel as an IDE for analytics.", "AI": {"tldr": "Excel has evolved into an Integrated Development Environment (IDE) for analytics.", "motivation": "The evolution of Excel has led to it becoming a powerful analytics tool, but many users are unaware of its capabilities.", "method": "Explain how the current risk framework for spreadsheets needs to be expanded.", "result": "The paper will explain how to expand the current risk framework.", "conclusion": "The importance of establishing a comprehensive risk framework for managing Excel as an IDE for analytics is clear."}}
{"id": "2409.12975", "title": "Subject integration with spreadsheets -- Ignoring education is the greatest risk ever", "url": "https://arxiv.org/abs/2409.12975", "pdf": "https://arxiv.org/pdf/2409.12975", "abs": "https://arxiv.org/abs/2409.12975", "authors": ["M\u00e1ria Csernoch", "\u00c1d\u00e1m Gul\u00e1csi", "J\u00falia Csernoch"], "categories": ["cs.HC"], "comment": "16 pages, 17 colour figures. Proceedings of the EuSpRIG 2024 Conference 'Spreadsheet Productivity & Risks' ISBN : 978-1-905404-59-9", "summary": "Within the framework of Technological Pedagogical and Content Knowledge, subject integration is one possible solution for the introduction of meaningful digitalization and digitization in schools. This process incorporates that any school subject can be taught with digital support, informatics (computer) classes can be contextualized, and the gap between 'serious informatics' and 'digital literacy' can be minimized. The present paper details how three traditional Grade 3 tasks can be solved in spreadsheets, what skills, competencies, and computer science knowledge of both teachers and students can be developed. The solutions also reveal that analysing, understanding, planning, and discussing tasks is as important as the activity in the spreadsheets, which process plays a crucial role in the preparation of students for their future jobs.", "AI": {"tldr": "Subject integration using spreadsheets in Grade 3 can enhance digitalization and bridge the gap between informatics and digital literacy.", "motivation": "Introduce meaningful digitalization in schools via subject integration.", "method": "Solving three traditional Grade 3 tasks using spreadsheets.", "result": "Identified skills, competencies, and computer science knowledge developed in teachers and students.", "conclusion": "Analyzing, understanding, planning, and discussing tasks in spreadsheets is crucial for preparing students for future jobs."}}
{"id": "2405.16234", "title": "Vision Language Models for Spreadsheet Understanding: Challenges and Opportunities", "url": "https://arxiv.org/abs/2405.16234", "pdf": "https://arxiv.org/pdf/2405.16234", "abs": "https://arxiv.org/abs/2405.16234", "authors": ["Shiyu Xia", "Junyu Xiong", "Haoyu Dong", "Jianbo Zhao", "Yuzhang Tian", "Mengyu Zhou", "Yeye He", "Shi Han", "Dongmei Zhang"], "categories": ["cs.CV"], "comment": null, "summary": "This paper explores capabilities of Vision Language Models on spreadsheet comprehension. We propose three self-supervised challenges with corresponding evaluation metrics to comprehensively evaluate VLMs on Optical Character Recognition (OCR), spatial perception, and visual format recognition. Additionally, we utilize the spreadsheet table detection task to assess the overall performance of VLMs by integrating these challenges. To probe VLMs more finely, we propose three spreadsheet-to-image settings: column width adjustment, style change, and address augmentation. We propose variants of prompts to address the above tasks in different settings. Notably, to leverage the strengths of VLMs in understanding text rather than two-dimensional positioning, we propose to decode cell values on the four boundaries of the table in spreadsheet boundary detection. Our findings reveal that VLMs demonstrate promising OCR capabilities but produce unsatisfactory results due to cell omission and misalignment, and they notably exhibit insufficient spatial and format recognition skills, motivating future work to enhance VLMs' spreadsheet data comprehension capabilities using our methods to generate extensive spreadsheet-image pairs in various settings.", "AI": {"tldr": "This paper evaluates Vision Language Models (VLMs) on spreadsheet comprehension using self-supervised challenges and a spreadsheet table detection task.", "motivation": "To assess VLMs' capabilities in Optical Character Recognition (OCR), spatial perception, and visual format recognition within spreadsheets.", "method": "Proposes three self-supervised challenges with evaluation metrics, spreadsheet-to-image settings (column width adjustment, style change, address augmentation), and variants of prompts. Decodes cell values on table boundaries for spreadsheet boundary detection.", "result": "VLMs show promise in OCR but struggle with cell omission, misalignment, and insufficient spatial and format recognition.", "conclusion": "The study highlights the need to enhance VLMs' spreadsheet data comprehension, suggesting future work using the proposed methods to generate more spreadsheet-image pairs."}}
{"id": "2408.03841", "title": "MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models", "url": "https://arxiv.org/abs/2408.03841", "pdf": "https://arxiv.org/pdf/2408.03841", "abs": "https://arxiv.org/abs/2408.03841", "authors": ["Yuchen Dong", "XiaoXiang Fang", "Yuchen Hu", "Renshuang Jiang", "Zhe Jiang"], "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The application of large language models to facilitate automated software operations and tool generation (SOTG), thus augmenting software productivity, mirrors the early stages of human evolution when the ability to create and use tools accelerated the progress of civilization. These complex tasks require AI to continuously summarize and improve. Current research often overlooks the importance of converting real-time task experiences into system memory and differentiating the value of existing knowledge for future reference. This paper addresses these issues by evolving external memory models into Memory-Loop Networks for timely memorization and experience referencing. We also enhance a RAG mechanism with knowledge precision segmentation to utilize memory based on value differentiation, and design the MaxMind model for SOTG accordingly.To demonstrate our approach, we developed MaxMind4Sheet, an electronic spreadsheet processing system aligned with the MaxMind philosophy. Comparative experiments with SheetCopilot have demonstrated that the accumulation and recycling of task memories lead to a steady enhancement in task success rate, with an improvement rate of approximately 3%-6% per round in this implementation example. Note that as the memories continue to grow, this cumulative improvement may be substantial. The inclusion of memory recycling can also boost the system's task execution efficiency by up to 25%, and it can address the retraining issue faced by LLMs when handling specialized tasks through memories transfer.These suggest that MaxMind has significant potential to enhance the capabilities and productivity of LLM systems in SOTG.", "AI": {"tldr": "This paper introduces Memory-Loop Networks and a knowledge precision segmentation-enhanced RAG mechanism to improve the performance of large language models in automated software operations and tool generation (SOTG).", "motivation": "Current research overlooks converting real-time task experiences into system memory and differentiating the value of existing knowledge for future reference in SOTG tasks.", "method": "The paper evolves external memory models into Memory-Loop Networks and enhances a RAG mechanism with knowledge precision segmentation. It designs the MaxMind model for SOTG.", "result": "Experiments with MaxMind4Sheet show a 3%-6% improvement in task success rate per round and a 25% boost in task execution efficiency due to memory recycling.", "conclusion": "MaxMind has significant potential to enhance the capabilities and productivity of LLM systems in SOTG by accumulating and recycling task memories and addressing the retraining issue faced by LLMs when handling specialized tasks through memories transfer."}}
{"id": "2408.01805", "title": "Billion-files File Systems (BfFS): A Comparison", "url": "https://arxiv.org/abs/2408.01805", "pdf": "https://arxiv.org/pdf/2408.01805", "abs": "https://arxiv.org/abs/2408.01805", "authors": ["Sohail Shaikh"], "categories": ["cs.PF"], "comment": "Paper is 9 pages. Source code is open and uploaded to Git, along with an Excel spreadsheet used for analysis", "summary": "As the volume of data being produced is increasing at an exponential rate that needs to be processed quickly, it is reasonable that the data needs to be available very close to the compute devices to reduce transfer latency. Due to this need, local filesystems are getting close attention to understand their inner workings, performance, and more importantly their limitations. This study analyzes few popular Linux filesystems: EXT4, XFS, BtrFS, ZFS, and F2FS by creating, storing, and then reading back one billion files from the local filesystem. The study also captured and analyzed read/write throughput, storage blocks usage, disk space utilization and overheads, and other metrics useful for system designers and integrators. Furthermore, the study explored other side effects such as filesystem performance degradation during and after these large numbers of files and folders are created.", "AI": {"tldr": "\u5206\u6790\u4e86\u591a\u79cd Linux \u6587\u4ef6\u7cfb\u7edf\u5728\u5904\u7406\u5927\u91cf\u6587\u4ef6\u65f6\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u6570\u636e\u91cf\u7206\u70b8\u5f0f\u589e\u957f\u4ee5\u53ca\u5bf9\u5feb\u901f\u5904\u7406\u7684\u9700\u6c42\uff0c\u7814\u7a76\u672c\u5730\u6587\u4ef6\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u5c40\u9650\u6027\u53d8\u5f97\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5728 EXT4, XFS, BtrFS, ZFS \u548c F2FS \u6587\u4ef6\u7cfb\u7edf\u4e0a\u521b\u5efa\u3001\u5b58\u50a8\u548c\u8bfb\u53d6\u5341\u4ebf\u4e2a\u6587\u4ef6\u6765\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u6355\u6349\u5e76\u5206\u6790\u4e86\u8bfb/\u5199\u541e\u5410\u91cf\u3001\u5b58\u50a8\u5757\u4f7f\u7528\u60c5\u51b5\u3001\u78c1\u76d8\u7a7a\u95f4\u5229\u7528\u7387\u548c\u5f00\u9500\u7b49\u6307\u6807\uff0c\u4ee5\u53ca\u6587\u4ef6\u7cfb\u7edf\u6027\u80fd\u4e0b\u964d\u7b49\u526f\u4f5c\u7528\u3002", "conclusion": "\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u8005\u548c\u96c6\u6210\u8005\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u53c2\u8003\u4fe1\u606f\u3002"}}
{"id": "2407.14042", "title": "Data Guards: Challenges and Solutions for Fostering Trust in Data", "url": "https://arxiv.org/abs/2407.14042", "pdf": "https://arxiv.org/pdf/2407.14042", "abs": "https://arxiv.org/abs/2407.14042", "authors": ["Nicole Sultanum", "Dennis Bromley", "Michael Correll"], "categories": ["cs.HC"], "comment": "VIS 2024 Short paper - 5 pages", "summary": "From dirty data to intentional deception, there are many threats to the validity of data-driven decisions. Making use of data, especially new or unfamiliar data, therefore requires a degree of trust or verification. How is this trust established? In this paper, we present the results of a series of interviews with both producers and consumers of data artifacts (outputs of data ecosystems like spreadsheets, charts, and dashboards) aimed at understanding strategies and obstacles to building trust in data. We find a recurring need, but lack of existing standards, for data validation and verification, especially among data consumers. We therefore propose a set of data guards: methods and tools for fostering trust in data artifacts.", "AI": {"tldr": "This paper investigates how trust is established in data artifacts and proposes data guards to foster trust.", "motivation": "Threats to the validity of data-driven decisions necessitate trust and verification in data.", "method": "The study uses interviews with data producers and consumers to understand strategies and obstacles to building trust in data artifacts.", "result": "The study reveals a need for data validation and verification, especially among data consumers, but a lack of existing standards.", "conclusion": "The paper proposes a set of data guards: methods and tools for fostering trust in data artifacts."}}
{"id": "2407.06354", "title": "High-Throughput Phenotyping using Computer Vision and Machine Learning", "url": "https://arxiv.org/abs/2407.06354", "pdf": "https://arxiv.org/pdf/2407.06354", "abs": "https://arxiv.org/abs/2407.06354", "authors": ["Vivaan Singhvi", "Langalibalele Lunga", "Pragya Nidhi", "Chris Keum", "Varrun Prakash"], "categories": ["cs.CV"], "comment": "Presented for the Smoky Mountains Computational Sciences and Engineering Conference: Best Paper Award", "summary": "High-throughput phenotyping refers to the non-destructive and efficient evaluation of plant phenotypes. In recent years, it has been coupled with machine learning in order to improve the process of phenotyping plants by increasing efficiency in handling large datasets and developing methods for the extraction of specific traits. Previous studies have developed methods to advance these challenges through the application of deep neural networks in tandem with automated cameras; however, the datasets being studied often excluded physical labels. In this study, we used a dataset provided by Oak Ridge National Laboratory with 1,672 images of Populus Trichocarpa with white labels displaying treatment (control or drought), block, row, position, and genotype. Optical character recognition (OCR) was used to read these labels on the plants, image segmentation techniques in conjunction with machine learning algorithms were used for morphological classifications, machine learning models were used to predict treatment based on those classifications, and analyzed encoded EXIF tags were used for the purpose of finding leaf size and correlations between phenotypes. We found that our OCR model had an accuracy of 94.31% for non-null text extractions, allowing for the information to be accurately placed in a spreadsheet. Our classification models identified leaf shape, color, and level of brown splotches with an average accuracy of 62.82%, and plant treatment with an accuracy of 60.08%. Finally, we identified a few crucial pieces of information absent from the EXIF tags that prevented the assessment of the leaf size. There was also missing information that prevented the assessment of correlations between phenotypes and conditions. However, future studies could improve upon this to allow for the assessment of these features.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 429 - [{'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
{"id": "2405.05292", "title": "Smart Portable Computer", "url": "https://arxiv.org/abs/2405.05292", "pdf": "https://arxiv.org/pdf/2405.05292", "abs": "https://arxiv.org/abs/2405.05292", "authors": ["Niladri Das"], "categories": ["cs.HC", "cs.AI", "cs.RO"], "comment": "34 pages", "summary": "Amidst the COVID-19 pandemic, with many organizations, schools, colleges, and universities transitioning to virtual platforms, students encountered difficulties in acquiring PCs such as desktops or laptops. The starting prices, around 15,000 INR, often failed to offer adequate system specifications, posing a challenge for consumers. Additionally, those reliant on laptops for work found the conventional approach cumbersome. Enter the \"Portable Smart Computer,\" a leap into the future of computing. This innovative device boasts speed and performance comparable to traditional desktops but in a compact, energy-efficient, and cost-effective package. It delivers a seamless desktop experience, whether one is editing documents, browsing multiple tabs, managing spreadsheets, or creating presentations. Moreover, it supports programming languages like Python, C, C++, as well as compilers such as Keil and Xilinx, catering to the needs of programmers.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 429 - [{'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
{"id": "2404.12608", "title": "Auto-Formula: Recommend Formulas in Spreadsheets using Contrastive Learning for Table Representations", "url": "https://arxiv.org/abs/2404.12608", "pdf": "https://arxiv.org/pdf/2404.12608", "abs": "https://arxiv.org/abs/2404.12608", "authors": ["Sibei Chen", "Yeye He", "Weiwei Cui", "Ju Fan", "Song Ge", "Haidong Zhang", "Dongmei Zhang", "Surajit Chaudhuri"], "categories": ["cs.DB", "cs.CL", "cs.PL"], "comment": "full version of a paper to appear in SIGMOD 2024", "summary": "Spreadsheets are widely recognized as the most popular end-user programming tools, which blend the power of formula-based computation, with an intuitive table-based interface. Today, spreadsheets are used by billions of users to manipulate tables, most of whom are neither database experts nor professional programmers.\n  Despite the success of spreadsheets, authoring complex formulas remains challenging, as non-technical users need to look up and understand non-trivial formula syntax. To address this pain point, we leverage the observation that there is often an abundance of similar-looking spreadsheets in the same organization, which not only have similar data, but also share similar computation logic encoded as formulas. We develop an Auto-Formula system that can accurately predict formulas that users want to author in a target spreadsheet cell, by learning and adapting formulas that already exist in similar spreadsheets, using contrastive-learning techniques inspired by \"similar-face recognition\" from compute vision.\n  Extensive evaluations on over 2K test formulas extracted from real enterprise spreadsheets show the effectiveness of Auto-Formula over alternatives. Our benchmark data is available at https://github.com/microsoft/Auto-Formula to facilitate future research.", "AI": {"tldr": "This paper introduces Auto-Formula, a system that predicts spreadsheet formulas by learning from similar spreadsheets using contrastive learning.", "motivation": "Authoring complex formulas in spreadsheets is challenging for non-technical users.", "method": "The paper uses contrastive-learning techniques to learn and adapt formulas from similar spreadsheets.", "result": "Evaluations on 2K formulas show Auto-Formula's effectiveness.", "conclusion": "Auto-Formula effectively predicts formulas by learning from similar spreadsheets."}}
{"id": "2404.07114", "title": "\"My toxic trait is thinking I'll remember this\": gaps in the learner experience of video tutorials for feature-rich software", "url": "https://arxiv.org/abs/2404.07114", "pdf": "https://arxiv.org/pdf/2404.07114", "abs": "https://arxiv.org/abs/2404.07114", "authors": ["Ian Drosos", "Advait Sarkar", "Andrew D. Gordon"], "categories": ["cs.HC"], "comment": null, "summary": "Video tutorials are a popular medium for informal and formal learning. However, when learners attempt to view and follow along with these tutorials, they encounter what we call gaps, that is, issues that can prevent learning. We examine the gaps encountered by users of video tutorials for feature-rich software, such as spreadsheets. We develop a theory and taxonomy of such gaps, identifying how they act as barriers to learning, by collecting and analyzing 360 viewer comments from 90 Microsoft Excel video tutorials published by 43 creators across YouTube, TikTok, and Instagram. We conducted contextual interviews with 8 highly influential tutorial creators to investigate the gaps their viewers experience and how they address them. Further, we obtain insights into their creative process and frustrations when creating video tutorials. Finally, we present creators with two designs that aim to address gaps identified in the comment analysis for feedback and alternative design ideas.", "AI": {"tldr": "This paper identifies and categorizes common issues (gaps) encountered by learners using video tutorials for complex software like Excel.", "motivation": "To understand the barriers to learning in video tutorials for feature-rich software.", "method": "Collected and analyzed 360 viewer comments from 90 Excel tutorials on YouTube, TikTok, and Instagram. Conducted interviews with 8 tutorial creators. Presented creators with designs to address identified gaps.", "result": "Developed a theory and taxonomy of gaps that hinder learning.", "conclusion": "The study provides insights into the gaps learners face and offers potential design solutions to improve video tutorials."}}
{"id": "2402.11734", "title": "Solving Data-centric Tasks using Large Language Models", "url": "https://arxiv.org/abs/2402.11734", "pdf": "https://arxiv.org/pdf/2402.11734", "abs": "https://arxiv.org/abs/2402.11734", "authors": ["Shraddha Barke", "Christian Poelitz", "Carina Suzana Negreanu", "Benjamin Zorn", "Jos\u00e9 Cambronero", "Andrew D. Gordon", "Vu Le", "Elnaz Nouri", "Nadia Polikarpova", "Advait Sarkar", "Brian Slininger", "Neil Toronto", "Jack Williams"], "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": "Paper accepted to NAACL 2024 (Findings)", "summary": "Large language models (LLMs) are rapidly replacing help forums like StackOverflow, and are especially helpful for non-professional programmers and end users. These users are often interested in data-centric tasks, such as spreadsheet manipulation and data wrangling, which are hard to solve if the intent is only communicated using a natural-language description, without including the data. But how do we decide how much data and which data to include in the prompt? This paper makes two contributions towards answering this question. First, we create a dataset of real-world NL-to-code tasks manipulating tabular data, mined from StackOverflow posts. Second, we introduce a cluster-then-select prompting technique, which adds the most representative rows from the input data to the LLM prompt. Our experiments show that LLM performance is indeed sensitive to the amount of data passed in the prompt, and that for tasks with a lot of syntactic variation in the input table, our cluster-then-select technique outperforms a random selection baseline.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63d0\u793a\u9009\u62e9\u5408\u9002\u7684\u6570\u636e\uff0c\u4ee5\u63d0\u9ad8\u5176\u5728\u5904\u7406\u8868\u683c\u6570\u636e\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u975e\u4e13\u4e1a\u7a0b\u5e8f\u5458\u548c\u6700\u7ec8\u7528\u6237\u5728\u5904\u7406\u6570\u636e\u4efb\u52a1\u65f6\uff0c\u4ec5\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u96be\u4ee5\u4f20\u8fbe\u610f\u56fe\u7684\u95ee\u9898\u3002", "method": "1. \u521b\u5efa\u4e86\u4e00\u4e2a\u6765\u81ea StackOverflow \u5e16\u5b50\uff0c\u7528\u4e8e\u64cd\u4f5c\u8868\u683c\u6570\u636e\u7684 NL-to-code \u4efb\u52a1\u6570\u636e\u96c6\u30022. \u63d0\u51fa\u4e86\u4e00\u79cd cluster-then-select \u63d0\u793a\u6280\u672f\uff0c\u8be5\u6280\u672f\u5c06\u8f93\u5165\u6570\u636e\u4e2d\u6700\u5177\u4ee3\u8868\u6027\u7684\u884c\u6dfb\u52a0\u5230 LLM \u63d0\u793a\u4e2d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLLM \u6027\u80fd\u786e\u5b9e\u5bf9\u63d0\u793a\u4e2d\u4f20\u9012\u7684\u6570\u636e\u91cf\u654f\u611f\uff0c\u5e76\u4e14\u5bf9\u4e8e\u8f93\u5165\u8868\u683c\u4e2d\u5b58\u5728\u5927\u91cf\u53e5\u6cd5\u53d8\u5f02\u7684\u4efb\u52a1\uff0ccluster-then-select \u6280\u672f\u4f18\u4e8e\u968f\u673a\u9009\u62e9\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u4e3a LLM \u9009\u62e9\u5408\u9002\u7684\u6570\u636e\u5bf9\u4e8e\u63d0\u9ad8\u5176\u5728\u5904\u7406\u8868\u683c\u6570\u636e\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u4e14 cluster-then-select \u6280\u672f\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
