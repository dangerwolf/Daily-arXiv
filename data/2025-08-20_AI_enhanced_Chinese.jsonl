{"id": "2508.00472", "title": "A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces", "url": "https://arxiv.org/abs/2508.00472", "pdf": "https://arxiv.org/pdf/2508.00472", "abs": "https://arxiv.org/abs/2508.00472", "authors": ["Leonidas Akritidis", "Panayiotis Bozanis"], "categories": ["cs.LG"], "comment": null, "summary": "The tabular form constitutes the standard way of representing data in\nrelational database systems and spreadsheets. But, similarly to other forms,\ntabular data suffers from class imbalance, a problem that causes serious\nperformance degradation in a wide variety of machine learning tasks. One of the\nmost effective solutions dictates the usage of Generative Adversarial Networks\n(GANs) in order to synthesize artificial data instances for the\nunder-represented classes. Despite their good performance, none of the proposed\nGAN models takes into account the vector subspaces of the input samples in the\nreal data space, leading to data generation in arbitrary locations. Moreover,\nthe class labels are treated in the same manner as the other categorical\nvariables during training, so conditional sampling by class is rendered less\neffective. To overcome these problems, this study presents ctdGAN, a\nconditional GAN for alleviating class imbalance in tabular datasets. Initially,\nctdGAN executes a space partitioning step to assign cluster labels to the input\nsamples. Subsequently, it utilizes these labels to synthesize samples via a\nnovel probabilistic sampling strategy and a new loss function that penalizes\nboth cluster and class mis-predictions. In this way, ctdGAN is trained to\ngenerate samples in subspaces that resemble those of the original data\ndistribution. We also introduce several other improvements, including a simple,\nyet effective cluster-wise scaling technique that captures multiple feature\nmodes without affecting data dimensionality. The exhaustive evaluation of\nctdGAN with 14 imbalanced datasets demonstrated its superiority in generating\nhigh fidelity samples and improving classification accuracy.", "AI": {"tldr": "ctdGAN\u662f\u4e00\u79cd\u6761\u4ef6GAN\uff0c\u901a\u8fc7\u7a7a\u95f4\u5212\u5206\u3001\u65b0\u9896\u7684\u6982\u7387\u91c7\u6837\u7b56\u7565\u548c\u65b0\u7684\u635f\u5931\u51fd\u6570\u6765\u4e3a\u4e0d\u5e73\u8861\u8868\u683c\u6570\u636e\u96c6\u751f\u6210\u9ad8\u4fdd\u771f\u5408\u6210\u6570\u636e\uff0c\u4ece\u800c\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u8868\u683c\u6570\u636e\u5b58\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5bfc\u81f4\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\u3002\u73b0\u6709\u7684GAN\u6a21\u578b\u5728\u751f\u6210\u4eba\u5de5\u6570\u636e\u65f6\uff0c\u6ca1\u6709\u8003\u8651\u5230\u8f93\u5165\u6837\u672c\u7684\u5411\u91cf\u5b50\u7a7a\u95f4\uff0c\u5bfc\u81f4\u6570\u636e\u751f\u6210\u4f4d\u7f6e\u968f\u610f\uff0c\u5e76\u4e14\u5bf9\u7c7b\u522b\u6807\u7b7e\u7684\u5904\u7406\u65b9\u5f0f\u4e0e\u5176\u4ed6\u5206\u7c7b\u53d8\u91cf\u76f8\u540c\uff0c\u4f7f\u5f97\u6761\u4ef6\u91c7\u6837\u6548\u679c\u4e0d\u4f73\u3002", "method": "ctdGAN\u9996\u5148\u6267\u884c\u7a7a\u95f4\u5212\u5206\u6b65\u9aa4\uff0c\u4e3a\u8f93\u5165\u6837\u672c\u5206\u914d\u805a\u7c7b\u6807\u7b7e\u3002\u968f\u540e\uff0c\u5b83\u5229\u7528\u8fd9\u4e9b\u6807\u7b7e\u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u6982\u7387\u91c7\u6837\u7b56\u7565\u548c\u60e9\u7f5a\u805a\u7c7b\u548c\u7c7b\u522b\u8bef\u5224\u7684\u65b0\u635f\u5931\u51fd\u6570\u6765\u5408\u6210\u6837\u672c\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u805a\u7c7b\u7f29\u653e\u6280\u672f\u6765\u6355\u83b7\u591a\u4e2a\u7279\u5f81\u6a21\u5f0f\u3002", "result": "ctdGAN\u5728\u4e0e\u539f\u59cb\u6570\u636e\u5206\u5e03\u76f8\u4f3c\u7684\u5b50\u7a7a\u95f4\u4e2d\u751f\u6210\u6837\u672c\uff0c\u5e76\u80fd\u591f\u6355\u83b7\u591a\u4e2a\u7279\u5f81\u6a21\u5f0f\u3002\u901a\u8fc7\u5bf914\u4e2a\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86ctdGAN\u5728\u751f\u6210\u9ad8\u4fdd\u771f\u6837\u672c\u548c\u63d0\u9ad8\u5206\u7c7b\u7cbe\u5ea6\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "ctdGAN\u901a\u8fc7\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6837\u672c\u6709\u6548\u7f13\u89e3\u4e86\u8868\u683c\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u3002"}}
{"id": "2508.00217", "title": "Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges", "url": "https://arxiv.org/abs/2508.00217", "pdf": "https://arxiv.org/pdf/2508.00217", "abs": "https://arxiv.org/abs/2508.00217", "authors": ["Xiaofeng Wu", "Alan Ritter", "Wei Xu"], "categories": ["cs.CL", "cs.DB", "cs.LG"], "comment": null, "summary": "Tables have gained significant attention in large language models (LLMs) and\nmultimodal large language models (MLLMs) due to their complex and flexible\nstructure. Unlike linear text inputs, tables are two-dimensional, encompassing\nformats that range from well-structured database tables to complex,\nmulti-layered spreadsheets, each with different purposes. This diversity in\nformat and purpose has led to the development of specialized methods and tasks,\ninstead of universal approaches, making navigation of table understanding tasks\nchallenging. To address these challenges, this paper introduces key concepts\nthrough a taxonomy of tabular input representations and an introduction of\ntable understanding tasks. We highlight several critical gaps in the field that\nindicate the need for further research: (1) the predominance of\nretrieval-focused tasks that require minimal reasoning beyond mathematical and\nlogical operations; (2) significant challenges faced by models when processing\ncomplex table structures, large-scale tables, length context, or multi-table\nscenarios; and (3) the limited generalization of models across different\ntabular representations and formats.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86LLMs/MLLMs\u5728\u8868\u683c\u7406\u89e3\u65b9\u9762\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8868\u683c\u8868\u793a\u5206\u7c7b\u6cd5\uff0c\u5e76\u6307\u51fa\u4e86\u8be5\u9886\u57df\u7684\u51e0\u4e2a\u7814\u7a76\u7a7a\u767d\u3002", "motivation": "\u8868\u683c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLMs) \u548c\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b (MLLMs) \u4e2d\u56e0\u5176\u590d\u6742\u548c\u7075\u6d3b\u7684\u7ed3\u6784\u800c\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5176\u591a\u6837\u6027\u4f7f\u5f97\u8868\u683c\u7406\u89e3\u4efb\u52a1\u6781\u5177\u6311\u6218\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u4ecb\u7ecd\u8868\u683c\u8f93\u5165\u8868\u793a\u7684\u5206\u7c7b\u6cd5\u548c\u8868\u683c\u7406\u89e3\u4efb\u52a1\u6765\u9610\u8ff0\u5173\u952e\u6982\u5ff5\u3002", "result": "\u8bba\u6587\u6307\u51fa\u4e86\u8be5\u9886\u57df\u7684\u51e0\u4e2a\u5173\u952e\u7a7a\u767d\uff0c\u5305\u62ec\uff1a1) \u504f\u91cd\u68c0\u7d22\u578b\u4efb\u52a1\uff0c\u5bf9\u63a8\u7406\u8981\u6c42\u4f4e\uff1b2) \u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u7ed3\u6784\u3001\u5927\u89c4\u6a21\u3001\u957f\u4e0a\u4e0b\u6587\u6216\u591a\u8868\u683c\u573a\u666f\u65f6\u9762\u4e34\u6311\u6218\uff1b3) \u6a21\u578b\u5728\u4e0d\u540c\u8868\u683c\u8868\u793a\u548c\u683c\u5f0f\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "conclusion": "\u5f53\u524d\u8868\u683c\u7406\u89e3\u9886\u57df\u5b58\u5728\u663e\u8457\u6311\u6218\u548c\u5c40\u9650\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u89e3\u51b3\u5173\u952e\u7a7a\u767d\u3002"}}
