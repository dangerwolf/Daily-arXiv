{"id": "2511.16935", "title": "LinkML: An Open Data Modeling Framework", "url": "https://arxiv.org/abs/2511.16935", "pdf": "https://arxiv.org/pdf/2511.16935", "abs": "https://arxiv.org/abs/2511.16935", "authors": ["Sierra A. T. Moxon", "Harold Solbrig", "Nomi L. Harris", "Patrick Kalita", "Mark A. Miller", "Sujay Patil", "Kevin Schaper", "Chris Bizon", "J. Harry Caufield", "Silvano Cirujano Cuesta", "Corey Cox", "Frank Dekervel", "Damion M. Dooley", "William D. Duncan", "Tim Fliss", "Sarah Gehrke", "Adam S. L. Graefe", "Harshad Hegde", "AJ Ireland", "Julius O. B. Jacobsen", "Madan Krishnamurthy", "Carlo Kroll", "David Linke", "Ryan Ly", "Nicolas Matentzoglu", "James A. Overton", "Jonny L. Saunders", "Deepak R. Unni", "Gaurav Vaidya", "Wouter-Michiel A. M. Vierdag", "LinkML Community Contributors", "Oliver Ruebel", "Christopher G. Chute", "Matthew H. Brush", "Melissa A. Haendel", "Christopher J. Mungall"], "categories": ["cs.DB"], "comment": "Removed author affiliations in metadata for proper author indexing. No changes to paper", "summary": "Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult. LinkML (Linked Data Modeling Language) is an open framework that simplifies the process of authoring, validating, and sharing data. LinkML can describe a range of data structures, from flat, list-based models to complex, interrelated, and normalized models that utilize polymorphism and compound inheritance. It offers an approachable syntax that is not tied to any one technical architecture and can be integrated seamlessly with many existing frameworks. The LinkML syntax provides a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas. These key features make LinkML an accessible platform for interdisciplinary collaboration and a reliable way to define and share data semantics.\n  LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development. In short, LinkML makes implicit models explicitly computable and allows data to be standardized at its origin. LinkML documentation and code are available at linkml.io.", "AI": {"tldr": "LinkML is an open framework that simplifies the process of authoring, validating, and sharing data.", "motivation": "Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult.", "method": "LinkML uses a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas.", "result": "LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development.", "conclusion": "LinkML makes implicit models explicitly computable and allows data to be standardized at its origin."}}
{"id": "2510.19342", "title": "To Use or to Refuse? Re-Centering Student Agency with Generative AI in Engineering Design Education", "url": "https://arxiv.org/abs/2510.19342", "pdf": "https://arxiv.org/pdf/2510.19342", "abs": "https://arxiv.org/abs/2510.19342", "authors": ["Thijs Willems", "Sumbul Khan", "Qian Huang", "Bradley Camburn", "Nachamma Sockalingam", "King Wang Poon"], "categories": ["cs.CY", "cs.AI"], "comment": "to be published in IEEE TALE 2025", "summary": "This pilot study traces students' reflections on the use of AI in a 13-week foundational design course enrolling over 500 first-year engineering and architecture students at the Singapore University of Technology and Design. The course was an AI-enhanced design course, with several interventions to equip students with AI based design skills. Students were required to reflect on whether the technology was used as a tool (instrumental assistant), a teammate (collaborative partner), or neither (deliberate non-use). By foregrounding this three-way lens, students learned to use AI for innovation rather than just automation and to reflect on agency, ethics, and context rather than on prompt crafting alone. Evidence stems from coursework artefacts: thirteen structured reflection spreadsheets and eight illustrated briefs submitted, combined with notes of teachers and researchers. Qualitative coding of these materials reveals shared practices brought about through the inclusion of Gen-AI, including accelerated prototyping, rapid skill acquisition, iterative prompt refinement, purposeful \"switch-offs\" during user research, and emergent routines for recognizing hallucinations. Unexpectedly, students not only harnessed Gen-AI for speed but (enabled by the tool-teammate-neither triage) also learned to reject its outputs, invent their own hallucination fire-drills, and divert the reclaimed hours into deeper user research, thereby transforming efficiency into innovation. The implications of the approach we explore shows that: we can transform AI uptake into an assessable design habit; that rewarding selective non-use cultivates hallucination-aware workflows; and, practically, that a coordinated bundle of tool access, reflection, role tagging, and public recognition through competition awards allows AI based innovation in education to scale without compromising accountability.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u65b0\u52a0\u5761\u79d1\u6280\u8bbe\u8ba1\u5927\u5b66\u4e00\u95e8\u4e3a\u671f 13 \u5468\u7684\u57fa\u7840\u8bbe\u8ba1\u8bfe\u7a0b\u4e2d\uff0c\u5b66\u751f\u5bf9\u4f7f\u7528\u4eba\u5de5\u667a\u80fd\u7684\u53cd\u601d\u3002\u8be5\u8bfe\u7a0b\u4e3a AI \u589e\u5f3a\u8bbe\u8ba1\u8bfe\u7a0b\uff0c\u65e8\u5728\u57f9\u517b\u5b66\u751f\u57fa\u4e8e AI \u7684\u8bbe\u8ba1\u6280\u80fd\u3002\u5b66\u751f\u9700\u8981\u53cd\u601d\u8be5\u6280\u672f\u662f\u4f5c\u4e3a\u5de5\u5177\u3001\u961f\u53cb\u8fd8\u662f\u4e0d\u4f7f\u7528\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u5b66\u751f\u5b66\u4f1a\u5c06 AI \u7528\u4e8e\u521b\u65b0\u800c\u975e\u4ec5\u4ec5\u7528\u4e8e\u81ea\u52a8\u5316\uff0c\u5e76\u53cd\u601d\u80fd\u52a8\u6027\u3001\u4f26\u7406\u548c\u80cc\u666f\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u5728\u8bbe\u8ba1\u8bfe\u7a0b\u4e2d\u5229\u7528\u4eba\u5de5\u667a\u80fd\u63d0\u5347\u5b66\u751f\u7684\u521b\u65b0\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5341\u4e09\u4efd\u7ed3\u6784\u5316\u53cd\u601d\u7535\u5b50\u8868\u683c\u3001\u516b\u4efd\u56fe\u89e3\u7b80\u62a5\u4ee5\u53ca\u6559\u5e08\u548c\u7814\u7a76\u4eba\u5458\u7684\u7b14\u8bb0\uff0c\u5bf9\u5b66\u751f\u7684\u8bfe\u7a0b\u4f5c\u4e1a\u6210\u679c\u8fdb\u884c\u5b9a\u6027\u7f16\u7801\u5206\u6790\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u878d\u5165\u5e26\u6765\u4e86\u52a0\u901f\u539f\u578b\u8bbe\u8ba1\u3001\u5feb\u901f\u6280\u80fd\u638c\u63e1\u3001\u8fed\u4ee3\u63d0\u793a\u4f18\u5316\u3001\u7528\u6237\u7814\u7a76\u671f\u95f4\u6709\u76ee\u7684\u7684\u201c\u5173\u95ed\u201d\u4ee5\u53ca\u8bc6\u522b\u5e7b\u89c9\u7684\u5e38\u89c4\u65b9\u6cd5\u3002\u5b66\u751f\u4e0d\u4ec5\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u6765\u63d0\u9ad8\u901f\u5ea6\uff0c\u800c\u4e14\u8fd8\u5b66\u4f1a\u62d2\u7edd\u5176\u8f93\u51fa\uff0c\u53d1\u660e\u81ea\u5df1\u7684\u5e7b\u89c9\u6f14\u7ec3\uff0c\u5e76\u5c06\u8282\u7701\u4e0b\u6765\u7684\u65f6\u95f4\u7528\u4e8e\u66f4\u6df1\u5165\u7684\u7528\u6237\u7814\u7a76\uff0c\u4ece\u800c\u5c06\u6548\u7387\u8f6c\u5316\u4e3a\u521b\u65b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u53ef\u4ee5\u5c06\u4eba\u5de5\u667a\u80fd\u7684\u91c7\u7eb3\u8f6c\u5316\u4e3a\u53ef\u8bc4\u4f30\u7684\u8bbe\u8ba1\u4e60\u60ef\uff1b\u5956\u52b1\u9009\u62e9\u6027\u4e0d\u4f7f\u7528\u53ef\u4ee5\u57f9\u517b\u5177\u6709\u5e7b\u89c9\u610f\u8bc6\u7684\u5de5\u4f5c\u6d41\u7a0b\uff1b\u5e76\u4e14\uff0c\u901a\u8fc7\u5de5\u5177\u8bbf\u95ee\u3001\u53cd\u601d\u3001\u89d2\u8272\u6807\u8bb0\u548c\u901a\u8fc7\u7ade\u8d5b\u5956\u52b1\u8fdb\u884c\u516c\u5f00\u8ba4\u53ef\uff0c\u53ef\u4ee5\u4f7f\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u6559\u80b2\u521b\u65b0\u5f97\u4ee5\u6269\u5c55\uff0c\u800c\u4e0d\u4f1a\u5f71\u54cd\u8d23\u4efb\u6027\u3002"}}
{"id": "2510.19247", "title": "SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets", "url": "https://arxiv.org/abs/2510.19247", "pdf": "https://arxiv.org/pdf/2510.19247", "abs": "https://arxiv.org/abs/2510.19247", "authors": ["Ziwei Wang", "Jiayuan Su", "Mengyu Zhou", "Huaxing Zeng", "Mengni Jia", "Xiao Lv", "Haoyu Dong", "Xiaojun Ma", "Shi Han", "Dongmei Zhang"], "categories": ["cs.CL"], "comment": null, "summary": "Understanding and reasoning over complex spreadsheets remain fundamental challenges for large language models (LLMs), which often struggle with accurately capturing the complex structure of tables and ensuring reasoning correctness. In this work, we propose SheetBrain, a neuro-symbolic dual workflow agent framework designed for accurate reasoning over tabular data, supporting both spreadsheet question answering and manipulation tasks. SheetBrain comprises three core modules: an understanding module, which produces a comprehensive overview of the spreadsheet - including sheet summary and query-based problem insight to guide reasoning; an execution module, which integrates a Python sandbox with preloaded table-processing libraries and an Excel helper toolkit for effective multi-turn reasoning; and a validation module, which verifies the correctness of reasoning and answers, triggering re-execution when necessary. We evaluate SheetBrain on multiple public tabular QA and manipulation benchmarks, and introduce SheetBench, a new benchmark targeting large, multi-table, and structurally complex spreadsheets. Experimental results show that SheetBrain significantly improves accuracy on both existing benchmarks and the more challenging scenarios presented in SheetBench. Our code is publicly available at https://github.com/microsoft/SheetBrain.", "AI": {"tldr": "SheetBrain is a neuro-symbolic framework for reasoning over tabular data, improving accuracy in spreadsheet question answering and manipulation.", "motivation": "LLMs struggle with complex spreadsheets, lacking accuracy in capturing table structure and ensuring reasoning correctness.", "method": "A neuro-symbolic dual workflow agent framework with understanding, execution, and validation modules.", "result": "Significantly improves accuracy on existing benchmarks and a new challenging benchmark (SheetBench).", "conclusion": "SheetBrain enhances accuracy in tabular data reasoning tasks."}}
{"id": "2508.00472", "title": "A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces", "url": "https://arxiv.org/abs/2508.00472", "pdf": "https://arxiv.org/pdf/2508.00472", "abs": "https://arxiv.org/abs/2508.00472", "authors": ["Leonidas Akritidis", "Panayiotis Bozanis"], "categories": ["cs.LG"], "comment": null, "summary": "The tabular form constitutes the standard way of representing data in relational database systems and spreadsheets. But, similarly to other forms, tabular data suffers from class imbalance, a problem that causes serious performance degradation in a wide variety of machine learning tasks. One of the most effective solutions dictates the usage of Generative Adversarial Networks (GANs) in order to synthesize artificial data instances for the under-represented classes. Despite their good performance, none of the proposed GAN models takes into account the vector subspaces of the input samples in the real data space, leading to data generation in arbitrary locations. Moreover, the class labels are treated in the same manner as the other categorical variables during training, so conditional sampling by class is rendered less effective. To overcome these problems, this study presents ctdGAN, a conditional GAN for alleviating class imbalance in tabular datasets. Initially, ctdGAN executes a space partitioning step to assign cluster labels to the input samples. Subsequently, it utilizes these labels to synthesize samples via a novel probabilistic sampling strategy and a new loss function that penalizes both cluster and class mis-predictions. In this way, ctdGAN is trained to generate samples in subspaces that resemble those of the original data distribution. We also introduce several other improvements, including a simple, yet effective cluster-wise scaling technique that captures multiple feature modes without affecting data dimensionality. The exhaustive evaluation of ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating high fidelity samples and improving classification accuracy.", "AI": {"tldr": "This paper introduces ctdGAN, a conditional GAN model, to address the class imbalance problem in tabular datasets by generating synthetic data for under-represented classes within the vector subspaces of the original data.", "motivation": "Existing GAN models for tabular data do not consider the vector subspaces of input samples, leading to data generation in arbitrary locations, and treat class labels as regular categorical variables, reducing the effectiveness of conditional sampling by class.", "method": "ctdGAN uses a space partitioning step to assign cluster labels to input samples, then synthesizes samples via a novel probabilistic sampling strategy and a new loss function that penalizes both cluster and class mis-predictions. It also includes a cluster-wise scaling technique.", "result": "Evaluated on 14 imbalanced datasets, ctdGAN demonstrates superior performance in generating high fidelity samples and improving classification accuracy.", "conclusion": "ctdGAN effectively alleviates class imbalance in tabular datasets by generating synthetic data within the vector subspaces of the original data distribution, leading to improved classification accuracy."}}
{"id": "2508.00217", "title": "Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges", "url": "https://arxiv.org/abs/2508.00217", "pdf": "https://arxiv.org/pdf/2508.00217", "abs": "https://arxiv.org/abs/2508.00217", "authors": ["Xiaofeng Wu", "Alan Ritter", "Wei Xu"], "categories": ["cs.CL", "cs.DB", "cs.LG"], "comment": null, "summary": "Tables have gained significant attention in large language models (LLMs) and multimodal large language models (MLLMs) due to their complex and flexible structure. Unlike linear text inputs, tables are two-dimensional, encompassing formats that range from well-structured database tables to complex, multi-layered spreadsheets, each with different purposes. This diversity in format and purpose has led to the development of specialized methods and tasks, instead of universal approaches, making navigation of table understanding tasks challenging. To address these challenges, this paper introduces key concepts through a taxonomy of tabular input representations and an introduction of table understanding tasks. We highlight several critical gaps in the field that indicate the need for further research: (1) the predominance of retrieval-focused tasks that require minimal reasoning beyond mathematical and logical operations; (2) significant challenges faced by models when processing complex table structures, large-scale tables, length context, or multi-table scenarios; and (3) the limited generalization of models across different tabular representations and formats.", "AI": {"tldr": "This paper reviews table understanding tasks in LLMs and MLLMs, highlighting challenges and gaps.", "motivation": "The diversity in table formats and purposes has led to specialized methods, making navigation of table understanding tasks challenging.", "method": "Introduces key concepts through a taxonomy of tabular input representations and an introduction of table understanding tasks.", "result": "Highlights critical gaps: (1) retrieval-focused tasks, (2) challenges with complex tables, (3) limited generalization.", "conclusion": "Indicates the need for further research in table understanding for LLMs and MLLMs."}}
