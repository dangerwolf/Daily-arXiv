<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets](https://arxiv.org/abs/2510.19247)
*Ziwei Wang,Jiayuan Su,Mengyu Zhou,Huaxing Zeng,Mengni Jia,Xiao Lv,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: SheetBrain是一个用于处理复杂表格数据的神经符号双工作流代理框架，能够准确地进行问答和操作，并在现有和新的SheetBench基准上显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在理解和推理复杂电子表格时遇到的挑战，特别是捕捉表格结构和确保推理的准确性。

Method: 提出SheetBrain，一个包含理解、执行和验证三个核心模块的神经符号双工作流代理框架。理解模块生成表格概述和问题洞察；执行模块集成Python沙箱和Excel工具包进行多轮推理；验证模块检查推理正确性并触发重新执行。

Result: SheetBrain在多个公开表格QA和操作基准以及新的SheetBench基准上都显著提高了准确性，特别是在处理大型、多表和结构复杂的电子表格方面。

Conclusion: SheetBrain在处理复杂电子表格数据方面表现出色，能够准确地进行问答和操作，并在各种基准测试中取得优异成绩。

Abstract: Understanding and reasoning over complex spreadsheets remain fundamental challenges for large language models (LLMs), which often struggle with accurately capturing the complex structure of tables and ensuring reasoning correctness. In this work, we propose SheetBrain, a neuro-symbolic dual workflow agent framework designed for accurate reasoning over tabular data, supporting both spreadsheet question answering and manipulation tasks. SheetBrain comprises three core modules: an understanding module, which produces a comprehensive overview of the spreadsheet - including sheet summary and query-based problem insight to guide reasoning; an execution module, which integrates a Python sandbox with preloaded table-processing libraries and an Excel helper toolkit for effective multi-turn reasoning; and a validation module, which verifies the correctness of reasoning and answers, triggering re-execution when necessary. We evaluate SheetBrain on multiple public tabular QA and manipulation benchmarks, and introduce SheetBench, a new benchmark targeting large, multi-table, and structurally complex spreadsheets. Experimental results show that SheetBrain significantly improves accuracy on both existing benchmarks and the more challenging scenarios presented in SheetBench. Our code is publicly available at https://github.com/microsoft/SheetBrain.

</details>


### [2] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 表格在大型语言模型（LLM）和多模态大型语言模型（MLLM）中受到广泛关注，因为其复杂的结构。本文提出了一种表格输入表示的分类法和表格理解任务的介绍，以应对挑战。


<details>
  <summary>Details</summary>
Motivation: 处理表格数据在大型语言模型（LLM）和多模态大型语言模型（MLLM）中是一个重要但具有挑战性的问题，因为表格具有复杂的二维结构，并且存在多种格式和用途，导致需要专门的方法而不是通用的方法。

Method: 通过表格输入表示的分类法和表格理解任务的介绍来阐述关键概念。

Result: 研究强调了该领域存在的关键差距，包括：1）以检索为主的任务，仅需要基本的数学和逻辑推理；2）模型在处理复杂表格结构、大规模表格、长上下文或多表格场景时面临挑战；3）模型在不同表格表示和格式之间的泛化能力有限。

Conclusion: 尽管表格在LLM和MLLM中受到关注，但仍存在一些关键的挑战和研究差距，特别是在处理复杂性、规模、上下文和泛化能力方面，这表明需要进一步的研究。

Abstract: Tables have gained significant attention in large language models (LLMs) and multimodal large language models (MLLMs) due to their complex and flexible structure. Unlike linear text inputs, tables are two-dimensional, encompassing formats that range from well-structured database tables to complex, multi-layered spreadsheets, each with different purposes. This diversity in format and purpose has led to the development of specialized methods and tasks, instead of universal approaches, making navigation of table understanding tasks challenging. To address these challenges, this paper introduces key concepts through a taxonomy of tabular input representations and an introduction of table understanding tasks. We highlight several critical gaps in the field that indicate the need for further research: (1) the predominance of retrieval-focused tasks that require minimal reasoning beyond mathematical and logical operations; (2) significant challenges faced by models when processing complex table structures, large-scale tables, length context, or multi-table scenarios; and (3) the limited generalization of models across different tabular representations and formats.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [3] [To Use or to Refuse? Re-Centering Student Agency with Generative AI in Engineering Design Education](https://arxiv.org/abs/2510.19342)
*Thijs Willems,Sumbul Khan,Qian Huang,Bradley Camburn,Nachamma Sockalingam,King Wang Poon*

Main category: cs.CY

TL;DR: 本研究追踪了新加坡科技设计大学一个包含500多名一年级工程和建筑学生的为期13周的基础设计课程中，学生对人工智能使用的反思。课程通过多项干预措施，为学生提供AI设计技能。学生需要反思AI是作为工具、团队成员还是不使用。研究通过分析课程作业、学生反思和师生笔记，发现AI促进了原型制作、技能获取、提示优化、用户研究中的“关闭”以及识别幻觉等实践。学生不仅利用AI提高效率，还学会拒绝不合适的输出来进行更深入的用户研究，从而实现从效率到创新的转变。研究表明，可以将AI应用转化为可评估的设计习惯，奖励选择性不使用可培养对幻觉有意识的工作流程，并通过工具接入、反思、角色标记和竞赛奖励来规模化AI驱动的教育创新，同时不牺牲问责制。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索如何引导学生在设计课程中有效利用人工智能，从单纯的自动化转向创新，并深入反思AI使用的代理权、伦理和情境，而不仅仅是关注提示词的优化。

Method: 本研究采用定性编码方法，分析了学生提交的13份结构化反思电子表格和8份图文并茂的简报，结合了教师和研究人员的笔记。研究聚焦于学生将AI视为“工具”（工具性助手）、“队友”（协作伙伴）或“不使用”这三种角色定位。

Result: 研究发现，AI的引入促成了加速原型制作、快速技能获取、迭代提示优化、用户研究中的刻意“关闭”以及识别幻觉的新例程。学生不仅利用AI提高效率，还学会拒绝其输出，发明“幻觉救火演习”，并将节省的时间投入到更深入的用户研究中，从而实现效率向创新的转化。

Conclusion: 研究表明，可以将AI的应用转化为可评估的设计习惯；奖励选择性不使用AI可以培养对幻觉有意识的工作流程；通过工具接入、反思、角色标记和公开竞赛奖励相结合，可以在不牺牲问责制的情况下，规模化AI驱动的教育创新。

Abstract: This pilot study traces students' reflections on the use of AI in a 13-week foundational design course enrolling over 500 first-year engineering and architecture students at the Singapore University of Technology and Design. The course was an AI-enhanced design course, with several interventions to equip students with AI based design skills. Students were required to reflect on whether the technology was used as a tool (instrumental assistant), a teammate (collaborative partner), or neither (deliberate non-use). By foregrounding this three-way lens, students learned to use AI for innovation rather than just automation and to reflect on agency, ethics, and context rather than on prompt crafting alone. Evidence stems from coursework artefacts: thirteen structured reflection spreadsheets and eight illustrated briefs submitted, combined with notes of teachers and researchers. Qualitative coding of these materials reveals shared practices brought about through the inclusion of Gen-AI, including accelerated prototyping, rapid skill acquisition, iterative prompt refinement, purposeful "switch-offs" during user research, and emergent routines for recognizing hallucinations. Unexpectedly, students not only harnessed Gen-AI for speed but (enabled by the tool-teammate-neither triage) also learned to reject its outputs, invent their own hallucination fire-drills, and divert the reclaimed hours into deeper user research, thereby transforming efficiency into innovation. The implications of the approach we explore shows that: we can transform AI uptake into an assessable design habit; that rewarding selective non-use cultivates hallucination-aware workflows; and, practically, that a coordinated bundle of tool access, reflection, role tagging, and public recognition through competition awards allows AI based innovation in education to scale without compromising accountability.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations](https://arxiv.org/abs/2510.19864)
*Amila Indika,Igor Molybog*

Main category: cs.SE

TL;DR: 现有的电子表格缺乏系统性的文档记录方法，阻碍了自动化、协作和知识转移。本文提出了一种名为“电子表格操作文档”（SOD）的人工智能任务，旨在从电子表格操作生成人类可读的解释。我们构建了一个包含111个电子表格操作代码片段及其对应自然语言摘要的基准。


<details>
  <summary>Details</summary>
Motivation: 现有的电子表格缺乏系统性的文档记录方法，阻碍了自动化、协作和知识转移，并可能导致关键的机构知识丢失。

Method: 引入“电子表格操作文档”（SOD）任务，构建了一个包含111个电子表格操作代码片段及其对应自然语言摘要的基准。评估了GPT-4o、GPT-4o-mini、LLaMA-3.3-70B、Mixtral-8x7B和Gemma2-9B这五种大型语言模型（LLM）的性能，并使用BLEU、GLEU、ROUGE-L和METEOR等指标进行评价。

Result: 研究结果表明，大型语言模型（LLM）能够生成准确的电子表格文档，证明SOD可以作为提高电子表格可重复性、可维护性和协作工作流程的可行前提步骤，但仍存在一些挑战需要解决。

Conclusion: SOD任务是可行的，可以提高电子表格的可重复性、可维护性和协作性，但仍需进一步研究以克服现有挑战。

Abstract: Numerous knowledge workers utilize spreadsheets in business, accounting, and finance. However, a lack of systematic documentation methods for spreadsheets hinders automation, collaboration, and knowledge transfer, which risks the loss of crucial institutional knowledge. This paper introduces Spreadsheet Operations Documentation (SOD), an AI task that involves generating human-readable explanations from spreadsheet operations. Many previous studies have utilized Large Language Models (LLMs) for generating spreadsheet manipulation code; however, translating that code into natural language for SOD is a less-explored area. To address this, we present a benchmark of 111 spreadsheet manipulation code snippets, each paired with a corresponding natural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini, LLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and METEOR metrics. Our findings suggest that LLMs can generate accurate spreadsheet documentation, making SOD a feasible prerequisite step toward enhancing reproducibility, maintainability, and collaborative workflows in spreadsheets, although there are challenges that need to be addressed.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [IIKL: Isometric Immersion Kernel Learning with Riemannian Manifold for Geometric Preservation](https://arxiv.org/abs/2505.06288)
*Zihao Chen,Wenyong Wang,Jiachen Yang,Yu Xiang*

Main category: cs.LG

TL;DR: 该研究提出了一种名为等距浸入核学习（IIKL）的新方法，用于在非欧几里得数据上进行几何表示学习，通过在李曼流形上学习度量来保持数据的内在几何和拓扑性质。


<details>
  <summary>Details</summary>
Motivation: 以往的表示学习方法将非欧几里得数据映射到欧几里得空间，可能丢失关键的几何信息。本研究旨在提出一种新的方法来解决这个问题，并保持原始数据的几何结构。

Method: 提出等距浸入核学习（IIKL）方法，在李曼流形上构建黎曼度量，并证明了等距浸入等价于切丛上的核函数，从而保证了内积在任意切空间中的不变性。在此基础上，引入了基于IIKL的参数化学习模型，并使用最大似然估计（MLE）推导出交替训练方法。

Result: 实验结果表明，所提出的IIKL方法能够成功地在三维和高维数据集上保持数据的内在几何表示，并显著提高了数据重建和分类等下游任务的准确性。与最先进（SOTA）的方法相比，内积不变量损失减少了90%以上，下游重建准确性平均提高了40%，涉及等距和共形的几何指标误差减少了90%。

Conclusion: IIKL方法能够有效保持非欧几里得数据的内在几何结构，并在下游任务中取得显著的性能提升。

Abstract: Geometric representation learning in preserving the intrinsic geometric and topological properties for discrete non-Euclidean data is crucial in scientific applications. Previous research generally mapped non-Euclidean discrete data into Euclidean space during representation learning, which may lead to the loss of some critical geometric information. In this paper, we propose a novel Isometric Immersion Kernel Learning (IIKL) method to build Riemannian manifold and isometrically induce Riemannian metric from discrete non-Euclidean data. We prove that Isometric immersion is equivalent to the kernel function in the tangent bundle on the manifold, which explicitly guarantees the invariance of the inner product between vectors in the arbitrary tangent space throughout the learning process, thus maintaining the geometric structure of the original data. Moreover, a novel parameterized learning model based on IIKL is introduced, and an alternating training method for this model is derived using Maximum Likelihood Estimation (MLE), ensuring efficient convergence. Experimental results proved that using the learned Riemannian manifold and its metric, our model preserved the intrinsic geometric representation of data in both 3D and high-dimensional datasets successfully, and significantly improved the accuracy of downstream tasks, such as data reconstruction and classification. It is showed that our method could reduce the inner product invariant loss by more than 90% compared to state-of-the-art (SOTA) methods, also achieved an average 40% improvement in downstream reconstruction accuracy and a 90% reduction in error for geometric metrics involving isometric and conformal.

</details>


### [6] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: ctdGAN通过空间划分、概率采样和新的损失函数来解决表格数据的类别不平衡问题，提高了生成样本的保真度和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的GAN模型在处理表格数据类别不平衡问题时，没有考虑输入样本的向量子空间，导致生成数据位置任意，并且类别标签被与其他类别特征同等对待，降低了条件采样的有效性。

Method: ctdGAN首先执行空间划分，为输入样本分配簇标签。然后，利用这些簇标签，通过新颖的概率采样策略和新的损失函数（该函数会惩罚簇和类别的误预测）来合成样本。此外，还引入了簇wise缩放技术来捕捉多个特征模式。

Result: ctdGAN在14个不平衡数据集上的广泛评估表明，它在生成高保真样本和提高分类准确性方面表现优越。

Conclusion: ctdGAN通过考虑向量子空间和改进的条件采样机制，有效解决了表格数据类别不平衡问题，并提高了生成样本的质量和下游任务的分类性能。

Abstract: The tabular form constitutes the standard way of representing data in relational database systems and spreadsheets. But, similarly to other forms, tabular data suffers from class imbalance, a problem that causes serious performance degradation in a wide variety of machine learning tasks. One of the most effective solutions dictates the usage of Generative Adversarial Networks (GANs) in order to synthesize artificial data instances for the under-represented classes. Despite their good performance, none of the proposed GAN models takes into account the vector subspaces of the input samples in the real data space, leading to data generation in arbitrary locations. Moreover, the class labels are treated in the same manner as the other categorical variables during training, so conditional sampling by class is rendered less effective. To overcome these problems, this study presents ctdGAN, a conditional GAN for alleviating class imbalance in tabular datasets. Initially, ctdGAN executes a space partitioning step to assign cluster labels to the input samples. Subsequently, it utilizes these labels to synthesize samples via a novel probabilistic sampling strategy and a new loss function that penalizes both cluster and class mis-predictions. In this way, ctdGAN is trained to generate samples in subspaces that resemble those of the original data distribution. We also introduce several other improvements, including a simple, yet effective cluster-wise scaling technique that captures multiple feature modes without affecting data dimensionality. The exhaustive evaluation of ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating high fidelity samples and improving classification accuracy.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [7] [LinkML: An Open Data Modeling Framework](https://arxiv.org/abs/2511.16935)
*Sierra A. T. Moxon,Harold Solbrig,Nomi L. Harris,Patrick Kalita,Mark A. Miller,Sujay Patil,Kevin Schaper,Chris Bizon,J. Harry Caufield,Silvano Cirujano Cuesta,Corey Cox,Frank Dekervel,Damion M. Dooley,William D. Duncan,Tim Fliss,Sarah Gehrke,Adam S. L. Graefe,Harshad Hegde,AJ Ireland,Julius O. B. Jacobsen,Madan Krishnamurthy,Carlo Kroll,David Linke,Ryan Ly,Nicolas Matentzoglu,James A. Overton,Jonny L. Saunders,Deepak R. Unni,Gaurav Vaidya,Wouter-Michiel A. M. Vierdag,LinkML Community Contributors,Oliver Ruebel,Christopher G. Chute,Matthew H. Brush,Melissa A. Haendel,Christopher J. Mungall*

Main category: cs.DB

TL;DR: LinkML是一个开源框架，用于简化数据的创建、验证和共享，通过提供一种标准化的方法来描述数据结构，从而减少异构性并促进FAIR数据标准的合规性。


<details>
  <summary>Details</summary>
Motivation: 当前科研数据存储格式（如自由文本、非标准化电子表格）缺乏结构化，阻碍了数据的互操作性、集成、验证和复用。

Method: LinkML提供了一个易于使用的语法来描述模式、类和关系，支持从简单到复杂的各种数据模型，并可与其他框架集成。它允许模型设计者构建定义明确、稳定且可选与本体对齐的数据结构，并且可以导入到其他LinkML模式中。

Result: LinkML已被生物学、化学、生物医学、金融、工程等多个领域采用，减少了数据模型的异构性和复杂性，并支持FAIR数据标准。

Conclusion: LinkML通过将隐含的模型显式化，使数据从源头即可标准化，从而成为跨学科协作和共享数据语义的可靠平台。

Abstract: Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult. LinkML (Linked Data Modeling Language) is an open framework that simplifies the process of authoring, validating, and sharing data. LinkML can describe a range of data structures, from flat, list-based models to complex, interrelated, and normalized models that utilize polymorphism and compound inheritance. It offers an approachable syntax that is not tied to any one technical architecture and can be integrated seamlessly with many existing frameworks. The LinkML syntax provides a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas. These key features make LinkML an accessible platform for interdisciplinary collaboration and a reliable way to define and share data semantics.
  LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development. In short, LinkML makes implicit models explicitly computable and allows data to be standardized at its origin. LinkML documentation and code are available at linkml.io.

</details>
