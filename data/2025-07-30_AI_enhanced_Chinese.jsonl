{"id": "2507.13558", "title": "Why Isn't Relational Learning Taking Over the World?", "url": "https://arxiv.org/abs/2507.13558", "pdf": "https://arxiv.org/pdf/2507.13558", "abs": "https://arxiv.org/abs/2507.13558", "authors": ["David Poole"], "categories": ["cs.AI", "cs.DB", "cs.LG"], "comment": "10 pages (6 pages + references + appendices)", "summary": "AI seems to be taking over the world with systems that model pixels, words,\nand phonemes. The world is arguably made up, not of pixels, words, and phonemes\nbut of entities (objects, things, including events) with properties and\nrelations among them. Surely we should model these, not the perception or\ndescription of them. You might suspect that concentrating on modeling words and\npixels is because all of the (valuable) data in the world is in terms of text\nand images. If you look into almost any company you will find their most\nvaluable data is in spreadsheets, databases and other relational formats. These\nare not the form that are studied in introductory machine learning, but are\nfull of product numbers, student numbers, transaction numbers and other\nidentifiers that can't be interpreted naively as numbers. The field that\nstudies this sort of data has various names including relational learning,\nstatistical relational AI, and many others. This paper explains why relational\nlearning is not taking over the world -- except in a few cases with restricted\nrelations -- and what needs to be done to bring it to it's rightful prominence.", "AI": {"tldr": "AI\u5e94\u8be5\u5173\u6ce8\u5b9e\u4f53\u53ca\u5176\u5173\u7cfb\uff0c\u800c\u4e0d\u662f\u50cf\u7d20\u6216\u8bcd\u8bed\u3002\u867d\u7136\u6700\u6709\u4ef7\u503c\u7684\u6570\u636e\u662f\u5173\u7cfb\u578b\u7684\uff0c\u4f46\u5173\u7cfb\u5b66\u4e60\u5e76\u672a\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\u3002\u672c\u6587\u5c06\u63a2\u8ba8\u539f\u56e0\u5e76\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "AI\u7cfb\u7edf\u5e94\u5173\u6ce8\u5bf9\u5b9e\u4f53\uff08\u5305\u62ec\u4e8b\u4ef6\u3001\u7269\u4f53\u3001\u4e8b\u7269\uff09\u53ca\u5176\u5c5e\u6027\u548c\u5173\u7cfb\u8fdb\u884c\u5efa\u6a21\uff0c\u800c\u4e0d\u662f\u5bf9\u611f\u77e5\u6216\u63cf\u8ff0\u8fdb\u884c\u5efa\u6a21\u3002\u6700\u6709\u4ef7\u503c\u7684\u6570\u636e\u662f\u4ee5\u6587\u672c\u548c\u56fe\u50cf\u5f62\u5f0f\u5b58\u5728\u7684\uff0c\u4f46\u5b9e\u9645\u6700\u6709\u4ef7\u503c\u7684\u6570\u636e\u662f\u4ee5\u7535\u5b50\u8868\u683c\u3001\u6570\u636e\u5e93\u548c\u5176\u4ed6\u5173\u7cfb\u683c\u5f0f\u5b58\u5728\u7684\u3002", "method": "\u89e3\u91ca\u4e86\u5173\u7cfb\u5b66\u4e60\u4e3a\u4f55\u6ca1\u6709\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4ee5\u53ca\u9700\u8981\u505a\u4ec0\u4e48\u3002", "result": "\u5173\u7cfb\u5b66\u4e60\u5728\u67d0\u4e9b\u53d7\u9650\u60c5\u51b5\u4e0b\u53d6\u5f97\u4e86\u4e00\u5b9a\u7684\u6210\u529f\uff0c\u4f46\u5e76\u672a\u666e\u53ca\u3002AI\u7cfb\u7edf\u5e94\u66f4\u591a\u5730\u5173\u6ce8\u5173\u7cfb\u5b66\u4e60\uff0c\u4ee5\u5145\u5206\u5229\u7528\u6709\u4ef7\u503c\u7684\u6570\u636e\u3002", "conclusion": "\u5173\u7cfb\u5b66\u4e60\u5e76\u672a\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\uff0c\u9664\u975e\u5728\u5173\u7cfb\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u9700\u8981\u91c7\u53d6\u63aa\u65bd\u6765\u63d0\u5347\u5176\u5730\u4f4d\u3002"}}
{"id": "2408.08068", "title": "The Paradox of Spreadsheet Self-Efficacy: Social Incentives for Informal Knowledge Sharing in End-User Programming", "url": "https://arxiv.org/abs/2408.08068", "pdf": "https://arxiv.org/pdf/2408.08068", "abs": "https://arxiv.org/abs/2408.08068", "authors": ["Qing", "Xia", "Advait Sarkar", "Duncan P. Brumby", "Anna Cox"], "categories": ["cs.HC"], "comment": "8 pages", "summary": "Informal Knowledge Sharing (KS) is vital for end-user programmers to gain\nexpertise. To better understand how personal (self-efficacy), social\n(reputational gains, trust between colleagues), and software-related\n(codification effort) variables influence spreadsheet KS intention, we\nconducted a multiple regressions analysis based on survey data from spreadsheet\nusers (n=100) in administrative and finance roles. We found that high levels of\nspreadsheet self-efficacy and a perception that sharing would result in\nreputational gains predicted higher KS intention, but individuals who found\nknowledge codification effortful showed lower KS intention. We also observed\nthat regardless of occupation, users tended to report a lower sense of\nself-efficacy in their general spreadsheet proficiency, despite also reporting\nhigh self-efficacy in spreadsheet use for job-related contexts. Our findings\nsuggest that acknowledging and designing for these social and personal\nvariables can help avoid situations where experienced individuals refrain\nunnecessarily from sharing, with implications for spreadsheet design.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u7535\u5b50\u8868\u683c\u7528\u6237\u7684\u81ea\u6211\u6548\u80fd\u611f\u3001\u58f0\u8a89\u6536\u76ca\u548c\u5bf9\u77e5\u8bc6\u7f16\u7e82\u96be\u5ea6\u7684\u770b\u6cd5\u4f1a\u5f71\u54cd\u5176\u77e5\u8bc6\u5171\u4eab\u610f\u613f\u3002\u63d0\u5347\u81ea\u6211\u6548\u80fd\u611f\u548c\u58f0\u8a89\u6536\u76ca\u6709\u52a9\u4e8e\u589e\u52a0\u77e5\u8bc6\u5171\u4eab\uff0c\u800c\u611f\u89c9\u77e5\u8bc6\u7f16\u7e82\u56f0\u96be\u5219\u4f1a\u6291\u5236\u77e5\u8bc6\u5171\u4eab\u3002\u7528\u6237\u5728\u65e5\u5e38\u719f\u7ec3\u5ea6\u65b9\u9762\u81ea\u6211\u6548\u80fd\u611f\u8f83\u4f4e\uff0c\u4f46\u5728\u5de5\u4f5c\u573a\u666f\u4e2d\u5219\u8f83\u9ad8\u3002\u56e0\u6b64\uff0c\u8bbe\u8ba1\u7535\u5b50\u8868\u683c\u65f6\u5e94\u8003\u8651\u8fd9\u4e9b\u56e0\u7d20\u4ee5\u9f13\u52b1\u77e5\u8bc6\u5206\u4eab\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u4e2a\u4eba\u3001\u793e\u4f1a\u548c\u8f6f\u4ef6\u76f8\u5173\u53d8\u91cf\u5982\u4f55\u5f71\u54cd\u7535\u5b50\u8868\u683c\u77e5\u8bc6\u5171\u4eab\u610f\u613f\uff0c\u4ece\u800c\u4fc3\u8fdb\u7ec8\u7aef\u7528\u6237\u7a0b\u5e8f\u5458\uff08end-user programmers\uff09\u7684\u4e13\u4e1a\u77e5\u8bc6\u83b7\u53d6\u3002", "method": "\u901a\u8fc7\u5bf9\u6765\u81ea\u884c\u653f\u548c\u8d22\u52a1\u5c97\u4f4d\u7684\u7535\u5b50\u8868\u683c\u7528\u6237\uff08n=100\uff09\u8fdb\u884c\u7684\u8c03\u67e5\u6570\u636e\u8fdb\u884c\u591a\u5143\u56de\u5f52\u5206\u6790\uff0c\u7814\u7a76\u4e86\u4e2a\u4eba\uff08\u81ea\u6211\u6548\u80fd\u611f\uff09\u3001\u793e\u4f1a\uff08\u58f0\u8a89\u6536\u76ca\u3001\u540c\u4e8b\u95f4\u7684\u4fe1\u4efb\uff09\u548c\u8f6f\u4ef6\u76f8\u5173\uff08\u7f16\u7e82\u5de5\u4f5c\u91cf\uff09\u53d8\u91cf\u5982\u4f55\u5f71\u54cd\u7535\u5b50\u8868\u683c\u77e5\u8bc6\u5171\u4eab\u610f\u613f\u3002", "result": "\u9ad8\u6c34\u5e73\u7684\u7535\u5b50\u8868\u683c\u81ea\u6211\u6548\u80fd\u611f\u548c\u8ba4\u77e5\u5230\u7684\u58f0\u8a89\u6536\u76ca\u53ef\u4ee5\u9884\u6d4b\u66f4\u9ad8\u7684\u77e5\u8bc6\u5171\u4eab\u610f\u613f\uff0c\u800c\u8ba4\u4e3a\u77e5\u8bc6\u7f16\u7e82\u8d39\u529b\u5219\u4f1a\u964d\u4f4e\u77e5\u8bc6\u5171\u4eab\u610f\u613f\u3002\u7528\u6237\u666e\u904d\u8868\u793a\u5728\u65e5\u5e38\u7535\u5b50\u8868\u683c\u719f\u7ec3\u5ea6\u65b9\u9762\u81ea\u6211\u6548\u80fd\u611f\u8f83\u4f4e\uff0c\u4f46\u5728\u5de5\u4f5c\u76f8\u5173\u573a\u666f\u4e0b\u5219\u8868\u73b0\u51fa\u9ad8\u81ea\u6211\u6548\u80fd\u611f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u5347\u7535\u5b50\u8868\u683c\u81ea\u6211\u6548\u80fd\u611f\u548c\u8ba4\u77e5\u5230\u7684\u58f0\u8a89\u6536\u76ca\u53ef\u4ee5\u9884\u6d4b\u66f4\u9ad8\u7684\u77e5\u8bc6\u5171\u4eab\u610f\u613f\uff0c\u800c\u8ba4\u4e3a\u77e5\u8bc6\u7f16\u7e82\u8d39\u529b\u5219\u4f1a\u964d\u4f4e\u77e5\u8bc6\u5171\u4eab\u610f\u613f\u3002\u6b64\u5916\uff0c\u65e0\u8bba\u4f55\u79cd\u804c\u4e1a\uff0c\u7528\u6237\u666e\u904d\u8868\u793a\u5728\u65e5\u5e38\u7535\u5b50\u8868\u683c\u719f\u7ec3\u5ea6\u65b9\u9762\u81ea\u6211\u6548\u80fd\u611f\u8f83\u4f4e\uff0c\u4f46\u5728\u5de5\u4f5c\u76f8\u5173\u573a\u666f\u4e0b\u5219\u8868\u73b0\u51fa\u9ad8\u81ea\u6211\u6548\u80fd\u611f\u3002\u8fd9\u4e9b\u53d1\u73b0\u63d0\u793a\uff0c\u5728\u8bbe\u8ba1\u7535\u5b50\u8868\u683c\u65f6\uff0c\u5e94\u8003\u8651\u548c\u8bbe\u8ba1\u8fd9\u4e9b\u793e\u4f1a\u53ca\u4e2a\u4eba\u53d8\u91cf\uff0c\u4ee5\u907f\u514d\u6709\u7ecf\u9a8c\u7684\u7528\u6237\u4e0d\u5fc5\u8981\u5730\u56de\u907f\u5206\u4eab\uff0c\u8fd9\u5bf9\u7535\u5b50\u8868\u683c\u7684\u8bbe\u8ba1\u5177\u6709\u542f\u793a\u610f\u4e49\u3002"}}
{"id": "2507.16073", "title": "Buckaroo: A Direct Manipulation Visual Data Wrangler", "url": "https://arxiv.org/abs/2507.16073", "pdf": "https://arxiv.org/pdf/2507.16073", "abs": "https://arxiv.org/abs/2507.16073", "authors": ["Annabelle Warner", "Andrew McNutt", "Paul Rosen", "El Kindi Rezig"], "categories": ["cs.HC", "cs.DB"], "comment": "Accepted to VLDB25 Demo track", "summary": "Preparing datasets -- a critical phase known as data wrangling -- constitutes\nthe dominant phase of data science development, consuming upwards of 80% of the\ntotal project time. This phase encompasses a myriad of tasks: parsing data,\nrestructuring it for analysis, repairing inaccuracies, merging sources,\neliminating duplicates, and ensuring overall data integrity. Traditional\napproaches, typically through manual coding in languages such as Python or\nusing spreadsheets, are not only laborious but also error-prone. These issues\nrange from missing entries and formatting inconsistencies to data type\ninaccuracies, all of which can affect the quality of downstream tasks if not\nproperly corrected. To address these challenges, we present Buckaroo, a\nvisualization system to highlight discrepancies in data and enable on-the-spot\ncorrections through direct manipulations of visual objects. Buckaroo (1)\nautomatically finds \"interesting\" data groups that exhibit anomalies compared\nto the rest of the groups and recommends them for inspection; (2) suggests\nwrangling actions that the user can choose to repair the anomalies; and (3)\nallows users to visually manipulate their data by displaying the effects of\ntheir wrangling actions and offering the ability to undo or redo these actions,\nwhich supports the iterative nature of data wrangling. A video companion is\navailable at https://youtu.be/iXdCYbvpQVE", "AI": {"tldr": "Buckaroo\u662f\u4e00\u4e2a\u53ef\u89c6\u5316\u7cfb\u7edf\uff0c\u65e8\u5728\u7b80\u5316\u548c\u52a0\u901f\u6570\u636e\u6574\u7406\u8fc7\u7a0b\uff0c\u901a\u8fc7\u81ea\u52a8\u8bc6\u522b\u6570\u636e\u5f02\u5e38\u3001\u63a8\u8350\u4fee\u590d\u64cd\u4f5c\u4ee5\u53ca\u63d0\u4f9b\u76f4\u89c2\u7684\u53ef\u89c6\u5316\u4ea4\u4e92\u6765\u89e3\u51b3\u4f20\u7edf\u624b\u52a8\u65b9\u6cd5\u7684\u75db\u70b9\u3002", "motivation": "\u6570\u636e\u6574\u7406\u662f\u6570\u636e\u79d1\u5b66\u9879\u76ee\u4e2d\u7684\u5173\u952e\u4e14\u8017\u65f6\u7684\u9636\u6bb5\uff08\u5360\u9879\u76ee\u65f6\u95f4\u768480%\u4ee5\u4e0a\uff09\uff0c\u4f20\u7edf\u7684\u624b\u52a8\u7f16\u7801\u6216\u7535\u5b50\u8868\u683c\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u548c\u6613\u51fa\u9519\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u7684\u6570\u636e\u8d28\u91cf\u3002", "method": "Buckaroo\u662f\u4e00\u4e2a\u53ef\u89c6\u5316\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5e2e\u52a9\u7528\u6237\u8fdb\u884c\u6570\u636e\u6574\u7406\uff1a(1) \u81ea\u52a8\u67e5\u627e\u5e76\u63a8\u8350\u5305\u542b\u5f02\u5e38\u503c\u7684\u6570\u636e\u7ec4\u4ee5\u4f9b\u68c0\u67e5\uff1b(2) \u5efa\u8bae\u53ef\u7528\u4e8e\u4fee\u590d\u5f02\u5e38\u503c\u7684\u6574\u7406\u64cd\u4f5c\uff1b(3) \u901a\u8fc7\u663e\u793a\u6574\u7406\u64cd\u4f5c\u7684\u6548\u679c\u5e76\u5141\u8bb8\u7528\u6237\u64a4\u9500\u6216\u91cd\u505a\u64cd\u4f5c\uff0c\u652f\u6301\u7528\u6237\u8fdb\u884c\u53ef\u89c6\u5316\u6570\u636e\u64cd\u4f5c\u548c\u8fed\u4ee3\u5f0f\u6570\u636e\u6574\u7406\u3002", "result": "Buckaroo\u901a\u8fc7\u81ea\u52a8\u5316\u5f02\u5e38\u503c\u68c0\u6d4b\u3001\u63d0\u4f9b\u64cd\u4f5c\u5efa\u8bae\u548c\u652f\u6301\u53ef\u89c6\u5316\u4ea4\u4e92\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u6574\u7406\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "conclusion": "Buckaroo\u901a\u8fc7\u53ef\u89c6\u5316\u7cfb\u7edf\u7a81\u51fa\u6570\u636e\u5dee\u5f02\uff0c\u5e76\u901a\u8fc7\u76f4\u63a5\u64cd\u4f5c\u89c6\u89c9\u5bf9\u8c61\u8fdb\u884c\u5373\u65f6\u66f4\u6b63\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u6570\u636e\u6574\u7406\u8017\u65f6\u4e14\u6613\u51fa\u9519\u7684\u95ee\u9898\u3002"}}
{"id": "2507.10456", "title": "Radif Corpus: A Symbolic Dataset for Non-Metric Iranian Classical Music", "url": "https://arxiv.org/abs/2507.10456", "pdf": "https://arxiv.org/pdf/2507.10456", "abs": "https://arxiv.org/abs/2507.10456", "authors": ["Maziar Kanani", "Sean O Leary", "James McDermott"], "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Non-metric music forms the core of the repertoire in Iranian classical music.\nDastgahi music serves as the underlying theoretical system for both Iranian art\nmusic and certain folk traditions. At the heart of Iranian classical music lies\nthe radif, a foundational repertoire that organizes melodic material central to\nperformance and pedagogy.\n  In this study, we introduce the first digital corpus representing the\ncomplete non-metrical radif repertoire, covering all 13 existing components of\nthis repertoire. We provide MIDI files (about 281 minutes in total) and data\nspreadsheets describing notes, note durations, intervals, and hierarchical\nstructures for 228 pieces of music. We faithfully represent the tonality\nincluding quarter-tones, and the non-metric aspect. Furthermore, we provide\nsupporting basic statistics, and measures of complexity and similarity over the\ncorpus.\n  Our corpus provides a platform for computational studies of Iranian classical\nmusic. Researchers might employ it in studying melodic patterns, investigating\nimprovisational styles, or for other tasks in music information retrieval,\nmusic theory, and computational (ethno)musicology.", "AI": {"tldr": "\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b281\u5206\u949f\u4f0a\u6717\u53e4\u5178\u97f3\u4e50\u7684\u6570\u5b57\u8bed\u6599\u5e93\uff0c\u5305\u62ec228\u9996\u4f5c\u54c1\u7684\u8be6\u7ec6\u6570\u636e\uff0c\u53ef\u7528\u4e8e\u8ba1\u7b97\u97f3\u4e50\u5b66\u7814\u7a76\u3002", "motivation": "\u4f0a\u6717\u53e4\u5178\u97f3\u4e50\u7684\u6838\u5fc3\u662fradif\uff0c\u8fd9\u662f\u4e00\u4e2a\u7ec4\u7ec7\u65cb\u5f8b\u6750\u6599\u7684\u7cfb\u7edf\uff0c\u5bf9\u8868\u6f14\u548c\u6559\u5b66\u6cd5\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u8fd8\u6ca1\u6709\u4e00\u4e2a\u5b8c\u6574\u7684\u6570\u5b57radif\u8bed\u6599\u5e93\u53ef\u4f9b\u7814\u7a76\u3002", "method": "\u6211\u4eec\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u4ee3\u8868\u5b8c\u6574\u7684\u975e\u516c\u5236radif\u66f2\u76ee\u7684\u6570\u5b57\u8bed\u6599\u5e93\uff0c\u5305\u62ec\u8be5\u66f2\u76ee\u7684\u6240\u670913\u4e2a\u73b0\u6709\u7ec4\u6210\u90e8\u5206\u3002\u6211\u4eec\u63d0\u4f9bMIDI\u6587\u4ef6\uff08\u603b\u8ba1\u7ea6281\u5206\u949f\uff09\u548c\u6570\u636e\u7535\u5b50\u8868\u683c\uff0c\u63cf\u8ff0\u4e86228\u9996\u97f3\u4e50\u4f5c\u54c1\u7684\u97f3\u7b26\u3001\u97f3\u7b26\u65f6\u503c\u3001\u97f3\u7a0b\u548c\u5c42\u6b21\u7ed3\u6784\u3002\u6211\u4eec\u5fe0\u5b9e\u5730\u8868\u793a\u4e86\u5305\u62ec\u56db\u5206\u97f3\u7b26\u5728\u5185\u7684\u97f3\u8c03\u548c\u975e\u516c\u5236\u65b9\u9762\u3002", "result": "\u6211\u4eec\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u4ee3\u8868\u5b8c\u6574\u975e\u516c\u5236radif\u66f2\u76ee\u7684\u6570\u5b57\u8bed\u6599\u5e93\uff0c\u5305\u62ec281\u5206\u949f\u7684MIDI\u6587\u4ef6\u548c\u6570\u636e\u7535\u5b50\u8868\u683c\uff0c\u63cf\u8ff0\u4e86228\u9996\u97f3\u4e50\u4f5c\u54c1\u7684\u5404\u79cd\u97f3\u4e50\u7279\u5f81\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63d0\u4f9b\u4e86\u652f\u6301\u6027\u57fa\u672c\u7edf\u8ba1\u6570\u636e\u4ee5\u53ca\u8bed\u6599\u5e93\u7684\u590d\u6742\u6027\u548c\u76f8\u4f3c\u6027\u5ea6\u91cf\u3002", "conclusion": "\u8be5\u8bed\u6599\u5e93\u4e3a\u4f0a\u6717\u53e4\u5178\u97f3\u4e50\u7684\u8ba1\u7b97\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u53f0\uff0c\u7814\u7a76\u4eba\u5458\u53ef\u4ee5\u5229\u7528\u5b83\u6765\u7814\u7a76\u65cb\u5f8b\u6a21\u5f0f\u3001\u8c03\u67e5\u5373\u5174\u98ce\u683c\u6216\u7528\u4e8e\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u3001\u4e50\u7406\u548c\u8ba1\u7b97\uff08\u6c11\u65cf\uff09\u97f3\u4e50\u5b66\u4e2d\u7684\u5176\u4ed6\u4efb\u52a1\u3002"}}
{"id": "2407.10657", "title": "An Empirical Study of Validating Synthetic Data for Formula Generation", "url": "https://arxiv.org/abs/2407.10657", "pdf": "https://arxiv.org/pdf/2407.10657", "abs": "https://arxiv.org/abs/2407.10657", "authors": ["Usneek Singh", "Jos\u00e9 Cambronero", "Sumit Gulwani", "Aditya Kanade", "Anirudh Khatry", "Vu Le", "Mukul Singh", "Gust Verbruggen"], "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at Findings of NAACL", "summary": "Large language models (LLMs) can be leveraged to help with writing formulas\nin spreadsheets, but resources on these formulas are scarce, impacting both the\nbase performance of pre-trained models and limiting the ability to fine-tune\nthem. Given a corpus of formulas, we can use a(nother) model to generate\nsynthetic natural language utterances for fine-tuning. However, it is important\nto validate whether the NL generated by the LLM is indeed accurate to be\nbeneficial for fine-tuning. In this paper, we provide empirical results on the\nimpact of validating these synthetic training examples with surrogate\nobjectives that evaluate the accuracy of the synthetic annotations. We\ndemonstrate that validation improves performance over raw data across four\nmodels (2 open and 2 closed weight). Interestingly, we show that although\nvalidation tends to prune more challenging examples, it increases the\ncomplexity of problems that models can solve after being fine-tuned on\nvalidated data.", "AI": {"tldr": "\u9a8c\u8bc1LLM\u751f\u6210\u7684\u7535\u5b50\u8868\u683c\u516c\u5f0f\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u5e76\u589e\u52a0\u5176\u89e3\u51b3\u95ee\u9898\u7684\u590d\u6742\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5728\u7535\u5b50\u8868\u683c\u516c\u5f0f\u4efb\u52a1\u4e0a\u7684\u8d44\u6e90\u7a00\u7f3a\uff0c\u5f71\u54cd\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6027\u80fd\u548c\u5fae\u8c03\u80fd\u529b\u3002\u9700\u8981\u9a8c\u8bc1LLM\u751f\u6210\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u51c6\u786e\u6027\uff0c\u4ee5\u786e\u4fdd\u5176\u5bf9\u5fae\u8c03\u6709\u76ca\u3002", "method": "\u4f7f\u7528\u4ee3\u7406\u76ee\u6807\u6765\u8bc4\u4f30\u5408\u6210\u6807\u6ce8\u7684\u51c6\u786e\u6027\uff0c\u5e76\u63d0\u4f9b\u5b9e\u8bc1\u7ed3\u679c\u3002", "result": "\u9a8c\u8bc1\u53ef\u4ee5\u63d0\u9ad8\u5728\u56db\u79cd\u6a21\u578b\uff082\u4e2a\u5f00\u653e\u6743\u91cd\u548c2\u4e2a\u5c01\u95ed\u6743\u91cd\uff09\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u589e\u52a0\u6a21\u578b\u89e3\u51b3\u95ee\u9898\u7684\u590d\u6742\u6027\u3002", "conclusion": "\u9a8c\u8bc1\u5408\u6210\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u5728\u7535\u5b50\u8868\u683c\u516c\u5f0f\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5c3d\u7ba1\u9a8c\u8bc1\u4f1a pruning \u6389\u66f4\u5177\u6311\u6218\u6027\u7684\u4f8b\u5b50\uff0c\u4f46\u5b83\u4f1a\u589e\u52a0\u6a21\u578b\u5728\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u6570\u636e\u5fae\u8c03\u540e\u53ef\u4ee5\u89e3\u51b3\u7684\u95ee\u9898\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2507.06171", "title": "Data-Semantics-Aware Recommendation of Diverse Pivot Tables", "url": "https://arxiv.org/abs/2507.06171", "pdf": "https://arxiv.org/pdf/2507.06171", "abs": "https://arxiv.org/abs/2507.06171", "authors": ["Whanhee Cho", "Anna Fariha"], "categories": ["cs.DB"], "comment": null, "summary": "Data summarization is essential to discover insights from large datasets. In\na spreadsheets, pivot tables offer a convenient way to summarize tabular data\nby computing aggregates over some attributes, grouped by others. However,\nidentifying attribute combinations that will result in useful pivot tables\nremains a challenge, especially for high-dimensional datasets. We formalize the\nproblem of automatically recommending insightful and interpretable pivot\ntables, eliminating the tedious manual process. A crucial aspect of\nrecommending a set of pivot tables is to diversify them. Traditional works\ninadequately address the table-diversification problem, which leads us to\nconsider the problem of pivot table diversification.\n  We present SAGE, a data-semantics-aware system for recommending k-budgeted\ndiverse pivot tables, overcoming the shortcomings of prior work for top-k\nrecommendations that cause redundancy. SAGE ensures that each pivot table is\ninsightful, interpretable, and adaptive to the user's actions and preferences,\nwhile also guaranteeing that the set of pivot tables are different from each\nother, offering a diverse recommendation. We make two key technical\ncontributions: (1) a data-semantics-aware model to measure the utility of a\nsingle pivot table and the diversity of a set of pivot tables, and (2) a\nscalable greedy algorithm that can efficiently select a set of diverse pivot\ntables of high utility, by leveraging data semantics to significantly reduce\nthe combinatorial search space. Our extensive experiments on three real-world\ndatasets show that SAGE outperforms alternative approaches, and efficiently\nscales to accommodate high-dimensional datasets. Additionally, we present\nseveral case studies to highlight SAGE's qualitative effectiveness over\ncommercial software and Large Language Models (LLMs).", "AI": {"tldr": "SAGE \u901a\u8fc7\u5176\u65b0\u9896\u7684\u6570\u636e\u8bed\u4e49\u6a21\u578b\u548c\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u63a8\u8350\u591a\u6837\u5316\u4e14\u6709\u7528\u7684\u6570\u636e\u900f\u89c6\u8868\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u5b9e\u9a8c\u548c\u6848\u4f8b\u7814\u7a76\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u96c6\u65f6\uff0c\u5c24\u5176\u662f\u5728\u7535\u5b50\u8868\u683c\u4e2d\uff0c\u8bc6\u522b\u80fd\u591f\u63d0\u4f9b\u6709\u7528\u6458\u8981\u7684\u5c5e\u6027\u7ec4\u5408\u4ee5\u521b\u5efa\u6570\u636e\u900f\u89c6\u8868\u662f\u4e00\u4e2a\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6570\u636e\u900f\u89c6\u8868\u7684\u591a\u6837\u5316\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5bfc\u81f4\u63a8\u8350\u7ed3\u679c\u5197\u4f59\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u63a8\u8350\u6709\u89c1\u5730\u4e14\u53ef\u89e3\u91ca\u7684\u6570\u636e\u900f\u89c6\u8868\u3002", "method": "SAGE \u662f\u4e00\u4e2a\u6570\u636e\u8bed\u4e49\u611f\u77e5\u7cfb\u7edf\uff0c\u7528\u4e8e\u63a8\u8350 k \u4e2a\u6709\u9884\u7b97\u9650\u5236\u7684\u591a\u6837\u5316\u6570\u636e\u900f\u89c6\u8868\u3002\u5b83\u901a\u8fc7\u4e00\u4e2a\u6570\u636e\u8bed\u4e49\u611f\u77e5\u6a21\u578b\u6765\u8861\u91cf\u5355\u4e2a\u6570\u636e\u900f\u89c6\u8868\u7684\u6548\u7528\u548c\u4e00\u7ec4\u6570\u636e\u900f\u89c6\u8868\u7684\u591a\u6837\u6027\uff0c\u5e76\u4f7f\u7528\u53ef\u6269\u5c55\u7684\u8d2a\u5a6a\u7b97\u6cd5\u6765\u9009\u62e9\u4e00\u7ec4\u5177\u6709\u9ad8\u6548\u7528\u7684\u591a\u6837\u5316\u6570\u636e\u900f\u89c6\u8868\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u6570\u636e\u8bed\u4e49\u6765\u663e\u8457\u51cf\u5c11\u7ec4\u5408\u641c\u7d22\u7a7a\u95f4\u3002", "result": "SAGE \u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u5730\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0cSAGE \u5728\u5b9a\u6027\u4e0a\u4e5f\u4f18\u4e8e\u5546\u4e1a\u8f6f\u4ef6\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "SAGE \u7cfb\u7edf\u901a\u8fc7\u5176\u6570\u636e\u8bed\u4e49\u611f\u77e5\u6a21\u578b\u548c\u53ef\u6269\u5c55\u7684\u8d2a\u5a6a\u7b97\u6cd5\uff0c\u5728\u63a8\u8350 k \u4e2a\u591a\u6837\u5316\u4e14\u6709\u7528\u7684\u6570\u636e\u900f\u89c6\u8868\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6709\u6548\u6269\u5c55\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0cSAGE \u5728\u5b9a\u6027\u65b9\u9762\u4e5f\u4f18\u4e8e\u5546\u4e1a\u8f6f\u4ef6\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2506.17330", "title": "Large Language Models for Spreadsheets: Benchmarking Progress and Evaluating Performance with FLARE", "url": "https://arxiv.org/abs/2506.17330", "pdf": "https://arxiv.org/pdf/2506.17330", "abs": "https://arxiv.org/abs/2506.17330", "authors": ["Simon Thorne"], "categories": ["cs.SE"], "comment": "18 Pages, 10 Tables, 1 Colour Figure", "summary": "Large Language Models (LLMs) have demonstrated some significant capabilities\nacross various domains; however, their effectiveness in spreadsheet related\ntasks remains underexplored. This study introduces a foundation for a\ncomprehensive benchmark framework to evaluate the performance of leading LLMs\nin executing spreadsheet functions, formula generation and data manipulation\ntasks. The benchmark encompasses tasks ranging from basic formula creation to\ncomplex, real world spreadsheet scenarios. Our findings reveal that while LLMs\nexhibit proficiency in straightforward tasks, they often falter in complex,\nmulti step operations, frequently producing plausible yet incorrect outputs.\nThese results underscore the limitations of current LLMs in handling\nspreadsheet tasks that require precise logical reasoning and highlight the need\nfor integrating symbolic reasoning capabilities into LLM architectures. To\nsupport this, we introduce FLARE (Formula Logic, Auditing, Reasoning and\nEvaluation) a new benchmark for evaluating LLM performance on real-world\nspreadsheet logic, auditing, and reasoning tasks.", "AI": {"tldr": "LLMs struggle with complex spreadsheet tasks requiring logical reasoning; a new benchmark, FLARE, is introduced to evaluate and improve their performance in this area.", "motivation": "To evaluate the underexplored effectiveness of LLMs in spreadsheet-related tasks and address their limitations in handling precise logical reasoning.", "method": "Introduced a foundation for a comprehensive benchmark framework to evaluate LLM performance in spreadsheet functions, formula generation, and data manipulation. Developed FLARE (Formula Logic, Auditing, Reasoning and Evaluation) benchmark for real-world spreadsheet logic, auditing, and reasoning tasks.", "result": "LLMs show proficiency in straightforward spreadsheet tasks but frequently falter in complex, multi-step operations, generating plausible but incorrect outputs.", "conclusion": "LLMs are proficient in simple spreadsheet tasks but struggle with complex, multi-step operations, producing plausible but incorrect outputs. This highlights the need for integrating symbolic reasoning capabilities into LLM architectures."}}
{"id": "2506.12339", "title": "SheetMind: An End-to-End LLM-Powered Multi-Agent Framework for Spreadsheet Automation", "url": "https://arxiv.org/abs/2506.12339", "pdf": "https://arxiv.org/pdf/2506.12339", "abs": "https://arxiv.org/abs/2506.12339", "authors": ["Ruiyan Zhu", "Xi Cheng", "Ke Liu", "Brian Zhu", "Daniel Jin", "Neeraj Parihar", "Zhoutian Xu", "Oliver Gao"], "categories": ["cs.HC", "cs.AI"], "comment": "Ruiyan Zhu and Xi Cheng contributed equally to this work", "summary": "We present SheetMind, a modular multi-agent framework powered by large\nlanguage models (LLMs) for spreadsheet automation via natural language\ninstructions. The system comprises three specialized agents: a Manager Agent\nthat decomposes complex user instructions into subtasks; an Action Agent that\ntranslates these into structured commands using a Backus Naur Form (BNF)\ngrammar; and a Reflection Agent that validates alignment between generated\nactions and the user's original intent. Integrated into Google Sheets via a\nWorkspace extension, SheetMind supports real-time interaction without requiring\nscripting or formula knowledge. Experiments on benchmark datasets demonstrate\nan 80 percent success rate on single step tasks and approximately 70 percent on\nmulti step instructions, outperforming ablated and baseline variants. Our\nresults highlight the effectiveness of multi agent decomposition and grammar\nbased execution for bridging natural language and spreadsheet functionalities.", "AI": {"tldr": "SheetMind\u662f\u4e00\u4e2a\u7531LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u5b9e\u73b0\u7535\u5b50\u8868\u683c\u81ea\u52a8\u5316\u3002\u5b83\u5305\u542b\u5206\u89e3\u4efb\u52a1\u3001\u7ffb\u8bd1\u547d\u4ee4\u548c\u9a8c\u8bc1\u610f\u56fe\u7684\u667a\u80fd\u4f53\uff0c\u5728Google\u8868\u683c\u4e2d\u8fd0\u884c\uff0c\u6210\u529f\u7387\u9ad8\u3002", "motivation": "\u4e3a\u4e86\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u5b9e\u73b0\u7535\u5b50\u8868\u683c\u81ea\u52a8\u5316\uff0c\u5e76\u89e3\u51b3\u7528\u6237\u65e0\u9700\u811a\u672c\u6216\u516c\u5f0f\u77e5\u8bc6\u5373\u53ef\u64cd\u4f5c\u7535\u5b50\u8868\u683c\u7684\u9700\u6c42\u3002", "method": "SheetMind\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e00\u4e2a\u7ba1\u7406\u5668\u667a\u80fd\u4f53\uff08\u5206\u89e3\u4efb\u52a1\uff09\u3001\u4e00\u4e2a\u52a8\u4f5c\u667a\u80fd\u4f53\uff08\u5c06\u4efb\u52a1\u8f6c\u5316\u4e3aBNF\u8bed\u6cd5\u547d\u4ee4\uff09\u548c\u4e00\u4e2a\u53cd\u601d\u667a\u80fd\u4f53\uff08\u9a8c\u8bc1\u547d\u4ee4\u4e0e\u7528\u6237\u610f\u56fe\u7684\u4e00\u81f4\u6027\uff09\u3002\u5b83\u901a\u8fc7Workspace\u6269\u5c55\u96c6\u6210\u5230Google\u8868\u683c\u4e2d\uff0c\u652f\u6301\u5b9e\u65f6\u4ea4\u4e92\uff0c\u65e0\u9700\u811a\u672c\u6216\u516c\u5f0f\u77e5\u8bc6\u3002", "result": "SheetMind\u5728\u5355\u6b65\u4efb\u52a1\u4e0a\u7684\u6210\u529f\u7387\u4e3a80%\uff0c\u5728\u591a\u6b65\u6307\u4ee4\u4e0a\u7684\u6210\u529f\u7387\u7ea6\u4e3a70%\uff0c\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "SheetMind\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5206\u89e3\u548c\u57fa\u4e8e\u8bed\u6cd5\u7684\u6267\u884c\uff0c\u6210\u529f\u5730\u5c06\u81ea\u7136\u8bed\u8a00\u548c\u7535\u5b50\u8868\u683c\u529f\u80fd\u8fde\u63a5\u8d77\u6765\u3002"}}
{"id": "2506.09216", "title": "\"How do you even know that stuff?\": Barriers to expertise sharing among spreadsheet users", "url": "https://arxiv.org/abs/2506.09216", "pdf": "https://arxiv.org/pdf/2506.09216", "abs": "https://arxiv.org/abs/2506.09216", "authors": ["Qing", "Xia", "Advait Sarkar", "Duncan Brumby", "Anna Cox"], "categories": ["cs.HC", "cs.CY", "H.5"], "comment": "Accepted at CSCW 2025", "summary": "Spreadsheet collaboration provides valuable opportunities for learning and\nexpertise sharing between colleagues. Sharing expertise is essential for the\nretention of important technical skillsets within organisations, but previous\nstudies suggest that spreadsheet experts often fail to disseminate their\nknowledge to others. We suggest that social norms and beliefs surrounding the\nvalue of spreadsheet use significantly influence user engagement in sharing\nbehaviours. To explore this, we conducted 31 semi-structured interviews with\nprofessional spreadsheet users from two separate samples. We found that\nspreadsheet providers face challenges in adapting highly personalised\nstrategies to often subjective standards and evaluating the appropriate social\ntiming of sharing. In addition, conflicted self-evaluations of one's\nspreadsheet expertise, dismissive normative beliefs about the value of this\nknowledge, and concerns about the potential disruptions associated with\ncollaboration can further deter sharing. We suggest these observations reflect\nthe challenges of long-term learning in feature-rich software designed\nprimarily with initial learnability in mind. We therefore provide implications\nfor design to navigate this tension. Overall, our findings demonstrate how the\ncomplex interaction between technology design and social dynamics can shape\ncollaborative learning behaviours in the context of feature-rich software.", "AI": {"tldr": "Spreadsheet collaboration can be hindered by social factors and individual perceptions of expertise, suggesting a need for design that better supports knowledge sharing in complex software.", "motivation": "previous studies suggest that spreadsheet experts often fail to disseminate their knowledge to others. We suggest that social norms and beliefs surrounding the value of spreadsheet use significantly influence user engagement in sharing behaviours.", "method": "31 semi-structured interviews with professional spreadsheet users from two separate samples", "result": "spreadsheet providers face challenges in adapting highly personalised strategies to often subjective standards and evaluating the appropriate social timing of sharing. In addition, conflicted self-evaluations of one's spreadsheet expertise, dismissive normative beliefs about the value of this knowledge, and concerns about the potential disruptions associated with collaboration can further deter sharing.", "conclusion": " the complex interaction between technology design and social dynamics can shape collaborative learning behaviours in the context of feature-rich software"}}
{"id": "2506.05587", "title": "MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark", "url": "https://arxiv.org/abs/2506.05587", "pdf": "https://arxiv.org/pdf/2506.05587", "abs": "https://arxiv.org/abs/2506.05587", "authors": ["Junjie Xing", "Yeye He", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Lingjiao Chen", "Dongmei Zhang", "Surajit Chaudhuri", "H. V. Jagadish"], "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "comment": null, "summary": "Tables and table-based use cases play a crucial role in many important\nreal-world applications, such as spreadsheets, databases, and computational\nnotebooks, which traditionally require expert-level users like data engineers,\ndata analysts, and database administrators to operate. Although LLMs have shown\nremarkable progress in working with tables (e.g., in spreadsheet and database\ncopilot scenarios), comprehensive benchmarking of such capabilities remains\nlimited. In contrast to an extensive and growing list of NLP benchmarks,\nevaluations of table-related tasks are scarce, and narrowly focus on tasks like\nNL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks\nthat professional users face. This gap limits our understanding and model\nprogress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 30K\nquestions across 25 real-world table tasks, designed to comprehensively\nevaluate models ability to understand, reason, and manipulate real tables at\nthe expert-level. These tasks are drawn from decades' worth of computer science\nresearch on tabular data, with a focus on complex table tasks faced by\nprofessional users. We show that MMTU require a combination of skills --\nincluding table understanding, reasoning, and coding -- that remain challenging\nfor today's frontier models, where even frontier reasoning models like OpenAI\no4-mini and DeepSeek R1 score only around 60%, suggesting significant room for\nimprovement. We highlight key findings in our evaluation using MMTU and hope\nthat this benchmark drives further advances in understanding and developing\nfoundation models for structured data processing and analysis. Our code and\ndata are available at https://github.com/MMTU-Benchmark/MMTU and\nhttps://huggingface.co/datasets/MMTU-benchmark/MMTU.", "AI": {"tldr": "MMTU\u662f\u4e00\u4e2a\u5305\u542b30K+\u95ee\u9898\u548c25\u4e2a\u771f\u5b9e\u4e16\u754c\u8868\u683c\u4efb\u52a1\u7684\u5927\u578b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u8868\u683c\u6570\u636e\u4e0a\u7684\u4e13\u5bb6\u7ea7\u7406\u89e3\u3001\u63a8\u7406\u548c\u64cd\u4f5c\u80fd\u529b\u3002\u5f53\u524d\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u51f8\u663e\u4e86\u5728\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u53d1\u5c55\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u57fa\u51c6\u6d4b\u8bd5\u867d\u7136\u5e7f\u6cdb\uff0c\u4f46\u9488\u5bf9\u8868\u683c\u76f8\u5173\u4efb\u52a1\u7684\u8bc4\u4f30\u5374\u6709\u9650\uff0c\u5e76\u4e14\u8fc7\u4e8e\u5173\u6ce8\u81ea\u7136\u8bed\u8a00\u5230SQL\u548c\u8868\u683c\u95ee\u7b54\u7b49\u7279\u5b9a\u4efb\u52a1\uff0c\u5ffd\u7565\u4e86\u4e13\u4e1a\u7528\u6237\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6240\u9762\u4e34\u7684\u66f4\u5e7f\u6cdb\u7684\u4efb\u52a1\u3002\u8fd9\u79cd\u4e0d\u8db3\u9650\u5236\u4e86\u5bf9\u6a21\u578b\u80fd\u529b\u5728\u8fd9\u4e00\u91cd\u8981\u9886\u57df\u7684\u7406\u89e3\u548c\u8fdb\u5c55\u3002", "method": "MMTU\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bbe\u8ba1\u5305\u542b\u4e86\u6765\u81ea\u6570\u5341\u5e74\u5173\u4e8e\u8868\u683c\u6570\u636e\u7684\u8ba1\u7b97\u673a\u79d1\u5b66\u7814\u7a76\u7684\u590d\u6742\u8868\u683c\u4efb\u52a1\uff0c\u4e13\u6ce8\u4e8e\u4e13\u4e1a\u7528\u6237\u9762\u4e34\u7684\u6311\u6218\u3002\u901a\u8fc7\u5728MMTU\u4e0a\u8bc4\u4f30\u5305\u62ecOpenAI o4-mini\u548cDeepSeek R1\u5728\u5185\u7684\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5b83\u4eec\u5728\u8868\u683c\u7406\u89e3\u3001\u63a8\u7406\u548c\u7f16\u7801\u7b49\u65b9\u9762\u7684\u80fd\u529b\u5c40\u9650\u6027\u3002", "result": "\u73b0\u6709\u524d\u6cbf\u6a21\u578b\uff08\u5982OpenAI o4-mini\u548cDeepSeek R1\uff09\u5728MMTU\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5f97\u5206\u4ec5\u4e3a60%\u5de6\u53f3\uff0c\u8868\u660e\u5728\u8868\u683c\u7406\u89e3\u3001\u63a8\u7406\u548c\u7f16\u7801\u7b49\u7efc\u5408\u6280\u80fd\u65b9\u9762\u4ecd\u6709\u5f88\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "MMTU\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b30K\u4ee5\u4e0a\u7684\u95ee\u9898\u548c25\u4e2a\u73b0\u5b9e\u4e16\u754c\u7684\u8868\u683c\u4efb\u52a1\uff0c\u65e8\u5728\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u5728\u4e13\u5bb6\u7ea7\u522b\u4e0a\u7406\u89e3\u3001\u63a8\u7406\u548c\u64cd\u4f5c\u771f\u5b9e\u8868\u683c\u7684\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u5f53\u4eca\u524d\u6cbf\u6a21\u578b\u5728\u5904\u7406\u8868\u683c\u6570\u636e\u65b9\u9762\u4ecd\u5b58\u5728\u663e\u8457\u7684\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2506.03232", "title": "Pivoting the paradigm: the role of spreadsheets in K-12 data science", "url": "https://arxiv.org/abs/2506.03232", "pdf": "https://arxiv.org/pdf/2506.03232", "abs": "https://arxiv.org/abs/2506.03232", "authors": ["Oren Tirschwell", "Nicholas Jon Horton"], "categories": ["stat.OT", "cs.CY"], "comment": null, "summary": "Spreadsheet tools are widely accessible to and commonly used by K-12 students\nand teachers. They have an important role in data collection and organization.\nBeyond data organization, spreadsheets also make data visible and easy to\ninteract with, facilitating student engagement in data exploration and\nanalysis. Though not suitable for all circumstances, spreadsheets can and do\nhelp foster data and computing skills for K-12 students. This paper 1) reviews\nprior frameworks on K-12 data tools; 2) proposes data-driven learning outcomes\nthat can be accomplished by incorporating spreadsheets into the curriculum; and\n3) discusses how spreadsheets can help develop data acumen and computational\nfluency. We provide example class activities, identify challenges and barriers\nto adoption, suggest pedagogical approaches to ease the learning curve for\ninstructors and students, and discuss the need for professional development to\nfacilitate deeper use of spreadsheets for data science and STEM disciplines.", "AI": {"tldr": "\u7535\u5b50\u8868\u683c\u662fK-12\u6559\u80b2\u4e2d\u7528\u4e8e\u6570\u636e\u6536\u96c6\u3001\u7ec4\u7ec7\u3001\u53ef\u89c6\u5316\u548c\u4ea4\u4e92\u7684\u5f3a\u5927\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u57f9\u517b\u5b66\u751f\u7684\u6570\u636e\u7d20\u517b\u548c\u8ba1\u7b97\u80fd\u529b\uff0c\u4f46\u4e5f\u5b58\u5728\u4e00\u4e9b\u6311\u6218\uff0c\u9700\u8981\u76f8\u5e94\u7684\u6559\u5b66\u548c\u4e13\u4e1a\u53d1\u5c55\u652f\u6301\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u5728K-12\u5b66\u751f\u548c\u6559\u5e08\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5b83\u4eec\u5728\u6570\u636e\u6536\u96c6\u3001\u7ec4\u7ec7\u3001\u53ef\u89c6\u5316\u548c\u4ea4\u4e92\u65b9\u9762\u53d1\u6325\u7740\u91cd\u8981\u4f5c\u7528\uff0c\u6709\u52a9\u4e8e\u57f9\u517b\u5b66\u751f\u7684\u6570\u636e\u63a2\u7d22\u3001\u5206\u6790\u3001\u6570\u636e\u7d20\u517b\u548c\u8ba1\u7b97\u80fd\u529b\u3002", "method": "1\uff09\u56de\u987e\u4e86\u5173\u4e8eK-12\u6570\u636e\u5de5\u5177\u7684\u73b0\u6709\u6846\u67b6\uff1b2\uff09\u63d0\u51fa\u4e86\u5c06\u7535\u5b50\u8868\u683c\u7eb3\u5165\u8bfe\u7a0b\u53ef\u4ee5\u5b9e\u73b0\u7684\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u6210\u679c\uff1b3\uff09\u8ba8\u8bba\u4e86\u7535\u5b50\u8868\u683c\u5982\u4f55\u5e2e\u52a9\u57f9\u517b\u6570\u636e\u7d20\u517b\u548c\u8ba1\u7b97\u80fd\u529b\u3002", "result": "\u63d0\u4f9b\u4e86\u8bfe\u5802\u6d3b\u52a8\u793a\u4f8b\uff0c\u6307\u51fa\u4e86\u7535\u5b50\u8868\u683c\u5728K-12\u6559\u80b2\u4e2d\u5e94\u7528\u7684\u6311\u6218\u548c\u969c\u788d\uff0c\u63d0\u51fa\u4e86\u7b80\u5316\u6559\u5b66\u548c\u5b66\u4e60\u66f2\u7ebf\u7684\u6559\u5b66\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u4fc3\u8fdb\u7535\u5b50\u8868\u683c\u5728\u6570\u636e\u79d1\u5b66\u548cSTEM\u5b66\u79d1\u4e2d\u5e94\u7528\u7684\u4e13\u4e1a\u53d1\u5c55\u9700\u6c42\u3002", "conclusion": "\u7535\u5b50\u8868\u683c\u6709\u52a9\u4e8e\u57f9\u517bK-12\u5b66\u751f\u7684\u6570\u636e\u7d20\u517b\u548c\u8ba1\u7b97\u80fd\u529b\u3002"}}
{"id": "2505.23667", "title": "Fortune: Formula-Driven Reinforcement Learning for Symbolic Table Reasoning in Language Models", "url": "https://arxiv.org/abs/2505.23667", "pdf": "https://arxiv.org/pdf/2505.23667", "abs": "https://arxiv.org/abs/2505.23667", "authors": ["Lang Cao", "Jingxian Xu", "Hanbing Liu", "Jinyu Wang", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Dongmei Zhang"], "categories": ["cs.AI"], "comment": null, "summary": "Tables are a fundamental structure for organizing and analyzing data, making\neffective table understanding a critical capability for intelligent systems.\nWhile large language models (LMs) demonstrate strong general reasoning\nabilities, they continue to struggle with accurate numerical or symbolic\nreasoning over tabular data, especially in complex scenarios. Spreadsheet\nformulas provide a powerful and expressive medium for representing executable\nsymbolic operations, encoding rich reasoning patterns that remain largely\nunderutilized. In this paper, we propose Formula Tuning (Fortune), a\nreinforcement learning (RL) framework that trains LMs to generate executable\nspreadsheet formulas for question answering over general tabular data. Formula\nTuning reduces the reliance on supervised formula annotations by using binary\nanswer correctness as a reward signal, guiding the model to learn formula\nderivation through reasoning. We provide a theoretical analysis of its\nadvantages and demonstrate its effectiveness through extensive experiments on\nseven table reasoning benchmarks. Formula Tuning substantially enhances LM\nperformance, particularly on multi-step numerical and symbolic reasoning tasks,\nenabling a 7B model to outperform OpenAI o1 on table understanding. This\nhighlights the potential of formula-driven RL to advance symbolic table\nreasoning in LMs.", "AI": {"tldr": "A new reinforcement learning framework called Formula Tuning (Fortune) trains language models to generate spreadsheet formulas for answering questions about data in tables. This approach improves the models' ability to perform complex calculations and reasoning, even outperforming larger models on certain tasks.", "motivation": "Existing large language models struggle with accurate numerical or symbolic reasoning over tabular data, despite the expressiveness of spreadsheet formulas for encoding reasoning patterns.", "method": "Formula Tuning (Fortune) is a reinforcement learning framework that trains LMs to generate spreadsheet formulas for table question answering. It uses binary answer correctness as a reward signal.", "result": "Formula Tuning substantially enhances LM performance on table understanding, especially on multi-step reasoning tasks, outperforming a larger model (OpenAI o1) with a 7B parameter model. This demonstrates the potential of formula-driven RL for symbolic table reasoning.", "conclusion": "Formula Tuning (Fortune) framework uses reinforcement learning to train LMs to generate executable spreadsheet formulas for question answering over tabular data. It reduces the need for supervised annotations by using answer correctness as a reward signal, improving performance on complex numerical and symbolic reasoning tasks."}}
{"id": "2505.23296", "title": "Is spreadsheet syntax better than numeric indexing for cell selection?", "url": "https://arxiv.org/abs/2505.23296", "pdf": "https://arxiv.org/pdf/2505.23296", "abs": "https://arxiv.org/abs/2505.23296", "authors": ["Philip Heltweg", "Dirk Riehle", "Georg-Daniel Schwarz"], "categories": ["cs.PL"], "comment": null, "summary": "Selecting a subset of cells is a common task in data engineering, for\nexample, to remove errors or select only specific parts of a table. Multiple\napproaches to express this selection exist. One option is numeric indexing,\ncommonly found in general programming languages, where a tuple of numbers\nidentifies the cell. Alternatively, the separate dimensions can be referred to\nusing different enumeration schemes like \"A1\" for the first cell, commonly\nfound in software such as spreadsheet systems.\n  In a large-scale controlled experiment with student participants as proxy for\ndata practitioners, we compare the two options with respect to speed and\ncorrectness of reading and writing code.\n  The results show that, when reading code, participants make less mistakes\nusing spreadsheet-style syntax. Additionally, when writing code, they make\nfewer mistakes and are faster when using spreadsheet syntax compared to numeric\nsyntax.\n  From this, a domain-specific syntax, such as spreadsheet syntax for data\nengineering, appears to be a promising alternative to explore in future tools\nto support practitioners without a software engineering background.", "AI": {"tldr": "Spreadsheet-style syntax is better than numeric indexing for selecting cells in data engineering, making code easier and faster to read and write, particularly for non-programmers.", "motivation": "The motivation was to compare two common approaches for cell selection in data engineering (numeric indexing and spreadsheet-style syntax) in terms of efficiency and accuracy, to inform the design of future data engineering tools.", "method": "A large-scale controlled experiment was conducted with student participants, comparing the speed and correctness of reading and writing code using numeric indexing versus spreadsheet-style syntax for cell selection.", "result": "Participants made fewer mistakes when reading code using spreadsheet-style syntax. When writing code, they were faster and made fewer mistakes with spreadsheet syntax compared to numeric syntax.", "conclusion": "The study suggests that spreadsheet-style syntax is a promising alternative to numeric syntax for cell selection in data engineering, especially for practitioners without a software engineering background, as it leads to fewer errors and faster execution."}}
{"id": "2503.12345", "title": "General Table Question Answering via Answer-Formula Joint Generation", "url": "https://arxiv.org/abs/2503.12345", "pdf": "https://arxiv.org/pdf/2503.12345", "abs": "https://arxiv.org/abs/2503.12345", "authors": ["Zhongyuan Wang", "Richong Zhang", "Zhijie Nie"], "categories": ["cs.CL", "cs.AI"], "comment": "work in progress", "summary": "Advanced table question answering (TableQA) methods prompt large language\nmodels (LLMs) to generate answer text, SQL query, Python code, or custom\noperations, which impressively improve the complex reasoning problems in the\nTableQA task. However, these methods lack the versatility to cope with specific\nquestion types or table structures. In contrast, the Spreadsheet Formula, the\nwidely used and well-defined operation language for tabular data, has not been\nthoroughly explored to solve TableQA. In this paper, we first attempt to use\nthe Formula as the executable representation for solving complex reasoning on\ntables with different structures. Specifically, we construct\n\\texttt{FromulaQA}, a large Formula-annotated TableQA dataset from existing\ndatasets. In addition, we propose \\texttt{TabAF}, a general table answering\nframework to solve multiple types of tasks over multiple types of tables\nsimultaneously. Unlike existing methods, \\texttt{TabAF} decodes answers and\nFormulas with a single LLM backbone, demonstrating great versatility and\ngeneralization. \\texttt{TabAF} based on Llama3.1-70B achieves new\nstate-of-the-art performance on the WikiTableQuestion, HiTab, and TabFact.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8868\u683c\u95ee\u7b54\u65b9\u6cd5\uff0c\u4f7f\u7528\u7535\u5b50\u8868\u683c\u516c\u5f0f\u4f5c\u4e3a\u53ef\u6267\u884c\u8868\u793a\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3a TabAF \u7684\u901a\u7528\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8868\u683c\u95ee\u7b54\uff08TableQA\uff09\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u751f\u6210\u7b54\u6848\u6587\u672c\u3001SQL \u67e5\u8be2\u3001Python \u4ee3\u7801\u6216\u81ea\u5b9a\u4e49\u64cd\u4f5c\uff0c\u4f46\u7f3a\u4e4f\u5904\u7406\u7279\u5b9a\u95ee\u9898\u7c7b\u578b\u6216\u8868\u683c\u7ed3\u6784\u7684\u591a\u529f\u80fd\u6027\u3002\u8868\u683c\u4f5c\u4e3a\u4e00\u79cd\u5e7f\u6cdb\u4f7f\u7528\u4e14\u5b9a\u4e49\u660e\u786e\u7684\u8868\u683c\u6570\u636e\u64cd\u4f5c\u8bed\u8a00\uff0c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u4ee5\u89e3\u51b3 TableQA \u95ee\u9898\u3002", "method": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3a FormulaQA \u7684\u5927\u578b\u516c\u5f0f\u6807\u6ce8\u8868\u683c\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86 TabAF \u901a\u7528\u8868\u683c\u95ee\u7b54\u6846\u67b6\u3002TabAF \u4f7f\u7528\u5355\u4e2a LLM \u9aa8\u5e72\u7f51\u7edc\u6765\u89e3\u7801\u7b54\u6848\u548c\u516c\u5f0f\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u5904\u7406\u4e0d\u540c\u7ed3\u6784\u8868\u683c\u548c\u7279\u5b9a\u7c7b\u578b\u95ee\u9898\u4e0a\u7684\u591a\u529f\u80fd\u6027\u3002", "result": "TabAF \u5728 WikiTableQuestion\u3001HiTab \u548c TabFact \u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5904\u7406\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a TabAF \u7684\u901a\u7528\u8868\u683c\u95ee\u7b54\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u591a\u79cd\u7c7b\u578b\u7684\u8868\u683c\u548c\u95ee\u7b54\u4efb\u52a1\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u4e0d\u540c\uff0cTabAF \u4f7f\u7528\u5355\u4e2a LLM \u9aa8\u5e72\u7f51\u7edc\u6765\u89e3\u7801\u7b54\u6848\u548c\u516c\u5f0f\uff0c\u5c55\u73b0\u4e86\u51fa\u8272\u7684\u901a\u7528\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2504.20681", "title": "Data Encryption Battlefield: A Deep Dive into the Dynamic Confrontations in Ransomware Attacks", "url": "https://arxiv.org/abs/2504.20681", "pdf": "https://arxiv.org/pdf/2504.20681", "abs": "https://arxiv.org/abs/2504.20681", "authors": ["Arash Mahboubi", "Hamed Aboutorab", "Seyit Camtepe", "Hang Thanh Bui", "Khanh Luong", "Keyvan Ansari", "Shenlu Wang", "Bazara Barry"], "categories": ["cs.CR", "68M25"], "comment": null, "summary": "In the rapidly evolving landscape of cybersecurity threats, ransomware\nrepresents a significant challenge. Attackers increasingly employ sophisticated\nencryption methods, such as entropy reduction through Base64 encoding, and\npartial or intermittent encryption to evade traditional detection methods. This\nstudy explores the dynamic battle between adversaries who continuously refine\nencryption strategies and defenders developing advanced countermeasures to\nprotect vulnerable data. We investigate the application of online incremental\nmachine learning algorithms designed to predict file encryption activities\ndespite adversaries evolving obfuscation techniques. Our analysis utilizes an\nextensive dataset of 32.6 GB, comprising 11,928 files across multiple formats,\nincluding Microsoft Word documents (doc), PowerPoint presentations (ppt), Excel\nspreadsheets (xlsx), image formats (jpg, jpeg, png, tif, gif), PDFs (pdf),\naudio (mp3), and video (mp4) files. These files were encrypted by 75 distinct\nransomware families, facilitating a robust empirical evaluation of machine\nlearning classifiers effectiveness against diverse encryption tactics. Results\nhighlight the Hoeffding Tree algorithms superior incremental learning\ncapability, particularly effective in detecting traditional and AES-Base64\nencryption methods employed to lower entropy. Conversely, the Random Forest\nclassifier with warm-start functionality excels at identifying intermittent\nencryption methods, demonstrating the necessity of tailored machine learning\nsolutions to counter sophisticated ransomware strategies.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5728\u7ebf\u589e\u91cf\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5728\u68c0\u6d4b\u5229\u7528\u71b5\u51cf\u5c11\u548c\u95f4\u6b47\u6027\u52a0\u5bc6\u7b49\u590d\u6742\u6280\u672f\u7684\u52d2\u7d22\u8f6f\u4ef6\u65b9\u9762\u7684\u6709\u6548\u6027\u3002Hoeffding Tree\u7b97\u6cd5\u5728\u5904\u7406\u4f20\u7edf\u52a0\u5bc6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u800cRandom Forest\u5219\u66f4\u64c5\u957f\u8bc6\u522b\u95f4\u6b47\u6027\u52a0\u5bc6\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u65e5\u76ca\u590d\u6742\u7684\u52d2\u7d22\u8f6f\u4ef6\u52a0\u5bc6\u6280\u672f\uff08\u5982\u901a\u8fc7Base64\u7f16\u7801\u8fdb\u884c\u7684\u71b5\u51cf\u5c11\u548c\u90e8\u5206/\u95f4\u6b47\u6027\u52a0\u5bc6\uff09\u5bf9\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u7684\u89c4\u907f\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u9632\u5fa1\u8005\u5982\u4f55\u901a\u8fc7\u5148\u8fdb\u7684\u5bf9\u7b56\u6765\u4fdd\u62a4\u6570\u636e\u3002", "method": "\u672c\u7814\u7a76\u5e94\u7528\u5728\u7ebf\u589e\u91cf\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u6765\u9884\u6d4b\u6587\u4ef6\u52a0\u5bc6\u6d3b\u52a8\uff0c\u5e76\u5229\u7528\u5305\u542b32.6 GB\u300111,928\u4e2a\u6587\u4ef6\uff08\u6db5\u76d6\u591a\u79cd\u683c\u5f0f\uff09\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6587\u4ef6\u753175\u4e2a\u4e0d\u540c\u7684\u52d2\u7d22\u8f6f\u4ef6\u5bb6\u65cf\u52a0\u5bc6\uff0c\u4ee5\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u5728\u5e94\u5bf9\u5404\u79cd\u52a0\u5bc6\u7b56\u7565\u65f6\u7684\u6709\u6548\u6027\u3002", "result": "Hoeffding Tree\u7b97\u6cd5\u5728\u68c0\u6d4b\u4f20\u7edf\u52a0\u5bc6\u548cAES-Base64\u52a0\u5bc6\u65b9\u9762\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u589e\u91cf\u5b66\u4e60\u80fd\u529b\uff0c\u800c\u5177\u6709\u6696\u542f\u52a8\u529f\u80fd\u7684Random Forest\u5206\u7c7b\u5668\u5219\u5728\u8bc6\u522b\u95f4\u6b47\u6027\u52a0\u5bc6\u65b9\u6cd5\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "Hoeffding Tree\u7b97\u6cd5\u5728\u68c0\u6d4b\u4f20\u7edf\u52a0\u5bc6\u548cAES-Base64\u52a0\u5bc6\u65b9\u9762\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u589e\u91cf\u5b66\u4e60\u80fd\u529b\uff0c\u800c\u5177\u6709\u6696\u542f\u52a8\u529f\u80fd\u7684Random Forest\u5206\u7c7b\u5668\u5219\u5728\u8bc6\u522b\u95f4\u6b47\u6027\u52a0\u5bc6\u65b9\u6cd5\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5b9a\u5236\u5316\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u5bf9\u4e8e\u5e94\u5bf9\u590d\u6742\u52d2\u7d22\u8f6f\u4ef6\u7b56\u7565\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2504.20657", "title": "Image deidentification in the XNAT ecosystem: use cases and solutions", "url": "https://arxiv.org/abs/2504.20657", "pdf": "https://arxiv.org/pdf/2504.20657", "abs": "https://arxiv.org/abs/2504.20657", "authors": ["Alex Michie", "Simon J Doran"], "categories": ["cs.CV", "J.3"], "comment": "For submission to MELBA (Machine Learning for Biomedical Imaging)\n  special issue on the MIDI-B deidentification challenge\n  (https://www.synapse.org/Synapse:syn53065760). 11 pages, 1 fig, 2 tables; 1\n  supplementary data file (supplementary_tables_S1_S2_S3.xlsx) containing three\n  spreadsheet tabs", "summary": "XNAT is a server-based data management platform widely used in academia for\ncurating large databases of DICOM images for research projects. We describe in\ndetail a deidentification workflow for DICOM data using facilities in XNAT,\ntogether with independent tools in the XNAT \"ecosystem\". We list different\ncontexts in which deidentification might be needed, based on our prior\nexperience. The starting point for participation in the Medical Image\nDe-Identification Benchmark (MIDI-B) challenge was a set of pre-existing local\nmethodologies, which were adapted during the validation phase of the challenge.\nOur result in the test phase was 97.91\\%, considerably lower than our peers,\ndue largely to an arcane technical incompatibility of our methodology with the\nchallenge's Synapse platform, which prevented us receiving feedback during the\nvalidation phase. Post-submission, additional discrepancy reports from the\norganisers and via the MIDI-B Continuous Benchmarking facility, enabled us to\nimprove this score significantly to 99.61\\%. An entirely rule-based approach\nwas shown to be capable of removing all name-related information in the test\ncorpus, but exhibited failures in dealing fully with address data. Initial\nexperiments using published machine-learning models to remove addresses were\npartially successful but showed the models to be \"over-aggressive\" on other\ntypes of free-text data, leading to a slight overall degradation in performance\nto 99.54\\%. Future development will therefore focus on improving\naddress-recognition capabilities, but also on better removal of identifiable\ndata burned into the image pixels. Several technical aspects relating to the\n\"answer key\" are still under discussion with the challenge organisers, but we\nestimate that our percentage of genuine deidentification failures on the MIDI-B\ntest corpus currently stands at 0.19\\%. (Abridged from original for arXiv\nsubmission)", "AI": {"tldr": "XNAT \u914d\u5408\u5916\u90e8\u5de5\u5177\u5b9e\u73b0 DICOM \u6570\u636e\u53bb\u6807\u8bc6\u5316\uff0cMIDI-B \u6311\u6218\u8d5b\u4e2d\u5206\u6570\u4ece 97.91% \u63d0\u5347\u81f3 99.61%\u3002\u89c4\u5219\u65b9\u6cd5\u53ef\u79fb\u9664\u59d3\u540d\u4fe1\u606f\u4f46\u5730\u5740\u4fe1\u606f\u5904\u7406\u6709\u5f85\u6539\u8fdb\u3002\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5730\u5740\u79fb\u9664\u65b9\u9762\u6709\u6f5c\u529b\u4f46\u9700\u4f18\u5316\uff0c\u4ee5\u907f\u514d\u5f71\u54cd\u5176\u4ed6\u6587\u672c\u6570\u636e\u3002\u6700\u7ec8\u5b9e\u9645\u53bb\u6807\u8bc6\u5316\u5931\u8d25\u7387\u4f30\u8ba1\u4e3a 0.19%\u3002", "motivation": "\u4e3a MIDI-B \u6311\u6218\u8d5b\u63d0\u4f9b\u4e00\u4e2a\u57fa\u4e8e XNAT \u7684 DICOM \u6570\u636e\u53bb\u6807\u8bc6\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u59d3\u540d\u3001\u5730\u5740\u7b49\u654f\u611f\u4fe1\u606f\u65b9\u9762\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528 XNAT \u53ca\u5176\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u72ec\u7acb\u5de5\u5177\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7528\u4e8e DICOM \u6570\u636e\u53bb\u6807\u8bc6\u5316\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002\u5c06\u4e0d\u540c\u7684\u53bb\u6807\u8bc6\u5316\u9700\u6c42\u573a\u666f\u5316\uff0c\u5e76\u5229\u7528 XNAT \u7684\u5185\u7f6e\u529f\u80fd\u548c\u5916\u90e8\u5de5\u5177\u6765\u5b9e\u73b0\u3002\u8be5\u65b9\u6cd5\u5728 MIDI-B \u6311\u6218\u8d5b\u7684\u9a8c\u8bc1\u9636\u6bb5\u8fdb\u884c\u4e86\u9002\u5e94\u6027\u8c03\u6574\uff0c\u5e76\u5728\u6d4b\u8bd5\u9636\u6bb5\u53d6\u5f97\u4e86\u521d\u6b65\u7ed3\u679c\u3002", "result": "\u5728 MIDI-B \u6d4b\u8bd5\u9636\u6bb5\uff0c\u521d\u59cb\u5f97\u5206\u4e3a 97.91%\uff0c\u7531\u4e8e\u4e0e Synapse \u5e73\u53f0\u7684\u6666\u6c14\u6280\u672f\u4e0d\u517c\u5bb9\uff0c\u963b\u788d\u4e86\u9a8c\u8bc1\u9636\u6bb5\u7684\u53cd\u9988\u3002\u901a\u8fc7\u989d\u5916\u7684\u5dee\u5f02\u62a5\u544a\uff0c\u5206\u6570\u663e\u8457\u63d0\u9ad8\u5230 99.61%\u3002\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u80fd\u591f\u79fb\u9664\u6240\u6709\u59d3\u540d\u4fe1\u606f\uff0c\u4f46\u5730\u5740\u4fe1\u606f\u5904\u7406\u4e0d\u5b8c\u5168\u3002\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5730\u5740\u79fb\u9664\u65b9\u9762\u90e8\u5206\u6210\u529f\uff0c\u4f46\u5bf9\u5176\u4ed6\u81ea\u7531\u6587\u672c\u6570\u636e\u8fc7\u4e8e\u6fc0\u8fdb\uff0c\u5bfc\u81f4\u6574\u4f53\u6027\u80fd\u4e0b\u964d\u81f3 99.54%\u3002", "conclusion": "XNAT \u7684\u89c4\u5219\u65b9\u6cd5\u80fd\u591f\u79fb\u9664\u6d4b\u8bd5\u8bed\u6599\u5e93\u4e2d\u6240\u6709\u4e0e\u59d3\u540d\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u4f46\u5728\u5904\u7406\u5730\u5740\u6570\u636e\u65f6\u5b58\u5728\u4e0d\u8db3\u3002\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u79fb\u9664\u5730\u5740\u7684\u521d\u6b65\u5b9e\u9a8c\u90e8\u5206\u6210\u529f\uff0c\u4f46\u5176\u4ed6\u7c7b\u578b\u7684\u81ea\u7531\u6587\u672c\u6570\u636e\u6a21\u578b\u8868\u73b0\u8fc7\u4e8e\u6fc0\u8fdb\uff0c\u5bfc\u81f4\u6574\u4f53\u6027\u80fd\u7565\u6709\u4e0b\u964d\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5c06\u96c6\u4e2d\u4e8e\u6539\u8fdb\u5730\u5740\u8bc6\u522b\u80fd\u529b\u4ee5\u53ca\u79fb\u9664\u56fe\u50cf\u50cf\u7d20\u4e2d\u70e7\u5f55\u7684\u53ef\u8bc6\u522b\u6570\u636e\u3002\u5c3d\u7ba1\u4e0e\u7ec4\u7ec7\u8005\u5c31\u201c\u7b54\u6848\u7684\u5173\u952e\u201d\u7684\u6280\u672f\u95ee\u9898\u4ecd\u5728\u8ba8\u8bba\u4e2d\uff0c\u4f46\u6211\u4eec\u4f30\u8ba1\u5728 MIDI-B \u6d4b\u8bd5\u8bed\u6599\u5e93\u4e2d\uff0c\u6211\u4eec\u5b9e\u9645\u7684\u53bb\u6807\u8bc6\u5316\u5931\u8d25\u7387\u7ea6\u4e3a 0.19%\u3002"}}
{"id": "2408.12622", "title": "The AI Risk Repository: A Comprehensive Meta-Review, Database, and Taxonomy of Risks From Artificial Intelligence", "url": "https://arxiv.org/abs/2408.12622", "pdf": "https://arxiv.org/pdf/2408.12622", "abs": "https://arxiv.org/abs/2408.12622", "authors": ["Peter Slattery", "Alexander K. Saeri", "Emily A. C. Grundy", "Jess Graham", "Michael Noetel", "Risto Uuk", "James Dao", "Soroush Pour", "Stephen Casper", "Neil Thompson"], "categories": ["cs.AI", "cs.CR", "cs.ET", "cs.LG", "cs.SY", "eess.SY", "I.2.0; K.4.1; K.4.1; K.4.2; K.4.3; K.6.0"], "comment": null, "summary": "The risks posed by Artificial Intelligence (AI) are of considerable concern\nto academics, auditors, policymakers, AI companies, and the public. However, a\nlack of shared understanding of AI risks can impede our ability to\ncomprehensively discuss, research, and react to them. This paper addresses this\ngap by creating an AI Risk Repository to serve as a common frame of reference.\nThis comprises a living database of 777 risks extracted from 43 taxonomies,\nwhich can be filtered based on two overarching taxonomies and easily accessed,\nmodified, and updated via our website and online spreadsheets. We construct our\nRepository with a systematic review of taxonomies and other structured\nclassifications of AI risk followed by an expert consultation. We develop our\ntaxonomies of AI risk using a best-fit framework synthesis. Our high-level\nCausal Taxonomy of AI Risks classifies each risk by its causal factors (1)\nEntity: Human, AI; (2) Intentionality: Intentional, Unintentional; and (3)\nTiming: Pre-deployment; Post-deployment. Our mid-level Domain Taxonomy of AI\nRisks classifies risks into seven AI risk domains: (1) Discrimination &\ntoxicity, (2) Privacy & security, (3) Misinformation, (4) Malicious actors &\nmisuse, (5) Human-computer interaction, (6) Socioeconomic & environmental, and\n(7) AI system safety, failures, & limitations. These are further divided into\n23 subdomains. The AI Risk Repository is, to our knowledge, the first attempt\nto rigorously curate, analyze, and extract AI risk frameworks into a publicly\naccessible, comprehensive, extensible, and categorized risk database. This\ncreates a foundation for a more coordinated, coherent, and complete approach to\ndefining, auditing, and managing the risks posed by AI systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u5305\u542b777\u4e2aAI\u98ce\u9669\u7684\u7efc\u5408\u6570\u636e\u5e93\uff0c\u89e3\u51b3\u4e86AI\u98ce\u9669\u7406\u89e3\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u4e3aAI\u98ce\u9669\u7684\u7ba1\u7406\u548c\u5ba1\u8ba1\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5b66\u672f\u754c\u3001\u5ba1\u8ba1\u5e08\u3001\u653f\u7b56\u5236\u5b9a\u8005\u3001AI\u516c\u53f8\u548c\u516c\u4f17\u5bf9AI\u98ce\u9669\u7f3a\u4e4f\u5171\u540c\u7406\u89e3\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u521b\u5efa\u4e00\u4e2aAI\u98ce\u9669\u77e5\u8bc6\u5e93\uff0c\u4f5c\u4e3a\u5171\u540c\u7684\u53c2\u8003\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u5ba1\u67e543\u4e2aAI\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e13\u5bb6\u54a8\u8be2\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b777\u4e2a\u98ce\u9669\u7684\u6570\u636e\u5e93\uff0c\u5e76\u6839\u636e\u56e0\u679c\u56e0\u7d20\uff08\u5b9e\u4f53\u3001\u610f\u56fe\u3001\u65f6\u5e8f\uff09\u548c\u4e03\u4e2a\u98ce\u9669\u9886\u57df\uff08\u6b67\u89c6\u4e0e\u6bd2\u6027\u3001\u9690\u79c1\u4e0e\u5b89\u5168\u3001\u9519\u8bef\u4fe1\u606f\u3001\u6076\u610f\u884c\u4e3a\u8005\u4e0e\u6ee5\u7528\u3001\u4eba\u673a\u4ea4\u4e92\u3001\u793e\u4f1a\u7ecf\u6d4e\u4e0e\u73af\u5883\u3001AI\u7cfb\u7edf\u5b89\u5168\u3001\u6545\u969c\u4e0e\u9650\u5236\uff09\u8fdb\u884c\u4e86\u5206\u7c7b\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b777\u4e2aAI\u98ce\u9669\u7684\u6570\u636e\u5e93\uff0c\u5206\u4e3a\u56e0\u679c\u5206\u7c7b\u6cd5\u548c\u9886\u57df\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6613\u4e8e\u8bbf\u95ee\u548c\u66f4\u65b0\u7684\u5728\u7ebf\u5e73\u53f0\u3002", "conclusion": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u4e00\u4e2a\u516c\u5f00\u7684\u3001\u53ef\u6269\u5c55\u7684\u3001\u5206\u7c7b\u7684AI\u98ce\u9669\u6570\u636e\u5e93\uff0c\u4e3a\u5b9a\u4e49\u3001\u5ba1\u8ba1\u548c\u7ba1\u7406AI\u98ce\u9669\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2407.09025", "title": "SpreadsheetLLM: Encoding Spreadsheets for Large Language Models", "url": "https://arxiv.org/abs/2407.09025", "pdf": "https://arxiv.org/pdf/2407.09025", "abs": "https://arxiv.org/abs/2407.09025", "authors": ["Haoyu Dong", "Jianbo Zhao", "Yuzhang Tian", "Junyu Xiong", "Shiyu Xia", "Mengyu Zhou", "Yun Lin", "Jos\u00e9 Cambronero", "Yeye He", "Shi Han", "Dongmei Zhang"], "categories": ["cs.AI"], "comment": null, "summary": "Spreadsheets are characterized by their extensive two-dimensional grids,\nflexible layouts, and varied formatting options, which pose significant\nchallenges for large language models (LLMs). In response, we introduce\nSpreadsheetLLM, pioneering an efficient encoding method designed to unleash and\noptimize LLMs' powerful understanding and reasoning capability on spreadsheets.\nInitially, we propose a vanilla serialization approach that incorporates cell\naddresses, values, and formats. However, this approach was limited by LLMs'\ntoken constraints, making it impractical for most applications. To tackle this\nchallenge, we develop SheetCompressor, an innovative encoding framework that\ncompresses spreadsheets effectively for LLMs. It comprises three modules:\nstructural-anchor-based compression, inverse index translation, and\ndata-format-aware aggregation. It significantly improves performance in the\nspreadsheet table detection task, outperforming the vanilla approach by 25.6%\nin GPT4's in-context learning setting. Moreover, fine-tuned LLM with\nSheetCompressor has an average compression ratio of 25 times, and achieves a\nstate-of-the-art 78.9% F1 score, surpassing the best existing models by 12.3%.\nFinally, we propose Chain of Spreadsheet for downstream tasks of spreadsheet\nunderstanding and validate it in a new and demanding spreadsheet QA task. We\nmethodically leverage the inherent layout and structure of spreadsheets,\ndemonstrating that SpreadsheetLLM is highly effective across a variety of\nspreadsheet tasks.", "AI": {"tldr": "SpreadsheetLLM\u901a\u8fc7\u521b\u65b0\u7684SheetCompressor\u7f16\u7801\u6846\u67b6\u548cChain of Spreadsheet\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u7535\u5b50\u8868\u683c\u7406\u89e3\u3001\u8868\u683c\u68c0\u6d4b\u548c\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u548c\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7406\u89e3\u548c\u5904\u7406\u7535\u5b50\u8868\u683c\u65f6\u9047\u5230\u7684\u6311\u6218\uff0c\u4f8b\u5982\u5176\u4e8c\u7ef4\u7f51\u683c\u3001\u7075\u6d3b\u5e03\u5c40\u548c\u591a\u6837\u7684\u683c\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSheetCompressor\u7684\u7f16\u7801\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8e\u7ed3\u6784\u951a\u7684\u538b\u7f29\u3001\u9006\u5411\u7d22\u5f15\u8f6c\u6362\u548c\u6570\u636e\u683c\u5f0f\u611f\u77e5\u805a\u5408\u4e09\u4e2a\u6a21\u5757\uff0c\u5e76\u7ed3\u5408Chain of Spreadsheet\u3002", "result": "SheetCompressor\u76f8\u6bd4\u57fa\u7840\u65b9\u6cd5\u5728\u7535\u5b50\u8868\u683c\u8868\u683c\u68c0\u6d4b\u4efb\u52a1\u4e0a\u63d0\u5347\u4e8625.6%\uff08\u5728GPT4\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u8bbe\u7f6e\u4e0b\uff09\u3002\u7ecf\u8fc7SheetCompressor\u5fae\u8c03\u7684LLM\u5b9e\u73b0\u4e8625\u500d\u7684\u5e73\u5747\u538b\u7f29\u7387\uff0c\u5e76\u5728\u7535\u5b50\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e8678.9%\u7684F1\u5206\u6570\uff0c\u8d85\u8d8a\u73b0\u6709\u6a21\u578b12.3%\u3002", "conclusion": "SpreadsheetLLM\u5728\u591a\u79cd\u7535\u5b50\u8868\u683c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\uff0c\u901a\u8fc7Chain of Spreadsheet\u80fd\u591f\u6709\u6548\u5904\u7406\u7535\u5b50\u8868\u683c\u7406\u89e3\u548c\u95ee\u7b54\u4efb\u52a1\u3002"}}
{"id": "2403.03636", "title": "SheetAgent: Towards A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models", "url": "https://arxiv.org/abs/2403.03636", "pdf": "https://arxiv.org/pdf/2403.03636", "abs": "https://arxiv.org/abs/2403.03636", "authors": ["Yibin Chen", "Yifu Yuan", "Zeyu Zhang", "Yan Zheng", "Jinyi Liu", "Fei Ni", "Jianye Hao", "Hangyu Mao", "Fuzheng Zhang"], "categories": ["cs.AI", "cs.LG"], "comment": "Accepted by International World Wide Web Conference (WWW) 2025 (oral)", "summary": "Spreadsheets are ubiquitous across the World Wide Web, playing a critical\nrole in enhancing work efficiency across various domains. Large language model\n(LLM) has been recently attempted for automatic spreadsheet manipulation but\nhas not yet been investigated in complicated and realistic tasks where\nreasoning challenges exist (e.g., long horizon manipulation with multi-step\nreasoning and ambiguous requirements). To bridge the gap with the real-world\nrequirements, we introduce SheetRM, a benchmark featuring long-horizon and\nmulti-category tasks with reasoning-dependent manipulation caused by real-life\nchallenges. To mitigate the above challenges, we further propose SheetAgent, a\nnovel autonomous agent that utilizes the power of LLMs. SheetAgent consists of\nthree collaborative modules: Planner, Informer, and Retriever, achieving both\nadvanced reasoning and accurate manipulation over spreadsheets without human\ninteraction through iterative task reasoning and reflection. Extensive\nexperiments demonstrate that SheetAgent delivers 20--40\\% pass rate\nimprovements on multiple benchmarks over baselines, achieving enhanced\nprecision in spreadsheet manipulation and demonstrating superior table\nreasoning abilities. More details and visualizations are available at the\nproject website: https://sheetagent.github.io/. The datasets and source code\nare available at https://anonymous.4open.science/r/SheetAgent.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86SheetRM\u57fa\u51c6\u6d4b\u8bd5\u548cSheetAgent\u6a21\u578b\uff0c\u4ee5\u5e94\u5bf9\u7535\u5b50\u8868\u683c\u5904\u7406\u4e2d\u7684\u957f\u671f\u63a8\u7406\u548c\u6a21\u7cca\u9700\u6c42\u6311\u6218\u3002SheetAgent\u901a\u8fc7\u5176\u521b\u65b0\u7684\u4ee3\u7406\u67b6\u6784\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u5904\u7406\u7535\u5b50\u8868\u683c\u65b9\u9762\u867d\u6709\u5c1d\u8bd5\uff0c\u4f46\u5728\u9762\u5bf9\u9700\u8981\u957f\u671f\u63a8\u7406\u3001\u591a\u6b65\u9aa4\u601d\u8003\u4ee5\u53ca\u5b58\u5728\u6a21\u7cca\u9700\u6c42\u7b49\u590d\u6742\u3001\u73b0\u5b9e\u573a\u666f\u65f6\uff0c\u5176\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u6316\u6398\u548c\u9a8c\u8bc1\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u63d0\u51faSheetRM\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u957f\u8de8\u5ea6\u3001\u591a\u7c7b\u522b\u4ee5\u53ca\u4f9d\u8d56\u63a8\u7406\u7684\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u4efb\u52a1\uff1b\u63d0\u51faSheetAgent\uff0c\u4e00\u4e2a\u5229\u7528LLM\u7684\u81ea\u4e3b\u4ee3\u7406\uff0c\u5305\u542b\u89c4\u5212\u3001\u4fe1\u606f\u63d0\u4f9b\u548c\u68c0\u7d22\u4e09\u4e2a\u534f\u540c\u6a21\u5757\uff0c\u901a\u8fc7\u8fed\u4ee3\u4efb\u52a1\u63a8\u7406\u548c\u53cd\u601d\u6765\u5b9e\u73b0\u9ad8\u7ea7\u63a8\u7406\u548c\u7cbe\u786e\u64cd\u4f5c\u3002", "result": "SheetAgent\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u901a\u8fc7\u7387\u63d0\u9ad8\u4e8620%-40%\uff0c\u5728\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u7684\u7cbe\u786e\u5ea6\u548c\u8868\u683c\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "SheetAgent\u901a\u8fc7\u5176\u63d0\u51fa\u7684SheetRM\u57fa\u51c6\u6d4b\u8bd5\u548cSheetAgent\u6a21\u578b\uff0c\u5728\u5904\u7406\u590d\u6742\u3001\u73b0\u5b9e\u573a\u666f\u4e0b\u7684\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u4efb\u52a1\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u5728\u591a\u6b65\u63a8\u7406\u548c\u6a21\u7cca\u9700\u6c42\u5904\u7406\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u63d0\u5347\u4e8620%-40%\u7684\u901a\u8fc7\u7387\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u548c\u8868\u683c\u63a8\u7406\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2403.19318", "title": "TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios", "url": "https://arxiv.org/abs/2403.19318", "pdf": "https://arxiv.org/pdf/2403.19318", "abs": "https://arxiv.org/abs/2403.19318", "authors": ["Xiaokang Zhang", "Sijia Luo", "Bohan Zhang", "Zeyao Ma", "Jing Zhang", "Yang Li", "Guanlin Li", "Zijun Yao", "Kangli Xu", "Jinchang Zhou", "Daniel Zhang-Li", "Jifan Yu", "Shu Zhao", "Juanzi Li", "Jie Tang"], "categories": ["cs.CL"], "comment": "https://tablellm.github.io/", "summary": "We introduce TableLLM, a robust large language model (LLM) with 8 billion\nparameters, purpose-built for proficiently handling tabular data manipulation\ntasks, whether they are embedded within documents or spreadsheets, catering to\nreal-world office scenarios. We propose a distant supervision method for\ntraining, which comprises a reasoning process extension strategy, aiding in\ntraining LLMs to understand reasoning patterns more effectively as well as a\ncross-way validation strategy, ensuring the quality of the automatically\ngenerated data. To evaluate the performance of TableLLM, we have crafted\nbenchmarks tailored to address both document and spreadsheet formats as well as\nconstructed a well-organized evaluation pipeline capable of handling both\nscenarios. Thorough evaluations underscore the advantages of TableLLM when\ncompared to various existing general-purpose and tabular data-focused LLMs. We\nhave publicly released the model checkpoint, source code, benchmarks, and a web\napplication for user interaction. Our codes and data are publicly available at\nhttps://github.com/TableLLM/TableLLM.", "AI": {"tldr": "TableLLM\u662f\u4e00\u4e2a80\u4ebf\u53c2\u6570\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u5904\u7406\u8868\u683c\u6570\u636e\uff0c\u901a\u8fc7\u8fdc\u7a0b\u76d1\u7763\u8bad\u7ec3\uff0c\u5e76\u5728\u516c\u5f00\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u771f\u5b9e\u529e\u516c\u573a\u666f\u4e2d\uff0c\u6587\u6863\u6216\u7535\u5b50\u8868\u683c\u4e2d\u8868\u683c\u6570\u636e\u5904\u7406\u7684\u6311\u6218\uff0c\u63d0\u51faTableLLM\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fdc\u7a0b\u76d1\u7763\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5305\u62ec\u7528\u4e8e\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\u548c\u786e\u4fdd\u81ea\u52a8\u751f\u6210\u6570\u636e\u8d28\u91cf\u7684\u63a8\u7406\u8fc7\u7a0b\u6269\u5c55\u7b56\u7565\u548c\u4ea4\u53c9\u9a8c\u8bc1\u7b56\u7565\u3002", "result": "TableLLM\u5728\u9488\u5bf9\u6587\u6863\u548c\u7535\u5b50\u8868\u683c\u683c\u5f0f\u5b9a\u5236\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u7684\u4f18\u52bf\u3002", "conclusion": "TableLLM\u5728\u5904\u7406\u6587\u6863\u548c\u7535\u5b50\u8868\u683c\u4e2d\u7684\u8868\u683c\u6570\u636e\u64cd\u4f5c\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u901a\u7528\u548c\u4e13\u6ce8\u4e8e\u8868\u683c\u6570\u636e\u7684LLM\u3002"}}
{"id": "2502.11267", "title": "Prompting in the Dark: Assessing Human Performance in Prompt Engineering for Data Labeling When Gold Labels Are Absent", "url": "https://arxiv.org/abs/2502.11267", "pdf": "https://arxiv.org/pdf/2502.11267", "abs": "https://arxiv.org/abs/2502.11267", "authors": ["Zeyu He", "Saniya Naphade", "Ting-Hao 'Kenneth' Huang"], "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted By CHI 2025", "summary": "Millions of users prompt large language models (LLMs) for various tasks, but\nhow good are people at prompt engineering? Do users actually get closer to\ntheir desired outcome over multiple iterations of their prompts? These\nquestions are crucial when no gold-standard labels are available to measure\nprogress. This paper investigates a scenario in LLM-powered data labeling,\n\"prompting in the dark,\" where users iteratively prompt LLMs to label data\nwithout using manually-labeled benchmarks. We developed PromptingSheet, a\nGoogle Sheets add-on that enables users to compose, revise, and iteratively\nlabel data through spreadsheets. Through a study with 20 participants, we found\nthat prompting in the dark was highly unreliable-only 9 participants improved\nlabeling accuracy after four or more iterations. Automated prompt optimization\ntools like DSPy also struggled when few gold labels were available. Our\nfindings highlight the importance of gold labels and the needs, as well as the\nrisks, of automated support in human prompt engineering, providing insights for\nfuture tool design.", "AI": {"tldr": "Prompting LLMs for data labeling without gold-standard benchmarks (\"prompting in the dark\") is unreliable. A study using PromptingSheet found that most users did not improve accuracy over iterations, and automated tools also struggled without gold labels. The findings emphasize the need for gold labels and careful design of automated support for prompt engineering.", "motivation": "Millions of users prompt large language models (LLMs) for various tasks, but how good are people at prompt engineering? Do users actually get closer to their desired outcome over multiple iterations of their prompts? These questions are crucial when no gold-standard labels are available to measure progress.", "method": "We developed PromptingSheet, a Google Sheets add-on that enables users to compose, revise, and iteratively label data through spreadsheets. Through a study with 20 participants, we found that prompting in the dark was highly unreliable-only 9 participants improved labeling accuracy after four or more iterations. Automated prompt optimization tools like DSPy also struggled when few gold labels were available.", "result": "Through a study with 20 participants, we found that prompting in the dark was highly unreliable-only 9 participants improved labeling accuracy after four or more iterations. Automated prompt optimization tools like DSPy also struggled when few gold labels were available.", "conclusion": "Millions of users prompt large language models (LLMs) for various tasks, but how good are people at prompt engineering? Do users actually get closer to their desired outcome over multiple iterations of their prompts? These questions are crucial when no gold-standard labels are available to measure progress. This paper investigates a scenario in LLM-powered data labeling, \"prompting in the dark,\" where users iteratively prompt LLMs to label data without using manually-labeled benchmarks. We developed PromptingSheet, a Google Sheets add-on that enables users to compose, revise, and iteratively label data through spreadsheets. Through a study with 20 participants, we found that prompting in the dark was highly unreliable-only 9 participants improved labeling accuracy after four or more iterations. Automated prompt optimization tools like DSPy also struggled when few gold labels were available. Our findings highlight the importance of gold labels and the needs, as well as the risks, of automated support in human prompt engineering, providing insights for future tool design."}}
{"id": "2502.09787", "title": "TableTalk: Scaffolding Spreadsheet Development with a Language Agent", "url": "https://arxiv.org/abs/2502.09787", "pdf": "https://arxiv.org/pdf/2502.09787", "abs": "https://arxiv.org/abs/2502.09787", "authors": ["Jenny T. Liang", "Aayush Kumar", "Yasharth Bajpai", "Sumit Gulwani", "Vu Le", "Chris Parnin", "Arjun Radhakrishna", "Ashish Tiwari", "Emerson Murphy-Hill", "Guastavo Soares"], "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": null, "summary": "Despite its ubiquity in the workforce, spreadsheet programming remains\nchallenging as programmers need both spreadsheet-specific knowledge (e.g., APIs\nto write formulas) and problem-solving skills to create complex spreadsheets.\nLarge language models (LLMs) can help automate aspects of this process, and\nrecent advances in planning and reasoning have enabled language agents, which\ndynamically plan, use tools, and take iterative actions to complete complex\ntasks. These agents observe, plan, and act, making them well-suited to scaffold\nspreadsheet programming by following expert processes.\n  We present TableTalk, a language agent that helps programmers build\nspreadsheets conversationally. Its design reifies three design principles --\nscaffolding, flexibility, and incrementality -- which we derived from two\nstudies of seven programmers and 62 Excel templates. TableTalk structures\nspreadsheet development by generating step-by-step plans and suggesting three\nnext steps users can choose from. It also integrates tools that enable\nincremental spreadsheet construction. A user study with 20 programmers shows\nthat TableTalk produces spreadsheets 2.3 times more likely to be preferred over\na baseline agent, while reducing cognitive load and time spent reasoning about\nspreadsheet actions by 12.6%. TableTalk's approach has implications for\nhuman-agent collaboration. This includes providing persistent direct\nmanipulation interfaces for stopping or undoing agent actions, while ensuring\nthat such interfaces for accepting actions can be deactivated.", "AI": {"tldr": "TableTalk \u662f\u4e00\u4e2a\u5bf9\u8bdd\u5f0f\u7535\u5b50\u8868\u683c\u52a9\u624b\uff0c\u53ef\u63d0\u9ad8\u6548\u7387\u5e76\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377\u3002", "motivation": "\u7531\u4e8e\u7535\u5b50\u8868\u683c\u7f16\u7a0b\u9700\u8981\u7535\u5b50\u8868\u683c\u7279\u5b9a\u77e5\u8bc6\u548c\u89e3\u51b3\u95ee\u9898\u80fd\u529b\uff0c\u5bf9\u7a0b\u5e8f\u5458\u6765\u8bf4\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002LLM \u548c\u8bed\u8a00\u667a\u80fd\u4f53\u53ef\u4ee5\u5e2e\u52a9\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "TableTalk \u662f\u4e00\u4e2a\u8bed\u8a00\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5206\u6b65\u8ba1\u5212\u548c\u63d0\u4f9b\u4e0b\u4e00\u6b65\u5efa\u8bae\u6765\u6784\u5efa\u7535\u5b50\u8868\u683c\uff0c\u5e76\u96c6\u6210\u5de5\u5177\u4ee5\u5b9e\u73b0\u589e\u91cf\u5f0f\u6784\u5efa\u3002", "result": "\u4e0e\u57fa\u7ebf\u667a\u80fd\u4f53\u76f8\u6bd4\uff0cTableTalk \u4ea7\u751f\u7684\u7535\u5b50\u8868\u683c\u66f4\u53d7\u7528\u6237\u9752\u7750\uff082.3 \u500d\uff09\uff0c\u540c\u65f6\u8ba4\u77e5\u8d1f\u8377\u548c\u63a8\u7406\u65f6\u95f4\u51cf\u5c11\u4e86 12.6%\u3002", "conclusion": "TableTalk \u7684\u65b9\u6cd5\u5bf9\u4eba\u4e0e\u667a\u80fd\u4f53\u534f\u4f5c\u6709\u542f\u793a\uff0c\u5305\u62ec\u4e3a\u4e2d\u6b62\u6216\u64a4\u9500\u667a\u80fd\u4f53\u64cd\u4f5c\u63d0\u4f9b\u6301\u4e45\u7684\u76f4\u63a5\u64cd\u4f5c\u754c\u9762\uff0c\u540c\u65f6\u786e\u4fdd\u53ef\u4ee5\u7981\u7528\u7528\u4e8e\u63a5\u53d7\u64cd\u4f5c\u7684\u6b64\u7c7b\u754c\u9762\u3002"}}
{"id": "2502.05113", "title": "GiesKaNe: Bridging Past and Present in Grammatical Theory and Practical Application", "url": "https://arxiv.org/abs/2502.05113", "pdf": "https://arxiv.org/pdf/2502.05113", "abs": "https://arxiv.org/abs/2502.05113", "authors": ["Volker Emmrich"], "categories": ["cs.CL"], "comment": null, "summary": "This article explores the requirements for corpus compilation within the\nGiesKaNe project (University of Giessen and Kassel, Syntactic Basic Structures\nof New High German). The project is defined by three central characteristics:\nit is a reference corpus, a historical corpus, and a syntactically deeply\nannotated treebank. As a historical corpus, GiesKaNe aims to establish\nconnections with both historical and contemporary corpora, ensuring its\nrelevance across temporal and linguistic contexts. The compilation process\nstrikes the balance between innovation and adherence to standards, addressing\nboth internal project goals and the broader interests of the research\ncommunity. The methodological complexity of such a project is managed through a\ncomplementary interplay of human expertise and machine-assisted processes. The\narticle discusses foundational topics such as tokenization, normalization,\nsentence definition, tagging, parsing, and inter-annotator agreement, alongside\nadvanced considerations. These include comparisons between grammatical models,\nannotation schemas, and established de facto annotation standards as well as\nthe integration of human and machine collaboration. Notably, a novel method for\nmachine-assisted classification of texts along the continuum of conceptual\norality and literacy is proposed, offering new perspectives on text selection.\nFurthermore, the article introduces an approach to deriving de facto standard\nannotations from existing ones, mediating between standardization and\ninnovation. In the course of describing the workflow the article demonstrates\nthat even ambitious projects like GiesKaNe can be effectively implemented using\nexisting research infrastructure, requiring no specialized annotation tools.\nInstead, it is shown that the workflow can be based on the strategic use of a\nsimple spreadsheet and integrates the capabilities of the existing\ninfrastructure.", "AI": {"tldr": "GiesKaNe\u9879\u76ee\u662f\u4e00\u4e2a\u53c2\u8003\u3001\u5386\u53f2\u548c\u53e5\u6cd5\u6ce8\u91ca\u6811\u5e93\uff0c\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u4eba\u5de5\u548c\u673a\u5668\u7684\u65b9\u6cd5\u6765\u7f16\u8bd1\u8bed\u6599\u5e93\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6587\u672c\u5206\u7c7b\u65b9\u6cd5\u3002", "motivation": "\u672c\u6587\u63a2\u8ba8\u4e86GiesKaNe\u9879\u76ee\uff08\u5409\u68ee-\u5361\u585e\u5c14\u5927\u5b66\uff0c\u73b0\u4ee3\u5fb7\u8bed\u53e5\u6cd5\u57fa\u672c\u7ed3\u6784\uff09\u7684\u8bed\u6599\u5e93\u7f16\u8bd1\u8981\u6c42\u3002\u8be5\u9879\u76ee\u5177\u6709\u4e09\u4e2a\u4e2d\u5fc3\u7279\u5f81\uff1a\u5b83\u662f\u4e00\u4e2a\u53c2\u8003\u8bed\u6599\u5e93\u3001\u4e00\u4e2a\u5386\u53f2\u8bed\u6599\u5e93\u548c\u4e00\u4e2a\u53e5\u6cd5\u6df1\u5ea6\u6ce8\u91ca\u7684\u6811\u5e93\u3002\u4f5c\u4e3a\u5386\u53f2\u8bed\u6599\u5e93\uff0cGiesKaNe\u65e8\u5728\u4e0e\u5386\u53f2\u548c\u5f53\u4ee3\u8bed\u6599\u5e93\u5efa\u7acb\u8054\u7cfb\uff0c\u786e\u4fdd\u5176\u5728\u65f6\u95f4\u4e0e\u8bed\u8a00\u80cc\u666f\u4e2d\u7684\u76f8\u5173\u6027\u3002", "method": "\u6587\u7ae0\u8ba8\u8bba\u4e86\u5206\u8bcd\u3001\u89c4\u8303\u5316\u3001\u53e5\u5b50\u5b9a\u4e49\u3001\u6807\u8bb0\u3001\u89e3\u6790\u548c\u6ce8\u91ca\u5458\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u7b49\u57fa\u7840\u4e3b\u9898\uff0c\u4ee5\u53ca\u5bf9\u8bed\u6cd5\u6a21\u578b\u3001\u6ce8\u91ca\u6a21\u5f0f\u548c\u5df2\u5efa\u7acb\u7684\u516c\u8ba4\u6ce8\u91ca\u6807\u51c6\u4e4b\u95f4\u7684\u6bd4\u8f83\u4ee5\u53ca\u4eba\u7c7b\u548c\u673a\u5668\u534f\u4f5c\u7684\u6574\u5408\u7b49\u9ad8\u7ea7\u8003\u8651\u56e0\u7d20\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u673a\u5668\u8f85\u52a9\u5bf9\u6587\u672c\u8fdb\u884c\u6982\u5ff5\u53e3\u8bed\u548c\u4e66\u9762\u8bed\u8fde\u7eed\u5206\u7c7b\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u73b0\u6709\u6ce8\u91ca\u4e2d\u63a8\u5bfc\u51fa\u516c\u8ba4\u6807\u51c6\u6ce8\u91ca\u7684\u65b9\u6cd5\u3002", "result": "GiesKaNe\u9879\u76ee\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u8fde\u63a5\u5386\u53f2\u548c\u5f53\u4ee3\u8bed\u6599\u5e93\u7684\u53c2\u8003\u8bed\u6599\u5e93\u3001\u5386\u53f2\u8bed\u6599\u5e93\u548c\u53e5\u6cd5\u6df1\u5ea6\u6ce8\u91ca\u6811\u5e93\u3002\u901a\u8fc7\u7ed3\u5408\u4eba\u5de5\u548c\u673a\u5668\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u8be5\u9879\u76ee\u7ba1\u7406\u7740\u590d\u6742\u7684\u7f16\u8bd1\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u4ece\u5206\u8bcd\u5230\u6ce8\u91ca\u6a21\u5f0f\u7b49\u4e00\u7cfb\u5217\u6311\u6218\u3002", "conclusion": "\u8be5\u9879\u76ee\u7684\u5de5\u4f5c\u6d41\u7a0b\u8868\u660e\uff0c\u50cfGiesKaNe\u8fd9\u6837\u96c4\u5fc3\u52c3\u52c3\u7684\u9879\u76ee\u53ef\u4ee5\u6709\u6548\u5730\u5b9e\u65bd\uff0c\u800c\u65e0\u9700\u4e13\u95e8\u7684\u6ce8\u91ca\u5de5\u5177\uff0c\u800c\u662f\u53ef\u4ee5\u57fa\u4e8e\u5bf9\u7b80\u5355\u7535\u5b50\u8868\u683c\u7684\u6218\u7565\u4f7f\u7528\uff0c\u5e76\u6574\u5408\u73b0\u6709\u57fa\u7840\u8bbe\u65bd\u7684\u529f\u80fd\u3002"}}
{"id": "2502.04389", "title": "Overcoming Vision Language Model Challenges in Diagram Understanding: A Proof-of-Concept with XML-Driven Large Language Models Solutions", "url": "https://arxiv.org/abs/2502.04389", "pdf": "https://arxiv.org/pdf/2502.04389", "abs": "https://arxiv.org/abs/2502.04389", "authors": ["Shue Shiinoki", "Ryo Koshihara", "Hayato Motegi", "Masumi Morishige"], "categories": ["cs.SE", "cs.AI"], "comment": "The related code is available at\n  \\url{https://github.com/galirage/spreadsheet-intelligence}, which provides\n  the core library developed for this research. The experimental code using\n  this library can be found at\n  \\url{https://github.com/galirage/XMLDriven-Diagram-Understanding}", "summary": "Diagrams play a crucial role in visually conveying complex relationships and\nprocesses within business documentation. Despite recent advances in\nVision-Language Models (VLMs) for various image understanding tasks, accurately\nidentifying and extracting the structures and relationships depicted in\ndiagrams continues to pose significant challenges. This study addresses these\nchallenges by proposing a text-driven approach that bypasses reliance on VLMs'\nvisual recognition capabilities. Instead, it utilizes the editable source\nfiles--such as xlsx, pptx or docx--where diagram elements (e.g., shapes, lines,\nannotations) are preserved as textual metadata. In our proof-of-concept, we\nextracted diagram information from xlsx-based system design documents and\ntransformed the extracted shape data into textual input for Large Language\nModels (LLMs). This approach allowed the LLM to analyze relationships and\ngenerate responses to business-oriented questions without the bottleneck of\nimage-based processing. Experimental comparisons with a VLM-based method\ndemonstrated that the proposed text-driven framework yielded more accurate\nanswers for questions requiring detailed comprehension of diagram\nstructures.The results obtained in this study are not limited to the tested\n.xlsx files but can also be extended to diagrams in other documents with source\nfiles, such as Office pptx and docx formats. These findings highlight the\nfeasibility of circumventing VLM constraints through direct textual extraction\nfrom original source files. By enabling robust diagram understanding through\nLLMs, our method offers a promising path toward enhanced workflow efficiency\nand information analysis in real-world business scenarios.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u6587\u672c\u9a71\u52a8\u65b9\u6cd5\uff0c\u5229\u7528\u6e90\u6587\u4ef6\uff08\u5982 .xlsx, .pptx, .docx\uff09\u4e2d\u7684\u5143\u6570\u636e\u6765\u63d0\u53d6\u56fe\u8868\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u5206\u6790\uff0c\u4ee5\u63d0\u9ad8\u56fe\u8868\u7406\u89e3\u7684\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u65b9\u6cd5\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u5728\u5546\u4e1a\u6587\u6863\u4e2d\u51c6\u786e\u8bc6\u522b\u548c\u63d0\u53d6\u56fe\u8868\u7ed3\u6784\u4e0e\u5173\u7cfb\u65b9\u9762\u7684\u6311\u6218\uff0c\u514b\u670d\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5728\u5904\u7406\u6b64\u7c7b\u4efb\u52a1\u65f6\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6587\u672c\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u53ef\u7f16\u8f91\u7684\u6e90\u6587\u4ef6\uff08\u5982 xlsx\u3001pptx\u3001docx\uff09\u4e2d\u4fdd\u7559\u7684\u6587\u672c\u5143\u6570\u636e\u6765\u63d0\u53d6\u56fe\u8868\u4fe1\u606f\uff0c\u5e76\u5c06\u63d0\u53d6\u7684\u5f62\u72b6\u6570\u636e\u8f6c\u6362\u4e3a\u6587\u672c\u8f93\u5165\uff0c\u4f9b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u5206\u6790\u548c\u95ee\u7b54\uff0c\u4ece\u800c\u7ed5\u8fc7\u5bf9 VLM \u89c6\u89c9\u8bc6\u522b\u80fd\u529b\u7684\u4f9d\u8d56\u3002", "result": "\u901a\u8fc7\u5c06 xlsx \u6587\u4ef6\u4e2d\u7684\u56fe\u8868\u4fe1\u606f\u63d0\u53d6\u4e3a\u6587\u672c\u8f93\u5165\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u591f\u5206\u6790\u5173\u7cfb\u5e76\u56de\u7b54\u4e1a\u52a1\u95ee\u9898\uff0c\u5176\u51c6\u786e\u6027\u4f18\u4e8e\u57fa\u4e8e VLM \u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u5305\u542b\u6e90\u6587\u4ef6\u7684\u56fe\u8868\u683c\u5f0f\uff0c\u5982 pptx \u548c docx\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u6587\u672c\u9a71\u52a8\u6846\u67b6\u901a\u8fc7\u76f4\u63a5\u4ece\u6e90\u6587\u4ef6\u63d0\u53d6\u56fe\u8868\u4fe1\u606f\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u56de\u7b54\u9700\u8981\u8be6\u7ec6\u7406\u89e3\u56fe\u8868\u7ed3\u6784\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u7ed5\u8fc7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u9650\u5236\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u63d0\u9ad8\u5b9e\u9645\u4e1a\u52a1\u573a\u666f\u4e2d\u7684\u5de5\u4f5c\u6d41\u7a0b\u6548\u7387\u548c\u4fe1\u606f\u5206\u6790\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2501.18268", "title": "Reducing Aleatoric and Epistemic Uncertainty through Multi-modal Data Acquisition", "url": "https://arxiv.org/abs/2501.18268", "pdf": "https://arxiv.org/pdf/2501.18268", "abs": "https://arxiv.org/abs/2501.18268", "authors": ["Arthur Hoarau", "Benjamin Quost", "S\u00e9bastien Destercke", "Willem Waegeman"], "categories": ["cs.LG"], "comment": null, "summary": "To generate accurate and reliable predictions, modern AI systems need to\ncombine data from multiple modalities, such as text, images, audio,\nspreadsheets, and time series. Multi-modal data introduces new opportunities\nand challenges for disentangling uncertainty: it is commonly assumed in the\nmachine learning community that epistemic uncertainty can be reduced by\ncollecting more data, while aleatoric uncertainty is irreducible. However, this\nassumption is challenged in modern AI systems when information is obtained from\ndifferent modalities. This paper introduces an innovative data acquisition\nframework where uncertainty disentanglement leads to actionable decisions,\nallowing sampling in two directions: sample size and data modality. The main\nhypothesis is that aleatoric uncertainty decreases as the number of modalities\nincreases, while epistemic uncertainty decreases by collecting more\nobservations. We provide proof-of-concept implementations on two multi-modal\ndatasets to showcase our data acquisition framework, which combines ideas from\nactive learning, active feature acquisition and uncertainty quantification.", "AI": {"tldr": "\u901a\u8fc7\u589e\u52a0\u6570\u636e\u6a21\u6001\u548c\u6837\u672c\u91cf\u6765\u89e3\u51b3\u591a\u6a21\u6001\u6570\u636e\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5047\u8bbeepistemic uncertainty\u53ef\u4ee5\u901a\u8fc7\u589e\u52a0\u6570\u636e\u91cf\u6765\u51cf\u5c11\uff0c\u800caleatoric uncertainty\u662f\u4e0d\u53ef\u907f\u514d\u7684\u3002\u7136\u800c\uff0c\u5f53\u4fe1\u606f\u6765\u81ea\u4e0d\u540c\u6a21\u6001\u65f6\uff0c\u8fd9\u4e00\u5047\u8bbe\u53d7\u5230\u6311\u6218\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u591a\u6a21\u6001\u6570\u636e\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u79bb\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u91c7\u96c6\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u4e3b\u52a8\u5b66\u4e60\u3001\u4e3b\u52a8\u7279\u5f81\u91c7\u96c6\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u901a\u8fc7\u5728\u4e24\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6982\u5ff5\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u7684\u6570\u636e\u91c7\u96c6\u6846\u67b6\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u5206\u79bb\uff08epistemic uncertainty \u548c aleatoric uncertainty\uff09\u53ef\u4ee5\u6307\u5bfc\u6570\u636e\u91c7\u96c6\uff0c\u901a\u8fc7\u589e\u52a0\u6837\u672c\u91cf\u548c\u6570\u636e\u6a21\u6001\u6765\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2407.04065", "title": "On the Workflows and Smells of Leaderboard Operations (LBOps): An Exploratory Study of Foundation Model Leaderboards", "url": "https://arxiv.org/abs/2407.04065", "pdf": "https://arxiv.org/pdf/2407.04065", "abs": "https://arxiv.org/abs/2407.04065", "authors": ["Zhimin Zhao", "Abdul Ali Bangash", "Filipe Roseiro C\u00f4go", "Bram Adams", "Ahmed E. Hassan"], "categories": ["cs.SE", "cs.LG"], "comment": "Awesome Foundation Model Leaderboard List:\n  https://github.com/SAILResearch/awesome-foundation-model-leaderboards;\n  Foundation Model Leaderboard Search Toolkit:\n  https://huggingface.co/spaces/zhiminy/awesome-foundation-model-leaderboard-search", "summary": "Foundation models (FM), such as large language models (LLMs), which are\nlarge-scale machine learning (ML) models, have demonstrated remarkable\nadaptability in various downstream software engineering (SE) tasks, such as\ncode completion, code understanding, and software development. As a result, FM\nleaderboards have become essential tools for SE teams to compare and select the\nbest third-party FMs for their specific products and purposes. However, the\nlack of standardized guidelines for FM evaluation and comparison threatens the\ntransparency of FM leaderboards and limits stakeholders' ability to perform\neffective FM selection. As a first step towards addressing this challenge, our\nresearch focuses on understanding how these FM leaderboards operate in\nreal-world scenarios (\"leaderboard operations\") and identifying potential\npitfalls and areas for improvement (\"leaderboard smells\"). In this regard, we\ncollect up to 1,045 FM leaderboards from five different sources: GitHub,\nHugging Face Spaces, Papers With Code, spreadsheet and independent platform, to\nexamine their documentation and engage in direct communication with leaderboard\noperators to understand their workflows. Through card sorting and negotiated\nagreement, we identify five distinct workflow patterns and develop a domain\nmodel that captures the key components and their interactions within these\nworkflows. We then identify eight unique types of leaderboard smells in LBOps.\nBy mitigating these smells, SE teams can improve transparency, accountability,\nand collaboration in current LBOps practices, fostering a more robust and\nresponsible ecosystem for FM comparison and selection.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u4e2d\u57fa\u7840\u6a21\u578b\uff08FM\uff09\u6392\u884c\u699c\u7684\u8fd0\u4f5c\u60c5\u51b5\uff0c\u53d1\u73b0\u5b58\u5728\u201c\u6392\u884c\u699c\u5f02\u5473\u201d\u963b\u788d\u4e86\u900f\u660e\u5ea6\u548c\u6709\u6548\u7684\u6a21\u578b\u9009\u62e9\u3002\u7814\u7a76\u4eba\u5458\u6536\u96c6\u5e76\u5206\u6790\u4e86\u5927\u91cf\u6392\u884c\u699c\u6570\u636e\uff0c\u8bc6\u522b\u51fa\u4e94\u79cd\u5de5\u4f5c\u6d41\u7a0b\u6a21\u5f0f\u548c\u516b\u79cd\u5f02\u5473\u7c7b\u578b\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u7f13\u89e3\u8fd9\u4e9b\u5f02\u5473\u6765\u6539\u8fdb\u6392\u884c\u699c\u7684\u8fd0\u4f5c\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u8d1f\u8d23\u4efb\u7684 FM \u751f\u6001\u7cfb\u7edf\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u7f3a\u4e4f\u57fa\u7840\u6a21\u578b\uff08FM\uff09\u8bc4\u4f30\u548c\u6bd4\u8f83\u7684\u6807\u51c6\u5316\u6307\u5357\u6240\u5e26\u6765\u7684\u6311\u6218\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7406\u89e3 FM \u6392\u884c\u699c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u8fd0\u4f5c\u65b9\u5f0f\uff08\u201c\u6392\u884c\u699c\u8fd0\u4f5c\u201d\uff09\u5e76\u8bc6\u522b\u6f5c\u5728\u7684\u9677\u9631\u548c\u6539\u8fdb\u9886\u57df\uff08\u201c\u6392\u884c\u699c\u5f02\u5473\u201d\uff09\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u6765\u81ea GitHub\u3001Hugging Face Spaces\u3001Papers With Code\u3001\u7535\u5b50\u8868\u683c\u548c\u72ec\u7acb\u5e73\u53f0\u7684 1,045 \u4e2a FM \u6392\u884c\u699c\uff0c\u68c0\u67e5\u5176\u6587\u6863\u5e76\u4e0e\u6392\u884c\u699c\u8fd0\u8425\u8005\u8fdb\u884c\u76f4\u63a5\u6c9f\u901a\uff0c\u4ee5\u4e86\u89e3\u5176\u5de5\u4f5c\u6d41\u7a0b\u3002\u901a\u8fc7\u5361\u7247\u5206\u7c7b\u548c\u534f\u5546\u4e00\u81f4\uff0c\u786e\u5b9a\u4e86\u4e94\u79cd\u4e0d\u540c\u7684\u5de5\u4f5c\u6d41\u7a0b\u6a21\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u9886\u57df\u6a21\u578b\u6765\u6355\u83b7\u8fd9\u4e9b\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u5173\u952e\u7ec4\u4ef6\u53ca\u5176\u4ea4\u4e92\u3002\u968f\u540e\uff0c\u5728 LBOps \u4e2d\u8bc6\u522b\u51fa\u516b\u79cd\u72ec\u7279\u7684\u6392\u884c\u699c\u5f02\u5473\u3002", "result": "\u786e\u5b9a\u4e86\u4e94\u79cd\u4e0d\u540c\u7684\u5de5\u4f5c\u6d41\u7a0b\u6a21\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u9886\u57df\u6a21\u578b\u6765\u6355\u83b7\u8fd9\u4e9b\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u5173\u952e\u7ec4\u4ef6\u53ca\u5176\u4ea4\u4e92\u3002\u6b64\u5916\uff0c\u8fd8\u8bc6\u522b\u51fa LBOps \u4e2d\u7684\u516b\u79cd\u72ec\u7279\u7684\u6392\u884c\u699c\u5f02\u5473\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u548c\u7f13\u89e3\u201c\u6392\u884c\u699c\u5f02\u5473\u201d\uff0c\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u56e2\u961f\u53ef\u4ee5\u63d0\u9ad8\u201c\u6392\u884c\u699c\u8fd0\u4f5c\u201d\uff08LBOps\uff09\u5b9e\u8df5\u7684\u900f\u660e\u5ea6\u3001\u53ef\u4fe1\u5ea6\u548c\u534f\u4f5c\u6027\uff0c\u4ece\u800c\u4e3a\u201c\u57fa\u7840\u6a21\u578b\u201d\uff08FM\uff09\u7684\u6bd4\u8f83\u548c\u9009\u62e9\u5efa\u7acb\u4e00\u4e2a\u66f4\u5f3a\u5927\u3001\u66f4\u8d1f\u8d23\u4efb\u7684\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2412.11711", "title": "MiMoTable: A Multi-scale Spreadsheet Benchmark with Meta Operations for Table Reasoning", "url": "https://arxiv.org/abs/2412.11711", "pdf": "https://arxiv.org/pdf/2412.11711", "abs": "https://arxiv.org/abs/2412.11711", "authors": ["Zheng Li", "Yang Du", "Mao Zheng", "Mingyang Song"], "categories": ["cs.CL"], "comment": "Accepted by COLING 2025", "summary": "Extensive research has been conducted to explore the capability of Large\nLanguage Models (LLMs) for table reasoning and has significantly improved the\nperformance on existing benchmarks. However, tables and user questions in\nreal-world applications are more complex and diverse, presenting an unignorable\ngap compared to the existing benchmarks. To fill the gap, we propose a\n\\textbf{M}ult\\textbf{i}-scale spreadsheet benchmark with \\textbf{M}eta\n\\textbf{o}perations for \\textbf{Table} reasoning, named as MiMoTable.\nSpecifically, MiMoTable incorporates two key features. First, the tables in\nMiMoTable are all spreadsheets used in real-world scenarios, which cover seven\ndomains and contain different types. Second, we define a new criterion with six\ncategories of meta operations for measuring the difficulty of each question in\nMiMoTable, simultaneously as a new perspective for measuring the difficulty of\nthe existing benchmarks. Experimental results show that Claude-3.5-Sonnet\nachieves the best performance with 77.4\\% accuracy, indicating that there is\nstill significant room to improve for LLMs on MiMoTable. Furthermore, we grade\nthe difficulty of existing benchmarks according to our new criteria.\nExperiments have shown that the performance of LLMs decreases as the difficulty\nof benchmarks increases, thereby proving the effectiveness of our proposed new\ncriterion.", "AI": {"tldr": "MiMoTable\u662f\u4e00\u4e2a\u5305\u542b\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u8868\u683c\u548c\u65b0\u96be\u5ea6\u8bc4\u4f30\u6807\u51c6\u7684\u65b0\u57fa\u51c6\uff0c\u65e8\u5728\u6539\u8fdbLLM\u7684\u8868\u683c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u586b\u8865\u73b0\u6709\u8868\u683c\u63a8\u7406\u57fa\u51c6\u4e0e\u771f\u5b9e\u4e16\u754c\u8868\u683c\u548c\u95ee\u9898\u4e4b\u95f4\u5b58\u5728\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMiMoTable\u7684\u591a\u5c3a\u5ea6\u7535\u5b50\u8868\u683c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u771f\u5b9e\u4e16\u754c\u7684\u7535\u5b50\u8868\u683c\u548c\u5305\u542b\u516d\u79cd\u5143\u64cd\u4f5c\u7684\u96be\u5ea6\u8bc4\u4f30\u6807\u51c6\u3002", "result": "MiMoTable\u5305\u542b\u4e03\u4e2a\u9886\u57df\u3001\u4e0d\u540c\u7c7b\u578b\u7684\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u8868\u683c\uff0c\u5e76\u63d0\u51fa\u4e86\u8861\u91cf\u95ee\u9898\u96be\u5ea6\u7684\u516d\u7c7b\u5143\u64cd\u4f5c\u65b0\u6807\u51c6\u3002\u5b9e\u9a8c\u8868\u660eClaude-3.5-Sonnet\u51c6\u786e\u7387\u4e3a77.4%\uff0c\u4e14LLM\u5728\u96be\u5ea6\u66f4\u9ad8\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u4e0b\u964d\u3002", "conclusion": "LLMs\u5728MiMoTable\u4e0a\u7684\u8868\u73b0\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\uff0cClaude-3.5-Sonnet\u8fbe\u5230\u6700\u4f73\u51c6\u786e\u738777.4%\u3002\u65b0\u63d0\u51fa\u7684\u8bc4\u4f30\u6807\u51c6\u80fd\u6709\u6548\u8861\u91cf\u57fa\u51c6\u6d4b\u8bd5\u7684\u96be\u5ea6\uff0c\u4e14LLM\u5728\u8be5\u6807\u51c6\u4e0b\u96be\u5ea6\u8d8a\u9ad8\u8868\u73b0\u8d8a\u5dee\u3002"}}
{"id": "2412.15030", "title": "When Copilot Becomes Autopilot: Generative AI's Critical Risk to Knowledge Work and a Critical Solution", "url": "https://arxiv.org/abs/2412.15030", "pdf": "https://arxiv.org/pdf/2412.15030", "abs": "https://arxiv.org/abs/2412.15030", "authors": ["Advait Sarkar", "Xiaotong", "Xu", "Neil Toronto", "Ian Drosos", "Christian Poelitz"], "categories": ["cs.HC"], "comment": null, "summary": "Generative AI, with its tendency to \"hallucinate\" incorrect results, may pose\na risk to knowledge work by introducing errors. On the other hand, it may also\nprovide unprecedented opportunities for users, particularly non-experts, to\nlearn and apply advanced software features and greatly increase the scope and\ncomplexity of tasks they can successfully achieve.\n  As an example of a complex knowledge workflow that is subject to risks and\nopportunities from generative AI, we consider the spreadsheet. AI\nhallucinations are an important challenge, but they are not the greatest risk\nposed by generative AI to spreadsheet workflows. Rather, as more work can be\nsafely delegated to AI, the risk is that human critical thinking -- the ability\nto holistically and rigorously evaluate a problem and its solutions -- is\ndegraded in the process. The solution is to design the interfaces of generative\nAI systems deliberately to foster and encourage critical thinking in knowledge\nwork, building primarily on a long history of research on critical thinking\ntools for education.\n  We discuss a prototype system for the activity of critical shortlisting in\nspreadsheets. The system uses generative AI to suggest shortlisting criteria\nand applies these criteria to sort rows in a spreadsheet. It also generates\n\"provocations\": short text snippets that critique the AI-generated criteria,\nhighlighting risks, shortcomings, and alternatives. Our prototype opens up a\nrich and completely unexplored design space of critical thinking tools for\nmodern AI-assisted knowledge work. We outline a research agenda for AI as a\ncritic or provocateur, including questions about where and when provocations\nshould appear, their form and content, and potential design trade-offs.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u77e5\u8bc6\u5de5\u4f5c\u4e2d\u6709\u98ce\u9669\uff08\u201c\u5e7b\u89c9\u201d\uff09\uff0c\u4f46\u4e5f\u6709\u673a\u9047\u3002\u6700\u5927\u7684\u98ce\u9669\u662f\u4eba\u7c7b\u6279\u5224\u6027\u601d\u7ef4\u7684\u9000\u5316\u3002\u8bbe\u8ba1\u80fd\u591f\u57f9\u517b\u6279\u5224\u6027\u601d\u7ef4\u7684AI\u754c\u9762\u662f\u5173\u952e\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u7535\u5b50\u8868\u683c\u7684AI\u7b5b\u9009\u539f\u578b\uff0c\u5e76\u901a\u8fc7\u201c\u6311\u8845\u201d\u6765\u5ba1\u89c6AI\u6807\u51c6\uff0c\u4e3aAI\u8f85\u52a9\u77e5\u8bc6\u5de5\u4f5c\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u77e5\u8bc6\u5de5\u4f5c\u4e2d\u53ef\u80fd\u5f15\u5165\u9519\u8bef\uff08\u201c\u5e7b\u89c9\u201d\uff09\uff0c\u4f46\u4e5f\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u5b66\u4e60\u548c\u5e94\u7528\u9ad8\u7ea7\u8f6f\u4ef6\u529f\u80fd\u7684\u673a\u4f1a\uff0c\u4ece\u800c\u589e\u52a0\u4e86\u4ed6\u4eec\u80fd\u591f\u6210\u529f\u5b8c\u6210\u7684\u4efb\u52a1\u7684\u8303\u56f4\u548c\u590d\u6742\u6027\u3002\u7136\u800c\uff0c\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u7684\u5de5\u4f5c\u53ef\u4ee5\u5b89\u5168\u5730\u59d4\u6258\u7ed9AI\uff0c\u4eba\u7c7b\u7684\u6279\u5224\u6027\u601d\u7ef4\u53ef\u80fd\u4f1a\u53d7\u5230\u635f\u5bb3\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u8bbe\u8ba1\u80fd\u591f\u57f9\u517b\u548c\u9f13\u52b1\u6279\u5224\u6027\u601d\u7ef4\u7684\u751f\u6210\u5f0fAI\u7cfb\u7edf\u754c\u9762\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u751f\u6210\u5f0fAI\u8fdb\u884c\u5173\u952e\u7b5b\u9009\u7684\u539f\u578b\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u5efa\u8bae\u7b5b\u9009\u6807\u51c6\u3001\u5bf9\u7535\u5b50\u8868\u683c\u8fdb\u884c\u6392\u5e8f\uff0c\u5e76\u751f\u6210\u201c\u6311\u8845\u201d\u6587\u672c\u6765\u6279\u8bc4AI\u751f\u6210\u7684\u6807\u51c6\uff0c\u7a81\u51fa\u98ce\u9669\u3001\u7f3a\u70b9\u548c\u66ff\u4ee3\u65b9\u6848\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u7535\u5b50\u8868\u683c\u5173\u952e\u7b5b\u9009\u7684\u539f\u578b\u7cfb\u7edf\uff0c\u5e76\u63a2\u8ba8\u4e86AI\u4f5c\u4e3a\u6279\u8bc4\u8005\u6216\u6311\u8845\u8005\u7684\u7814\u7a76\u8bae\u7a0b\uff0c\u5305\u62ec\u6311\u8845\u51fa\u73b0\u7684\u65f6\u95f4\u3001\u5f62\u5f0f\u3001\u5185\u5bb9\u4ee5\u53ca\u6f5c\u5728\u7684\u8bbe\u8ba1\u6743\u8861\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u77e5\u8bc6\u5de5\u4f5c\u4e2d\u5e26\u6765\u4e86\u98ce\u9669\u548c\u673a\u9047\u3002\u867d\u7136\u201c\u5e7b\u89c9\u201d\u4f1a\u5f15\u5165\u9519\u8bef\uff0c\u4f46\u5b83\u4e5f\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u5b66\u4e60\u548c\u5e94\u7528\u9ad8\u7ea7\u8f6f\u4ef6\u529f\u80fd\u7684\u673a\u4f1a\u3002\u7136\u800c\uff0c\u6700\u5927\u7684\u98ce\u9669\u5728\u4e8e\u4eba\u7c7b\u6279\u5224\u6027\u601d\u7ef4\u7684\u9000\u5316\u3002\u901a\u8fc7\u8bbe\u8ba1\u80fd\u591f\u57f9\u517b\u6279\u5224\u6027\u601d\u7ef4\u7684\u751f\u6210\u5f0fAI\u754c\u9762\uff0c\u53ef\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u751f\u6210\u5f0fAI\u8fdb\u884c\u5173\u952e\u7b5b\u9009\u7684\u539f\u578b\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u201c\u6311\u8845\u201d\u6765\u5ba1\u89c6AI\u751f\u6210\u7684\u6807\u51c6\uff0c\u4ece\u800c\u5f00\u8f9f\u4e86AI\u8f85\u52a9\u77e5\u8bc6\u5de5\u4f5c\u6279\u5224\u6027\u601d\u7ef4\u5de5\u5177\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2412.14062", "title": "Understanding and Evaluating Trust in Generative AI and Large Language Models for Spreadsheets", "url": "https://arxiv.org/abs/2412.14062", "pdf": "https://arxiv.org/pdf/2412.14062", "abs": "https://arxiv.org/abs/2412.14062", "authors": ["Simon Thorne"], "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Generative AI and Large Language Models (LLMs) hold promise for automating\nspreadsheet formula creation. However, due to hallucinations, bias and variable\nuser skill, outputs obtained from generative AI cannot be assumed to be\naccurate or trustworthy. To address these challenges, a trustworthiness\nframework is proposed based on evaluating the transparency and dependability of\nthe formula. The transparency of the formula is explored through explainability\n(understanding the formula's reasoning) and visibility (inspecting the\nunderlying algorithms). The dependability of the generated formula is evaluated\nin terms of reliability (consistency and accuracy) and ethical considerations\n(bias and fairness). The paper also examines the drivers to these metrics in\nthe form of hallucinations, training data bias and poorly constructed prompts.\nFinally, examples of mistrust in technology are considered and the consequences\nexplored.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u7684\u7535\u5b50\u8868\u683c\u516c\u5f0f\u4e0d\u53ef\u4fe1\uff1f\u8bd5\u8bd5\u8fd9\u4e2a\u4fe1\u4efb\u6846\u67b6\uff0c\u5b83\u80fd\u8bc4\u4f30\u516c\u5f0f\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\uff01", "motivation": "\u7531\u4e8e\u751f\u6210\u5f0fAI\u7684\u5e7b\u89c9\u3001\u504f\u5dee\u548c\u7528\u6237\u6280\u80fd\u5dee\u5f02\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u751f\u6210\u516c\u5f0f\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u9700\u8981\u4e00\u4e2a\u4fe1\u4efb\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u901a\u8fc7\u8bc4\u4f30\u516c\u5f0f\u7684\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u89c1\u6027\u3001\u53ef\u9760\u6027\u548c\u9053\u5fb7\u6027\u6765\u6784\u5efa\u4fe1\u4efb\u6846\u67b6\uff0c\u5e76\u5206\u6790\u4e86\u5e7b\u89c9\u3001\u8bad\u7ec3\u6570\u636e\u504f\u5dee\u548c\u63d0\u793a\u8bcd\u6784\u9020\u4e0d\u826f\u7b49\u56e0\u7d20\u5bf9\u8fd9\u4e9b\u6307\u6807\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u63a2\u8ba8\u4e86\u63d0\u9ad8\u751f\u6210\u5f0fAI\u7535\u5b50\u8868\u683c\u516c\u5f0f\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u8003\u8651\u4e86\u4e0d\u4fe1\u4efb\u6280\u672f\u7684\u4f8b\u5b50\u53ca\u5176\u540e\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u7684\u751f\u6210\u5f0fAI\u7535\u5b50\u8868\u683c\u516c\u5f0f\u7684\u4fe1\u4efb\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3AI\u751f\u6210\u516c\u5f0f\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u95ee\u9898\u3002"}}
{"id": "2412.02357", "title": "Dynamic Prompt Middleware: Contextual Prompt Refinement Controls for Comprehension Tasks", "url": "https://arxiv.org/abs/2412.02357", "pdf": "https://arxiv.org/pdf/2412.02357", "abs": "https://arxiv.org/abs/2412.02357", "authors": ["Ian Drosos", "Jack Williams", "Advait Sarkar", "Nicholas Wilson"], "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Effective prompting of generative AI is challenging for many users,\nparticularly in expressing context for comprehension tasks such as explaining\nspreadsheet formulas, Python code, and text passages. Prompt middleware aims to\naddress this barrier by assisting in prompt construction, but barriers remain\nfor users in expressing adequate control so that they can receive AI-responses\nthat match their preferences.\n  We conduct a formative survey (n=38) investigating user needs for control\nover AI-generated explanations in comprehension tasks, which uncovers a\ntrade-off between standardized but predictable support for prompting, and\nadaptive but unpredictable support tailored to the user and task. To explore\nthis trade-off, we implement two prompt middleware approaches: Dynamic Prompt\nRefinement Control (Dynamic PRC) and Static Prompt Refinement Control (Static\nPRC). The Dynamic PRC approach generates context-specific UI elements that\nprovide prompt refinements based on the user's prompt and user needs from the\nAI, while the Static PRC approach offers a preset list of generally applicable\nrefinements.\n  We evaluate these two approaches with a controlled user study (n=16) to\nassess the impact of these approaches on user control of AI responses for\ncrafting better explanations. Results show a preference for the Dynamic PRC\napproach as it afforded more control, lowered barriers to providing context,\nand encouraged exploration and reflection of the tasks, but that reasoning\nabout the effects of different generated controls on the final output remains\nchallenging. Drawing on participant feedback, we discuss design implications\nfor future Dynamic PRC systems that enhance user control of AI responses. Our\nfindings suggest that dynamic prompt middleware can improve the user experience\nof generative AI workflows by affording greater control and guide users to a\nbetter AI response.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u7528\u6237\u5728\u7406\u89e3\u4efb\u52a1\u4e2d\u63a7\u5236AI\u751f\u6210\u89e3\u91ca\u7684\u9700\u6c42\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDynamic PRC\u7684\u63d0\u793a\u4e2d\u95f4\u4ef6\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u63d0\u4f9b\u4e0a\u4e0b\u6587\u76f8\u5173\u7684UI\u5143\u7d20\u6765\u5e2e\u52a9\u7528\u6237\u6539\u8fdb\u63d0\u793a\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDynamic PRC\u4f18\u4e8eStatic PRC\uff0c\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u7528\u6237\u63a7\u5236\u548c\u4f53\u9a8c\uff0c\u4f46\u7528\u6237\u5728\u7406\u89e3\u63a7\u4ef6\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u65b9\u9762\u4ecd\u6709\u5f85\u6539\u8fdb\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u6709\u6548\u63d0\u793a\u5bf9\u8bb8\u591a\u7528\u6237\u6765\u8bf4\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5728\u4e3a\u7406\u89e3\u4efb\u52a1\uff08\u4f8b\u5982\uff0c\u89e3\u91ca\u7535\u5b50\u8868\u683c\u516c\u5f0f\u3001Python\u4ee3\u7801\u548c\u6587\u672c\u6bb5\u843d\uff09\u8868\u8fbe\u4e0a\u4e0b\u6587\u65f6\u3002\u63d0\u793a\u4e2d\u95f4\u4ef6\u65e8\u5728\u901a\u8fc7\u8f85\u52a9\u63d0\u793a\u6784\u5efa\u6765\u89e3\u51b3\u8fd9\u4e00\u969c\u788d\uff0c\u4f46\u7528\u6237\u5728\u8868\u8fbe\u5145\u5206\u63a7\u5236\u4ee5\u4f7f\u4ed6\u4eec\u80fd\u591f\u83b7\u5f97\u7b26\u5408\u5176\u504f\u597d\u7684AI\u54cd\u5e94\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u969c\u788d\u3002", "method": "\u901a\u8fc7\u4e00\u9879\u5305\u542b38\u540d\u53c2\u4e0e\u8005\u7684\u5f62\u6210\u6027\u8c03\u67e5\uff0c\u7814\u7a76\u4e86\u7528\u6237\u5bf9AI\u751f\u6210\u89e3\u91ca\u7684\u63a7\u5236\u9700\u6c42\u3002\u7136\u540e\uff0c\u6211\u4eec\u5b9e\u73b0\u4e86\u4e24\u79cd\u63d0\u793a\u4e2d\u95f4\u4ef6\u65b9\u6cd5\uff1a\u52a8\u6001\u63d0\u793a\u6539\u8fdb\u63a7\u5236\uff08Dynamic PRC\uff09\u548c\u9759\u6001\u63d0\u793a\u6539\u8fdb\u63a7\u5236\uff08Static PRC\uff09\u3002\u6700\u540e\uff0c\u901a\u8fc7\u4e00\u9879\u5305\u542b16\u540d\u53c2\u4e0e\u8005\u7684\u5bf9\u7167\u7528\u6237\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5bf9\u7528\u6237\u63a7\u5236AI\u54cd\u5e94\u4ee5\u5236\u4f5c\u66f4\u597d\u89e3\u91ca\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u7528\u6237\u66f4\u503e\u5411\u4e8eDynamic PRC\u65b9\u6cd5\uff0c\u56e0\u4e3a\u5b83\u63d0\u4f9b\u4e86\u66f4\u591a\u7684\u63a7\u5236\uff0c\u964d\u4f4e\u4e86\u63d0\u4f9b\u4e0a\u4e0b\u6587\u7684\u969c\u788d\uff0c\u5e76\u9f13\u52b1\u5bf9\u4efb\u52a1\u8fdb\u884c\u63a2\u7d22\u548c\u53cd\u601d\u3002\u7136\u800c\uff0c\u7528\u6237\u5728\u63a8\u7406\u4e0d\u540c\u751f\u6210\u7684\u63a7\u4ef6\u5bf9\u6700\u7ec8\u8f93\u51fa\u7684\u5f71\u54cd\u65b9\u9762\u4ecd\u7136\u9762\u4e34\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u52a8\u6001\u63d0\u793a\u4e2d\u95f4\u4ef6\u53ef\u4ee5\u901a\u8fc7\u63d0\u4f9b\u66f4\u5927\u7684\u63a7\u5236\u529b\u6765\u6539\u5584\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5de5\u4f5c\u6d41\u7684\u7528\u6237\u4f53\u9a8c\uff0c\u5e76\u5f15\u5bfc\u7528\u6237\u83b7\u5f97\u66f4\u597d\u7684AI\u54cd\u5e94\u3002"}}
{"id": "2406.12031", "title": "Large Scale Transfer Learning for Tabular Data via Language Modeling", "url": "https://arxiv.org/abs/2406.12031", "pdf": "https://arxiv.org/pdf/2406.12031", "abs": "https://arxiv.org/abs/2406.12031", "authors": ["Josh Gardner", "Juan C. Perdomo", "Ludwig Schmidt"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "NeurIPS 2024 camera-ready updates", "summary": "Tabular data -- structured, heterogeneous, spreadsheet-style data with rows\nand columns -- is widely used in practice across many domains. However, while\nrecent foundation models have reduced the need for developing task-specific\ndatasets and predictors in domains such as language modeling and computer\nvision, this transfer learning paradigm has not had similar impact in the\ntabular domain. In this work, we seek to narrow this gap and present TabuLa-8B,\na language model for tabular prediction. We define a process for extracting a\nlarge, high-quality training dataset from the TabLib corpus, proposing methods\nfor tabular data filtering and quality control. Using the resulting dataset,\nwhich comprises over 2.1B rows from over 4M unique tables, we fine-tune a Llama\n3-8B large language model (LLM) for tabular data prediction (classification and\nbinned regression) using a novel packing and attention scheme for tabular\nprediction. Through evaluation across a test suite of 329 datasets, we find\nthat TabuLa-8B has zero-shot accuracy on unseen tables that is over 15\npercentage points (pp) higher than random guessing, a feat that is not possible\nwith existing state-of-the-art tabular prediction models (e.g. XGBoost,\nTabPFN). In the few-shot setting (1-32 shots), without any fine-tuning on the\ntarget datasets, TabuLa-8B is 5-15 pp more accurate than XGBoost and TabPFN\nmodels that are explicitly trained on equal, or even up to 16x more data. We\nrelease our model, code, and data along with the publication of this paper.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3a TabuLa-8B \u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u8868\u683c\u9884\u6d4b\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u548c\u65b0\u9896\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u8868\u683c\u9884\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u65e8\u5728\u5f25\u5408\u57fa\u7840\u6a21\u578b\u5728\u8868\u683c\u6570\u636e\u9886\u57df\u7684\u5e94\u7528\u4e0e\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u9886\u57df\u76f8\u6bd4\u5b58\u5728\u7684\u5dee\u8ddd\uff0c\u4e3a\u8868\u683c\u9884\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e00\u4e2a\u5f3a\u5927\u7684\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a TabuLa-8B \u7684\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u8868\u683c\u9884\u6d4b\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u4ece TabLib \u8bed\u6599\u5e93\u4e2d\u63d0\u53d6\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u91c7\u7528\u65b0\u9896\u7684\u6253\u5305\u548c\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u9002\u5e94\u8868\u683c\u6570\u636e\u7684\u7279\u6027\u3002", "result": "TabuLa-8B \u5728 329 \u4e2a\u6570\u636e\u96c6\u7684\u6d4b\u8bd5\u5957\u4ef6\u4e0a\uff0c\u96f6\u6837\u672c\u51c6\u786e\u7387\u6bd4\u968f\u673a\u731c\u6d4b\u9ad8\u51fa 15 \u4e2a\u767e\u5206\u70b9\u4ee5\u4e0a\u3002\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\uff0c\u5176\u51c6\u786e\u7387\u6bd4\u7ecf\u8fc7\u663e\u5f0f\u8bad\u7ec3\u7684 XGBoost \u548c TabPFN \u6a21\u578b\u9ad8 5-15 \u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "TabuLa-8B \u5728\u8868\u683c\u9884\u6d4b\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5982 XGBoost \u548c TabPFN\u3002"}}
{"id": "2402.05121", "title": "Large Language Model for Table Processing: A Survey", "url": "https://arxiv.org/abs/2402.05121", "pdf": "https://arxiv.org/pdf/2402.05121", "abs": "https://arxiv.org/abs/2402.05121", "authors": ["Weizheng Lu", "Jing Zhang", "Ju Fan", "Zihao Fu", "Yueguo Chen", "Xiaoyong Du"], "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Tables, typically two-dimensional and structured to store large amounts of\ndata, are essential in daily activities like database queries, spreadsheet\nmanipulations, web table question answering, and image table information\nextraction. Automating these table-centric tasks with Large Language Models\n(LLMs) or Visual Language Models (VLMs) offers significant public benefits,\ngarnering interest from academia and industry. This survey provides a\ncomprehensive overview of table-related tasks, examining both user scenarios\nand technical aspects. It covers traditional tasks like table question\nanswering as well as emerging fields such as spreadsheet manipulation and table\ndata analysis. We summarize the training techniques for LLMs and VLMs tailored\nfor table processing. Additionally, we discuss prompt engineering, particularly\nthe use of LLM-powered agents, for various table-related tasks. Finally, we\nhighlight several challenges, including diverse user input when serving and\nslow thinking using chain-of-thought.", "AI": {"tldr": "\u8be5\u8c03\u67e5\u603b\u7ed3\u4e86\u5904\u7406\u8868\u683c\u7684LLM\u548cVLM\u7684\u8bad\u7ec3\u548c\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u5e76\u8ba8\u8bba\u4e86\u76f8\u5173\u6311\u6218\u3002", "motivation": "\u81ea\u52a8\u5316\u8fd9\u4e9b\u4ee5\u8868\u683c\u4e3a\u4e2d\u5fc3\u7684\u4efb\u52a1\uff08\u5982\u6570\u636e\u5e93\u67e5\u8be2\u3001\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u3001\u7f51\u7edc\u8868\u683c\u95ee\u7b54\u548c\u56fe\u50cf\u8868\u683c\u4fe1\u606f\u63d0\u53d6\uff09\u5177\u6709\u663e\u8457\u7684\u516c\u5171\u5229\u76ca\uff0c\u5e76\u5f15\u8d77\u4e86\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7684\u5174\u8da3\u3002", "method": "\u8be5\u8c03\u67e5\u603b\u7ed3\u4e86\u7528\u4e8e\u8868\u683c\u5904\u7406\u7684LLM\u548cVLM\u7684\u8bad\u7ec3\u6280\u672f\uff0c\u5e76\u8ba8\u8bba\u4e86\u7528\u4e8e\u5404\u79cd\u8868\u683c\u76f8\u5173\u4efb\u52a1\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u7279\u522b\u662fLLM\u9a71\u52a8\u7684\u4ee3\u7406\u3002", "result": "\u8be5\u8c03\u67e5\u5168\u9762\u6982\u8ff0\u4e86\u4e0e\u8868\u683c\u76f8\u5173\u7684\u4efb\u52a1\uff0c\u5305\u62ec\u4f20\u7edf\u4efb\u52a1\uff08\u5982\u8868\u683c\u95ee\u7b54\uff09\u548c\u65b0\u5174\u9886\u57df\uff08\u5982\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u548c\u8868\u683c\u6570\u636e\u5206\u6790\uff09\u3002", "conclusion": "\u6b64\u8c03\u67e5\u5168\u9762\u6982\u8ff0\u4e86\u4e0e\u8868\u683c\u76f8\u5173\u7684\u4efb\u52a1\uff0c\u6db5\u76d6\u4e86\u7528\u6237\u573a\u666f\u548c\u6280\u672f\u65b9\u9762\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u9488\u5bf9\u8868\u683c\u5904\u7406\u7684LLM\u548cVLM\u8bad\u7ec3\u6280\u672f\uff0c\u4ee5\u53ca\u7528\u4e8e\u5404\u79cd\u8868\u683c\u4efb\u52a1\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u7279\u522b\u662fLLM\u9a71\u52a8\u7684\u4ee3\u7406\u3002"}}
{"id": "2406.14991", "title": "SpreadsheetBench: Towards Challenging Real World Spreadsheet Manipulation", "url": "https://arxiv.org/abs/2406.14991", "pdf": "https://arxiv.org/pdf/2406.14991", "abs": "https://arxiv.org/abs/2406.14991", "authors": ["Zeyao Ma", "Bohan Zhang", "Jing Zhang", "Jifan Yu", "Xiaokang Zhang", "Xiaohan Zhang", "Sijia Luo", "Xi Wang", "Jie Tang"], "categories": ["cs.CL", "cs.SE"], "comment": "Neurips 2024 (Spotlight); Homepage:\n  https://spreadsheetbench.github.io/", "summary": "We introduce SpreadsheetBench, a challenging spreadsheet manipulation\nbenchmark exclusively derived from real-world scenarios, designed to immerse\ncurrent large language models (LLMs) in the actual workflow of spreadsheet\nusers. Unlike existing benchmarks that rely on synthesized queries and\nsimplified spreadsheet files, SpreadsheetBench is built from 912 real questions\ngathered from online Excel forums, which reflect the intricate needs of users.\nThe associated spreadsheets from the forums contain a variety of tabular data\nsuch as multiple tables, non-standard relational tables, and abundant\nnon-textual elements. Furthermore, we propose a more reliable evaluation metric\nakin to online judge platforms, where multiple spreadsheet files are created as\ntest cases for each instruction, ensuring the evaluation of robust solutions\ncapable of handling spreadsheets with varying values. Our comprehensive\nevaluation of various LLMs under both single-round and multi-round inference\nsettings reveals a substantial gap between the state-of-the-art (SOTA) models\nand human performance, highlighting the benchmark's difficulty.", "AI": {"tldr": "SpreadsheetBench\u662f\u4e00\u4e2a\u5305\u542b\u771f\u5b9e\u4e16\u754cExcel\u95ee\u9898\u548c\u6570\u636e\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u7535\u5b50\u8868\u683c\u5904\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002\u73b0\u6709\u6a21\u578b\u8868\u73b0\u8fdc\u4e0d\u5982\u4eba\u7c7b\uff0c\u8868\u660e\u8be5\u9886\u57df\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u65e8\u5728\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63d0\u4f9b\u4e00\u4e2a\u66f4\u8d34\u8fd1\u771f\u5b9e\u7535\u5b50\u8868\u683c\u7528\u6237\u5de5\u4f5c\u6d41\u7a0b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u514b\u670d\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u5408\u6210\u67e5\u8be2\u548c\u7b80\u5316\u6587\u4ef6\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpreadsheetBench\u7684\u65b0\u578b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u57fa\u51c6\u6d4b\u8bd5\u5305\u542b912\u4e2a\u6765\u81ea\u5728\u7ebfExcel\u8bba\u575b\u7684\u771f\u5b9e\u7528\u6237\u95ee\u9898\u548c\u76f8\u5173\u7535\u5b50\u8868\u683c\u6570\u636e\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7c7b\u4f3c\u5728\u7ebf\u5224\u9898\u5e73\u53f0\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u4f7f\u7528\u591a\u4e2a\u7535\u5b50\u8868\u683c\u6587\u4ef6\u4f5c\u4e3a\u6d4b\u8bd5\u7528\u4f8b\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728\u5355\u8f6e\u548c\u591a\u8f6e\u63a8\u7406\u8bbe\u7f6e\u4e0b\u5bf9\u591a\u79cdLLM\u8fdb\u884c\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5373\u4f7f\u662fSOTA\u6a21\u578b\u5728\u5904\u7406SpreadsheetBench\u57fa\u51c6\u6d4b\u8bd5\u65f6\uff0c\u4e0e\u4eba\u7c7b\u8868\u73b0\u76f8\u6bd4\u4ecd\u5b58\u5728\u5de8\u5927\u5dee\u8ddd\uff0c\u8bc1\u660e\u4e86\u8be5\u57fa\u51c6\u6d4b\u8bd5\u7684\u6311\u6218\u6027\u3002", "conclusion": "\u73b0\u6709\u7684LLM\u5728\u5904\u7406\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u8868\u683c\u4efb\u52a1\u65b9\u9762\u4e0e\u4eba\u7c7b\u6c34\u5e73\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u8be5\u57fa\u51c6\u6d4b\u8bd5\u7a81\u663e\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2409.20224", "title": "Trapped in Transformative Agreements? A Multifaceted Analysis of >1,000 Contracts", "url": "https://arxiv.org/abs/2409.20224", "pdf": "https://arxiv.org/pdf/2409.20224", "abs": "https://arxiv.org/abs/2409.20224", "authors": ["Laura Rothfritz", "W. Benedikt Schmal", "Ulrich Herb"], "categories": ["cs.DL"], "comment": "37 pages, appendix", "summary": "Transformative agreements between academic publishers and research\ninstitutions are ubiquitous. The 'Efficiency and Standards for Article Charges'\n(ESAC) Initiative lists more than 1,000 contracts in its database. We make use\nof this unique dataset by web-scraping the details of every contract to\nsubstantially expand the overview spreadsheet provided by the ESAC Initiative.\nBased on that hitherto unused data source, we combine qualitative and\nquantitative methods to conduct an in-depth analysis of the contract\ncharacteristics and the TA landscape. Our analysis demonstrates that research\ninstitutions seem to be 'trapped' in transformative agreements. Instead of\nbeing a bridge towards a fully Open Access world, academia is stuck in the\nhybrid system. This endows the legacy (non-Open Access) publishing houses with\nsubstantial market power. It raises entry barriers, lowers competition, and\nincreases costs for libraries and universities.", "AI": {"tldr": "\u53d8\u9769\u6027\u534f\u8bae\u672a\u80fd\u5b9e\u73b0\u5b8c\u5168\u5f00\u653e\u83b7\u53d6\uff0c\u53cd\u800c\u4f7f\u5b66\u672f\u754c\u9677\u5165\u6df7\u5408\u7cfb\u7edf\uff0c\u4f7f\u4f20\u7edf\u51fa\u7248\u5546\u53d7\u76ca\uff0c\u589e\u52a0\u4e86\u5927\u5b66\u6210\u672c\u3002", "motivation": "\u5229\u7528ESAC\u6570\u636e\u5e93\u7684\u5408\u540c\u6570\u636e\uff0c\u6df1\u5165\u5206\u6790\u53d8\u9769\u6027\u534f\u8bae\u7684\u7279\u5f81\u53ca\u5176\u5bf9\u5b66\u672f\u51fa\u7248\u548c\u5f00\u653e\u83b7\u53d6\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7f51\u7edc\u6293\u53d6ESAC\u6570\u636e\u5e93\u4e2d\u76841000\u591a\u4e2a\u5408\u540c\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u5e76\u7ed3\u5408\u5b9a\u6027\u548c\u5b9a\u91cf\u65b9\u6cd5\u5bf9\u5408\u540c\u7279\u5f81\u548cTA\u683c\u5c40\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5b66\u672f\u673a\u6784\u88ab\u56f0\u5728\u53d8\u9769\u6027\u534f\u8bae\u4e2d\uff0c\u963b\u788d\u4e86\u5411\u5b8c\u5168\u5f00\u653e\u83b7\u53d6\u7684\u8fc7\u6e21\uff0c\u5e76\u4f7f\u4f20\u7edf\u51fa\u7248\u5546\u83b7\u5f97\u5f3a\u5927\u7684\u5e02\u573a\u529b\u91cf\uff0c\u63d0\u9ad8\u4e86\u8fdb\u5165\u58c1\u5792\uff0c\u964d\u4f4e\u4e86\u7ade\u4e89\uff0c\u589e\u52a0\u4e86\u56fe\u4e66\u9986\u548c\u5927\u5b66\u7684\u6210\u672c\u3002", "conclusion": "\u5b66\u672f\u673a\u6784\u4f3c\u4e4e\u88ab\u56f0\u5728\u53d8\u9769\u6027\u534f\u8bae\u4e2d\uff0c\u963b\u788d\u4e86\u5411\u5b8c\u5168\u5f00\u653e\u83b7\u53d6\u7684\u8fc7\u6e21\uff0c\u5e76\u4f7f\u4f20\u7edf\u51fa\u7248\u5546\u53d7\u76ca\u3002"}}
{"id": "2409.08897", "title": "Ensuring Adherence to Standards in Experiment-Related Metadata Entered Via Spreadsheets", "url": "https://arxiv.org/abs/2409.08897", "pdf": "https://arxiv.org/pdf/2409.08897", "abs": "https://arxiv.org/abs/2409.08897", "authors": ["Martin J. O'Connor", "Josef Hardi", "Marcos Mart\u00ednez-Romero", "Sowmya Somasundaram", "Brendan Honick", "Stephen A. Fisher", "Ajay Pillai", "Mark A. Musen"], "categories": ["cs.DL"], "comment": null, "summary": "Scientists increasingly recognize the importance of providing rich,\nstandards-adherent metadata to describe their experimental results. Despite the\navailability of sophisticated tools to assist in the process of data\nannotation, investigators generally seem to prefer to use spreadsheets when\nsupplying metadata, despite the limitations of spreadsheets in ensuring\nmetadata consistency and compliance with formal specifications. In this paper,\nwe describe an end-to-end approach that supports spreadsheet-based entry of\nmetadata, while ensuring rigorous adherence to community-based metadata\nstandards and providing quality control. Our methods employ several key\ncomponents, including customizable templates that capture metadata standards\nand that can inform the spreadsheets that investigators use to author metadata,\ncontrolled terminologies and ontologies for defining metadata values that can\nbe accessed directly from a spreadsheet, and an interactive Web-based tool that\nallows users to rapidly identify and fix errors in their spreadsheet-based\nmetadata. We demonstrate how this approach is being deployed in a biomedical\nconsortium known as HuBMAP to define and collect metadata about a wide range of\nbiological assays.", "AI": {"tldr": "\u5c3d\u7ba1\u7814\u7a76\u4eba\u5458\u503e\u5411\u4e8e\u4f7f\u7528\u7535\u5b50\u8868\u683c\uff0c\u4f46\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u53ef\u5b9a\u5236\u6a21\u677f\u3001\u53d7\u63a7\u672f\u8bed\u548c\u4ea4\u4e92\u5f0f Web \u5de5\u5177\uff0c\u786e\u4fdd\u4e86\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u7684\u5143\u6570\u636e\u7684\u4e00\u81f4\u6027\u548c\u5408\u89c4\u6027\u3002", "motivation": "\u5c3d\u7ba1\u6709\u8bb8\u591a\u5de5\u5177\u53ef\u4ee5\u5e2e\u52a9\u8fdb\u884c\u6570\u636e\u6ce8\u91ca\uff0c\u4f46\u7814\u7a76\u4eba\u5458\u901a\u5e38\u66f4\u559c\u6b22\u4f7f\u7528\u7535\u5b50\u8868\u683c\u6765\u63d0\u4f9b\u5143\u6570\u636e\uff0c\u5c3d\u7ba1\u7535\u5b50\u8868\u683c\u5728\u786e\u4fdd\u5143\u6570\u636e\u4e00\u81f4\u6027\u548c\u7b26\u5408\u6b63\u5f0f\u89c4\u8303\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u8be5\u65b9\u6cd5\u91c7\u7528\u53ef\u5b9a\u5236\u7684\u6a21\u677f\u6765\u6355\u83b7\u5143\u6570\u636e\u6807\u51c6\u5e76\u4e3a\u7528\u6237\u63d0\u4f9b\u4fe1\u606f\uff0c\u4f7f\u7528\u53d7\u63a7\u672f\u8bed\u548c\u672c\u4f53\u6765\u5b9a\u4e49\u5143\u6570\u636e\u503c\uff0c\u5e76\u4f7f\u7528\u4ea4\u4e92\u5f0f Web \u5de5\u5177\u6765\u5feb\u901f\u8bc6\u522b\u548c\u4fee\u590d\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u7684\u5143\u6570\u636e\u4e2d\u7684\u9519\u8bef\u3002", "result": "\u8be5\u65b9\u6cd5\u5df2\u88ab\u90e8\u7f72\u5728 HuBMAP \u751f\u7269\u533b\u5b66\u8054\u76df\u4e2d\uff0c\u7528\u4e8e\u5b9a\u4e49\u548c\u6536\u96c6\u6709\u5173\u591a\u79cd\u751f\u7269\u5b66\u68c0\u6d4b\u7684\u5143\u6570\u636e\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u652f\u6301\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u7684\u5143\u6570\u636e\u8f93\u5165\uff0c\u540c\u65f6\u786e\u4fdd\u4e25\u683c\u9075\u5b88\u57fa\u4e8e\u793e\u533a\u7684\u5143\u6570\u636e\u6807\u51c6\u5e76\u63d0\u4f9b\u8d28\u91cf\u63a7\u5236\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u5143\u6570\u636e\u4e00\u81f4\u6027\u548c\u5408\u89c4\u6027\u95ee\u9898\u3002"}}
{"id": "2409.05735", "title": "A System and Benchmark for LLM-based Q&A on Heterogeneous Data", "url": "https://arxiv.org/abs/2409.05735", "pdf": "https://arxiv.org/pdf/2409.05735", "abs": "https://arxiv.org/abs/2409.05735", "authors": ["Achille Fokoue", "Srideepika Jayaraman", "Elham Khabiri", "Jeffrey O. Kephart", "Yingjie Li", "Dhruv Shah", "Youssef Drissi", "Fenno F. Heath III", "Anu Bhamidipaty", "Fateh A. Tipu", "Robert J. Baseman"], "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "In many industrial settings, users wish to ask questions whose answers may be\nfound in structured data sources such as a spreadsheets, databases, APIs, or\ncombinations thereof. Often, the user doesn't know how to identify or access\nthe right data source. This problem is compounded even further if multiple (and\npotentially siloed) data sources must be assembled to derive the answer.\nRecently, various Text-to-SQL applications that leverage Large Language Models\n(LLMs) have addressed some of these problems by enabling users to ask questions\nin natural language. However, these applications remain impractical in\nrealistic industrial settings because they fail to cope with the data source\nheterogeneity that typifies such environments. In this paper, we address\nheterogeneity by introducing the siwarex platform, which enables seamless\nnatural language access to both databases and APIs. To demonstrate the\neffectiveness of siwarex, we extend the popular Spider dataset and benchmark by\nreplacing some of its tables by data retrieval APIs. We find that siwarex does\na good job of coping with data source heterogeneity. Our modified Spider\nbenchmark will soon be available to the research community", "AI": {"tldr": "siwarex platform allows natural language queries on mixed data sources (databases and APIs) and performs well on a new benchmark designed to test this capability.", "motivation": "Users in industrial settings often struggle to access and combine data from heterogeneous sources (spreadsheets, databases, APIs) to answer questions. Existing Text-to-SQL applications using LLMs are impractical due to their inability to cope with this heterogeneity.", "method": "Introducing the siwarex platform to enable natural language access to databases and APIs, and extending the Spider dataset by replacing tables with data retrieval APIs.", "result": "The siwarex platform performs well in coping with data source heterogeneity.", "conclusion": "The siwarex platform effectively handles data source heterogeneity, demonstrated by its performance on a modified Spider benchmark."}}
{"id": "2409.01517", "title": "Auditable and reusable crosswalks for fast, scaled integration of scattered tabular data", "url": "https://arxiv.org/abs/2409.01517", "pdf": "https://arxiv.org/pdf/2409.01517", "abs": "https://arxiv.org/abs/2409.01517", "authors": ["Gavin Chait"], "categories": ["cs.DB"], "comment": "14 pages, 12 colour figures", "summary": "This paper presents an open-source curatorial toolkit intended to produce\nwell-structured and interoperable data. Curation is divided into discrete\ncomponents, with a schema-centric focus for auditable restructuring of complex\nand scattered tabular data to conform to a destination schema. Task separation\nallows development of software and analysis without source data being present.\nTransformations are captured as high-level sequential scripts describing\nschema-to-schema mappings, reducing complexity and resource requirements.\nUltimately, data are transformed, but the objective is that any data meeting a\nschema definition can be restructured using a crosswalk. The toolkit is\navailable both as a Python package, and as a 'no-code' visual web application.\nA visual example is presented, derived from a longitudinal study where\nscattered source data from hundreds of local councils are integrated into a\nsingle database.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f00\u6e90\u7684\u7b56\u5c55\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u5c06\u5206\u6563\u7684\u8868\u683c\u6570\u636e\u8f6c\u6362\u4e3a\u7ed3\u6784\u826f\u597d\u4e14\u53ef\u4e92\u64cd\u4f5c\u7684\u6570\u636e\u3002\u8be5\u5de5\u5177\u5305\u901a\u8fc7\u6a21\u5f0f\u5230\u6a21\u5f0f\u7684\u6620\u5c04\u6765\u63d0\u53d6\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a Python \u5305\u548c\u4e00\u4e2a\u53ef\u89c6\u5316 Web \u5e94\u7528\u7a0b\u5e8f\u3002", "motivation": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f00\u6e90\u7684\u7b56\u5c55\u5de5\u5177\u5305\uff0c\u65e8\u5728\u751f\u6210\u7ed3\u6784\u826f\u597d\u4e14\u53ef\u4e92\u64cd\u4f5c\u7684\u6570\u636e\u3002", "method": "\u8be5\u7814\u7a76\u5c06\u7b56\u5c55\u5206\u4e3a\u79bb\u6563\u7684\u7ec4\u4ef6\uff0c\u5e76\u91c7\u7528\u9762\u5411\u6a21\u5f0f\u7684\u65b9\u6cd5\u6765\u5ba1\u8ba1\u91cd\u6784\uff0c\u5c06\u590d\u6742\u4e14\u5206\u6563\u7684\u8868\u683c\u6570\u636e\u91cd\u6784\u4e3a\u7b26\u5408\u76ee\u6807\u6a21\u5f0f\u3002\u4efb\u52a1\u5206\u79bb\u5141\u8bb8\u5728\u6ca1\u6709\u6e90\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5f00\u53d1\u8f6f\u4ef6\u548c\u5206\u6790\u3002", "result": "\u8be5\u5de5\u5177\u5305\u88ab\u5b9e\u73b0\u4e3a\u4e00\u4e2a Python \u5305\u548c\u4e00\u4e2a\u2018\u65e0\u4ee3\u7801\u2019\u7684\u53ef\u89c6\u5316 Web \u5e94\u7528\u7a0b\u5e8f\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8de8\u672c\u5730\u59d4\u5458\u4f1a\u7684\u6570\u636e\u96c6\u793a\u4f8b\uff0c\u5176\u4e2d\u5c06\u5206\u6563\u7684\u6e90\u6570\u636e\u96c6\u6210\u5230\u4e00\u4e2a\u6570\u636e\u5e93\u4e2d\u3002", "conclusion": "\u8be5\u5de5\u5177\u5305\u65e8\u5728\u901a\u8fc7\u6a21\u5f0f\u5230\u6a21\u5f0f\u7684\u6620\u5c04\u6765\u8f6c\u6362\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u4ee5\u8de8\u6240\u6709\u4ea4\u53c9\u7684\u6a21\u5f0f\u5b9a\u4e49\uff0c\u4ee5\u5b9e\u73b0\u6570\u636e\u7684\u7ed3\u6784\u5316\u3002"}}
{"id": "2409.12976", "title": "Excel: Automated Ledger or Analytics IDE?", "url": "https://arxiv.org/abs/2409.12976", "pdf": "https://arxiv.org/pdf/2409.12976", "abs": "https://arxiv.org/abs/2409.12976", "authors": ["Andrew Kumiega"], "categories": ["cs.CY"], "comment": "9 pages, one table", "summary": "Since the inception of VisiCalc over four decades ago, spreadsheets have\nundergone a gradual transformation, evolving from simple ledger automation\ntools to the current state of Excel, which can be described as an Integrated\nDevelopment Environment (IDE) for analytics. The slow evolution of Excel from\nan automation tool for ledgers to an IDE for analytics explains why many people\nhave not noticed that Excel includes a fully functional database, an OLAP\nEngine, multiple statistical programming languages, multiple third-party\nsoftware libraries, dynamic charts, and real time data connectors. The\nsimplicity of accessing these multiple tools is a low-code framework controlled\nfrom the Excel tool that is effectively an IDE. Once we acknowledge Excel's\nshift from a desk top application to an IDE for analytics, the importance of\nestablishing a comprehensive risk framework for managing this distinctive\ndevelopment environment becomes clear. In this paper we will explain how the\ncurrent risk framework for spreadsheets needs to be expanded to manage the\ngrowing risks of using Excel as an IDE for analytics.", "AI": {"tldr": "Excel\u5df2\u6210\u4e3a\u4e00\u4e2a\u5206\u6790IDE\uff0c\u9700\u8981\u66f4\u65b0\u5176\u98ce\u9669\u7ba1\u7406\u6846\u67b6\u3002", "motivation": "\u9274\u4e8eExcel\u5df2\u4ece\u7b80\u5355\u7684\u8d26\u7c3f\u81ea\u52a8\u5316\u5de5\u5177\u6f14\u53d8\u4e3a\u529f\u80fd\u9f50\u5168\u7684\u5206\u6790IDE\uff0c\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u5168\u9762\u7684\u98ce\u9669\u7ba1\u7406\u6846\u67b6\u3002", "method": "\u89e3\u91ca\u4e86\u5f53\u524d\u7684\u7535\u5b50\u8868\u683c\u98ce\u9669\u6846\u67b6\u5982\u4f55\u9700\u8981\u6269\u5c55\uff0c\u4ee5\u7ba1\u7406\u4f7f\u7528Excel\u4f5c\u4e3a\u5206\u6790IDE\u6240\u5e26\u6765\u7684\u65e5\u76ca\u589e\u957f\u7684\u98ce\u9669\u3002", "result": "Excel\u5df2\u6f14\u53d8\u4e3a\u4e00\u4e2a\u5305\u542b\u6570\u636e\u5e93\u3001OLAP\u5f15\u64ce\u3001\u591a\u79cd\u7edf\u8ba1\u7f16\u7a0b\u8bed\u8a00\u3001\u7b2c\u4e09\u65b9\u8f6f\u4ef6\u5e93\u3001\u52a8\u6001\u56fe\u8868\u548c\u5b9e\u65f6\u6570\u636e\u8fde\u63a5\u5668\u7684\u5206\u6790IDE\u3002", "conclusion": "Excel\u5df2\u4ece\u684c\u9762\u5e94\u7528\u7a0b\u5e8f\u6f14\u53d8\u4e3a\u5206\u6790\u7684\u96c6\u6210\u5f00\u53d1\u73af\u5883\uff08IDE\uff09\uff0c\u9700\u8981\u6269\u5c55\u5176\u98ce\u9669\u6846\u67b6\u6765\u5e94\u5bf9\u7531\u6b64\u4ea7\u751f\u7684\u65e5\u76ca\u589e\u957f\u7684\u98ce\u9669\u3002"}}
{"id": "2409.12975", "title": "Subject integration with spreadsheets -- Ignoring education is the greatest risk ever", "url": "https://arxiv.org/abs/2409.12975", "pdf": "https://arxiv.org/pdf/2409.12975", "abs": "https://arxiv.org/abs/2409.12975", "authors": ["M\u00e1ria Csernoch", "\u00c1d\u00e1m Gul\u00e1csi", "J\u00falia Csernoch"], "categories": ["cs.HC"], "comment": "16 pages, 17 colour figures. Proceedings of the EuSpRIG 2024\n  Conference 'Spreadsheet Productivity & Risks' ISBN : 978-1-905404-59-9", "summary": "Within the framework of Technological Pedagogical and Content Knowledge,\nsubject integration is one possible solution for the introduction of meaningful\ndigitalization and digitization in schools. This process incorporates that any\nschool subject can be taught with digital support, informatics (computer)\nclasses can be contextualized, and the gap between 'serious informatics' and\n'digital literacy' can be minimized. The present paper details how three\ntraditional Grade 3 tasks can be solved in spreadsheets, what skills,\ncompetencies, and computer science knowledge of both teachers and students can\nbe developed. The solutions also reveal that analysing, understanding,\nplanning, and discussing tasks is as important as the activity in the\nspreadsheets, which process plays a crucial role in the preparation of students\nfor their future jobs.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u6280\u672f\u6559\u5b66\u6cd5\u548c\u5185\u5bb9\u77e5\u8bc6\u7684\u6846\u67b6\u5185\uff0c\u5982\u4f55\u5229\u7528\u7535\u5b50\u8868\u683c\u89e3\u51b3\u5c0f\u5b66\u4e09\u5e74\u7ea7\u6570\u5b66\u95ee\u9898\uff0c\u5e76\u5206\u6790\u4e86\u8be5\u65b9\u6cd5\u5bf9\u5e08\u751f\u6570\u5b57\u7d20\u517b\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u80fd\u529b\u57f9\u517b\u7684\u4f5c\u7528\u3002", "motivation": "\u5b66\u79d1\u6574\u5408\u662f\u5b66\u6821\u6709\u610f\u4e49\u5730\u5f15\u5165\u6570\u5b57\u5316\u548c\u6570\u5b57\u5316\u7684\u4e00\u79cd\u53ef\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5982\u4f55\u5728\u7535\u5b50\u8868\u683c\u4e2d\u89e3\u51b3\u4e09\u4e2a\u4f20\u7edf\u7684\u4e09\u5e74\u7ea7\u4efb\u52a1\uff0c\u4ee5\u53ca\u53ef\u4ee5\u57f9\u517b\u6559\u5e08\u548c\u5b66\u751f\u7684\u54ea\u4e9b\u6280\u80fd\u3001\u80fd\u529b\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u77e5\u8bc6\u3002", "result": "\u89e3\u51b3\u65b9\u6848\u8fd8\u63ed\u793a\u4e86\u5206\u6790\u3001\u7406\u89e3\u3001\u89c4\u5212\u548c\u8ba8\u8bba\u4efb\u52a1\u4e0e\u7535\u5b50\u8868\u683c\u4e2d\u7684\u6d3b\u52a8\u540c\u6837\u91cd\u8981\uff0c\u800c\u8fd9\u4e2a\u8fc7\u7a0b\u5728\u4e3a\u5b66\u751f\u7684\u672a\u6765\u5de5\u4f5c\u505a\u51c6\u5907\u65b9\u9762\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002", "conclusion": "\u5728\u6280\u672f\u6559\u5b66\u6cd5\u548c\u5185\u5bb9\u77e5\u8bc6\u7684\u6846\u67b6\u5185\uff0c\u5b66\u79d1\u6574\u5408\u662f\u5b66\u6821\u6709\u610f\u4e49\u5730\u5f15\u5165\u6570\u5b57\u5316\u548c\u6570\u5b57\u5316\u7684\u4e00\u79cd\u53ef\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u5305\u542b\u4efb\u4f55\u5b66\u6821\u79d1\u76ee\u90fd\u53ef\u4ee5\u7528\u6570\u5b57\u652f\u6301\u8fdb\u884c\u6559\u5b66\uff0c\u4fe1\u606f\u5b66\uff08\u8ba1\u7b97\u673a\uff09\u8bfe\u7a0b\u53ef\u4ee5\u60c5\u5883\u5316\uff0c\u5e76\u4e14\u201c\u4e25\u8083\u7684\u4fe1\u606f\u5b66\u201d\u548c\u201c\u6570\u5b57\u7d20\u517b\u201d\u4e4b\u95f4\u7684\u5dee\u8ddd\u53ef\u4ee5\u6700\u5c0f\u5316\u3002"}}
{"id": "2409.12974", "title": "Exploring Higher Education Competencies through Spreadsheet Self-Assessment and Time", "url": "https://arxiv.org/abs/2409.12974", "pdf": "https://arxiv.org/pdf/2409.12974", "abs": "https://arxiv.org/abs/2409.12974", "authors": ["Maria Csernoch", "Judit T. Kiss", "Viktor Tak\u00e1cs", "Domici\u00e1n M\u00e1t\u00e9"], "categories": ["cs.HC"], "comment": "16 pages, 10 colour figures, 9 tables", "summary": "The present paper aims to explore higher education students' spreadsheet\ncompetencies and reliability through self-assessment and real-world\nproblem-solving practices. Digital natives alleged skills and competences\nallowed us to hypothesize that students perform better in Excel than on paper,\nbut the findings cannot confirm this hypothesis. However, our results indicate\nthat students tend to inaccurately assess their spreadsheet competencies\ncompared to their actual performance in both paper-based and Excel tasks. It\nhas also be found that students need at least twice as much time to achieve the\nsame high scores in the digital environment as they do on paper. The results\nviolated the widely accepted assumption that digital native students do not\nneed computer science education, since they are born with it. This study\nhighlights the importance of accurate self-assessment in digital skill\ndevelopment and time management within higher education contexts, particularly\nin technology-driven disciplines.", "AI": {"tldr": "\u5927\u5b66\u751f\u5bf9\u81ea\u8eab\u7535\u5b50\u8868\u683c\u80fd\u529b\u7684\u81ea\u6211\u8bc4\u4f30\u4e0d\u51c6\u786e\uff0c\u5728\u6570\u5b57\u73af\u5883\u4e2d\u5b8c\u6210\u4efb\u52a1\u6bd4\u7eb8\u8d28\u73af\u5883\u6548\u7387\u4f4e\u3002", "motivation": "\u63a2\u7a76\u5927\u5b66\u751f\u5728\u7535\u5b50\u8868\u683c\u65b9\u9762\u7684\u80fd\u529b\u548c\u53ef\u9760\u6027\uff0c\u5e76\u68c0\u9a8c\u201c\u6570\u5b57\u539f\u4f4f\u6c11\u201d\u5b66\u751f\u662f\u5426\u6bd4\u5728\u7eb8\u4e0a\u66f4\u597d\u5730\u638c\u63e1Excel\u3002", "method": "\u901a\u8fc7\u81ea\u6211\u8bc4\u4f30\u548c\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u7684\u7ec3\u4e60\u6765\u63a2\u7a76\u5927\u5b66\u751f\u5728\u7535\u5b50\u8868\u683c\u65b9\u9762\u7684\u80fd\u529b\u548c\u53ef\u9760\u6027\u3002", "result": "\u5b66\u751f\u7684\u7535\u5b50\u8868\u683c\u80fd\u529b\u81ea\u6211\u8bc4\u4f30\u4e0d\u51c6\u786e\uff0c\u5728\u6570\u5b57\u73af\u5883\u4e2d\u5b8c\u6210\u4efb\u52a1\u6bd4\u7eb8\u8d28\u73af\u5883\u9700\u8981\u66f4\u957f\u65f6\u95f4\u3002\u8fd9\u8868\u660e\u6570\u5b57\u539f\u4f4f\u6c11\u5b66\u751f\u5e76\u975e\u5929\u751f\u5c31\u4f1a\u4f7f\u7528\u8ba1\u7b97\u673a\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5927\u5b66\u751f\u5f80\u5f80\u4f1a\u4e0d\u51c6\u786e\u5730\u8bc4\u4f30\u4ed6\u4eec\u5728\u7535\u5b50\u8868\u683c\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u6570\u5b57\u73af\u5883\u4e2d\u5b8c\u6210\u4efb\u52a1\u6240\u9700\u7684\u65f6\u95f4\u662f\u7eb8\u8d28\u73af\u5883\u7684\u4e24\u500d\u3002\u8fd9\u6311\u6218\u4e86\u201c\u6570\u5b57\u539f\u4f4f\u6c11\u201d\u5b66\u751f\u65e0\u9700\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u5373\u53ef\u638c\u63e1\u6280\u672f\u7684\u5047\u8bbe\u3002"}}
{"id": "2405.16234", "title": "Vision Language Models for Spreadsheet Understanding: Challenges and Opportunities", "url": "https://arxiv.org/abs/2405.16234", "pdf": "https://arxiv.org/pdf/2405.16234", "abs": "https://arxiv.org/abs/2405.16234", "authors": ["Shiyu Xia", "Junyu Xiong", "Haoyu Dong", "Jianbo Zhao", "Yuzhang Tian", "Mengyu Zhou", "Yeye He", "Shi Han", "Dongmei Zhang"], "categories": ["cs.CV"], "comment": null, "summary": "This paper explores capabilities of Vision Language Models on spreadsheet\ncomprehension. We propose three self-supervised challenges with corresponding\nevaluation metrics to comprehensively evaluate VLMs on Optical Character\nRecognition (OCR), spatial perception, and visual format recognition.\nAdditionally, we utilize the spreadsheet table detection task to assess the\noverall performance of VLMs by integrating these challenges. To probe VLMs more\nfinely, we propose three spreadsheet-to-image settings: column width\nadjustment, style change, and address augmentation. We propose variants of\nprompts to address the above tasks in different settings. Notably, to leverage\nthe strengths of VLMs in understanding text rather than two-dimensional\npositioning, we propose to decode cell values on the four boundaries of the\ntable in spreadsheet boundary detection. Our findings reveal that VLMs\ndemonstrate promising OCR capabilities but produce unsatisfactory results due\nto cell omission and misalignment, and they notably exhibit insufficient\nspatial and format recognition skills, motivating future work to enhance VLMs'\nspreadsheet data comprehension capabilities using our methods to generate\nextensive spreadsheet-image pairs in various settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u8bc4\u4f30\u548c\u589e\u5f3aVLMs\u5728\u7535\u5b50\u8868\u683c\u7406\u89e3\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u4e86VLMs\u5728OCR\u65b9\u9762\u6709\u6f5c\u529b\u4f46\u7a7a\u95f4\u548c\u683c\u5f0f\u7406\u89e3\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u5168\u9762\u8bc4\u4f30VLMs\u5728\u7535\u5b50\u8868\u683c\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u4e3a\u672a\u6765\u589e\u5f3aVLMs\u7684\u7535\u5b50\u8868\u683c\u6570\u636e\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u65b9\u5411\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u81ea\u76d1\u7763\u6311\u6218\u53ca\u76f8\u5e94\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u4ee5\u5168\u9762\u8bc4\u4f30VLMs\u7684\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09\u3001\u7a7a\u95f4\u611f\u77e5\u548c\u89c6\u89c9\u683c\u5f0f\u8bc6\u522b\u80fd\u529b\u3002\u6b64\u5916\uff0c\u5229\u7528\u7535\u5b50\u8868\u683c\u8868\u683c\u68c0\u6d4b\u4efb\u52a1\u6765\u8bc4\u4f30VLMs\u7684\u6574\u4f53\u6027\u80fd\u3002\u4e3a\u4e86\u66f4\u7cbe\u7ec6\u5730\u63a2\u6d4bVLMs\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e09\u79cd\u7535\u5b50\u8868\u683c\u5230\u56fe\u50cf\u7684\u8bbe\u7f6e\uff1a\u5217\u5bbd\u8c03\u6574\u3001\u6837\u5f0f\u66f4\u6539\u548c\u5730\u5740\u589e\u5f3a\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u63d0\u793a\u7684\u53d8\u4f53\u6765\u5904\u7406\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u4e0a\u8ff0\u4efb\u52a1\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u4e3a\u4e86\u5229\u7528VLMs\u5728\u7406\u89e3\u6587\u672c\u800c\u975e\u4e8c\u7ef4\u5b9a\u4f4d\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u6211\u4eec\u5efa\u8bae\u5728\u7535\u5b50\u8868\u683c\u8fb9\u754c\u68c0\u6d4b\u4e2d\u89e3\u7801\u8868\u683c\u56db\u4e2a\u8fb9\u754c\u7684\u5355\u5143\u683c\u503c\u3002", "result": "VLMs\u5728\u7535\u5b50\u8868\u683c\u7406\u89e3\u65b9\u9762\u5c55\u73b0\u51fa\u6709\u5e0c\u671b\u7684\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09\u80fd\u529b\uff0c\u4f46\u5728\u5355\u5143\u683c\u9057\u6f0f\u548c\u4e0d\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u5728\u7a7a\u95f4\u548c\u683c\u5f0f\u8bc6\u522b\u80fd\u529b\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002", "conclusion": "VLMs\u5728\u7535\u5b50\u8868\u683c\u7406\u89e3\u65b9\u9762\u5c55\u73b0\u51fa\u6709\u5e0c\u671b\u7684\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09\u80fd\u529b\uff0c\u4f46\u5728\u5355\u5143\u683c\u9057\u6f0f\u548c\u4e0d\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u5728\u7a7a\u95f4\u548c\u683c\u5f0f\u8bc6\u522b\u80fd\u529b\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u8fd9\u8868\u660e\u672a\u6765\u7684\u5de5\u4f5c\u9700\u8981\u5229\u7528\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u6765\u589e\u5f3aVLMs\u7684\u7535\u5b50\u8868\u683c\u6570\u636e\u7406\u89e3\u80fd\u529b\uff0c\u901a\u8fc7\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\u751f\u6210\u5927\u91cf\u7684\u7535\u5b50\u8868\u683c-\u56fe\u50cf\u5bf9\u3002"}}
{"id": "2408.03841", "title": "MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models", "url": "https://arxiv.org/abs/2408.03841", "pdf": "https://arxiv.org/pdf/2408.03841", "abs": "https://arxiv.org/abs/2408.03841", "authors": ["Yuchen Dong", "XiaoXiang Fang", "Yuchen Hu", "Renshuang Jiang", "Zhe Jiang"], "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The application of large language models to facilitate automated software\noperations and tool generation (SOTG), thus augmenting software productivity,\nmirrors the early stages of human evolution when the ability to create and use\ntools accelerated the progress of civilization. These complex tasks require AI\nto continuously summarize and improve. Current research often overlooks the\nimportance of converting real-time task experiences into system memory and\ndifferentiating the value of existing knowledge for future reference. This\npaper addresses these issues by evolving external memory models into\nMemory-Loop Networks for timely memorization and experience referencing. We\nalso enhance a RAG mechanism with knowledge precision segmentation to utilize\nmemory based on value differentiation, and design the MaxMind model for SOTG\naccordingly.To demonstrate our approach, we developed MaxMind4Sheet, an\nelectronic spreadsheet processing system aligned with the MaxMind philosophy.\nComparative experiments with SheetCopilot have demonstrated that the\naccumulation and recycling of task memories lead to a steady enhancement in\ntask success rate, with an improvement rate of approximately 3%-6% per round in\nthis implementation example. Note that as the memories continue to grow, this\ncumulative improvement may be substantial. The inclusion of memory recycling\ncan also boost the system's task execution efficiency by up to 25%, and it can\naddress the retraining issue faced by LLMs when handling specialized tasks\nthrough memories transfer.These suggest that MaxMind has significant potential\nto enhance the capabilities and productivity of LLM systems in SOTG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMaxMind\u6a21\u578b\uff0c\u901a\u8fc7\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\u548c\u77e5\u8bc6\u7cbe\u5ea6\u5206\u5272\u589e\u5f3aRAG\uff0c\u63d0\u5347LLM\u5728\u8f6f\u4ef6\u64cd\u4f5c\u548c\u5de5\u5177\u751f\u6210\uff08SOTG\uff09\u4e2d\u7684\u6548\u7387\u548c\u6210\u529f\u7387\uff0c\u5e76\u89e3\u51b3\u4e86\u6a21\u578b\u91cd\u8bad\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u5728\u5c06\u5b9e\u65f6\u4efb\u52a1\u7ecf\u9a8c\u8f6c\u5316\u4e3a\u7cfb\u7edf\u8bb0\u5fc6\u4ee5\u53ca\u533a\u5206\u73b0\u6709\u77e5\u8bc6\u7684\u672a\u6765\u53c2\u8003\u4ef7\u503c\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u64cd\u4f5c\u548c\u5de5\u5177\u751f\u6210\uff08SOTG\uff09\u65b9\u9762\u7684\u5e94\u7528\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u8fd9\u4e9b\u590d\u6742\u4efb\u52a1\u9700\u8981AI\u80fd\u591f\u6301\u7eed\u5730\u603b\u7ed3\u548c\u6539\u8fdb\uff0c\u800c\u73b0\u6709\u7684\u65b9\u6cd5\u5ffd\u7565\u4e86\u8bb0\u5fc6\u548c\u77e5\u8bc6\u4ef7\u503c\u533a\u5206\u7684\u91cd\u8981\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMaxMind\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6f14\u5316\u5916\u90e8\u8bb0\u5fc6\u6a21\u578b\u4e3a\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\uff08Memory-Loop Networks\uff09\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u7684\u8bb0\u5fc6\u548c\u7ecf\u9a8c\u5f15\u7528\u3002\u540c\u65f6\uff0c\u589e\u5f3a\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u673a\u5236\uff0c\u5f15\u5165\u77e5\u8bc6\u7cbe\u5ea6\u5206\u5272\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u4ef7\u503c\u5dee\u5f02\u5316\u7684\u8bb0\u5fc6\u5229\u7528\u3002\u5e76\u636e\u6b64\u8bbe\u8ba1\u4e86MaxMind\u6a21\u578b\u7528\u4e8eSOTG\u3002", "result": "MaxMind4Sheet\uff08\u4e00\u4e2a\u7535\u5b50\u8868\u683c\u5904\u7406\u7cfb\u7edf\uff09\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0eSheetCopilot\u76f8\u6bd4\uff0c\u4efb\u52a1\u8bb0\u5fc6\u7684\u79ef\u7d2f\u548c\u518d\u5229\u7528\u80fd\u591f\u7a33\u6b65\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\uff08\u7ea63%-6%\uff09\uff0c\u5e76\u5c06\u7cfb\u7edf\u4efb\u52a1\u6267\u884c\u6548\u7387\u63d0\u5347\u9ad8\u8fbe25%\u3002\u6b64\u5916\uff0c\u8bb0\u5fc6\u8fc1\u79fb\u80fd\u591f\u89e3\u51b3LLM\u5728\u5904\u7406\u4e13\u4e1a\u4efb\u52a1\u65f6\u7684\u91cd\u65b0\u8bad\u7ec3\u95ee\u9898\u3002", "conclusion": "MaxMind\u901a\u8fc7\u6301\u7eed\u7684\u4efb\u52a1\u8bb0\u5fc6\u79ef\u7d2f\u548c\u518d\u5229\u7528\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u64cd\u4f5c\u548c\u5de5\u5177\u751f\u6210\uff08SOTG\uff09\u65b9\u9762\u7684\u80fd\u529b\u548c\u751f\u4ea7\u529b\uff0c\u80fd\u591f\u9010\u6b65\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\uff08\u7ea63%-6%\uff09\uff0c\u5e76\u5c06\u4efb\u52a1\u6267\u884c\u6548\u7387\u63d0\u5347\u9ad8\u8fbe25%\uff0c\u540c\u65f6\u901a\u8fc7\u8bb0\u5fc6\u8fc1\u79fb\u89e3\u51b3\u4e86LLM\u5728\u5904\u7406\u4e13\u4e1a\u4efb\u52a1\u65f6\u9762\u4e34\u7684\u91cd\u65b0\u8bad\u7ec3\u95ee\u9898\u3002"}}
{"id": "2408.01805", "title": "Billion-files File Systems (BfFS): A Comparison", "url": "https://arxiv.org/abs/2408.01805", "pdf": "https://arxiv.org/pdf/2408.01805", "abs": "https://arxiv.org/abs/2408.01805", "authors": ["Sohail Shaikh"], "categories": ["cs.PF"], "comment": "Paper is 9 pages. Source code is open and uploaded to Git, along with\n  an Excel spreadsheet used for analysis", "summary": "As the volume of data being produced is increasing at an exponential rate\nthat needs to be processed quickly, it is reasonable that the data needs to be\navailable very close to the compute devices to reduce transfer latency. Due to\nthis need, local filesystems are getting close attention to understand their\ninner workings, performance, and more importantly their limitations. This study\nanalyzes few popular Linux filesystems: EXT4, XFS, BtrFS, ZFS, and F2FS by\ncreating, storing, and then reading back one billion files from the local\nfilesystem. The study also captured and analyzed read/write throughput, storage\nblocks usage, disk space utilization and overheads, and other metrics useful\nfor system designers and integrators. Furthermore, the study explored other\nside effects such as filesystem performance degradation during and after these\nlarge numbers of files and folders are created.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86EXT4, XFS, BtrFS, ZFS\u548cF2FS\u8fd9\u51e0\u79cdLinux\u6587\u4ef6\u7cfb\u7edf\u5728\u5904\u7406\u5927\u91cf\u6587\u4ef6\u65f6\u7684\u6027\u80fd\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u7684\u8bfb\u5199\u541e\u5410\u91cf\u3001\u5b58\u50a8\u5229\u7528\u7387\u548c\u6027\u80fd\u4e0b\u964d\u7b49\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u6570\u636e\u91cf\u7684\u7206\u70b8\u5f0f\u589e\u957f\uff0c\u9700\u8981\u5feb\u901f\u5904\u7406\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u6570\u636e\u5c3d\u53ef\u80fd\u5730\u79fb\u8fd1\u8ba1\u7b97\u8bbe\u5907\u4ee5\u51cf\u5c11\u4f20\u8f93\u5ef6\u8fdf\u3002\u56e0\u6b64\uff0c\u672c\u5730\u6587\u4ef6\u7cfb\u7edf\u56e0\u5176\u5185\u5728\u673a\u5236\u3001\u6027\u80fd\u548c\u5c40\u9650\u6027\u800c\u53d7\u5230\u5173\u6ce8\u3002", "method": "\u901a\u8fc7\u521b\u5efa\u3001\u5b58\u50a8\u548c\u8bfb\u53d6\u5341\u4ebf\u4e2a\u6587\u4ef6\u6765\u5206\u6790EXT4, XFS, BtrFS, ZFS\u548cF2FS\u8fd9\u51e0\u79cd\u6d41\u884c\u7684Linux\u6587\u4ef6\u7cfb\u7edf\u3002\u7814\u7a76\u4eba\u5458\u8fd8\u6355\u83b7\u5e76\u5206\u6790\u4e86\u8bfb/\u5199\u541e\u5410\u91cf\u3001\u5b58\u50a8\u5757\u4f7f\u7528\u60c5\u51b5\u3001\u78c1\u76d8\u7a7a\u95f4\u5229\u7528\u7387\u548c\u5f00\u9500\u7b49\u6307\u6807\uff0c\u5e76\u63a2\u8ba8\u4e86\u6587\u4ef6\u7cfb\u7edf\u6027\u80fd\u4e0b\u964d\u7b49\u526f\u4f5c\u7528\u3002", "result": "\u8be5\u7814\u7a76\u5206\u6790\u4e86EXT4, XFS, BtrFS, ZFS\u548cF2FS\u8fd9\u51e0\u79cd\u6d41\u884c\u7684Linux\u6587\u4ef6\u7cfb\u7edf\uff0c\u5e76\u8bc4\u4f30\u4e86\u5b83\u4eec\u7684\u8bfb/\u5199\u541e\u5410\u91cf\u3001\u5b58\u50a8\u5757\u4f7f\u7528\u60c5\u51b5\u3001\u78c1\u76d8\u7a7a\u95f4\u5229\u7528\u7387\u548c\u5f00\u9500\u7b49\u6307\u6807\uff0c\u540c\u65f6\u8fd8\u63a2\u8ba8\u4e86\u5728\u521b\u5efa\u5927\u91cf\u6587\u4ef6\u548c\u6587\u4ef6\u5939\u671f\u95f4\u53ca\u4e4b\u540e\u6587\u4ef6\u7cfb\u7edf\u6027\u80fd\u4e0b\u964d\u7b49\u526f\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u5206\u6790\u4e86EXT4, XFS, BtrFS, ZFS\u548cF2FS\u8fd9\u51e0\u79cd\u6d41\u884c\u7684Linux\u6587\u4ef6\u7cfb\u7edf\uff0c\u901a\u8fc7\u521b\u5efa\u3001\u5b58\u50a8\u548c\u8bfb\u53d6\u5341\u4ebf\u4e2a\u6587\u4ef6\u6765\u8bc4\u4f30\u5b83\u4eec\u3002\u7814\u7a76\u4eba\u5458\u8fd8\u5206\u6790\u4e86\u8bfb/\u5199\u541e\u5410\u91cf\u3001\u5b58\u50a8\u5757\u4f7f\u7528\u60c5\u51b5\u3001\u78c1\u76d8\u7a7a\u95f4\u5229\u7528\u7387\u548c\u5f00\u9500\u7b49\u6307\u6807\uff0c\u5e76\u63a2\u8ba8\u4e86\u5728\u521b\u5efa\u5927\u91cf\u6587\u4ef6\u548c\u6587\u4ef6\u5939\u671f\u95f4\u53ca\u4e4b\u540e\u6587\u4ef6\u7cfb\u7edf\u6027\u80fd\u4e0b\u964d\u7b49\u526f\u4f5c\u7528\u3002"}}
{"id": "2407.14042", "title": "Data Guards: Challenges and Solutions for Fostering Trust in Data", "url": "https://arxiv.org/abs/2407.14042", "pdf": "https://arxiv.org/pdf/2407.14042", "abs": "https://arxiv.org/abs/2407.14042", "authors": ["Nicole Sultanum", "Dennis Bromley", "Michael Correll"], "categories": ["cs.HC"], "comment": "VIS 2024 Short paper - 5 pages", "summary": "From dirty data to intentional deception, there are many threats to the\nvalidity of data-driven decisions. Making use of data, especially new or\nunfamiliar data, therefore requires a degree of trust or verification. How is\nthis trust established? In this paper, we present the results of a series of\ninterviews with both producers and consumers of data artifacts (outputs of data\necosystems like spreadsheets, charts, and dashboards) aimed at understanding\nstrategies and obstacles to building trust in data. We find a recurring need,\nbut lack of existing standards, for data validation and verification,\nespecially among data consumers. We therefore propose a set of data guards:\nmethods and tools for fostering trust in data artifacts.", "AI": {"tldr": "\u6570\u636e\u5de5\u4ef6\u7684\u4fe1\u4efb\u662f\u901a\u8fc7\u6570\u636e\u9a8c\u8bc1\u548c\u6838\u67e5\u6765\u5efa\u7acb\u7684\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6807\u51c6\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u5957\u6570\u636e\u536b\u58eb\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u9762\u4e34\u6570\u636e\u6709\u6548\u6027\u65b9\u9762\u7684\u5a01\u80c1\uff0c\u4f8b\u5982\u810f\u6570\u636e\u548c\u6545\u610f\u6b3a\u9a97\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u548c\u6838\u67e5\u4ee5\u5efa\u7acb\u4fe1\u4efb\u3002", "method": "\u901a\u8fc7\u5bf9\u6570\u636e\u751f\u4ea7\u8005\u548c\u6570\u636e\u6d88\u8d39\u8005\u8fdb\u884c\u4e00\u7cfb\u5217\u8bbf\u8c08\uff0c\u4e86\u89e3\u5efa\u7acb\u6570\u636e\u4fe1\u4efb\u7684\u7b56\u7565\u548c\u969c\u788d\u3002", "result": "\u53d1\u73b0\u6570\u636e\u6d88\u8d39\u8005\u5c24\u5176\u9700\u8981\u6570\u636e\u9a8c\u8bc1\u548c\u6838\u67e5\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u73b0\u6709\u6807\u51c6\u3002", "conclusion": "\u9700\u8981\u4e3a\u6570\u636e\u5de5\u4ef6\uff08\u5982\u7535\u5b50\u8868\u683c\u3001\u56fe\u8868\u548c\u4eea\u8868\u677f\uff09\u5f00\u53d1\u6570\u636e\u9a8c\u8bc1\u548c\u6838\u67e5\u6807\u51c6\uff0c\u4ee5\u5efa\u7acb\u6d88\u8d39\u8005\u5bf9\u6570\u636e\u7684\u4fe1\u4efb\u3002"}}
{"id": "2407.06354", "title": "High-Throughput Phenotyping using Computer Vision and Machine Learning", "url": "https://arxiv.org/abs/2407.06354", "pdf": "https://arxiv.org/pdf/2407.06354", "abs": "https://arxiv.org/abs/2407.06354", "authors": ["Vivaan Singhvi", "Langalibalele Lunga", "Pragya Nidhi", "Chris Keum", "Varrun Prakash"], "categories": ["cs.CV", "I.4.6; I.4.7"], "comment": "Presented for the Smoky Mountains Computational Sciences and\n  Engineering Conference: Best Paper Award", "summary": "High-throughput phenotyping refers to the non-destructive and efficient\nevaluation of plant phenotypes. In recent years, it has been coupled with\nmachine learning in order to improve the process of phenotyping plants by\nincreasing efficiency in handling large datasets and developing methods for the\nextraction of specific traits. Previous studies have developed methods to\nadvance these challenges through the application of deep neural networks in\ntandem with automated cameras; however, the datasets being studied often\nexcluded physical labels. In this study, we used a dataset provided by Oak\nRidge National Laboratory with 1,672 images of Populus Trichocarpa with white\nlabels displaying treatment (control or drought), block, row, position, and\ngenotype. Optical character recognition (OCR) was used to read these labels on\nthe plants, image segmentation techniques in conjunction with machine learning\nalgorithms were used for morphological classifications, machine learning models\nwere used to predict treatment based on those classifications, and analyzed\nencoded EXIF tags were used for the purpose of finding leaf size and\ncorrelations between phenotypes. We found that our OCR model had an accuracy of\n94.31% for non-null text extractions, allowing for the information to be\naccurately placed in a spreadsheet. Our classification models identified leaf\nshape, color, and level of brown splotches with an average accuracy of 62.82%,\nand plant treatment with an accuracy of 60.08%. Finally, we identified a few\ncrucial pieces of information absent from the EXIF tags that prevented the\nassessment of the leaf size. There was also missing information that prevented\nthe assessment of correlations between phenotypes and conditions. However,\nfuture studies could improve upon this to allow for the assessment of these\nfeatures.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528 OCR\u3001\u56fe\u50cf\u5206\u5272\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\u5206\u6790\u4e86 1,672 \u5f20\u6768\u6811\u56fe\u50cf\uff0c\u4ee5\u63d0\u53d6\u8868\u578b\u4fe1\u606f\u5e76\u9884\u6d4b\u5904\u7406\u7c7b\u578b\u3002\u7814\u7a76\u5b9e\u73b0\u4e86\u8f83\u9ad8\u7684\u6807\u7b7e\u8bfb\u53d6\u51c6\u786e\u7387 (94.31%)\uff0c\u4f46\u5f62\u6001\u5b66\u5206\u7c7b\u548c\u5904\u7406\u9884\u6d4b\u7684\u51c6\u786e\u7387\u5206\u522b\u4e3a 62.82% \u548c 60.08%\u3002EXIF \u6807\u7b7e\u7684\u7f3a\u5931\u4fe1\u606f\u9650\u5236\u4e86\u5bf9\u53f6\u7247\u5927\u5c0f\u548c\u8868\u578b\u76f8\u5173\u6027\u7684\u8fdb\u4e00\u6b65\u5206\u6790\uff0c\u4f46\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u9ad8\u901a\u91cf\u8868\u578b\u5206\u6790\u65e8\u5728\u63d0\u9ad8\u690d\u7269\u8868\u578b\u8bc4\u4f30\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\u548c\u63d0\u53d6\u7279\u5b9a\u6027\u72b6\u65b9\u9762\u3002\u5c3d\u7ba1\u5df2\u6709\u4e00\u4e9b\u7814\u7a76\u5c1d\u8bd5\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u81ea\u52a8\u76f8\u673a\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u5e38\u5e38\u7f3a\u4e4f\u7269\u7406\u6807\u7b7e\uff0c\u9650\u5236\u4e86\u4fe1\u606f\u63d0\u53d6\u7684\u7cbe\u5ea6\u548c\u4e0b\u6e38\u5206\u6790\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u96c6\u6210 OCR\u3001\u56fe\u50cf\u5206\u5272\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5e76\u5229\u7528\u5305\u542b\u8be6\u7ec6\u6807\u7b7e\u7684\u6570\u636e\u96c6\uff0c\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u690d\u7269\u8868\u578b\u4fe1\u606f\u63d0\u53d6\u548c\u5206\u6790\u3002", "method": "\u672c\u7814\u7a76\u5229\u7528\u5305\u542b 1,672 \u5f20\u6768\u6811\uff08Populus Trichocarpa\uff09\u56fe\u50cf\u7684\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u663e\u793a\u5904\u7406\uff08\u5bf9\u7167\u6216\u5e72\u65f1\uff09\u3001\u5757\u3001\u884c\u3001\u4f4d\u7f6e\u548c\u57fa\u56e0\u578b\u7684\u767d\u8272\u6807\u7b7e\u3002\u7814\u7a76\u91c7\u7528\u4e86\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09\u6280\u672f\u6765\u8bfb\u53d6\u690d\u7269\u6807\u7b7e\uff0c\u7ed3\u5408\u56fe\u50cf\u5206\u5272\u6280\u672f\u548c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5f62\u6001\u5b66\u5206\u7c7b\uff0c\u5e76\u5229\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6839\u636e\u8fd9\u4e9b\u5206\u7c7b\u9884\u6d4b\u5904\u7406\u7c7b\u578b\u3002\u6b64\u5916\uff0c\u8fd8\u5206\u6790\u4e86\u7f16\u7801\u7684 EXIF \u6807\u7b7e\uff0c\u4ee5\u786e\u5b9a\u53f6\u7247\u5927\u5c0f\u548c\u8868\u578b\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002", "result": "OCR \u6a21\u578b\u5728\u975e\u7a7a\u6587\u672c\u63d0\u53d6\u65b9\u9762\u8fbe\u5230\u4e86 94.31% \u7684\u51c6\u786e\u7387\uff0c\u80fd\u591f\u51c6\u786e\u5730\u5c06\u4fe1\u606f\u5f55\u5165\u7535\u5b50\u8868\u683c\u3002\u5f62\u6001\u5b66\u5206\u7c7b\u6a21\u578b\uff08\u8bc6\u522b\u53f6\u7247\u5f62\u72b6\u3001\u989c\u8272\u548c\u8910\u6591\u7a0b\u5ea6\uff09\u7684\u5e73\u5747\u51c6\u786e\u7387\u4e3a 62.82%\uff0c\u9884\u6d4b\u690d\u7269\u5904\u7406\u7684\u51c6\u786e\u7387\u4e3a 60.08%\u3002\u7814\u7a76\u53d1\u73b0 EXIF \u6807\u7b7e\u7f3a\u5931\u5173\u952e\u4fe1\u606f\uff0c\u963b\u788d\u4e86\u53f6\u7247\u5927\u5c0f\u7684\u8bc4\u4f30\u4ee5\u53ca\u8868\u578b\u4e0e\u6761\u4ef6\u4e4b\u95f4\u76f8\u5173\u6027\u7684\u5206\u6790\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u7ed3\u5408 OCR\u3001\u56fe\u50cf\u5206\u5272\u548c\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u4ece\u690d\u7269\u56fe\u50cf\u4e2d\u63d0\u53d6\u8868\u578b\u4fe1\u606f\uff0c\u5e76\u9884\u6d4b\u690d\u7269\u5904\u7406\uff08\u5bf9\u7167\u6216\u5e72\u65f1\uff09\u3002\u867d\u7136\u5728\u8bc6\u522b\u53f6\u7247\u5f62\u72b6\u3001\u989c\u8272\u548c\u8910\u6591\u7a0b\u5ea6\u7b49\u8868\u578b\u65b9\u9762\u53d6\u5f97\u4e86 62.82% \u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u4ee5\u53ca 60.08% \u7684\u690d\u7269\u5904\u7406\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u4f46 EXIF \u6807\u7b7e\u7684\u7f3a\u5931\u4fe1\u606f\u963b\u788d\u4e86\u53f6\u7247\u5927\u5c0f\u548c\u8868\u578b\u4e4b\u95f4\u76f8\u5173\u6027\u7684\u8bc4\u4f30\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u6539\u8fdb\u8fd9\u4e9b\u65b9\u9762\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u8fd9\u4e9b\u7279\u5f81\u7684\u66f4\u5168\u9762\u8bc4\u4f30\u3002"}}
{"id": "2405.05292", "title": "Smart Portable Computer", "url": "https://arxiv.org/abs/2405.05292", "pdf": "https://arxiv.org/pdf/2405.05292", "abs": "https://arxiv.org/abs/2405.05292", "authors": ["Niladri Das"], "categories": ["cs.HC", "cs.AI", "cs.RO"], "comment": "34 pages", "summary": "Amidst the COVID-19 pandemic, with many organizations, schools, colleges, and\nuniversities transitioning to virtual platforms, students encountered\ndifficulties in acquiring PCs such as desktops or laptops. The starting prices,\naround 15,000 INR, often failed to offer adequate system specifications, posing\na challenge for consumers. Additionally, those reliant on laptops for work\nfound the conventional approach cumbersome. Enter the \"Portable Smart\nComputer,\" a leap into the future of computing. This innovative device boasts\nspeed and performance comparable to traditional desktops but in a compact,\nenergy-efficient, and cost-effective package. It delivers a seamless desktop\nexperience, whether one is editing documents, browsing multiple tabs, managing\nspreadsheets, or creating presentations. Moreover, it supports programming\nlanguages like Python, C, C++, as well as compilers such as Keil and Xilinx,\ncatering to the needs of programmers.", "AI": {"tldr": "\u75ab\u60c5\u671f\u95f4\u8d2d\u673a\u96be\uff1f\u8bd5\u8bd5\u8fd9\u6b3e\u201c\u4fbf\u643a\u5f0f\u667a\u80fd\u8ba1\u7b97\u673a\u201d\uff0c\u5b83\u5c0f\u5de7\u3001\u9ad8\u6548\u3001\u7ecf\u6d4e\uff0c\u8fd8\u80fd\u7f16\u7a0b\uff01", "motivation": "\u89e3\u51b3\u5b66\u751f\u548c\u4f9d\u8d56\u7b14\u8bb0\u672c\u7535\u8111\u5de5\u4f5c\u8005\u5728\u75ab\u60c5\u671f\u95f4\u9762\u4e34\u7684\u8d2d\u673a\u56f0\u96be\u548c\u4f20\u7edf\u7b14\u8bb0\u672c\u7535\u8111\u4f7f\u7528\u4e0d\u4fbf\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e00\u6b3e\u540d\u4e3a\u201c\u4fbf\u643a\u5f0f\u667a\u80fd\u8ba1\u7b97\u673a\u201d\u7684\u65b0\u578b\u8bbe\u5907\u3002", "result": "\u8be5\u8bbe\u5907\u6027\u80fd\u5ab2\u7f8e\u53f0\u5f0f\u673a\uff0c\u4f53\u79ef\u5c0f\u5de7\uff0c\u8282\u80fd\u4e14\u6210\u672c\u4f4e\u5ec9\uff0c\u53ef\u6ee1\u8db3\u65e5\u5e38\u529e\u516c\u3001\u6d4f\u89c8\u7f51\u9875\u3001\u7f16\u7a0b\u7b49\u591a\u79cd\u9700\u6c42\u3002", "conclusion": "Portable Smart Computer\u662f\u4e00\u6b3e\u4fbf\u643a\u3001\u9ad8\u6548\u4e14\u7ecf\u6d4e\u7684\u8ba1\u7b97\u8bbe\u5907\uff0c\u80fd\u591f\u63d0\u4f9b\u65e0\u7f1d\u7684\u684c\u9762\u4f53\u9a8c\uff0c\u5e76\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c\u7f16\u8bd1\u5668\u3002"}}
{"id": "2404.12608", "title": "Auto-Formula: Recommend Formulas in Spreadsheets using Contrastive Learning for Table Representations", "url": "https://arxiv.org/abs/2404.12608", "pdf": "https://arxiv.org/pdf/2404.12608", "abs": "https://arxiv.org/abs/2404.12608", "authors": ["Sibei Chen", "Yeye He", "Weiwei Cui", "Ju Fan", "Song Ge", "Haidong Zhang", "Dongmei Zhang", "Surajit Chaudhuri"], "categories": ["cs.DB", "cs.CL", "cs.PL"], "comment": "full version of a paper to appear in SIGMOD 2024", "summary": "Spreadsheets are widely recognized as the most popular end-user programming\ntools, which blend the power of formula-based computation, with an intuitive\ntable-based interface. Today, spreadsheets are used by billions of users to\nmanipulate tables, most of whom are neither database experts nor professional\nprogrammers.\n  Despite the success of spreadsheets, authoring complex formulas remains\nchallenging, as non-technical users need to look up and understand non-trivial\nformula syntax. To address this pain point, we leverage the observation that\nthere is often an abundance of similar-looking spreadsheets in the same\norganization, which not only have similar data, but also share similar\ncomputation logic encoded as formulas. We develop an Auto-Formula system that\ncan accurately predict formulas that users want to author in a target\nspreadsheet cell, by learning and adapting formulas that already exist in\nsimilar spreadsheets, using contrastive-learning techniques inspired by\n\"similar-face recognition\" from compute vision.\n  Extensive evaluations on over 2K test formulas extracted from real enterprise\nspreadsheets show the effectiveness of Auto-Formula over alternatives. Our\nbenchmark data is available at https://github.com/microsoft/Auto-Formula to\nfacilitate future research.", "AI": {"tldr": "Auto-Formula \u662f\u4e00\u4e2a\u65b0\u7cfb\u7edf\uff0c\u53ef\u4ee5\u6839\u636e\u7ec4\u7ec7\u5185\u76f8\u4f3c\u7535\u5b50\u8868\u683c\u4e2d\u7684\u73b0\u6709\u516c\u5f0f\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u6765\u9884\u6d4b\u7528\u6237\u60f3\u8981\u7684\u7535\u5b50\u8868\u683c\u516c\u5f0f\uff0c\u5927\u5927\u7b80\u5316\u4e86\u975e\u6280\u672f\u7528\u6237\u7684\u516c\u5f0f\u7f16\u5199\u8fc7\u7a0b\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u662f\u5e7f\u53d7\u6b22\u8fce\u7684\u5de5\u5177\uff0c\u4f46\u5bf9\u975e\u6280\u672f\u7528\u6237\u800c\u8a00\uff0c\u7f16\u5199\u590d\u6742\u516c\u5f0f\u4ecd\u7136\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u4ed6\u4eec\u9700\u8981\u67e5\u627e\u548c\u7406\u89e3\u590d\u6742\u7684\u516c\u5f0f\u8bed\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Auto-Formula \u7684\u65b0\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5229\u7528\u7ec4\u7ec7\u5185\u76f8\u4f3c\u7535\u5b50\u8868\u683c\u4e2d\u5df2\u5b58\u5728\u7684\u516c\u5f0f\uff0c\u5e76\u501f\u9274\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5bf9\u6bd4\u5b66\u4e60\u6280\u672f\uff08\u7c7b\u4f3c\u4e8e \u201c\u76f8\u4f3c\u4eba\u8138\u8bc6\u522b\u201d\uff09\uff0c\u6765\u5b66\u4e60\u548c\u9002\u5e94\u8fd9\u4e9b\u516c\u5f0f\uff0c\u4ece\u800c\u9884\u6d4b\u7528\u6237\u60f3\u8981\u8f93\u5165\u7684\u516c\u5f0f\u3002", "result": "\u5728\u4ece\u771f\u5b9e\u4f01\u4e1a\u7535\u5b50\u8868\u683c\u4e2d\u63d0\u53d6\u7684 2K \u591a\u4e2a\u6d4b\u8bd5\u516c\u5f0f\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cAuto-Formula \u7684\u6709\u6548\u6027\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5229\u7528\u76f8\u4f3c\u7ec4\u7ec7\u4e2d\u5df2\u5b58\u5728\u7684\u516c\u5f0f\uff0c\u5e76\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u6280\u672f\uff0c\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3a Auto-Formula \u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u7528\u6237\u5728\u76ee\u6807\u5355\u5143\u683c\u4e2d\u6240\u9700\u7684\u516c\u5f0f\u3002"}}
{"id": "2404.07114", "title": "\"My toxic trait is thinking I'll remember this\": gaps in the learner experience of video tutorials for feature-rich software", "url": "https://arxiv.org/abs/2404.07114", "pdf": "https://arxiv.org/pdf/2404.07114", "abs": "https://arxiv.org/abs/2404.07114", "authors": ["Ian Drosos", "Advait Sarkar", "Andrew D. Gordon"], "categories": ["cs.HC"], "comment": null, "summary": "Video tutorials are a popular medium for informal and formal learning.\nHowever, when learners attempt to view and follow along with these tutorials,\nthey encounter what we call gaps, that is, issues that can prevent learning. We\nexamine the gaps encountered by users of video tutorials for feature-rich\nsoftware, such as spreadsheets. We develop a theory and taxonomy of such gaps,\nidentifying how they act as barriers to learning, by collecting and analyzing\n360 viewer comments from 90 Microsoft Excel video tutorials published by 43\ncreators across YouTube, TikTok, and Instagram. We conducted contextual\ninterviews with 8 highly influential tutorial creators to investigate the gaps\ntheir viewers experience and how they address them. Further, we obtain insights\ninto their creative process and frustrations when creating video tutorials.\nFinally, we present creators with two designs that aim to address gaps\nidentified in the comment analysis for feedback and alternative design ideas.", "AI": {"tldr": "Learners face \"gaps\" in video tutorials for software like Excel. This study analyzes viewer comments and interviews creators to identify these gaps, offering a taxonomy and proposing design solutions.", "motivation": "Video tutorials are a popular learning medium, but learners often face \"gaps\" (issues preventing learning) when trying to follow along, especially with complex software like spreadsheets. This research aims to understand these gaps and their impact on learning.", "method": "The study analyzes 360 viewer comments from 90 Microsoft Excel video tutorials across YouTube, TikTok, and Instagram. It also includes contextual interviews with 8 influential tutorial creators to understand viewer-reported gaps and creator perspectives. Finally, two design concepts are presented to creators for feedback.", "result": "The research develops a theory and taxonomy of gaps encountered by learners using video tutorials for feature-rich software. It also provides insights into creators' processes, frustrations, and feedback on design interventions aimed at addressing these gaps.", "conclusion": "The study identifies and categorizes learning barriers ("}}
{"id": "2402.11734", "title": "Solving Data-centric Tasks using Large Language Models", "url": "https://arxiv.org/abs/2402.11734", "pdf": "https://arxiv.org/pdf/2402.11734", "abs": "https://arxiv.org/abs/2402.11734", "authors": ["Shraddha Barke", "Christian Poelitz", "Carina Suzana Negreanu", "Benjamin Zorn", "Jos\u00e9 Cambronero", "Andrew D. Gordon", "Vu Le", "Elnaz Nouri", "Nadia Polikarpova", "Advait Sarkar", "Brian Slininger", "Neil Toronto", "Jack Williams"], "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": "Paper accepted to NAACL 2024 (Findings)", "summary": "Large language models (LLMs) are rapidly replacing help forums like\nStackOverflow, and are especially helpful for non-professional programmers and\nend users. These users are often interested in data-centric tasks, such as\nspreadsheet manipulation and data wrangling, which are hard to solve if the\nintent is only communicated using a natural-language description, without\nincluding the data. But how do we decide how much data and which data to\ninclude in the prompt? This paper makes two contributions towards answering\nthis question. First, we create a dataset of real-world NL-to-code tasks\nmanipulating tabular data, mined from StackOverflow posts. Second, we introduce\na cluster-then-select prompting technique, which adds the most representative\nrows from the input data to the LLM prompt. Our experiments show that LLM\nperformance is indeed sensitive to the amount of data passed in the prompt, and\nthat for tasks with a lot of syntactic variation in the input table, our\ncluster-then-select technique outperforms a random selection baseline.", "AI": {"tldr": "LLM\u5728\u5904\u7406\u8868\u683c\u6570\u636e\u4efb\u52a1\u65f6\uff0c\u901a\u8fc7\u201c\u805a\u7c7b\u540e\u9009\u62e9\u201d\u6280\u672f\u5e76\u63d0\u4f9b\u4ee3\u8868\u6027\u6570\u636e\u884c\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5176\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u8bed\u6cd5\u591a\u53d8\u7684\u60c5\u51b5\u4e0b\u3002\u7814\u7a76\u4eba\u5458\u8fd8\u4e3a\u6b64\u521b\u5efa\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7f16\u7a0b\u8f85\u52a9\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bf9\u4e8e\u9700\u8981\u5904\u7406\u8868\u683c\u6570\u636e\u7684\u4efb\u52a1\uff0c\u5982\u4f55\u6709\u6548\u5730\u5728\u63d0\u793a\u4e2d\u5305\u542b\u6570\u636e\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5982\u4f55\u51b3\u5b9a\u5728\u63d0\u793a\u4e2d\u5305\u542b\u591a\u5c11\u6570\u636e\u4ee5\u53ca\u54ea\u4e9b\u6570\u636e\uff0c\u4ee5\u63d0\u9ad8LLM\u5728\u6570\u636e\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u201c\u805a\u7c7b\u540e\u9009\u62e9\u201d\u63d0\u793a\u6280\u672f\uff0c\u8be5\u6280\u672f\u901a\u8fc7\u5c06\u6700\u5177\u4ee3\u8868\u6027\u7684\u6570\u636e\u884c\u6dfb\u52a0\u5230LLM\u63d0\u793a\u4e2d\u6765\u4f18\u5316LLM\u5728\u5904\u7406\u6570\u636e\u5bc6\u96c6\u578b\u4efb\u52a1\u65f6\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0c\u7814\u7a76\u4eba\u5458\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u771f\u5b9e\u4e16\u754c\u81ea\u7136\u8bed\u8a00\u5230\u4ee3\u7801\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u4efb\u52a1\u662f\u4eceStackOverflow\u5e16\u5b50\u4e2d\u63d0\u53d6\u7684\uff0c\u4e13\u6ce8\u4e8e\u8868\u683c\u6570\u636e\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLLM\u5728\u5904\u7406\u9700\u8981\u8868\u683c\u6570\u636e\u7684\u4efb\u52a1\u65f6\u7684\u6027\u80fd\u786e\u5b9e\u53d7\u5230\u63d0\u793a\u4e2d\u6570\u636e\u91cf\u7684\u5f71\u54cd\u3002\u6240\u63d0\u51fa\u7684\u201c\u805a\u7c7b\u540e\u9009\u62e9\u201d\u6280\u672f\u6bd4\u968f\u673a\u9009\u62e9\u57fa\u7ebf\u66f4\u80fd\u6709\u6548\u63d0\u5347LLM\u5728\u5904\u7406\u5177\u6709\u9ad8\u8bed\u6cd5\u53d8\u5f02\u6027\u7684\u8868\u683c\u6570\u636e\u4efb\u52a1\u65f6\u7684\u8868\u73b0\u3002", "conclusion": "LLM\u5728\u5904\u7406\u6570\u636e\u5bc6\u96c6\u578b\u4efb\u52a1\u65b9\u9762\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u975e\u4e13\u4e1a\u7a0b\u5e8f\u5458\u548c\u7ec8\u7aef\u7528\u6237\uff0c\u6b63\u9010\u6e10\u53d6\u4ee3\u4f20\u7edf\u7684\u5e2e\u52a9\u8bba\u575b\u3002LLM\u7684\u6027\u80fd\u5bf9\u63d0\u793a\u4e2d\u63d0\u4f9b\u7684\u6570\u636e\u91cf\u654f\u611f\uff0c\u6240\u63d0\u51fa\u7684\u201c\u805a\u7c7b\u540e\u9009\u62e9\u201d\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u9ad8\u8bed\u6cd5\u53d8\u5f02\u6027\u7684\u8868\u683c\u6570\u636e\u4efb\u52a1\u65f6\uff0c\u4f18\u4e8e\u968f\u673a\u9009\u62e9\u57fa\u7ebf\u3002"}}
{"id": "2403.07762", "title": "Supporting Annotators with Affordances for Efficiently Labeling Conversational Data", "url": "https://arxiv.org/abs/2403.07762", "pdf": "https://arxiv.org/pdf/2403.07762", "abs": "https://arxiv.org/abs/2403.07762", "authors": ["Austin Z. Henley", "David Piorkowski"], "categories": ["cs.HC"], "comment": null, "summary": "Without well-labeled ground truth data, machine learning-based systems would\nnot be as ubiquitous as they are today, but these systems rely on substantial\namounts of correctly labeled data. Unfortunately, crowdsourced labeling is time\nconsuming and expensive. To address the concerns of effort and tedium, we\ndesigned CAL, a novel interface to aid in data labeling. We made several key\ndesign decisions for CAL, which include preventing inapt labels from being\nselected, guiding users in selecting an appropriate label when they need\nassistance, incorporating labeling documentation into the interface, and\nproviding an efficient means to view previous labels. We implemented a\nproduction-quality implementation of CAL and report a user-study evaluation\nthat compares CAL to a standard spreadsheet. Key findings of our study include\nusers using CAL reported lower cognitive load, did not increase task time,\nusers rated CAL to be easier to use, and users preferred CAL over the\nspreadsheet.", "AI": {"tldr": "CAL is a new data labeling interface that is easier to use and preferred by users over spreadsheets, without increasing task time.", "motivation": "Crowdsourced labeling is time consuming and expensive, and current methods often involve effort and tedium. This paper aims to address these concerns by designing a more efficient and user-friendly data labeling interface.", "method": "CAL is a novel interface designed to aid in data labeling. Key design decisions include preventing inapt labels, guiding users, incorporating labeling documentation, and providing an efficient means to view previous labels. A user study was conducted comparing CAL to a standard spreadsheet.", "result": "Users using CAL reported lower cognitive load, did not increase task time, rated CAL to be easier to use, and preferred CAL over the spreadsheet.", "conclusion": "CAL is a novel interface designed to aid in data labeling, which was found to be easier to use, have lower cognitive load, and be preferred by users compared to a standard spreadsheet."}}
{"id": "2310.09985", "title": "Prompting for Discovery: Flexible Sense-Making for AI Art-Making with Dreamsheets", "url": "https://arxiv.org/abs/2310.09985", "pdf": "https://arxiv.org/pdf/2310.09985", "abs": "https://arxiv.org/abs/2310.09985", "authors": ["Shm Garanganao Almeda", "J. D. Zamfirescu-Pereira", "Kyu Won Kim", "Pradeep Mani Rathnam", "Bjoern Hartmann"], "categories": ["cs.HC"], "comment": "13 pages, 14 figures, currently under review", "summary": "Design space exploration (DSE) for Text-to-Image (TTI) models entails\nnavigating a vast, opaque space of possible image outputs, through a\ncommensurately vast input space of hyperparameters and prompt text. Minor\nadjustments to prompt input can surface unexpectedly disparate images. How can\ninterfaces support end-users in reliably steering prompt-space explorations\ntowards interesting results? Our design probe, DreamSheets, supports\nexploration strategies with LLM-based functions for assisted prompt\nconstruction and simultaneous display of generated results, hosted in a\nspreadsheet interface. The flexible layout and novel generative functions\nenable experimentation with user-defined workflows. Two studies, a preliminary\nlab study and a longitudinal study with five expert artists, revealed a set of\nstrategies participants use to tackle the challenges of TTI design space\nexploration, and the interface features required to support them - like using\ntext-generation to define local \"axes\" of exploration. We distill these\ninsights into a UI mockup to guide future interfaces.", "AI": {"tldr": "DreamSheets\u662f\u4e00\u4e2a\u7535\u5b50\u8868\u683c\u754c\u9762\uff0c\u5229\u7528LLM\u8f85\u52a9\u63d0\u793a\u8bcd\u6784\u5efa\u548c\u7ed3\u679c\u5c55\u793a\uff0c\u5e2e\u52a9\u7528\u6237\u5728TTI\u6a21\u578b\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63a2\u7d22\u3002\u7814\u7a76\u53d1\u73b0\u7528\u6237\u4f7f\u7528\u7279\u5b9a\u7b56\u7565\uff0c\u5982\u5229\u7528\u6587\u672c\u751f\u6210\u5b9a\u4e49\u63a2\u7d22\u8f74\uff0c\u5e76\u636e\u6b64\u63d0\u51fa\u4e86\u672a\u6765\u754c\u9762\u7684\u8bbe\u8ba1\u6307\u5bfc\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u6587\u672c\u5230\u56fe\u50cf\uff08TTI\uff09\u6a21\u578b\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u4e2d\uff0c\u7528\u6237\u96be\u4ee5\u901a\u8fc7\u6d77\u91cf\u7684\u8d85\u53c2\u6570\u548c\u63d0\u793a\u8bcd\u5bfc\u822a\uff0c\u4ee5\u53ca\u5fae\u5c0f\u7684\u63d0\u793a\u8bcd\u8c03\u6574\u5bfc\u81f4\u8f93\u51fa\u56fe\u50cf\u5dee\u5f02\u5de8\u5927\u7684\u95ee\u9898\uff0c\u4ee5\u652f\u6301\u7528\u6237\u53ef\u9760\u5730\u5c06\u63d0\u793a\u8bcd\u7a7a\u95f4\u63a2\u7d22\u5f15\u5bfc\u81f3\u6709\u8da3\u7684\u7ed3\u679c\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u63a2\u9488DreamSheets\uff0c\u5229\u7528\u57fa\u4e8eLLM\u7684\u51fd\u6570\u8f85\u52a9\u63d0\u793a\u6784\u5efa\u548c\u540c\u65f6\u663e\u793a\u751f\u6210\u7ed3\u679c\uff0c\u5e76\u7ed3\u5408\u7535\u5b50\u8868\u683c\u754c\u9762\uff0c\u652f\u6301\u7528\u6237\u5b9a\u4e49\u7684\u63a2\u7d22\u7b56\u7565\u548c\u5de5\u4f5c\u6d41\u3002\u901a\u8fc7\u521d\u6b65\u7684\u5b9e\u9a8c\u5ba4\u7814\u7a76\u548c\u5305\u542b\u4e94\u4f4d\u827a\u672f\u5bb6\u8fdb\u884c\u7eb5\u5411\u7814\u7a76\uff0c\u6536\u96c6\u7528\u6237\u5728TTI\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u4e2d\u7684\u7b56\u7565\u548c\u6240\u9700\u754c\u9762\u529f\u80fd\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u53c2\u4e0e\u8005\u5728TTI\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u4e2d\u4f7f\u7528\u7684\u7b56\u7565\uff0c\u4ee5\u53ca\u652f\u6301\u8fd9\u4e9b\u7b56\u7565\u6240\u9700\u7684\u754c\u9762\u529f\u80fd\uff0c\u4f8b\u5982\u5229\u7528\u6587\u672c\u751f\u6210\u5b9a\u4e49\u63a2\u7d22\u7684\u5c40\u90e8\u201c\u8f74\u201d\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u70bc\u4e86\u652f\u6301\u6587\u672c\u5230\u56fe\u50cf\uff08TTI\uff09\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u7684\u754c\u9762\u529f\u80fd\uff0c\u5e76\u901a\u8fc7UI\u6a21\u578b\u6307\u5bfc\u672a\u6765\u7684\u754c\u9762\u8bbe\u8ba1\u3002"}}
{"id": "2402.14853", "title": "NL2Formula: Generating Spreadsheet Formulas from Natural Language Queries", "url": "https://arxiv.org/abs/2402.14853", "pdf": "https://arxiv.org/pdf/2402.14853", "abs": "https://arxiv.org/abs/2402.14853", "authors": ["Wei Zhao", "Zhitao Hou", "Siyuan Wu", "Yan Gao", "Haoyu Dong", "Yao Wan", "Hongyu Zhang", "Yulei Sui", "Haidong Zhang"], "categories": ["cs.CL", "cs.AI"], "comment": "To appear at EACL 2024", "summary": "Writing formulas on spreadsheets, such as Microsoft Excel and Google Sheets,\nis a widespread practice among users performing data analysis. However,\ncrafting formulas on spreadsheets remains a tedious and error-prone task for\nmany end-users, particularly when dealing with complex operations. To alleviate\nthe burden associated with writing spreadsheet formulas, this paper introduces\na novel benchmark task called NL2Formula, with the aim to generate executable\nformulas that are grounded on a spreadsheet table, given a Natural Language\n(NL) query as input. To accomplish this, we construct a comprehensive dataset\nconsisting of 70,799 paired NL queries and corresponding spreadsheet formulas,\ncovering 21,670 tables and 37 types of formula functions. We realize the\nNL2Formula task by providing a sequence-to-sequence baseline implementation\ncalled fCoder. Experimental results validate the effectiveness of fCoder,\ndemonstrating its superior performance compared to the baseline models.\nFurthermore, we also compare fCoder with an initial GPT-3.5 model (i.e.,\ntext-davinci-003). Lastly, through in-depth error analysis, we identify\npotential challenges in the NL2Formula task and advocate for further\ninvestigation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86NL2Formula\u4efb\u52a1\u548cfCoder\u6a21\u578b\uff0c\u7528\u4e8e\u6839\u636e\u81ea\u7136\u8bed\u8a00\u751f\u6210\u7535\u5b50\u8868\u683c\u516c\u5f0f\uff0c\u5e76\u53d6\u5f97\u4e86\u826f\u597d\u7684\u6548\u679c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u7528\u6237\u5728\u7535\u5b50\u8868\u683c\u4e2d\u7f16\u5199\u590d\u6742\u516c\u5f0f\u65f6\u9047\u5230\u7684\u56f0\u96be\u548c\u6613\u9519\u6027\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u7b80\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3afCoder\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u6765\u5b9e\u73b0NL2Formula\u4efb\u52a1\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b70,799\u4e2a\u67e5\u8be2-\u516c\u5f0f\u5bf9\u7684\u6570\u636e\u96c6\u3002", "result": "fCoder\u6a21\u578b\u5728NL2Formula\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u4e0eGPT-3.5\u8fdb\u884c\u4e86\u6027\u80fd\u6bd4\u8f83\u3002", "conclusion": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86NL2Formula\u8fd9\u4e00\u65b0\u57fa\u51c6\u4efb\u52a1\uff0c\u65e8\u5728\u6839\u636e\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u751f\u6210\u7535\u5b50\u8868\u683c\u516c\u5f0f\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3afCoder\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660efCoder\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u4e0eGPT-3.5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7814\u7a76\u8fd8\u901a\u8fc7\u9519\u8bef\u5206\u6790\u6307\u51fa\u4e86NL2Formula\u4efb\u52a1\u7684\u6311\u6218\uff0c\u5e76\u9f13\u52b1\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2006.14706", "title": "Will Dynamic Arrays finally change the way Models are built?", "url": "https://arxiv.org/abs/2006.14706", "pdf": "https://arxiv.org/pdf/2006.14706", "abs": "https://arxiv.org/abs/2006.14706", "authors": ["Peter Bartholomew"], "categories": ["cs.SE"], "comment": "11 Pages, 5 Figures, Numerous Spreadsheet Formulae. This version\n  email address update", "summary": "Spreadsheets offer a supremely successful and intuitive means of processing\nand exchanging numerical content. Its intuitive ad-hoc nature makes it hugely\npopular for use in diverse areas including business and engineering, yet these\nvery same characteristics make it extraordinarily error-prone; many would\nquestion whether it is suitable for serious analysis or modelling tasks. A\nprevious EuSpRIG paper examined the role of Names in increasing solution\ntransparency and providing a readable notation to forge links with the problem\ndomain. Extensive use was made of CSE array formulas, but it is acknowledged\nthat their use makes spreadsheet development a distinctly cumbersome task.\nSince that time, the new dynamic arrays have been introduced and array\ncalculation is now the default mode of operation for Excel. This paper examines\nthe thesis that their adoption within a more professional development\nenvironment could replace traditional techniques where solution integrity is\nimportant. A major advantage of fully dynamic models is that they require less\nmanual intervention to keep them updated and so have the potential to reduce\nthe attendant errors and risk.", "AI": {"tldr": "\u7535\u5b50\u8868\u683c\u7684\u52a8\u6001\u6570\u7ec4\u6280\u672f\u6709\u671b\u63d0\u9ad8\u5176\u5728\u4e13\u4e1a\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u867d\u7136\u76f4\u89c2\u6613\u7528\uff0c\u4f46\u5bb9\u6613\u51fa\u9519\uff0c\u4e0d\u9002\u5408\u4e25\u8c28\u7684\u5206\u6790\u6216\u5efa\u6a21\u3002\u5148\u524d\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528 CSE \u6570\u7ec4\u516c\u5f0f\u53ef\u4ee5\u63d0\u9ad8\u900f\u660e\u5ea6\uff0c\u4f46\u8fc7\u7a0b\u7e41\u7410\u3002\u65b0\u7684\u52a8\u6001\u6570\u7ec4\u6280\u672f\u7684\u51fa\u73b0\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002", "method": "\u672c\u7814\u7a76\u68c0\u9a8c\u4e86\u52a8\u6001\u6570\u7ec4\u5728\u66f4\u4e13\u4e1a\u7684\u5f00\u53d1\u73af\u5883\u4e2d\u53d6\u4ee3\u4f20\u7edf\u6280\u672f\u4ee5\u786e\u4fdd\u89e3\u51b3\u65b9\u6848\u5b8c\u6574\u6027\u7684\u53ef\u80fd\u6027\u3002", "result": "\u65b0\u7684\u52a8\u6001\u6570\u7ec4\u6280\u672f\u53ef\u80fd\u53d6\u4ee3\u4f20\u7edf\u6280\u672f\uff0c\u56e0\u4e3a\u5b83\u4eec\u9700\u8981\u66f4\u5c11\u7684\u624b\u52a8\u5e72\u9884\u6765\u66f4\u65b0\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u9519\u8bef\u548c\u98ce\u9669\u3002", "conclusion": "\u7535\u5b50\u8868\u683c\u7684\u52a8\u6001\u6570\u7ec4\u4e3a\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u7684\u5b8c\u6574\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u4e13\u4e1a\u3001\u66f4\u6613\u4e8e\u7ef4\u62a4\u7684\u65b9\u6cd5\uff0c\u6709\u53ef\u80fd\u51cf\u5c11\u9519\u8bef\u548c\u98ce\u9669\u3002"}}
{"id": "1704.01142", "title": "A Structured Approach to the development of Solutions in Excel", "url": "https://arxiv.org/abs/1704.01142", "pdf": "https://arxiv.org/pdf/1704.01142", "abs": "https://arxiv.org/abs/1704.01142", "authors": ["Peter Bartholomew"], "categories": ["cs.SE"], "comment": "12 pages, 6 figures. This version updated email address", "summary": "Spreadsheets offer a supremely successful democratisation platform, placing\nthe manipulation and presentation of numbers within the grasp of users that\nhave little or no mathematical expertise or IT experience. What appears to be\nalmost completely lacking within a \"normal\" solution built using Excel default\nsettings is the deployment of any structure that extends beyond a single-cell\nformula. The structural elements that allow conventional code to scale without\nescalating errors appear to be absent. This paper considers the use of\ncontroversial or lesser-used techniques to create a coherent solution strategy\nin which the problem is solved by a sequence of formulas resembling the steps\nof a programmed language.", "AI": {"tldr": "Excel \u7f3a\u4e4f\u7ed3\u6784\uff0c\u4f1a\u5bfc\u81f4\u9519\u8bef\u7d2f\u79ef\uff1b\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4e00\u7cfb\u5217\u516c\u5f0f\u6765\u89e3\u51b3\u95ee\u9898\u7684\u7b56\u7565\u3002", "motivation": "Excel \u666e\u53ca\u4e86\u6570\u636e\u5904\u7406\uff0c\u4f46\u5176\u7ed3\u6784\u9650\u5236\u4e86\u590d\u6742\u95ee\u9898\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4e00\u7cfb\u5217\u516c\u5f0f\u6765\u89e3\u51b3\u95ee\u9898\u7684\u7b56\u7565\uff0c\u8fd9\u4e9b\u516c\u5f0f\u7c7b\u4f3c\u4e8e\u7f16\u7a0b\u8bed\u8a00\u7684\u6b65\u9aa4\u3002", "result": "\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u6709\u4e89\u8bae\u6216\u9c9c\u4e3a\u4eba\u7528\u7684\u6280\u672f\uff0c\u4ee5\u521b\u5efa\u4e00\u79cd\u7c7b\u4f3c\u7f16\u7a0b\u8bed\u8a00\u7684\u6709\u5e8f\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "Excel \u7f3a\u5c11\u53ef\u6269\u5c55\u7684\u7ed3\u6784\uff0c\u8fd9\u4f1a\u968f\u7740\u9519\u8bef\u7684\u7d2f\u79ef\u800c\u5bfc\u81f4\u95ee\u9898\u3002"}}
{"id": "2402.00069", "title": "Using the Abstract Computer Architecture Description Language to Model AI Hardware Accelerators", "url": "https://arxiv.org/abs/2402.00069", "pdf": "https://arxiv.org/pdf/2402.00069", "abs": "https://arxiv.org/abs/2402.00069", "authors": ["Mika Markus M\u00fcller", "Alexander Richard Manfred Borst", "Konstantin L\u00fcbeck", "Alexander Louis-Ferdinand Jung", "Oliver Bringmann"], "categories": ["cs.AR", "cs.AI"], "comment": "Accepted Version for: MBMV'24", "summary": "Artificial Intelligence (AI) has witnessed remarkable growth, particularly\nthrough the proliferation of Deep Neural Networks (DNNs). These powerful models\ndrive technological advancements across various domains. However, to harness\ntheir potential in real-world applications, specialized hardware accelerators\nare essential. This demand has sparked a market for parameterizable AI hardware\naccelerators offered by different vendors.\n  Manufacturers of AI-integrated products face a critical challenge: selecting\nan accelerator that aligns with their product's performance requirements. The\ndecision involves choosing the right hardware and configuring a suitable set of\nparameters. However, comparing different accelerator design alternatives\nremains a complex task. Often, engineers rely on data sheets, spreadsheet\ncalculations, or slow black-box simulators, which only offer a coarse\nunderstanding of the performance characteristics.\n  The Abstract Computer Architecture Description Language (ACADL) is a concise\nformalization of computer architecture block diagrams, which helps to\ncommunicate computer architecture on different abstraction levels and allows\nfor inferring performance characteristics. In this paper, we demonstrate how to\nuse the ACADL to model AI hardware accelerators, use their ACADL description to\nmap DNNs onto them, and explain the timing simulation semantics to gather\nperformance results.", "AI": {"tldr": "ACADL can model AI hardware accelerators and simulate DNN performance.", "motivation": "The motivation is to address the challenge faced by manufacturers of AI-integrated products in selecting the most suitable AI hardware accelerator by providing a more efficient and accurate method for comparing different accelerator design alternatives, moving beyond reliance on data sheets, spreadsheets, or slow black-box simulators.", "method": "The paper uses the Abstract Computer Architecture Description Language (ACADL) to model AI hardware accelerators, map Deep Neural Networks (DNNs) onto these models, and utilizes timing simulation semantics to collect performance data.", "result": "The result is a demonstrated methodology for using ACADL to model AI hardware accelerators and simulate their performance with DNNs, offering engineers a better understanding of performance characteristics compared to traditional methods.", "conclusion": "The paper demonstrates the use of ACADL for modeling AI hardware accelerators, mapping DNNs onto them, and simulating performance, providing a more efficient alternative to traditional methods."}}
{"id": "2401.11042", "title": "Does Using ChatGPT Result in Human Cognitive Augmentation?", "url": "https://arxiv.org/abs/2401.11042", "pdf": "https://arxiv.org/pdf/2401.11042", "abs": "https://arxiv.org/abs/2401.11042", "authors": ["Ron Fulbright", "Miranda Morrison"], "categories": ["cs.HC"], "comment": "12 pages, 5 figures", "summary": "Human cognitive performance is enhanced by the use of tools. For example, a\nhuman can produce a much greater, and more accurate, volume of mathematical\ncalculation in a unit of time using a calculator or a spreadsheet application\non a computer. Such tools have taken over the burden of lower level cognitive\ngrunt work but the human still serves the role of the expert performing higher\nlevel thinking and reasoning. Recently, however, unsupervised, deep, machine\nlearning has produced cognitive systems able to outperform humans in several\ndomains. When humans use these tools in a human cog ensemble, the cognitive\nability of the human is augmented. In some cases, even non experts can achieve,\nand even exceed, the performance of experts in a particular domain, synthetic\nexpertise. A new cognitive system, ChatGPT, has burst onto the scene during the\npast year. This paper investigates human cognitive augmentation due to using\nChatGPT by presenting the results of two experiments comparing responses\ncreated using ChatGPT with results created not using ChatGPT. We find using\nChatGPT does not always result in cognitive augmentation and does not yet\nreplace human judgement, discernment, and evaluation in certain types of tasks.\nIn fact, ChatGPT was observed to result in misleading users resulting in\nnegative cognitive augmentation.", "AI": {"tldr": "ChatGPT \u5e76\u4e0d\u603b\u80fd\u589e\u5f3a\u8ba4\u77e5\u80fd\u529b\uff0c\u6709\u65f6\u751a\u81f3\u4f1a\u8bef\u5bfc\u7528\u6237\uff0c\u56e0\u6b64\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\uff0c\u4eba\u7c7b\u7684\u5224\u65ad\u548c\u8bc4\u4f30\u4ecd\u7136\u662f\u5fc5\u4e0d\u53ef\u5c11\u7684\u3002", "motivation": "\u968f\u7740 ChatGPT \u7b49\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u7684\u51fa\u73b0\uff0c\u7814\u7a76\u4eba\u7c7b\u8ba4\u77e5\u80fd\u529b\u5982\u4f55\u88ab\u8fd9\u4e9b\u5de5\u5177\u589e\u5f3a\uff0c\u4ee5\u53ca\u5b83\u4eec\u662f\u5426\u4f1a\u53d6\u4ee3\u4eba\u7c7b\u7684\u4e13\u4e1a\u77e5\u8bc6\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u8fdb\u884c\u4e24\u9879\u5b9e\u9a8c\u6765\u6bd4\u8f83\u4f7f\u7528 ChatGPT \u548c\u4e0d\u4f7f\u7528 ChatGPT \u6240\u521b\u5efa\u7684\u56de\u5e94\uff0c\u4ee5\u7814\u7a76\u4f7f\u7528 ChatGPT \u5bf9\u4eba\u7c7b\u8ba4\u77e5\u589e\u5f3a\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528 ChatGPT \u5e76\u4e0d\u603b\u80fd\u5e26\u6765\u8ba4\u77e5\u589e\u5f3a\uff0c\u4e5f\u4e0d\u80fd\u53d6\u4ee3\u7279\u5b9a\u4efb\u52a1\u4e2d\u7684\u4eba\u7c7b\u5224\u65ad\u3001\u8fa8\u522b\u548c\u8bc4\u4f30\u3002\u6709\u65f6\uff0cChatGPT \u4f1a\u8bef\u5bfc\u7528\u6237\uff0c\u5bfc\u81f4\u8ba4\u77e5\u80fd\u529b\u4e0b\u964d\u3002", "conclusion": "\u4f7f\u7528 ChatGPT \u8fdb\u884c\u7814\u7a76\u8868\u660e\uff0c\u5b83\u5e76\u4e0d\u603b\u80fd\u589e\u5f3a\u8ba4\u77e5\u80fd\u529b\uff0c\u4e5f\u4e0d\u80fd\u53d6\u4ee3\u4eba\u7c7b\u7684\u5224\u65ad\u3001\u8fa8\u522b\u548c\u8bc4\u4f30\u3002\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5b83\u751a\u81f3\u53ef\u80fd\u8bef\u5bfc\u7528\u6237\uff0c\u5bfc\u81f4\u8d1f\u9762\u7684\u8ba4\u77e5\u589e\u5f3a\u3002"}}
{"id": "2301.13779", "title": "FLAME: A small language model for spreadsheet formulas", "url": "https://arxiv.org/abs/2301.13779", "pdf": "https://arxiv.org/pdf/2301.13779", "abs": "https://arxiv.org/abs/2301.13779", "authors": ["Harshit Joshi", "Abishai Ebenezer", "Jos\u00e9 Cambronero", "Sumit Gulwani", "Aditya Kanade", "Vu Le", "Ivan Radi\u010dek", "Gust Verbruggen"], "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": "Accepted to AAAI 2024", "summary": "Spreadsheets are a vital tool for end-user data management. Using large\nlanguage models for formula authoring assistance in these environments can be\ndifficult, as these models are expensive to train and challenging to deploy due\nto their size (up to billions of parameters). We present FLAME, a\ntransformer-based model trained exclusively on Excel formulas that leverages\ndomain insights to achieve competitive performance while being substantially\nsmaller (60M parameters) and training on two orders of magnitude less data. We\ncurate a training dataset using sketch deduplication, introduce an\nExcel-specific formula tokenizer, and use domain-specific versions of masked\nspan prediction and noisy auto-encoding as pre-training objectives. We evaluate\nFLAME on formula repair, formula completion, and similarity-based formula\nretrieval. FLAME can outperform much larger models, such as the Davinci (175B)\nand Cushman (12B) variants of Codex and CodeT5 (220M), in 10 of 14 evaluation\nsettings for the repair and completion tasks. For formula retrieval, FLAME\noutperforms CodeT5, CodeBERT, and GraphCodeBERT.", "AI": {"tldr": "FLAME is a small, efficient language model for Excel formulas that performs as well as or better than much larger models in various tasks.", "motivation": "To address the difficulties of using large language models for spreadsheet formula authoring assistance due to their size and training costs. The goal is to create a smaller, more efficient model with competitive performance.", "method": "FLAME, a transformer-based model, leverages domain insights, sketch deduplication for dataset curation, an Excel-specific formula tokenizer, and domain-specific pre-training objectives (masked span prediction and noisy auto-encoding).", "result": "FLAME outperforms much larger models like Davinci (175B), Cushman (12B), and CodeT5 (220M) in 10 out of 14 evaluation settings for formula repair and completion. It also outperforms CodeT5, CodeBERT, and GraphCodeBERT in formula retrieval.", "conclusion": "FLAME, a 60M parameter transformer model trained on Excel formulas, achieves competitive performance with much larger models in formula repair, completion, and retrieval tasks. It outperforms Davinci, Cushman, CodeT5, CodeBERT, and GraphCodeBERT in several settings."}}
{"id": "2312.09107", "title": "A Comprehensive Approach to Ensuring Quality in Spreadsheet-Based Metadata", "url": "https://arxiv.org/abs/2312.09107", "pdf": "https://arxiv.org/pdf/2312.09107", "abs": "https://arxiv.org/abs/2312.09107", "authors": ["Martin J. O'Connor", "Marcos Mart\u00ednez-Romero", "Mete Ugur Akdogan", "Josef Hardi", "Mark A. Musen"], "categories": ["cs.DL"], "comment": null, "summary": "While scientists increasingly recognize the importance of metadata in\ndescribing their data, spreadsheets remain the preferred tool for supplying\nthis information despite their limitations in ensuring compliance and quality.\nVarious tools have been developed to address these limitations, but they suffer\nfrom their own shortcomings, such as steep learning curves and limited\ncustomization. In this paper, we describe an end-to-end approach that supports\nspreadsheet-based entry of metadata while providing rigorous compliance and\nquality control. Our approach employs several key strategies, including\ncustomizable templates for defining metadata, integral support for the use of\ncontrolled terminologies when defining these templates, and an interactive\nWeb-based tool that allows users to rapidly identify and fix errors in the\nspreadsheet-based metadata they supply. We demonstrate how this approach is\nbeing deployed in a biomedical consortium to define and collect metadata about\nscientific experiments.", "AI": {"tldr": "\u4e00\u79cd\u652f\u6301\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u7684\u5143\u6570\u636e\u8f93\u5165\u7684\u7aef\u5230\u7aef\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u5b9a\u5236\u7684\u6a21\u677f\u3001\u53d7\u63a7\u672f\u8bed\u548c\u4ea4\u4e92\u5f0f Web \u5de5\u5177\uff0c\u53ef\u786e\u4fdd\u5408\u89c4\u6027\u548c\u8d28\u91cf\u3002", "motivation": "\u79d1\u5b66??\u8d8a\u6765\u8d8a\u8ba4\u8bc6\u5230\u5143\u6570\u636e\u7684\u91cd\u8981\u6027\uff0c\u4f46\u7535\u5b50\u8868\u683c\u4f5c\u4e3a\u63d0\u4f9b\u5143\u6570\u636e\u7684\u9996\u9009\u5de5\u5177\u5b58\u5728\u5c40\u9650\u6027\u3002\u73b0\u6709\u7684\u5de5\u5177\u4e5f\u5b58\u5728\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u548c\u5b9a\u5236\u6027\u6709\u9650\u7b49\u7f3a\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u652f\u6301\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u7684\u5143\u6570\u636e\u8f93\u5165\uff0c\u540c\u65f6\u63d0\u4f9b\u4e25\u683c\u7684\u5408\u89c4\u6027\u548c\u8d28\u91cf\u63a7\u5236\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u53ef\u5b9a\u5236\u7684\u6a21\u677f\u3001\u53d7\u63a7\u672f\u8bed\u4ee5\u53ca\u4ea4\u4e92\u5f0f Web \u5de5\u5177\u6765\u8bc6\u522b\u548c\u4fee\u590d\u9519\u8bef\u3002", "result": "\u8be5\u65b9\u6cd5\u6b63\u5728\u751f\u7269\u5927??\u8054\u76df\u4e2d\u90e8\u7f72\uff0c\u7528\u4e8e\u5b9a\u4e49\u548c\u6536\u96c6\u6709\u5173\u79d1\u5b66\u5b9e\u9a8c\u7684\u5143\u6570\u636e\uff0c\u4ee5\u514b\u670d\u4f20\u7edf\u7535\u5b50\u8868\u683c\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u53ef\u5b9a\u5236\u7684\u6a21\u677f\u3001\u53d7\u63a7\u672f\u8bed\u652f\u6301\u548c\u4ea4\u4e92\u5f0f\u57fa\u4e8e Web \u7684\u5de5\u5177\uff0c\u53ef\u4ee5\u652f\u6301\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u7684\u5143\u6570\u636e\u8f93\u5165\uff0c\u540c\u65f6\u63d0\u4f9b\u4e25\u683c\u7684\u5408\u89c4\u6027\u548c\u8d28\u91cf\u63a7\u5236\u3002"}}
{"id": "2312.06517", "title": "Facilitating Digital Agriculture with Simple Databases", "url": "https://arxiv.org/abs/2312.06517", "pdf": "https://arxiv.org/pdf/2312.06517", "abs": "https://arxiv.org/abs/2312.06517", "authors": ["Dennis Buckmaster", "Sami Basir", "Hanae Sakata"], "categories": ["cs.DB", "H.4; E.0; K.8"], "comment": "6 pages, 1 table, 1 figure. Journal of Extension Tools of the Trade,\n  in press", "summary": "As an on-ramp to databases, we offer several well-structured private database\ntemplates as open source resources for agriculturalists, particularly those\nwith modest spreadsheet skills. These farmer-oriented Air table databases use\nsimple data-validated forms, with the look and feel of a customized app, to\nyield operational data that is tidy, machine- and human-readable, editable, and\nexportable for analysis in other software. Such data can facilitate logistics,\nprovide contextual metadata, and improve enterprise analysis. A recorded\nworkshop explaining how to build a database for activity records is presented.\nThese resources may facilitate infusion of digital agriculture principles\nthrough Extension and structured educational programming.", "AI": {"tldr": "\u4e3a\u519c\u4e1a\u4ece\u4e1a\u8005\u63d0\u4f9b\u6613\u7528\u7684Airtable\u6570\u636e\u5e93\u6a21\u677f\uff0c\u4ee5\u6539\u5584\u6570\u636e\u7ba1\u7406\u548c\u5206\u6790\u3002", "motivation": "\u4e3a\u4e86\u5e2e\u52a9\u519c\u4e1a\u4ece\u4e1a\u8005\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u7535\u5b50\u8868\u683c\u6280\u80fd\u6709\u9650\u7684\u4eba\uff0c\u80fd\u591f\u66f4\u5bb9\u6613\u5730\u83b7\u53d6\u548c\u5229\u7528\u8fd0\u8425\u6570\u636e\uff0c\u4ee5\u4fc3\u8fdb\u7269\u6d41\u3001\u63d0\u4f9b\u5143\u6570\u636e\u548c\u6539\u8fdb\u4f01\u4e1a\u5206\u6790\u3002", "method": "\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u4e8eAirtable\u7684\u3001\u9762\u5411\u519c\u4e1a\u4ece\u4e1a\u8005\u7684\u6570\u636e\u5e93\u6a21\u677f\uff0c\u8fd9\u4e9b\u6a21\u677f\u5229\u7528\u4e86\u6570\u636e\u9a8c\u8bc1\u8868\u5355\uff0c\u5916\u89c2\u548c\u611f\u89c9\u7c7b\u4f3c\u4e8e\u5b9a\u5236\u5e94\u7528\u7a0b\u5e8f\uff0c\u4ee5\u751f\u6210\u7ed3\u6784\u5316\u6570\u636e\u3002", "result": "\u7814\u7a76\u6210\u529f\u5f00\u53d1\u5e76\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u5f00\u6e90\u7684\u3001\u7ed3\u6784\u5316\u7684\u79c1\u6709\u6570\u636e\u5e93\u6a21\u677f\uff0c\u8fd9\u4e9b\u6a21\u677f\u6613\u4e8e\u4f7f\u7528\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u8fd0\u8425\u6570\u636e\uff0c\u5e76\u914d\u5957\u63d0\u4f9b\u4e86\u76f8\u5173\u7684\u6559\u5b66\u8d44\u6e90\uff08\u5982 workshop \u5f55\u50cf\uff09\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5f00\u6e90\u7684\u3001\u7ed3\u6784\u5316\u7684\u79c1\u6709\u6570\u636e\u5e93\u6a21\u677f\uff0c\u65e8\u5728\u5e2e\u52a9\u519c\u4e1a\u4ece\u4e1a\u8005\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u7535\u5b50\u8868\u683c\u6280\u80fd\u6709\u9650\u7684\u4eba\uff0c\u66f4\u597d\u5730\u7ba1\u7406\u548c\u5206\u6790\u5176\u8fd0\u8425\u6570\u636e\u3002\u8fd9\u4e9b\u57fa\u4e8eAirtable\u7684\u6570\u636e\u5e93\u6a21\u677f\u4f7f\u7528\u7528\u6237\u53cb\u597d\u7684\u8868\u5355\uff0c\u80fd\u591f\u751f\u6210\u6574\u6d01\u3001\u6613\u4e8e\u673a\u5668\u548c\u4eba\u7c7b\u8bfb\u53d6\u3001\u53ef\u7f16\u8f91\u4e14\u53ef\u5bfc\u51fa\u7684\u6570\u636e\uff0c\u4fbf\u4e8e\u5728\u5176\u4ed6\u8f6f\u4ef6\u4e2d\u8fdb\u884c\u5206\u6790\u3002"}}
{"id": "2310.17306", "title": "FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language", "url": "https://arxiv.org/abs/2310.17306", "pdf": "https://arxiv.org/pdf/2310.17306", "abs": "https://arxiv.org/abs/2310.17306", "authors": ["Mukul Singh", "Jos\u00e9 Cambronero", "Sumit Gulwani", "Vu Le", "Carina Negreanu", "Elnaz Nouri", "Mohammad Raza", "Gust Verbruggen"], "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.PL"], "comment": "Contains inappropriately sourced conjecture of OpenAI's ChatGPT\n  parameter count from\n  www.forbes.com/sites/forbestechcouncil/2023/02/17/is-bigger-better-why-the-chatgpt-vs-gpt-3-vs-gpt-4-battle-is-just-a-family-chat,\n  a citation which was omitted. The authors do not have direct knowledge or\n  verification of this information, and relied solely on this article, which\n  may lead to public confusion", "summary": "Formatting is an important property in tables for visualization,\npresentation, and analysis. Spreadsheet software allows users to automatically\nformat their tables by writing data-dependent conditional formatting (CF)\nrules. Writing such rules is often challenging for users as it requires them to\nunderstand and implement the underlying logic. We present FormaT5, a\ntransformer-based model that can generate a CF rule given the target table and\na natural language description of the desired formatting logic. We find that\nuser descriptions for these tasks are often under-specified or ambiguous,\nmaking it harder for code generation systems to accurately learn the desired\nrule in a single step. To tackle this problem of under-specification and\nminimise argument errors, FormaT5 learns to predict placeholders though an\nabstention objective. These placeholders can then be filled by a second model\nor, when examples of rows that should be formatted are available, by a\nprogramming-by-example system. To evaluate FormaT5 on diverse and real\nscenarios, we create an extensive benchmark of 1053 CF tasks, containing\nreal-world descriptions collected from four different sources. We release our\nbenchmarks to encourage research in this area. Abstention and filling allow\nFormaT5 to outperform 8 different neural approaches on our benchmarks, both\nwith and without examples. Our results illustrate the value of building\ndomain-specific learning systems.", "AI": {"tldr": "FormaT5\u662f\u4e00\u4e2a\u80fd\u6839\u636e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210\u7535\u5b50\u8868\u683c\u6761\u4ef6\u683c\u5f0f\u5316\u89c4\u5219\u7684AI\u6a21\u578b\u3002\u5b83\u901a\u8fc7\u9884\u6d4b\u548c\u586b\u5145\u5360\u4f4d\u7b26\u6765\u89e3\u51b3\u7528\u6237\u63cf\u8ff0\u4e0d\u6e05\u6670\u7684\u95ee\u9898\uff0c\u5e76\u5728\u5305\u542b\u771f\u5b9e\u4e16\u754c\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u4e86\u5176\u4ed6AI\u65b9\u6cd5\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u8f6f\u4ef6\u4e2d\u7684\u6761\u4ef6\u683c\u5f0f\u5316\uff08CF\uff09\u529f\u80fd\u5bf9\u4e8e\u6570\u636e\u53ef\u89c6\u5316\u3001\u5448\u73b0\u548c\u5206\u6790\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7528\u6237\u7f16\u5199CF\u89c4\u5219\u5f80\u5f80\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u9700\u8981\u7406\u89e3\u548c\u5b9e\u73b0\u5e95\u5c42\u903b\u8f91\u3002\u7528\u6237\u5bf9\u8fd9\u4e9b\u4efb\u52a1\u7684\u63cf\u8ff0\u5e38\u5e38\u4e0d\u5b8c\u5168\u6216\u6a21\u68f1\u4e24\u53ef\uff0c\u4f7f\u5f97\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u96be\u4ee5\u4e00\u6b65\u51c6\u786e\u5730\u5b66\u4e60\u6240\u9700\u7684\u89c4\u5219\u3002", "method": "FormaT5\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u5b83\u63a5\u6536\u76ee\u6807\u8868\u683c\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\uff0c\u5e76\u751f\u6210\u6761\u4ef6\u683c\u5f0f\u5316\u89c4\u5219\u3002\u4e3a\u4e86\u5904\u7406\u4e0d\u5b8c\u5168\u6307\u5b9a\u548c\u6b67\u4e49\u7684\u7528\u6237\u63cf\u8ff0\uff0cFormaT5\u5b66\u4f1a\u9884\u6d4b\u5360\u4f4d\u7b26\uff0c\u7136\u540e\u7531\u7b2c\u4e8c\u4e2a\u6a21\u578b\u6216\u7f16\u7a0b\u793a\u4f8b\u7cfb\u7edf\u6765\u586b\u5199\u8fd9\u4e9b\u5360\u4f4d\u7b26\u3002", "result": "FormaT5\u901a\u8fc7\u5176\u5360\u4f4d\u7b26\u9884\u6d4b\u548c\u586b\u5145\u673a\u5236\uff0c\u5728\u5305\u542b1053\u4e2a\u6761\u4ef6\u683c\u5f0f\u5316\u4efb\u52a1\u7684\u5e7f\u6cdb\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f18\u4e8e8\u79cd\u4e0d\u540c\u7684\u795e\u7ecf\u65b9\u6cd5\uff0c\u65e0\u8bba\u662f\u5426\u6709\u793a\u4f8b\u6570\u636e\u3002", "conclusion": "FormaT5\u901a\u8fc7\u5f15\u5165\u5360\u4f4d\u7b26\u548c\u4f7f\u7528\u4e24\u79cd\u6a21\u578b\uff08\u4e00\u4e2a\u7528\u4e8e\u9884\u6d4b\u5360\u4f4d\u7b26\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u586b\u5199\u5360\u4f4d\u7b26\uff09\u6765\u89e3\u51b3\u6761\u4ef6\u683c\u5f0f\u5316\u89c4\u5219\u751f\u6210\u4e2d\u7684\u4e0d\u5b8c\u5168\u6307\u5b9a\u548c\u6b67\u4e49\u95ee\u9898\u3002\u8be5\u6a21\u578b\u5728\u5305\u542b1053\u4e2a\u6761\u4ef6\u683c\u5f0f\u5316\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f18\u4e8e8\u79cd\u4e0d\u540c\u7684\u795e\u7ecf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u6784\u5efa\u7279\u5b9a\u9886\u57df\u5b66\u4e60\u7cfb\u7edf\u7684\u4ef7\u503c\u3002"}}
{"id": "2310.20395", "title": "Spreadsheet-based Configuration of Families of Real-Time Specifications", "url": "https://arxiv.org/abs/2310.20395", "pdf": "https://arxiv.org/pdf/2310.20395", "abs": "https://arxiv.org/abs/2310.20395", "authors": ["Jos\u00e9 Proen\u00e7a", "David Pereira", "Giann Spilere Nandi", "Sina Borrami", "Jonas Melchert"], "categories": ["cs.SE"], "comment": "In Proceedings TiCSA 2023, arXiv:2310.18720", "summary": "Model checking real-time systems is complex, and requires a careful trade-off\nbetween including enough detail to be useful and not too much detail to avoid\nstate explosion. This work exploits variability of the formal model being\nanalysed and the requirements being checked, to facilitate the model-checking\nof variations of real-time specifications. This work results from the\ncollaboration between academics and Alstom, a railway company with a concrete\nuse-case, in the context of the VALU3S European project. The configuration of\nthe variability of the formal specifications is described in MS Excel\nspreadsheets with a particular structure, making it easy to use also by\ndevelopers. These spreadsheets are processed automatically by our prototype\ntool that generates instances and runs the model checker. We propose the\nextension of our previous work by exploiting analysis over valid combination of\nfeatures, while preserving the simplicity of a spreadsheet-based interface with\nthe model checker.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u9700\u6c42\u548c\u6a21\u578b\u53d8\u5f02\u6027\u6765\u7b80\u5316\u5b9e\u65f6\u7cfb\u7edf\u6a21\u578b\u68c0\u67e5\u7684\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8eExcel\u7684\u6613\u4e8e\u4f7f\u7528\u7684\u754c\u9762\u3002", "motivation": "\u6a21\u578b\u68c0\u67e5\u5b9e\u65f6\u7cfb\u7edf\u5f88\u590d\u6742\uff0c\u9700\u8981\u5728\u5305\u542b\u8db3\u591f\u7ec6\u8282\u4ee5\u4fdd\u8bc1\u6709\u7528\u6027\u548c\u907f\u514d\u72b6\u6001\u7206\u70b8\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u5f62\u5f0f\u5316\u6a21\u578b\u548c\u88ab\u68c0\u67e5\u9700\u6c42\u7684\u53d8\u5f02\u6027\uff0c\u6765\u7b80\u5316\u5b9e\u65f6\u89c4\u7ea6\u53d8\u4f53\u7684\u6a21\u578b\u68c0\u67e5\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u5177\u6709\u7279\u5b9a\u7ed3\u6784\u7684\u6570\u636e\u8868\uff08MS Excel\u7535\u5b50\u8868\u683c\uff09\u6765\u914d\u7f6e\u5f62\u5f0f\u5316\u89c4\u7ea6\u7684\u53d8\u5f02\u6027\uff0c\u7531\u539f\u578b\u5de5\u5177\u81ea\u52a8\u5904\u7406\u8fd9\u4e9b\u7535\u5b50\u8868\u683c\u4ee5\u751f\u6210\u5b9e\u4f8b\u5e76\u8fd0\u884c\u6a21\u578b\u68c0\u67e5\u5668\u3002\u672c\u7814\u7a76\u5c06\u6b64\u524d\u7684\u7814\u7a76\u8fdb\u884c\u4e86\u6269\u5c55\uff0c\u5728\u4fdd\u6301\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u7684\u754c\u9762\u7684\u7b80\u6d01\u6027\u7684\u540c\u65f6\uff0c\u5bf9\u6709\u6548\u7279\u5f81\u7ec4\u5408\u8fdb\u884c\u4e86\u5206\u6790\u3002", "result": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5bf9\u6709\u6548\u7279\u5f81\u7ec4\u5408\u7684\u5206\u6790\uff0c\u5728\u4fdd\u6301\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u754c\u9762\u7684\u7b80\u6d01\u6027\u7684\u540c\u65f6\uff0c\u6269\u5c55\u4e86\u6211\u4eec\u5148\u524d\u7684\u5de5\u4f5c\uff0c\u5e76\u4e0e\u6a21\u578b\u68c0\u67e5\u5668\u8fdb\u884c\u4e86\u4ea4\u4e92\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5728\u5f62\u5f0f\u5316\u89c4\u7ea6\u548c\u88ab\u68c0\u67e5\u7684\u9700\u6c42\u4e2d\u5229\u7528\u53d8\u5f02\u6027\uff0c\u4fc3\u8fdb\u4e86\u5b9e\u65f6\u89c4\u7ea6\u53d8\u4f53\u7684\u6a21\u578b\u68c0\u67e5\u3002"}}
{"id": "2305.19308", "title": "SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models", "url": "https://arxiv.org/abs/2305.19308", "pdf": "https://arxiv.org/pdf/2305.19308", "abs": "https://arxiv.org/abs/2305.19308", "authors": ["Hongxin Li", "Jingran Su", "Yuntao Chen", "Qing Li", "Zhaoxiang Zhang"], "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "Accepted to NeurIPS 2023", "summary": "Computer end users have spent billions of hours completing daily tasks like\ntabular data processing and project timeline scheduling. Most of these tasks\nare repetitive and error-prone, yet most end users lack the skill to automate\nthese burdensome works. With the advent of large language models (LLMs),\ndirecting software with natural language user requests become a reachable goal.\nIn this work, we propose a SheetCopilot agent that takes natural language task\nand control spreadsheet to fulfill the requirements. We propose a set of atomic\nactions as an abstraction of spreadsheet software functionalities. We further\ndesign a state machine-based task planning framework for LLMs to robustly\ninteract with spreadsheets. We curate a representative dataset containing 221\nspreadsheet control tasks and establish a fully automated evaluation pipeline\nfor rigorously benchmarking the ability of LLMs in software control tasks. Our\nSheetCopilot correctly completes 44.3\\% of tasks for a single generation,\noutperforming the strong code generation baseline by a wide margin. Our project\npage:https://sheetcopilot.github.io/.", "AI": {"tldr": "SheetCopilot uses LLMs to control spreadsheets via natural language, automating tasks and outperforming other methods.", "motivation": "Addresses the need for automating repetitive and error-prone computer end-user tasks like tabular data processing and project timeline scheduling, which most users lack the skill to do.", "method": "Proposes SheetCopilot agent, an atomic actions abstraction, and a state machine-based task planning framework for LLMs. Curates a dataset of 221 spreadsheet control tasks and an automated evaluation pipeline.", "result": "SheetCopilot correctly completes 44.3% of tasks in a single generation, significantly outperforming the code generation baseline.", "conclusion": "SheetCopilot agent can control spreadsheets with natural language, outperforming baselines."}}
{"id": "2310.17414", "title": "LEI2JSON: Schema-based Validation and Conversion of Livestock Event Information", "url": "https://arxiv.org/abs/2310.17414", "pdf": "https://arxiv.org/pdf/2310.17414", "abs": "https://arxiv.org/abs/2310.17414", "authors": ["Mahir Habib", "Muhammad Ashad Kabir", "Lihong Zheng"], "categories": ["eess.SY", "cs.SE", "cs.SY"], "comment": "20 pages, 6 figures", "summary": "Livestock producers often need help in standardising (i.e., converting and\nvalidating) their livestock event data. This article introduces a novel\nsolution, LEI2JSON (Livestock Event Information To JSON). The tool is an add-on\nfor Google Sheets, adhering to the livestock event information (LEI) schema.\nThe core objective of LEI2JSON is to provide livestock producers with an\nefficient mechanism to standardise their data, leading to substantial savings\nin time and resources. This is achieved by building the spreadsheet template\nwith the appropriate column headers, notes, and validation rules, converting\nthe spreadsheet data into JSON format, and validating the output against the\nschema. LEI2JSON facilitates the seamless storage of livestock event\ninformation locally or on Google Drive in JSON. Additionally, we have conducted\nan extensive experimental evaluation to assess the effectiveness of the tool.", "AI": {"tldr": "LEI2JSON\u662f\u4e00\u6b3eGoogle Sheets\u63d2\u4ef6\uff0c\u7528\u4e8e\u5c06\u755c\u7267\u4e8b\u4ef6\u6570\u636e\u6807\u51c6\u5316\u4e3aJSON\u683c\u5f0f\uff0c\u4fbf\u4e8e\u5b58\u50a8\u548c\u7ba1\u7406\uff0c\u8282\u7701\u65f6\u95f4\u548c\u8d44\u6e90\u3002", "motivation": "\u4e3a\u4e86\u5e2e\u52a9\u755c\u7267\u4e1a\u751f\u4ea7\u8005\u89e3\u51b3\u5728\u6807\u51c6\u5316\uff08\u8f6c\u6362\u548c\u9a8c\u8bc1\uff09\u755c\u7267\u4e8b\u4ef6\u6570\u636e\u65f6\u9047\u5230\u7684\u56f0\u96be\uff0c\u63d0\u9ad8\u6570\u636e\u5904\u7406\u6548\u7387\uff0c\u8282\u7701\u65f6\u95f4\u548c\u8d44\u6e90\u3002", "method": "LEI2JSON\u662f\u4e00\u6b3e\u4f5c\u4e3aGoogle Sheets\u63d2\u4ef6\u7684\u5de5\u5177\uff0c\u9075\u5faa\u755c\u7267\u4e8b\u4ef6\u4fe1\u606f\uff08LEI\uff09\u6a21\u5f0f\u3002\u5b83\u901a\u8fc7\u6784\u5efa\u5305\u542b\u5408\u9002\u5217\u6807\u9898\u3001\u6ce8\u91ca\u548c\u9a8c\u8bc1\u89c4\u5219\u7684\u7535\u5b50\u8868\u683c\u6a21\u677f\uff0c\u5c06\u7535\u5b50\u8868\u683c\u6570\u636e\u8f6c\u6362\u4e3aJSON\u683c\u5f0f\uff0c\u5e76\u6839\u636e\u6a21\u5f0f\u9a8c\u8bc1\u8f93\u51fa\u6765\u5b9e\u73b0\u6570\u636e\u6807\u51c6\u5316\u3002", "result": "LEI2JSON\u80fd\u591f\u6709\u6548\u5730\u6807\u51c6\u5316\u755c\u7267\u4e1a\u6570\u636e\uff0c\u5b9e\u73b0\u6570\u636e\u5230JSON\u683c\u5f0f\u7684\u8f6c\u6362\uff0c\u5e76\u652f\u6301\u672c\u5730\u6216Google Drive\u5b58\u50a8\uff0c\u5b9e\u9a8c\u8bc4\u4f30\u8bc1\u5b9e\u4e86\u8be5\u5de5\u5177\u7684\u6709\u6548\u6027\u3002", "conclusion": "LEI2JSON\u662f\u4e00\u6b3e\u5b9e\u7528\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u5c06\u755c\u7267\u4e1a\u4e8b\u4ef6\u4fe1\u606f\u6807\u51c6\u5316\u5e76\u8f6c\u6362\u4e3aJSON\u683c\u5f0f\uff0c\u65b9\u4fbf\u672c\u5730\u6216\u4e91\u7aef\u5b58\u50a8\uff0c\u5e76\u4e14\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2310.16700", "title": "Streamlining Knowledge Graph Construction with a fa\u00e7ade: The SPARQL Anything project", "url": "https://arxiv.org/abs/2310.16700", "pdf": "https://arxiv.org/pdf/2310.16700", "abs": "https://arxiv.org/abs/2310.16700", "authors": ["Luigi Asprino", "Enrico Daga", "Justin Dowdy", "Paul Mulholland", "Aldo Gangemi", "Marco Ratta"], "categories": ["cs.DB", "cs.DS"], "comment": "15 pages", "summary": "What should a data integration framework for knowledge engineers look like?\nRecent research on Knowledge Graph construction proposes the design of a\nfa\\c{c}ade, a notion borrowed from object-oriented software engineering. This\nidea is applied to SPARQL Anything, a system that allows querying heterogeneous\nresources as-if they were in RDF, in plain SPARQL 1.1, by overloading the\nSERVICE clause. SPARQL Anything supports a wide variety of file formats, from\npopular ones (CSV, JSON, XML, Spreadsheets) to others that are not supported by\nalternative solutions (Markdown, YAML, DOCx, Bibtex). Features include querying\nWeb APIs with high flexibility, parametrised queries, and chaining multiple\ntransformations into complex pipelines. In this paper, we describe the design\nrationale and software architecture of the SPARQL Anything system. We provide\nreferences to an extensive set of reusable, real-world scenarios from various\napplication domains. We report on the value-to-users of the founding\nassumptions of its design, compared to alternative solutions through a\ncommunity survey and a field report from the industry.", "AI": {"tldr": "SPARQL Anything is a system that lets you query diverse data formats (like CSV, JSON, even Word docs) using SPARQL, making data integration easier for knowledge engineers. It supports various features and has been evaluated by users.", "motivation": "To propose a data integration framework for knowledge engineers, specifically the SPARQL Anything system, which allows querying heterogeneous resources as if they were in RDF using SPARQL 1.1.", "method": "The paper analyzes the design rationale and software architecture of the SPARQL Anything system. It also references real-world scenarios and reports on user value through a community survey and an industry field report.", "result": "SPARQL Anything supports a wide variety of file formats (CSV, JSON, XML, Spreadsheets, Markdown, YAML, DOCx, Bibtex), querying Web APIs flexibly, parameterized queries, and complex pipelines. User value was assessed through a community survey and industry field report.", "conclusion": "The paper describes the design rationale and software architecture of the SPARQL Anything system, highlighting its ability to query heterogeneous resources as if they were in RDF using SPARQL 1.1. It supports a wide range of file formats and features like querying Web APIs and complex pipelines. The paper also includes real-world scenarios and user feedback from a community survey and industry field report."}}
{"id": "2310.14495", "title": "InstructExcel: A Benchmark for Natural Language Instruction in Excel", "url": "https://arxiv.org/abs/2310.14495", "pdf": "https://arxiv.org/pdf/2310.14495", "abs": "https://arxiv.org/abs/2310.14495", "authors": ["Justin Payan", "Swaroop Mishra", "Mukul Singh", "Carina Negreanu", "Christian Poelitz", "Chitta Baral", "Subhro Roy", "Rasika Chakravarthy", "Benjamin Van Durme", "Elnaz Nouri"], "categories": ["cs.CL", "cs.AI"], "comment": "Findings of EMNLP 2023, 18 pages", "summary": "With the evolution of Large Language Models (LLMs) we can solve increasingly\nmore complex NLP tasks across various domains, including spreadsheets. This\nwork investigates whether LLMs can generate code (Excel OfficeScripts, a\nTypeScript API for executing many tasks in Excel) that solves Excel specific\ntasks provided via natural language user instructions. To do so we introduce a\nnew large-scale benchmark, InstructExcel, created by leveraging the 'Automate'\nfeature in Excel to automatically generate OfficeScripts from users' actions.\nOur benchmark includes over 10k samples covering 170+ Excel operations across\n2,000 publicly available Excel spreadsheets. Experiments across various\nzero-shot and few-shot settings show that InstructExcel is a hard benchmark for\nstate of the art models like GPT-4. We observe that (1) using GPT-4 over\nGPT-3.5, (2) providing more in-context examples, and (3) dynamic prompting can\nhelp improve performance on this benchmark.", "AI": {"tldr": "A new benchmark, InstructExcel, was created to test LLMs' ability to generate Excel code from natural language. GPT-4 performs better than GPT-3.5, and improvements were seen with more examples and dynamic prompting, but it remains a challenging task.", "motivation": "Investigated whether LLMs can generate code (Excel OfficeScripts) that solves Excel-specific tasks provided via natural language user instructions.", "method": "Introduced a new large-scale benchmark, InstructExcel, by leveraging Excel's 'Automate' feature to automatically generate OfficeScripts from user actions. The benchmark includes over 10k samples covering 170+ Excel operations across 2,000 publicly available Excel spreadsheets.", "result": "Experiments in zero-shot and few-shot settings showed that InstructExcel is a challenging benchmark for GPT-4. Performance improved with GPT-4 over GPT-3.5, more in-context examples, and dynamic prompting.", "conclusion": "LLMs can generate code for Excel tasks, but state-of-the-art models like GPT-4 still struggle with this benchmark, indicating a need for further research and development."}}
{"id": "2311.10728", "title": "Improving Feedback from Automated Reviews of Student Spreadsheets", "url": "https://arxiv.org/abs/2311.10728", "pdf": "https://arxiv.org/pdf/2311.10728", "abs": "https://arxiv.org/abs/2311.10728", "authors": ["S\u00f6ren Aguirre Reid", "Frank Kammer", "Jonas-Ian Kuche", "Pia-Doreen Ritzke", "Markus Siepermann", "Max Stephan", "Armin Wagenknecht"], "categories": ["cs.CY", "D.2.0"], "comment": null, "summary": "Spreadsheets are one of the most widely used tools for end users. As a\nresult, spreadsheets such as Excel are now included in many curricula. However,\ndigital solutions for assessing spreadsheet assignments are still scarce in the\nteaching context. Therefore, we have developed an Intelligent Tutoring System\n(ITS) to review students' Excel submissions and provide individualized feedback\nautomatically. Although the lecturer only needs to provide one reference\nsolution, the students' submissions are analyzed automatically in several ways:\nvalue matching, detailed analysis of the formulas, and quality assessment of\nthe solution. To take the students' learning level into account, we have\ndeveloped feedback levels for an ITS that provide gradually more information\nabout the error by using one of the different analyses. Feedback at a higher\nlevel has been shown to lead to a higher percentage of correct submissions and\nwas also perceived as well understandable and helpful by the students.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u6559\u5b66\u4e2d\u8bc4\u4f30Excel\u4f5c\u4e1a\u7684\u6311\u6218\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\uff08ITS\uff09\uff0c\u53ef\u81ea\u52a8\u5206\u6790\u5b66\u751f\u63d0\u4ea4\u7684\u6587\u4ef6\u5e76\u63d0\u4f9b\u5206\u7ea7\u53cd\u9988\uff0c\u63d0\u9ad8\u4e86\u4f5c\u4e1a\u6b63\u786e\u7387\u5e76\u83b7\u5f97\u5b66\u751f\u597d\u8bc4\u3002", "motivation": "\u9274\u4e8e\u7535\u5b50\u8868\u683c\u662f\u7ec8\u7aef\u7528\u6237\u5e7f\u6cdb\u4f7f\u7528\u7684\u5de5\u5177\uff0c\u5e76\u4e14\u5df2\u7eb3\u5165\u8bb8\u591a\u8bfe\u7a0b\u4e2d\uff0c\u4f46\u76ee\u524d\u5728\u6559\u5b66\u73af\u5883\u4e2d\u8bc4\u4f30\u7535\u5b50\u8868\u683c\u4f5c\u4e1a\u7684\u6570\u5b57\u89e3\u51b3\u65b9\u6848\u4ecd\u7136\u5f88\u5c11\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u7cfb\u7edf\u6765\u81ea\u52a8\u8bc4\u4f30\u5b66\u751f\u7684Excel\u63d0\u4ea4\u5e76\u63d0\u4f9b\u53cd\u9988\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\uff08ITS\uff09\uff0c\u53ef\u4ee5\u81ea\u52a8\u5206\u6790\u5b66\u751f\u7684Excel\u63d0\u4ea4\u6587\u4ef6\uff0c\u5305\u62ec\u503c\u5339\u914d\u3001\u516c\u5f0f\u8be6\u7ec6\u5206\u6790\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u8bc4\u4f30\u3002\u4e3a\u8003\u8651\u5b66\u751f\u7684\u5b66\u4e60\u6c34\u5e73\uff0c\u5f00\u53d1\u4e86\u4e0d\u540c\u53cd\u9988\u7ea7\u522b\u7684ITS\uff0c\u9010\u6b65\u63d0\u4f9b\u66f4\u591a\u5173\u4e8e\u9519\u8bef\u7684\u4fe1\u606f\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u66f4\u9ad8\u7ea7\u522b\u7684\u53cd\u9988\u80fd\u591f\u63d0\u9ad8\u6b63\u786e\u63d0\u4ea4\u7684\u767e\u5206\u6bd4\uff0c\u5e76\u4e14\u5b66\u751f\u8ba4\u4e3a\u8fd9\u79cd\u53cd\u9988\u6613\u4e8e\u7406\u89e3\u4e14\u6709\u5e2e\u52a9\u3002", "conclusion": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\uff08ITS\uff09\uff0c\u53ef\u4ee5\u81ea\u52a8\u8bc4\u4f30\u5b66\u751f\u7684Excel\u4f5c\u4e1a\u5e76\u63d0\u4f9b\u4e2a\u6027\u5316\u53cd\u9988\uff0c\u63d0\u9ad8\u4e86\u4f5c\u4e1a\u7684\u6b63\u786e\u7387\uff0c\u5e76\u88ab\u5b66\u751f\u8ba4\u4e3a\u662f\u53ef\u7406\u89e3\u548c\u6709\u5e2e\u52a9\u7684\u3002"}}
{"id": "2309.02110", "title": "Wordle: A Microcosm of Life. Luck, Skill, Cheating, Loyalty, and Influence!", "url": "https://arxiv.org/abs/2309.02110", "pdf": "https://arxiv.org/pdf/2309.02110", "abs": "https://arxiv.org/abs/2309.02110", "authors": ["James P. Dilger"], "categories": ["math.HO", "cs.CL"], "comment": null, "summary": "Wordle is a popular, online word game offered by the New York Times\n(nytimes.com). Currently there are some 2 million players of the English\nversion worldwide. Players have 6 attempts to guess the daily word (target\nword) and after each attempt, the player receives color-coded information about\nthe correctness and position of each letter in the guess. After either a\nsuccessful completion of the puzzle or the final unsuccessful attempt, software\ncan assess the player's luck and skill using Information Theory and can display\ndata for the first, second, ..., sixth guesses of a random sample of all\nplayers. Recently, I discovered that the latter data is presented in a format\nthat can easily be copied and pasted into a spreadsheet. I compiled data on\nWordle players' first guesses from May 2023 - August 2023 and inferred some\ninteresting information about Wordle players. A) Every day, about 0.2-0.5% of\nplayers solve the puzzle in one attempt. Because the odds of guessing the one\nof 2,315 possible target words at random is 0.043%, this implies that 4,000 -\n10,000 players cheat by obtaining the target word outside of playing the game!\nB) At least 1/3 of the players have a favorite starting word, or cycle through\nseveral. And even though players should be aware that target words are never\nrepeated, most players appear to remain loyal to their starting word even after\nits appearance as a target word. C) On August 15, 2023, about 30,000 players\nabruptly changed their starting word, presumably based on a crossword puzzle\nclue! Wordle players can be influenced! This study goes beyond social media\npostings, surveys, and Google Trends to provide solid, quantitative evidence\nabout cheating in Wordle.", "AI": {"tldr": "Wordle \u73a9\u5bb6\u884c\u4e3a\u5206\u6790\uff1a\u53d1\u73b0\u201c\u4f5c\u5f0a\u201d\u73a9\u5bb6\u3001\u8d77\u59cb\u8bcd\u504f\u597d\u548c\u5916\u90e8\u5f71\u54cd\u3002", "motivation": "\u4e3a\u4e86\u91cf\u5316\u5206\u6790 Wordle \u73a9\u5bb6\u7684\u884c\u4e3a\uff0c\u63ed\u793a\u5982\u201c\u4f5c\u5f0a\u201d\u73a9\u5bb6\u6bd4\u4f8b\u3001\u73a9\u5bb6\u5bf9\u8d77\u59cb\u8bcd\u7684\u504f\u597d\u548c\u5fe0\u8bda\u5ea6\uff0c\u4ee5\u53ca\u73a9\u5bb6\u6613\u53d7\u5916\u90e8\u4fe1\u606f\u5f71\u54cd\u7b49\u73b0\u8c61\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u793e\u4ea4\u5a92\u4f53\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u548c\u5206\u6790 2023 \u5e74 5 \u6708\u81f3 8 \u6708\u7684 Wordle \u73a9\u5bb6\u8d77\u59cb\u731c\u6d4b\u8bcd\u6570\u636e\uff0c\u8fd0\u7528\u4fe1\u606f\u8bba\u8bc4\u4f30\u73a9\u5bb6\u7684\u8fd0\u6c14\u548c\u6280\u5de7\u3002", "result": "A) \u6bcf\u5929\u7ea6\u6709 0.2%-0.5% \u7684\u73a9\u5bb6\u5728\u4e00\u5c40\u6e38\u620f\u4e2d\u89e3\u51b3 Wordle\uff0c\u8fdc\u9ad8\u4e8e\u968f\u673a\u731c\u6d4b\u7684\u6982\u7387 (0.043%)\uff0c\u8868\u660e\u7ea6\u6709 4,000-10,000 \u540d\u73a9\u5bb6\u53ef\u80fd\u901a\u8fc7\u975e\u6b63\u5e38\u9014\u5f84\u83b7\u53d6\u7b54\u6848\u3002B) \u81f3\u5c11\u6709 1/3 \u7684\u73a9\u5bb6\u6709\u81ea\u5df1\u504f\u597d\u7684\u8d77\u59cb\u8bcd\uff0c\u5e76\u4e14\u5373\u4f7f\u5728\u76ee\u6807\u8bcd\u51fa\u73b0\u540e\uff0c\u73a9\u5bb6\u4ecd\u7136\u503e\u5411\u4e8e\u7ee7\u7eed\u4f7f\u7528\u4ed6\u4eec\u504f\u597d\u7684\u8d77\u59cb\u8bcd\u3002C) \u5728 2023 \u5e74 8 \u6708 15 \u65e5\uff0c\u7ea6\u6709 30,000 \u540d\u73a9\u5bb6\u7a81\u7136\u66f4\u6362\u4e86\u4ed6\u4eec\u7684\u8d77\u59cb\u8bcd\uff0c\u8fd9\u53ef\u80fd\u4e0e\u586b\u5b57\u6e38\u620f\u7ebf\u7d22\u6709\u5173\uff0c\u8868\u660e\u73a9\u5bb6\u7684\u884c\u4e3a\u53ef\u80fd\u53d7\u5230\u5916\u90e8\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790 Wordle \u73a9\u5bb6\u7684\u8d77\u59cb\u731c\u6d4b\u8bcd\u6570\u636e\uff0c\u53d1\u73b0\u4e86\u73a9\u5bb6\u884c\u4e3a\u7684\u51e0\u4e2a\u6709\u8da3\u6a21\u5f0f\uff0c\u5305\u62ec\u201c\u4f5c\u5f0a\u201d\u73a9\u5bb6\u7684\u6570\u91cf\u3001\u73a9\u5bb6\u5bf9\u8d77\u59cb\u8bcd\u7684\u504f\u597d\u4ee5\u53ca\u73a9\u5bb6\u6613\u53d7\u5916\u90e8\u4fe1\u606f\u5f71\u54cd\u7684\u7a0b\u5ea6\u3002"}}
{"id": "2310.01297", "title": "Co-audit: tools to help humans double-check AI-generated content", "url": "https://arxiv.org/abs/2310.01297", "pdf": "https://arxiv.org/pdf/2310.01297", "abs": "https://arxiv.org/abs/2310.01297", "authors": ["Andrew D. Gordon", "Carina Negreanu", "Jos\u00e9 Cambronero", "Rasika Chakravarthy", "Ian Drosos", "Hao Fang", "Bhaskar Mitra", "Hannah Richardson", "Advait Sarkar", "Stephanie Simmons", "Jack Williams", "Ben Zorn"], "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.PL"], "comment": null, "summary": "Users are increasingly being warned to check AI-generated content for\ncorrectness. Still, as LLMs (and other generative models) generate more complex\noutput, such as summaries, tables, or code, it becomes harder for the user to\naudit or evaluate the output for quality or correctness. Hence, we are seeing\nthe emergence of tool-assisted experiences to help the user double-check a\npiece of AI-generated content. We refer to these as co-audit tools. Co-audit\ntools complement prompt engineering techniques: one helps the user construct\nthe input prompt, while the other helps them check the output response. As a\nspecific example, this paper describes recent research on co-audit tools for\nspreadsheet computations powered by generative models. We explain why co-audit\nexperiences are essential for any application of generative AI where quality is\nimportant and errors are consequential (as is common in spreadsheet\ncomputations). We propose a preliminary list of principles for co-audit, and\noutline research challenges.", "AI": {"tldr": "Users need help checking AI-generated content, especially complex outputs like spreadsheets. This paper introduces \"co-audit tools\" that work alongside AI prompts to ensure accuracy in important applications and suggests principles for their creation.", "motivation": "As AI-generated content becomes more complex (e.g., summaries, tables, code), it is increasingly difficult for users to audit or evaluate its quality and correctness, necessitating the development of co-audit tools to assist users in double-checking AI output.", "method": "This paper describes recent research on co-audit tools for spreadsheet computations powered by generative models, explaining their necessity and proposing a preliminary list of principles and research challenges.", "result": "The paper discusses the importance of co-audit tools for generative AI applications where quality and correctness are crucial, using spreadsheet computations as a specific example. It also outlines principles for co-audit and identifies research challenges.", "conclusion": "As AI-generated content becomes more complex, tool-assisted experiences, or co-audit tools, are emerging to help users check for correctness, especially in consequential applications like spreadsheet computations. This paper explores co-audit tools for generative AI, proposes principles for their design, and outlines future research challenges."}}
{"id": "2309.00115", "title": "Excel as a Turing-complete Functional Programming Environment", "url": "https://arxiv.org/abs/2309.00115", "pdf": "https://arxiv.org/pdf/2309.00115", "abs": "https://arxiv.org/abs/2309.00115", "authors": ["Peter Bartholomew"], "categories": ["cs.SE"], "comment": "14 page, 6 figures", "summary": "Since the calculation engine of Excel was the subject of a major upgrade to\naccommodate Dynamic Arrays in 2018 there has been a series of seismic changes\nto the art of building spreadsheet solutions. This paper will show the ad-hoc\nend user practices of traditional spreadsheets can be replaced by radically\ndifferent approaches that have far more in common with formal programming. It\nis too early to guess the extent to which the new functionality will be adopted\nby the business and engineering communities and the impact that may have upon\nrisk. Nevertheless, some trends are emerging from pioneering work within the\nExcel community which we will discuss here.", "AI": {"tldr": "Excel's Dynamic Arrays upgrade enables programming-like spreadsheet development, with emerging trends and potential risks discussed.", "motivation": "To show how Excel's Dynamic Arrays upgrade has changed spreadsheet development, moving it towards formal programming, and to discuss emerging trends and potential risks.", "method": "The paper discusses emerging trends from pioneering work within the Excel community regarding the impact of the Dynamic Arrays upgrade.", "result": "Emerging trends from pioneering work within the Excel community are discussed, though the full extent of adoption and impact on risk is yet to be determined.", "conclusion": "The ad-hoc end user practices of traditional spreadsheets can be replaced by radically different approaches that have far more in common with formal programming due to the Dynamic Arrays upgrade in Excel."}}
{"id": "2309.12353", "title": "How Beaufort, Neumann and Gates met? Subject integration with spreadsheeting", "url": "https://arxiv.org/abs/2309.12353", "pdf": "https://arxiv.org/pdf/2309.12353", "abs": "https://arxiv.org/abs/2309.12353", "authors": ["Maria Csernoch", "Julia Csernoch"], "categories": ["cs.CY"], "comment": "17 pages, 14 figures", "summary": "Computational thinking should be the fourth fundamental skill, along with\nreading, writing, and arithmetic (3R). To reach the level where computational\nthinking skills, especially digital problem solving have their own schemata,\nthere is a long way to go. In the present paper, a novel approach is detailed\nto support subject integration and building digital schemata, on the well-known\nBeaufort scale. The conversion of a traditional, paper-based problem and a data\nretrieval process are presented within the frame of a Grade 8 action research\nstudy. It is found that both students content knowledge and their digital\nskills developed more efficiently than in traditional course book and\ndecontextualized digital environments. Furthermore, the method presented here\ncan be adapted to any paper-based problems whose solutions would be more\neffective in a digital environment and which offer various forms for building\nschemata both in the subject matter and informatics.", "AI": {"tldr": "\u8ba1\u7b97\u601d\u7ef4\u5e94\u6210\u4e3a\u7b2c\u56db\u9879\u57fa\u672c\u6280\u80fd\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e Beaufort \u5c3a\u5ea6\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4f20\u7edf\u7eb8\u8d28\u95ee\u9898\u548c\u6570\u636e\u68c0\u7d22\u8fc7\u7a0b\u6570\u5b57\u5316\uff0c\u4ee5\u6574\u5408\u5b66\u79d1\u5e76\u6784\u5efa\u6570\u5b57\u56fe\u5f0f\u3002\u5b9e\u9a8c\u53d1\u73b0\u8be5\u65b9\u6cd5\u80fd\u540c\u65f6\u63d0\u5347\u5b66\u751f\u7684\u5b66\u79d1\u77e5\u8bc6\u548c\u6570\u5b57\u6280\u80fd\u3002", "motivation": "\u8ba1\u7b97\u601d\u7ef4\u5e94\u8be5\u6210\u4e3a\u7ee7\u9605\u8bfb\u3001\u5199\u4f5c\u548c\u7b97\u672f\uff083R\uff09\u4e4b\u540e\u7684\u7b2c\u56db\u9879\u57fa\u672c\u6280\u80fd\u3002\u4e3a\u4e86\u8fbe\u5230\u8ba1\u7b97\u601d\u7ef4\u6280\u80fd\uff0c\u7279\u522b\u662f\u6570\u5b57\u95ee\u9898\u89e3\u51b3\u65b9\u6cd5\u62e5\u6709\u81ea\u5df1\u56fe\u5f0f\uff08schemata\uff09\u7684\u6c34\u5e73\uff0c\u8fd8\u6709\u5f88\u957f\u7684\u8def\u8981\u8d70\u3002", "method": "\u5c06\u4f20\u7edf\u3001\u57fa\u4e8e\u7eb8\u5f20\u7684\u95ee\u9898\u548c\u6570\u636e\u68c0\u7d22\u8fc7\u7a0b\u7684\u8f6c\u6362\u5728\u4e00\u4e2a\u516b\u5e74\u7ea7\u884c\u52a8\u7814\u7a76\u7814\u7a76\u7684\u6846\u67b6\u5185\u8fdb\u884c\u4ecb\u7ecd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0e\u4f20\u7edf\u7684\u6559\u79d1\u4e66\u548c\u53bb\u80cc\u666f\u5316\u7684\u6570\u5b57\u73af\u5883\u76f8\u6bd4\uff0c\u5b66\u751f\u7684\u5185\u200b\u200b\u5bb9\u77e5\u8bc6\u548c\u6570\u5b57\u6280\u80fd\u90fd\u5f97\u5230\u4e86\u66f4\u6709\u6548\u7684\u57f9\u517b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5e94\u7528\u4e8e\u4efb\u4f55\u57fa\u4e8e\u7eb8\u5f20\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u5728\u6570\u5b57\u73af\u5883\u4e2d\u66f4\u6709\u6548\uff0c\u5e76\u4e14\u4e3a\u6784\u5efa\u4e3b\u9898\u548c\u4fe1\u606f\u5b66\u7684\u4e3b\u9898\u63d0\u4f9b\u4e86\u5404\u79cd\u5f62\u5f0f\u3002"}}
{"id": "2309.00104", "title": "A Use Case-Engineering Resources Taxonomy for Analytical Spreadsheet Models", "url": "https://arxiv.org/abs/2309.00104", "pdf": "https://arxiv.org/pdf/2309.00104", "abs": "https://arxiv.org/abs/2309.00104", "authors": ["Thomas A. Grossman", "Vijay Mehrotra"], "categories": ["cs.SE"], "comment": "13 Pages, 7 Figures, 2 Tables", "summary": "This paper presents a taxonomy for analytical spreadsheet models. It\nconsiders both the use case that a spreadsheet is meant to serve, and the\nengineering resources devoted to its development. We extend a previous\nthree-type taxonomy, to identify nine types of spreadsheet models, that\nencompass the many analytical spreadsheet models seen in the literature. We\nconnect disparate research literature to distinguish between an \"analytical\nsolution\" and an \"industrial-quality analytical spreadsheet model\". We explore\nthe nature of each of the nine types, propose definitions for some, relate them\nto the literature, and hypothesize on how they might arise. The taxonomy aids\nin identifying where various spreadsheet development guidelines are most\nuseful, provides a lens for viewing spreadsheet errors and risk, and offers a\nstructure for understanding how spreadsheets change over time. This taxonomy\nopens the door to many interesting research questions, including refinements to\nitself.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e5d\u79cd\u7c7b\u578b\u5206\u6790\u6027\u7535\u5b50\u8868\u683c\u6a21\u578b\u7684\u5206\u7c7b\u6cd5\uff0c\u8003\u8651\u4e86\u7528\u4f8b\u548c\u5de5\u7a0b\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u6307\u5357\u7684\u9002\u7528\u6027\uff0c\u5ba1\u89c6\u9519\u8bef\u548c\u98ce\u9669\uff0c\u5e76\u7406\u89e3\u6a21\u578b\u7684\u6f14\u53d8\u3002", "motivation": "\u4e3a\u4e86\u5bf9\u5206\u6790\u6027\u7535\u5b50\u8868\u683c\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u533a\u5206\u201c\u5206\u6790\u6027\u89e3\u51b3\u65b9\u6848\u201d\u548c\u201c\u5de5\u4e1a\u7ea7\u5206\u6790\u6027\u7535\u5b50\u8868\u683c\u6a21\u578b\u201d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5206\u6790\u6027\u7535\u5b50\u8868\u683c\u6a21\u578b\u7684\u5206\u7c7b\u6cd5\uff0c\u6269\u5c55\u4e86\u5148\u524d\u7684\u4e00\u4e2a\u4e09\u7c7b\u578b\u5206\u7c7b\u6cd5\uff0c\u8bc6\u522b\u4e86\u4e5d\u79cd\u7c7b\u578b\u7684\u7535\u5b50\u8868\u683c\u6a21\u578b\uff0c\u6db5\u76d6\u4e86\u6587\u732e\u4e2d\u53ef\u89c1\u7684\u8bb8\u591a\u5206\u6790\u6027\u7535\u5b50\u8868\u683c\u6a21\u578b\u3002\u8be5\u5206\u7c7b\u6cd5\u6709\u52a9\u4e8e\u8bc6\u522b\u5404\u79cd\u7535\u5b50\u8868\u683c\u5f00\u53d1\u6307\u5357\u7684\u9002\u7528\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5ba1\u89c6\u7535\u5b50\u8868\u683c\u9519\u8bef\u548c\u98ce\u9669\u7684\u89c6\u89d2\uff0c\u5e76\u4e3a\u7406\u89e3\u7535\u5b50\u8868\u683c\u5982\u4f55\u968f\u65f6\u95f4\u53d8\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u3002", "result": "\u8bc6\u522b\u4e86\u4e5d\u79cd\u7c7b\u578b\u7684\u7535\u5b50\u8868\u683c\u6a21\u578b\uff0c\u5e76\u63a2\u8ba8\u4e86\u6bcf\u79cd\u7c7b\u578b\u7684\u6027\u8d28\uff0c\u4e3a\u5176\u4e2d\u4e00\u4e9b\u63d0\u51fa\u4e86\u5b9a\u4e49\uff0c\u5c06\u5b83\u4eec\u4e0e\u6587\u732e\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u63a8\u6d4b\u4e86\u5b83\u4eec\u53ef\u80fd\u5982\u4f55\u4ea7\u751f\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u6709\u52a9\u4e8e\u8bc6\u522b\u5404\u79cd\u7535\u5b50\u8868\u683c\u5f00\u53d1\u6307\u5357\u7684\u9002\u7528\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5ba1\u89c6\u7535\u5b50\u8868\u683c\u9519\u8bef\u548c\u98ce\u9669\u7684\u89c6\u89d2\uff0c\u5e76\u4e3a\u7406\u89e3\u7535\u5b50\u8868\u683c\u5982\u4f55\u968f\u65f6\u95f4\u53d8\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u3002\u8be5\u5206\u7c7b\u6cd5\u4e3a\u5305\u62ec\u5176\u81ea\u8eab\u5728\u5185\u7684\u8bb8\u591a\u6709\u8da3\u7684 \u0936\u094b\u0927 \u092a\u094d\u0930\u0936\u094d\u0928 m\u1edf c\u1eeda."}}
{"id": "2309.00095", "title": "Experimenting with ChatGPT for Spreadsheet Formula Generation: Evidence of Risk in AI Generated Spreadsheets", "url": "https://arxiv.org/abs/2309.00095", "pdf": "https://arxiv.org/pdf/2309.00095", "abs": "https://arxiv.org/abs/2309.00095", "authors": ["Simon Thorne"], "categories": ["cs.SE"], "comment": "15 Pages", "summary": "Large Language Models (LLM) have become sophisticated enough that complex\ncomputer programs can be created through interpretation of plain English\nsentences and implemented in a variety of modern languages such as Python, Java\nScript, C++ and Spreadsheets. These tools are powerful and relatively accurate\nand therefore provide broad access to computer programming regardless of the\nbackground or knowledge of the individual using them. This paper presents a\nseries of experiments with ChatGPT to explore the tool's ability to produce\nvalid spreadsheet formulae and related computational outputs in situations\nwhere ChatGPT has to deduce, infer and problem solve the answer. The results\nshow that in certain circumstances, ChatGPT can produce correct spreadsheet\nformulae with correct reasoning, deduction and inference. However, when\ninformation is limited, uncertain or the problem is too complex, the accuracy\nof ChatGPT breaks down as does its ability to reason, infer and deduce. This\ncan also result in false statements and \"hallucinations\" that all subvert the\nprocess of creating spreadsheet formulae.", "AI": {"tldr": "ChatGPT \u5728\u751f\u6210\u7535\u5b50\u8868\u683c\u516c\u5f0f\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u9762\u5bf9\u590d\u6742\u6216\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u65f6\uff0c\u5176\u51c6\u786e\u6027\u548c\u63a8\u7406\u80fd\u529b\u4f1a\u4e0b\u964d\uff0c\u5e76\u53ef\u80fd\u51fa\u73b0\u9519\u8bef\u6216\u201c\u5e7b\u89c9\u201d\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5df2\u8db3\u591f\u6210\u719f\uff0c\u53ef\u4ee5\u901a\u8fc7\u89e3\u91ca\u666e\u901a\u82f1\u8bed\u53e5\u5b50\u6765\u521b\u5efa\u590d\u6742\u7684\u8ba1\u7b97\u673a\u7a0b\u5e8f\uff0c\u5e76\u80fd\u7528\u591a\u79cd\u73b0\u4ee3\u8bed\u8a00\uff08\u5982 Python\u3001Java Script\u3001C++ \u548c\u7535\u5b50\u8868\u683c\uff09\u5b9e\u73b0\u3002\u8fd9\u4e9b\u5de5\u5177\u529f\u80fd\u5f3a\u5927\u4e14\u76f8\u5bf9\u51c6\u786e\uff0c\u56e0\u6b64\u65e0\u8bba\u4f7f\u7528\u8005\u80cc\u666f\u6216\u77e5\u8bc6\u5982\u4f55\uff0c\u90fd\u80fd\u5e7f\u6cdb\u5730\u8fdb\u884c\u8ba1\u7b97\u673a\u7f16\u7a0b\u3002", "method": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u4f7f\u7528 ChatGPT \u7684\u5b9e\u9a8c\uff0c\u4ee5\u63a2\u7d22\u8be5\u5de5\u5177\u5728\u9700\u8981\u63a8\u65ad\u3001\u63a8\u7406\u548c\u89e3\u51b3\u95ee\u9898\u7684\u82f1\u8bed\u53e5\u5b50\u89e3\u8bfb\u540e\uff0c\u751f\u6210\u6709\u6548\u7684\u7535\u5b50\u8868\u683c\u516c\u5f0f\u548c\u76f8\u5173\u8ba1\u7b97\u8f93\u51fa\u7684\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0cChatGPT \u80fd\u591f\u901a\u8fc7\u6b63\u786e\u7684\u63a8\u7406\u3001\u63a8\u65ad\u548c\u8fdb\u884c\uff0c\u751f\u6210\u6b63\u786e\u7684\u7535\u5b50\u8868\u683c\u516c\u5f0f\u3002", "conclusion": "\u5f53\u4fe1\u606f\u6709\u9650\u3001\u4e0d\u786e\u5b9a\u6216\u95ee\u9898\u8fc7\u4e8e\u590d\u6742\u65f6\uff0cChatGPT \u7684\u51c6\u786e\u6027\u4f1a\u4e0b\u964d\uff0c\u5176\u63a8\u7406\u3001\u63a8\u65ad\u548c\u6f14\u7ece\u80fd\u529b\u4e5f\u4f1a\u968f\u4e4b\u4e0b\u964d\u3002\u8fd9\u4e5f\u4f1a\u5bfc\u81f4\u9519\u8bef\u7684\u9648\u8ff0\u548c\u201c\u5e7b\u89c9\u201d\uff0c\u7834\u574f\u4e86\u521b\u5efa\u7535\u5b50\u8868\u683c\u516c\u5f0f\u7684\u8fc7\u7a0b\u3002"}}
{"id": "2308.14784", "title": "Generating tabular datasets under differential privacy", "url": "https://arxiv.org/abs/2308.14784", "pdf": "https://arxiv.org/pdf/2308.14784", "abs": "https://arxiv.org/abs/2308.14784", "authors": ["Gianluca Truda"], "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DB", "I.2.6"], "comment": null, "summary": "Machine Learning (ML) is accelerating progress across fields and industries,\nbut relies on accessible and high-quality training data. Some of the most\nimportant datasets are found in biomedical and financial domains in the form of\nspreadsheets and relational databases. But this tabular data is often sensitive\nin nature. Synthetic data generation offers the potential to unlock sensitive\ndata, but generative models tend to memorise and regurgitate training data,\nwhich undermines the privacy goal. To remedy this, researchers have\nincorporated the mathematical framework of Differential Privacy (DP) into the\ntraining process of deep neural networks. But this creates a trade-off between\nthe quality and privacy of the resulting data. Generative Adversarial Networks\n(GANs) are the dominant paradigm for synthesising tabular data under DP, but\nsuffer from unstable adversarial training and mode collapse, which are\nexacerbated by the privacy constraints and challenging tabular data modality.\nThis work optimises the quality-privacy trade-off of generative models,\nproducing higher quality tabular datasets with the same privacy guarantees. We\nimplement novel end-to-end models that leverage attention mechanisms to learn\nreversible tabular representations. We also introduce TableDiffusion, the first\ndifferentially-private diffusion model for tabular data synthesis. Our\nexperiments show that TableDiffusion produces higher-fidelity synthetic\ndatasets, avoids the mode collapse problem, and achieves state-of-the-art\nperformance on privatised tabular data synthesis. By implementing\nTableDiffusion to predict the added noise, we enabled it to bypass the\nchallenges of reconstructing mixed-type tabular data. Overall, the diffusion\nparadigm proves vastly more data and privacy efficient than the adversarial\nparadigm, due to augmented re-use of each data batch and a smoother iterative\ntraining process.", "AI": {"tldr": "Sensitive tabular data (like financial/biomedical) needs private synthetic generation. Existing methods (GANs+DP) have privacy-quality trade-offs and training issues. This paper introduces TableDiffusion, a new differentially-private diffusion model for tabular data, which improves data quality, privacy efficiency, and avoids common problems, outperforming previous methods.", "motivation": "Existing generative models for sensitive tabular data, like GANs, suffer from memorization, undermining privacy. Differentially private methods create a quality-privacy trade-off, and GANs specifically face unstable training and mode collapse, which are worsened by privacy constraints and the nature of tabular data.", "method": "This work optimizes the quality-privacy trade-off of generative models by implementing novel end-to-end models that leverage attention mechanisms for reversible tabular representations. It also introduces TableDiffusion, a differentially-private diffusion model for tabular data synthesis, which bypasses challenges in reconstructing mixed-type tabular data by predicting added noise.", "result": "TableDiffusion produces higher-fidelity synthetic datasets, avoids mode collapse, and achieves state-of-the-art performance on privatised tabular data synthesis. The diffusion model is also shown to be vastly more data and privacy efficient than the adversarial paradigm.", "conclusion": "The diffusion paradigm is more data and privacy efficient than the adversarial paradigm for synthetic tabular data generation, achieving state-of-the-art performance."}}
{"id": "2308.10922", "title": "DataVinci: Learning Syntactic and Semantic String Repairs", "url": "https://arxiv.org/abs/2308.10922", "pdf": "https://arxiv.org/pdf/2308.10922", "abs": "https://arxiv.org/abs/2308.10922", "authors": ["Mukul Singh", "Jos\u00e9 Cambronero", "Sumit Gulwani", "Vu Le", "Carina Negreanu", "Gust Verbruggen"], "categories": ["cs.DB", "cs.AI"], "comment": "13 pages", "summary": "String data is common in real-world datasets: 67.6% of values in a sample of\n1.8 million real Excel spreadsheets from the web were represented as text.\nSystems that successfully clean such string data can have a significant impact\non real users. While prior work has explored errors in string data, proposed\napproaches have often been limited to error detection or require that the user\nprovide annotations, examples, or constraints to fix the errors. Furthermore,\nthese systems have focused independently on syntactic errors or semantic errors\nin strings, but ignore that strings often contain both syntactic and semantic\nsubstrings. We introduce DataVinci, a fully unsupervised string data error\ndetection and repair system. DataVinci learns regular-expression-based patterns\nthat cover a majority of values in a column and reports values that do not\nsatisfy such patterns as data errors. DataVinci can automatically derive edits\nto the data error based on the majority patterns and constraints learned over\nother columns without the need for further user interaction. To handle strings\nwith both syntactic and semantic substrings, DataVinci uses an LLM to abstract\n(and re-concretize) portions of strings that are semantic prior to learning\nmajority patterns and deriving edits. Because not all data can result in\nmajority patterns, DataVinci leverages execution information from an existing\nprogram (which reads the target data) to identify and correct data repairs that\nwould not otherwise be identified. DataVinci outperforms 7 baselines on both\nerror detection and repair when evaluated on 4 existing and new benchmarks.", "AI": {"tldr": "DataVinci \u662f\u4e00\u4e2a\u65e0\u76d1\u7763\u7684\u5b57\u7b26\u4e32\u6570\u636e\u6e05\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b66\u4e60\u6b63\u5219\u8868\u8fbe\u5f0f\u6a21\u5f0f\u548c\u5229\u7528 LLM \u6765\u5904\u7406\u590d\u6742\u7684\u5b57\u7b26\u4e32\uff0c\u4ece\u800c\u68c0\u6d4b\u548c\u4fee\u590d\u8bed\u6cd5\u548c\u8bed\u4e49\u9519\u8bef\u3002", "motivation": "\u5b57\u7b26\u4e32\u6570\u636e\u5728\u771f\u5b9e\u6570\u636e\u96c6\u5f88\u5e38\u89c1\uff0c\u4f46\u73b0\u6709\u7684\u5b57\u7b26\u4e32\u6570\u636e\u6e05\u7406\u65b9\u6cd5\u901a\u5e38\u4ec5\u9650\u4e8e\u9519\u8bef\u68c0\u6d4b\uff0c\u6216\u8005\u9700\u8981\u7528\u6237\u63d0\u4f9b\u6ce8\u91ca\u3001\u793a\u4f8b\u6216\u7ea6\u675f\u6765\u4fee\u590d\u9519\u8bef\u3002\u6b64\u5916\uff0c\u73b0\u6709\u7cfb\u7edf\u72ec\u7acb\u5730\u5173\u6ce8\u5b57\u7b26\u4e32\u4e2d\u7684\u8bed\u6cd5\u9519\u8bef\u6216\u8bed\u4e49\u9519\u8bef\uff0c\u800c\u5ffd\u7565\u4e86\u5b57\u7b26\u4e32\u901a\u5e38\u5305\u542b\u8bed\u6cd5\u548c\u8bed\u4e49\u5b50\u5b57\u7b26\u4e32\u7684\u7ec4\u5408\u3002", "method": "DataVinci \u662f\u4e00\u4e2a\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u5b57\u7b26\u4e32\u6570\u636e\u9519\u8bef\u68c0\u6d4b\u548c\u4fee\u590d\u7cfb\u7edf\u3002\u5b83\u5b66\u4e60\u57fa\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u6a21\u5f0f\uff0c\u8986\u76d6\u5217\u4e2d\u7684\u5927\u90e8\u5206\u503c\uff0c\u5e76\u5c06\u4e0d\u6ee1\u8db3\u8fd9\u4e9b\u6a21\u5f0f\u7684\u503c\u62a5\u544a\u4e3a\u6570\u636e\u9519\u8bef\u3002DataVinci \u53ef\u4ee5\u6839\u636e\u5728\u5176\u4ed6\u5217\u4e0a\u5b66\u4e60\u5230\u7684\u4e3b\u8981\u6a21\u5f0f\u548c\u7ea6\u675f\u81ea\u52a8\u63a8\u5bfc\u51fa\u6570\u636e\u9519\u8bef\u7684\u7f16\u8f91\uff0c\u65e0\u9700\u7528\u6237\u8fdb\u4e00\u6b65\u4ea4\u4e92\u3002\u4e3a\u4e86\u5904\u7406\u540c\u65f6\u5305\u542b\u8bed\u6cd5\u548c\u8bed\u4e49\u5b50\u5b57\u7b26\u4e32\u7684\u5b57\u7b26\u4e32\uff0cDataVinci \u4f7f\u7528 LLM \u5728\u5b66\u4e60\u4e3b\u8981\u6a21\u5f0f\u548c\u63a8\u5bfc\u7f16\u8f91\u4e4b\u524d\u62bd\u8c61\uff08\u548c\u91cd\u65b0\u5177\u4f53\u5316\uff09\u5b57\u7b26\u4e32\u7684\u90e8\u5206\u3002\u7531\u4e8e\u5e76\u975e\u6240\u6709\u6570\u636e\u90fd\u80fd\u4ea7\u751f\u4e3b\u8981\u6a21\u5f0f\uff0cDataVinci \u5229\u7528\u73b0\u6709\u7a0b\u5e8f\uff08\u8bfb\u53d6\u76ee\u6807\u6570\u636e\uff09\u7684\u6267\u884c\u4fe1\u606f\u6765\u8bc6\u522b\u548c\u7ea0\u6b63\u5426\u5219\u65e0\u6cd5\u8bc6\u522b\u7684\u6570\u636e\u4fee\u590d\u3002", "result": "DataVinci \u5b66\u4e60\u57fa\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u6a21\u5f0f\u6765\u8bc6\u522b\u548c\u4fee\u590d\u5b57\u7b26\u4e32\u6570\u636e\u4e2d\u7684\u9519\u8bef\uff0c\u80fd\u591f\u5904\u7406\u540c\u65f6\u5305\u542b\u8bed\u6cd5\u548c\u8bed\u4e49\u5b50\u5b57\u7b26\u4e32\u7684\u5b57\u7b26\u4e32\uff0c\u5e76\u5229\u7528\u7a0b\u5e8f\u6267\u884c\u4fe1\u606f\u6765\u6539\u8fdb\u4fee\u590d\u3002\u5728\u8bc4\u4f30\u4e2d\uff0cDataVinci \u5728\u9519\u8bef\u68c0\u6d4b\u548c\u4fee\u590d\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e 7 \u4e2a\u57fa\u7ebf\u3002", "conclusion": "DataVinci \u5728\u9519\u8bef\u68c0\u6d4b\u548c\u4fee\u590d\u65b9\u9762\u4f18\u4e8e 7 \u4e2a\u57fa\u7ebf\uff0c\u5e76\u5728 4 \u4e2a\u73b0\u6709\u548c\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002"}}
{"id": "2308.07357", "title": "Demonstration of CORNET: A System For Learning Spreadsheet Formatting Rules By Example", "url": "https://arxiv.org/abs/2308.07357", "pdf": "https://arxiv.org/pdf/2308.07357", "abs": "https://arxiv.org/abs/2308.07357", "authors": ["Mukul Singh", "Jose Cambronero", "Sumit Gulwani", "Vu Le", "Carina Negreanu", "Gust Verbruggen"], "categories": ["cs.SE", "cs.AI", "cs.DB"], "comment": "4 Pages, VLDB 2023 Demonstration Track", "summary": "Data management and analysis tasks are often carried out using spreadsheet\nsoftware. A popular feature in most spreadsheet platforms is the ability to\ndefine data-dependent formatting rules. These rules can express actions such as\n\"color red all entries in a column that are negative\" or \"bold all rows not\ncontaining error or failure.\" Unfortunately, users who want to exercise this\nfunctionality need to manually write these conditional formatting (CF) rules.\nWe introduce CORNET, a system that automatically learns such conditional\nformatting rules from user examples. CORNET takes inspiration from inductive\nprogram synthesis and combines symbolic rule enumeration, based on\nsemi-supervised clustering and iterative decision tree learning, with a neural\nranker to produce accurate conditional formatting rules. In this demonstration,\nwe show CORNET in action as a simple add-in to Microsoft Excel. After the user\nprovides one or two formatted cells as examples, CORNET generates formatting\nrule suggestions for the user to apply to the spreadsheet.", "AI": {"tldr": "CORNET is an Excel add-in that learns formatting rules from examples, automating a tedious manual process.", "motivation": "Users manually write conditional formatting rules in spreadsheet software, which can be tedious. CORNET aims to automate this process.", "method": "CORNET combines symbolic rule enumeration (using semi-supervised clustering and iterative decision tree learning) with a neural ranker to generate accurate conditional formatting rules.", "result": "CORNET generates formatting rule suggestions based on user-provided examples, demonstrated as an Excel add-in.", "conclusion": "CORNET can automatically learn conditional formatting rules from user examples, reducing manual effort for users."}}
{"id": "2307.14565", "title": "Auto-Tables: Synthesizing Multi-Step Transformations to Relationalize Tables without Using Examples", "url": "https://arxiv.org/abs/2307.14565", "pdf": "https://arxiv.org/pdf/2307.14565", "abs": "https://arxiv.org/abs/2307.14565", "authors": ["Peng Li", "Yeye He", "Cong Yan", "Yue Wang", "Surajit Chaudhuri"], "categories": ["cs.DB", "cs.LG"], "comment": "full version of a paper accepted to VLDB 2023", "summary": "Relational tables, where each row corresponds to an entity and each column\ncorresponds to an attribute, have been the standard for tables in relational\ndatabases. However, such a standard cannot be taken for granted when dealing\nwith tables \"in the wild\". Our survey of real spreadsheet-tables and web-tables\nshows that over 30% of such tables do not conform to the relational standard,\nfor which complex table-restructuring transformations are needed before these\ntables can be queried easily using SQL-based analytics tools. Unfortunately,\nthe required transformations are non-trivial to program, which has become a\nsubstantial pain point for technical and non-technical users alike, as\nevidenced by large numbers of forum questions in places like StackOverflow and\nExcel/Power-BI/Tableau forums.\n  We develop an Auto-Tables system that can automatically synthesize pipelines\nwith multi-step transformations (in Python or other languages), to transform\nnon-relational tables into standard relational forms for downstream analytics,\nobviating the need for users to manually program transformations. We compile an\nextensive benchmark for this new task, by collecting 244 real test cases from\nuser spreadsheets and online forums. Our evaluation suggests that Auto-Tables\ncan successfully synthesize transformations for over 70% of test cases at\ninteractive speeds, without requiring any input from users, making this an\neffective tool for both technical and non-technical users to prepare data for\nanalytics.", "AI": {"tldr": "Auto-Tables\u7cfb\u7edf\u901a\u8fc7\u81ea\u52a8\u5408\u6210\u8f6c\u6362\u6d41\u7a0b\uff0c\u89e3\u51b3\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u8868\u683c\u6570\u636e\u4e0d\u89c4\u8303\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u51c6\u5907\u6548\u7387\u3002", "motivation": "\u5728\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u7535\u5b50\u8868\u683c\u548c\u7f51\u9875\u8868\u683c\u65f6\uff0c\u8d85\u8fc730%\u7684\u8868\u683c\u4e0d\u7b26\u5408\u5173\u7cfb\u578b\u6807\u51c6\uff0c\u9700\u8981\u590d\u6742\u7684\u8868\u683c\u91cd\u7ec4\u8f6c\u6362\u624d\u80fd\u65b9\u4fbf\u5730\u4f7f\u7528SQL\u7b49\u5de5\u5177\u8fdb\u884c\u67e5\u8be2\u3002\u624b\u52a8\u7f16\u7a0b\u8f6c\u6362\u56f0\u96be\uff0c\u7ed9\u6280\u672f\u548c\u975e\u6280\u672f\u7528\u6237\u5e26\u6765\u4e86\u56f0\u6270\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aAuto-Tables\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u53ef\u4ee5\u81ea\u52a8\u5408\u6210\u5305\u542b\u591a\u6b65\u9aa4\u8f6c\u6362\uff08\u7528Python\u6216\u5176\u4ed6\u8bed\u8a00\uff09\u7684\u6d41\u7a0b\uff0c\u5c06\u975e\u5173\u7cfb\u578b\u8868\u683c\u8f6c\u6362\u4e3a\u6807\u51c6\u7684 and relational forms\uff0c\u7528\u4e8e\u4e0b\u6e38\u5206\u6790\u3002", "result": "Auto-Tables\u7cfb\u7edf\u53ef\u4ee5\u4e3a70%\u4ee5\u4e0a\u7684\u6d4b\u8bd5\u7528\u4f8b\u6210\u529f\u5408\u6210\u8f6c\u6362\uff0c\u5e76\u4e14\u901f\u5ea6\u5feb\uff0c\u65e0\u9700\u7528\u6237\u8f93\u5165\u3002", "conclusion": "Auto-Tables\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u5408\u6210\u8f6c\u6362\u6d41\u7a0b\uff0c\u5904\u7406\u8d85\u8fc770%\u7684\u975e\u5173\u7cfb\u578b\u8868\u683c\uff0c\u5e76\u4e14\u901f\u5ea6\u5feb\uff0c\u65e0\u9700\u7528\u6237\u5e72\u9884\uff0c\u80fd\u591f\u6709\u6548\u5e2e\u52a9\u6280\u672f\u548c\u975e\u6280\u672f\u7528\u6237\u51c6\u5907\u6570\u636e\u7528\u4e8e\u5206\u6790\u3002"}}
{"id": "2309.12317", "title": "Using a Catenary Trajectory to Reduce Wellbore Friction in Horizontal Extended Reach Drilling", "url": "https://arxiv.org/abs/2309.12317", "pdf": "https://arxiv.org/pdf/2309.12317", "abs": "https://arxiv.org/abs/2309.12317", "authors": ["Vu Nguyen"], "categories": ["cs.RO"], "comment": null, "summary": "Wellbore friction is one of the biggest concerns when drilling due to its\nrelation to the total cost. The catenary concept was introduced to reduce\nwellbore friction, but it requires detailed analyses. This project would fill\nthis gap. A catenary shape is simply the natural shape of a rope, chain, or\ndrill string. The drill string will then hang freely inside the wellbore.\nPerfectly, there should be no contact between the hole and the string, and thus\nno friction. Torque and drag should be minimized this way. A case study is\nintroduced to examine the outcome between Catenary Trajectory Design and\ntraditional 2D Arc design. The calculation procedure of Catenary Trajectory and\n2D Arc Design can be found in an MS Excel spreadsheet which is easy to use and\nreliable for designing catenary well trajectories for extended-reach wells.", "AI": {"tldr": "Catenary concept can reduce wellbore friction, needs more analysis. A case study compares it to 2D Arc design.", "motivation": "Wellbore friction is a major concern in drilling due to its impact on cost. The catenary concept was introduced to mitigate this, but it lacks detailed analysis.", "method": "A case study comparing Catenary Trajectory Design with traditional 2D Arc design was introduced. Calculation procedures for both methods are available in an MS Excel spreadsheet.", "result": "The project aims to examine the outcome of Catenary Trajectory Design versus traditional 2D Arc design in reducing wellbore friction.", "conclusion": "The catenary concept can potentially reduce wellbore friction, but requires further detailed analysis and design."}}
{"id": "2306.12850", "title": "Don't Treat the Symptom, Find the Cause! Efficient Artificial-Intelligence Methods for (Interactive) Debugging", "url": "https://arxiv.org/abs/2306.12850", "pdf": "https://arxiv.org/pdf/2306.12850", "abs": "https://arxiv.org/abs/2306.12850", "authors": ["Patrick Rodler"], "categories": ["cs.AI", "cs.DM", "cs.LO"], "comment": "Habilitation Thesis", "summary": "In the modern world, we are permanently using, leveraging, interacting with,\nand relying upon systems of ever higher sophistication, ranging from our cars,\nrecommender systems in e-commerce, and networks when we go online, to\nintegrated circuits when using our PCs and smartphones, the power grid to\nensure our energy supply, security-critical software when accessing our bank\naccounts, and spreadsheets for financial planning and decision making. The\ncomplexity of these systems coupled with our high dependency on them implies\nboth a non-negligible likelihood of system failures, and a high potential that\nsuch failures have significant negative effects on our everyday life. For that\nreason, it is a vital requirement to keep the harm of emerging failures to a\nminimum, which means minimizing the system downtime as well as the cost of\nsystem repair. This is where model-based diagnosis comes into play.\n  Model-based diagnosis is a principled, domain-independent approach that can\nbe generally applied to troubleshoot systems of a wide variety of types,\nincluding all the ones mentioned above, and many more. It exploits and\norchestrates i.a. techniques for knowledge representation, automated reasoning,\nheuristic problem solving, intelligent search, optimization, stochastics,\nstatistics, decision making under uncertainty, machine learning, as well as\ncalculus, combinatorics and set theory to detect, localize, and fix faults in\nabnormally behaving systems.\n  In this thesis, we will give an introduction to the topic of model-based\ndiagnosis, point out the major challenges in the field, and discuss a selection\nof approaches from our research addressing these issues.", "AI": {"tldr": "Model-based diagnosis is a versatile troubleshooting approach for complex modern systems, aiming to minimize failure impact by detecting, localizing, and fixing faults using a combination of AI and mathematical techniques. This thesis explores its challenges and solutions.", "motivation": "Modern systems are highly sophisticated and essential for everyday life, but their complexity leads to potential failures with significant negative impacts. Therefore, minimizing downtime and repair costs through effective fault management is crucial.", "method": "Model-based diagnosis leverages various techniques like knowledge representation, automated reasoning, heuristic problem solving, intelligent search, optimization, stochastics, statistics, decision making under uncertainty, machine learning, calculus, combinatorics, and set theory to detect, localize, and fix faults in malfunctioning systems.", "result": "The thesis provides an overview of model-based diagnosis and presents research-based solutions to major challenges in the field.", "conclusion": "The thesis introduces model-based diagnosis, highlights key challenges, and discusses research approaches to address them."}}
{"id": "2304.07303", "title": "Smart Metro: Deep Learning Approaches to Forecasting the MRT Line 3 Ridership", "url": "https://arxiv.org/abs/2304.07303", "pdf": "https://arxiv.org/pdf/2304.07303", "abs": "https://arxiv.org/abs/2304.07303", "authors": ["Jayrald Empino", "Jean Allyson Junsay", "Mary Grace Verzon", "Mideth Abisado", "Shekinah Lor Huyo-a", "Gabriel Avelino Sampedro"], "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "Since its establishment in 1999, the Metro Rail Transit Line 3 (MRT3) has\nserved as a transportation option for numerous passengers in Metro Manila,\nPhilippines. The Philippine government's transportation department records more\nthan a thousand people using the MRT3 daily and forecasting the daily passenger\ncount may be rather challenging. The MRT3's daily ridership fluctuates owing to\nvariables such as holidays, working days, and other unexpected issues.\nCommuters do not know how many other commuters are on their route on a given\nday, which may hinder their ability to plan an efficient itinerary. Currently,\nthe DOTr depends on spreadsheets containing historical data, which might be\nchallenging to examine. This study presents a time series prediction of daily\ntraffic to anticipate future attendance at a particular station on specific\ndays.", "AI": {"tldr": "This study uses time series prediction to forecast MRT3 daily ridership, addressing challenges faced by commuters and the DOTr due to fluctuating passenger numbers and outdated data management methods.", "motivation": "The daily ridership of MRT3 fluctuates due to various factors, making it challenging for commuters to plan their itineraries and for the DOTr to analyze historical data, which is currently managed using spreadsheets.", "method": "Time series prediction", "result": "The study aims to provide a more efficient way to forecast daily traffic and anticipate future attendance at MRT3 stations.", "conclusion": "This study presents a time series prediction of daily traffic to anticipate future attendance at a particular station on specific days."}}
{"id": "2304.06597", "title": "\"What It Wants Me To Say\": Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models", "url": "https://arxiv.org/abs/2304.06597", "pdf": "https://arxiv.org/pdf/2304.06597", "abs": "https://arxiv.org/abs/2304.06597", "authors": ["Michael Xieyang Liu", "Advait Sarkar", "Carina Negreanu", "Ben Zorn", "Jack Williams", "Neil Toronto", "Andrew D. Gordon"], "categories": ["cs.HC"], "comment": null, "summary": "Code-generating large language models translate natural language into code.\nHowever, only a small portion of the infinite space of naturalistic utterances\nis effective at guiding code generation. For non-expert end-user programmers,\nlearning this is the challenge of abstraction matching. We examine this\nchallenge in the specific context of data analysis in spreadsheets, in a system\nthat maps the users natural language query to Python code using the Codex\ngenerator, executes the code, and shows the result. We propose grounded\nabstraction matching, which bridges the abstraction gap by translating the code\nback into a systematic and predictable naturalistic utterance. In a\nbetween-subjects, think-aloud study (n=24), we compare grounded abstraction\nmatching to an ungrounded alternative based on previously established query\nframing principles. We find that the grounded approach improves end-users'\nunderstanding of the scope and capabilities of the code-generating model, and\nthe kind of language needed to use it effectively.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4ee3\u7801\u751f\u6210\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u62bd\u8c61\u5339\u914d\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4ee3\u7801\u8f6c\u6362\u56de\u81ea\u7136\u8bed\u8a00\u7684\u57fa\u7840\u6027\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u4ee3\u7801\u751f\u6210\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u975e\u4e13\u5bb6\u6700\u7ec8\u7528\u6237\u7a0b\u5e8f\u5458\u5728\u7406\u89e3\u548c\u6709\u6548\u5f15\u5bfc\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u6311\u6218\uff0c\u5373\u62bd\u8c61\u5339\u914d\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u201c\u57fa\u7840\u6027\u62bd\u8c61\u5339\u914d\u201d\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u4ee3\u7801\u8f6c\u6362\u56de\u7cfb\u7edf\u5316\u3001\u53ef\u9884\u6d4b\u7684\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\uff0c\u5e76\u4e0e\u57fa\u4e8e\u5148\u524d\u65e2\u5b9a\u67e5\u8be2\u8868\u8ff0\u539f\u5219\u7684\u975e\u57fa\u7840\u6027\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u57fa\u7840\u6027\u65b9\u6cd5\u80fd\u591f\u6539\u8fdb\u6700\u7ec8\u7528\u6237\u5bf9\u4ee3\u7801\u751f\u6210\u6a21\u578b\u8303\u56f4\u548c\u80fd\u529b\u7684\u7406\u89e3\uff0c\u4ee5\u53ca\u6709\u6548\u4f7f\u7528\u8be5\u6a21\u578b\u6240\u9700\u7684\u8bed\u8a00\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u4ee3\u7801\u8f6c\u6362\u56de\u7cfb\u7edf\u5316\u3001\u53ef\u9884\u6d4b\u7684\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u6765\u5f25\u5408\u62bd\u8c61\u9e3f\u6c9f\uff0c\u4ece\u800c\u6539\u8fdb\u4e86\u6700\u7ec8\u7528\u6237\u5bf9\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u7406\u89e3\uff0c\u4ee5\u53ca\u4f7f\u7528\u5b83\u6240\u9700\u7684\u8bed\u8a00\u3002"}}
{"id": "2210.13619", "title": "A Simpler Method for Understanding Emergency Shelter Access Patterns", "url": "https://arxiv.org/abs/2210.13619", "pdf": "https://arxiv.org/pdf/2210.13619", "abs": "https://arxiv.org/abs/2210.13619", "authors": ["Geoffrey G. Messier"], "categories": ["cs.CY"], "comment": null, "summary": "The Simplified Access Metric (SAM) is a new approach for characterizing\nemergency shelter access patterns as a measure of shelter client vulnerability.\nThe goal of SAM is to provide shelter operators with an intuitive way to\nunderstand access patterns that can be implemented by non-technical staff using\nspreadsheet operations. Client data from a large North American shelter will be\nused to demonstrate that SAM produces similar results to traditional\ntransitional, episodic and chronic client cluster analysis. Since SAM requires\nless data than cluster analysis, it is also able to generate a real time\npicture of how shelter access patterns are affected by external factors.\nTimelines generated from nine years of shelter client data using SAM\ndemonstrate the impact of Housing First programming and the COVID-19 lockdown\non how people access shelter. Finally, SAM allows shelter staff to move beyond\nassigning transitional, episodic and chronic labels and instead use the \"soft\"\noutput of SAM directly as a measure of vulnerability.", "AI": {"tldr": "SAM\u662f\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8868\u5f81\u7d27\u6025\u5e87\u62a4\u6240\u7684\u8bbf\u95ee\u6a21\u5f0f\uff0c\u4ee5\u8861\u91cf\u5ba2\u6237\u7684\u8106\u5f31\u6027\u3002SAM\u6613\u4e8e\u4f7f\u7528\uff0c\u6240\u9700\u6570\u636e\u5c11\uff0c\u5e76\u4e14\u53ef\u4ee5\u5b9e\u65f6\u663e\u793a\u5916\u90e8\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "motivation": "\u4e3a\u5e87\u62a4\u6240\u8fd0\u8425\u5546\u63d0\u4f9b\u4e00\u79cd\u76f4\u89c2\u7684\u3001\u53ef\u7531\u975e\u6280\u672f\u4eba\u5458\u901a\u8fc7\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u5b9e\u73b0\u7684\u8bbf\u95ee\u6a21\u5f0f\u7406\u89e3\u65b9\u5f0f\uff0c\u4ee5\u8861\u91cf\u5ba2\u6237\u7684\u8106\u5f31\u6027\u3002", "method": "\u4f7f\u7528\u7b80\u5316\u63a5\u5165\u6307\u6807\uff08SAM\uff09\u5bf9\u5e87\u62a4\u6240\u5ba2\u6237\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u4ee5\u8868\u5f81\u7d27\u6025\u5e87\u62a4\u6240\u7684\u8bbf\u95ee\u6a21\u5f0f\u3002", "result": "SAM\u751f\u6210\u7684\u7ed3\u679c\u4e0e\u4f20\u7edf\u7684\u5ba2\u6237\u805a\u7c7b\u5206\u6790\u76f8\u4f3c\uff0c\u4f46\u6240\u9700\u6570\u636e\u66f4\u5c11\uff0c\u80fd\u591f\u5b9e\u65f6\u663e\u793a\u5916\u90e8\u56e0\u7d20\u5bf9\u8bbf\u95ee\u6a21\u5f0f\u7684\u5f71\u54cd\uff0c\u5e76\u80fd\u76f4\u63a5\u4f5c\u4e3a\u8106\u5f31\u6027\u6307\u6807\u3002", "conclusion": "SAM\u662f\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8868\u5f81\u7d27\u6025\u5e87\u62a4\u6240\u7684\u8bbf\u95ee\u6a21\u5f0f\uff0c\u4f5c\u4e3a\u8861\u91cf\u5e87\u62a4\u6240\u5ba2\u6237\u8106\u5f31\u6027\u7684\u6307\u6807\u3002SAM\u65e8\u5728\u4e3a\u5e87\u62a4\u6240\u8fd0\u8425\u5546\u63d0\u4f9b\u4e00\u79cd\u76f4\u89c2\u7684\u8bbf\u95ee\u6a21\u5f0f\u7406\u89e3\u65b9\u5f0f\uff0c\u8be5\u65b9\u5f0f\u53ef\u7531\u975e\u6280\u672f\u4eba\u5458\u901a\u8fc7\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u6765\u5b9e\u73b0\u3002SAM\u751f\u6210\u7684\u7ed3\u679c\u4e0e\u4f20\u7edf\u7684\u8fc7\u6e21\u6027\u3001\u5076\u53d1\u6027\u548c\u6162\u6027\u5ba2\u6237\u805a\u7c7b\u5206\u6790\u76f8\u4f3c\uff0c\u4f46\u6240\u9700\u6570\u636e\u66f4\u5c11\uff0c\u56e0\u6b64\u80fd\u591f\u5b9e\u65f6\u663e\u793a\u5916\u90e8\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u5e87\u62a4\u6240\u7684\u8bbf\u95ee\u6a21\u5f0f\u3002SAM\u8fd8\u53ef\u4ee5\u8ba9\u5e87\u62a4\u6240\u5de5\u4f5c\u4eba\u5458\u8d85\u8d8a\u4f20\u7edf\u7684\u5ba2\u6237\u5206\u7c7b\u6807\u7b7e\uff0c\u76f4\u63a5\u4f7f\u7528SAM\u7684\u201c\u8f6f\u201d\u8f93\u51fa\u4f5c\u4e3a\u8106\u5f31\u6027\u6307\u6807\u3002"}}
{"id": "2302.05482", "title": "Efficient and Compact Spreadsheet Formula Graphs", "url": "https://arxiv.org/abs/2302.05482", "pdf": "https://arxiv.org/pdf/2302.05482", "abs": "https://arxiv.org/abs/2302.05482", "authors": ["Dixin Tang", "Fanchao Chen", "Christopher De Leon", "Tana Wattanawaroon", "Jeaseok Yun", "Srinivasan Seshadri", "Aditya G. Parameswaran"], "categories": ["cs.DB"], "comment": null, "summary": "Spreadsheets are one of the most popular data analysis tools, wherein users\ncan express computation as formulae alongside data. The ensuing dependencies\nare tracked as formula graphs. Efficiently querying and maintaining these\nformula graphs is critical for interactivity across multiple settings.\nUnfortunately, formula graphs are often large and complex such that querying\nand maintaining them is time-consuming, reducing interactivity. We propose\nTACO, a framework for efficiently compressing formula graphs, thereby reducing\nthe time for querying and maintenance. The efficiency of TACO stems from a key\nspreadsheet property: tabular locality, which means that cells close to each\nother are likely to have similar formula structures. We leverage four such\ntabular locality-based patterns and develop algorithms for compressing formula\ngraphs using these patterns, directly querying the compressed graph without\ndecompression, and incrementally maintaining the graph during updates. We\nintegrate TACO into an open-source spreadsheet system and show that TACO can\nsignificantly reduce formula graph sizes. For querying formula graphs, the\nspeedups of TACO over a baseline implemented in our framework and a commercial\nspreadsheet system are up to 34,972x and 632x, respectively.", "AI": {"tldr": "TACO\u901a\u8fc7\u5229\u7528\u8868\u5c40\u90e8\u6027\u6765\u538b\u7f29\u7535\u5b50\u8868\u683c\u7684\u516c\u5f0f\u56fe\uff0c\u4ece\u800c\u52a0\u901f\u67e5\u8be2\u548c\u7ef4\u62a4\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u662f\u6d41\u884c\u7684\u6570\u636e\u5206\u6790\u5de5\u5177\uff0c\u5176\u4e2d\u516c\u5f0f\u56fe\u7684\u67e5\u8be2\u548c\u7ef4\u62a4\u6548\u7387\u5bf9\u7528\u6237\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u516c\u5f0f\u56fe\u901a\u5e38\u5e9e\u5927\u800c\u590d\u6742\uff0c\u5bfc\u81f4\u67e5\u8be2\u548c\u7ef4\u62a4\u8017\u65f6\uff0c\u964d\u4f4e\u4e86\u4ea4\u4e92\u6027\u3002", "method": "TACO\u6846\u67b6\u5229\u7528\u4e86\u7535\u5b50\u8868\u683c\u7684\u201c\u8868\u5c40\u90e8\u6027\u201d\u5c5e\u6027\uff0c\u5373\u76f8\u90bb\u5355\u5143\u683c\u7684\u516c\u5f0f\u7ed3\u6784\u76f8\u4f3c\u3002\u5b83\u8bc6\u522b\u5e76\u5229\u7528\u4e86\u56db\u79cd\u57fa\u4e8e\u8868\u5c40\u90e8\u6027\u7684\u6a21\u5f0f\u6765\u538b\u7f29\u516c\u5f0f\u56fe\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u89e3\u538b\u7684\u60c5\u51b5\u4e0b\u76f4\u63a5\u67e5\u8be2\u538b\u7f29\u540e\u7684\u56fe\uff0c\u5e76\u80fd\u589e\u91cf\u7ef4\u62a4\u56fe\u7ed3\u6784\u3002", "result": "TACO\u6846\u67b6\u80fd\u591f\u663e\u8457\u51cf\u5c0f\u516c\u5f0f\u56fe\u7684\u5927\u5c0f\uff0c\u5e76\u5728\u67e5\u8be2\u516c\u5f0f\u56fe\u65f6\u63d0\u4f9b\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u76f8\u6bd4\u57fa\u7ebf\u548c\u5546\u4e1a\u7cfb\u7edf\u5206\u522b\u6709\u9ad8\u8fbe34,972\u500d\u548c632\u500d\u7684\u52a0\u901f\u3002", "conclusion": "TACO\u6846\u67b6\u80fd\u591f\u663e\u8457\u51cf\u5c0f\u516c\u5f0f\u56fe\u7684\u5927\u5c0f\uff0c\u5e76\u5728\u67e5\u8be2\u516c\u5f0f\u56fe\u65f6\u63d0\u4f9b\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u76f8\u6bd4\u57fa\u7ebf\u548c\u5546\u4e1a\u7cfb\u7edf\u5206\u522b\u6709\u9ad8\u8fbe34,972\u500d\u548c632\u500d\u7684\u52a0\u901f\u3002"}}
{"id": "2301.11964", "title": "Adversarial Networks and Machine Learning for File Classification", "url": "https://arxiv.org/abs/2301.11964", "pdf": "https://arxiv.org/pdf/2301.11964", "abs": "https://arxiv.org/abs/2301.11964", "authors": ["Ken St. Germain", "Josh Angichiodo"], "categories": ["cs.LG"], "comment": null, "summary": "Correctly identifying the type of file under examination is a critical part\nof a forensic investigation. The file type alone suggests the embedded content,\nsuch as a picture, video, manuscript, spreadsheet, etc. In cases where a system\nowner might desire to keep their files inaccessible or file type concealed, we\npropose using an adversarially-trained machine learning neural network to\ndetermine a file's true type even if the extension or file header is obfuscated\nto complicate its discovery. Our semi-supervised generative adversarial network\n(SGAN) achieved 97.6% accuracy in classifying files across 11 different types.\nWe also compared our network against a traditional standalone neural network\nand three other machine learning algorithms. The adversarially-trained network\nproved to be the most precise file classifier especially in scenarios with few\nsupervised samples available. Our implementation of a file classifier using an\nSGAN is implemented on GitHub (https://ksaintg.github.io/SGAN-File-Classier).", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u5bf9\u6297\u6027\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\uff08SGAN\uff09\uff0c\u6211\u4eec\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u6587\u4ef6\u7c7b\u578b\uff0c\u5373\u4f7f\u6587\u4ef6\u6269\u5c55\u540d\u6216\u6587\u4ef6\u5934\u88ab\u6df7\u6dc6\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe97.6%\u3002", "motivation": "\u6587\u4ef6\u7c7b\u578b\u7684\u6b63\u786e\u8bc6\u522b\u5728\u53d6\u8bc1\u8c03\u67e5\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u653b\u51fb\u8005\u53ef\u80fd\u8bd5\u56fe\u901a\u8fc7\u6df7\u6dc6\u6587\u4ef6\u6269\u5c55\u540d\u6216\u6587\u4ef6\u5934\u6765\u9690\u85cf\u6587\u4ef6\u7c7b\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u534a\u76d1\u7763\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08SGAN\uff09\u7684\u6587\u4ef6\u7c7b\u578b\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u8bad\u7ec3\u6765\u514b\u670d\u6587\u4ef6\u6269\u5c55\u540d\u6216\u6587\u4ef6\u5934\u88ab\u6df7\u6dc6\u7684\u95ee\u9898\u3002", "result": "\u572811\u79cd\u4e0d\u540c\u6587\u4ef6\u7c7b\u578b\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cSGAN\u6a21\u578b\u8fbe\u5230\u4e8697.6%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u5728\u76d1\u7763\u6837\u672c\u8f83\u5c11\u7684\u60c5\u51b5\u4e0b\u6bd4\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u548c\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u66f4\u7cbe\u786e\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684\u57fa\u4e8eSGAN\u7684\u6587\u4ef6\u5206\u7c7b\u5668\u5728\u6587\u4ef6\u7c7b\u578b\u8bc6\u522b\u65b9\u9762\u5c55\u73b0\u4e86\u9ad8\u7cbe\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u76d1\u7763\u6837\u672c\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2208.06032", "title": "CORNET: Learning Table Formatting Rules By Example", "url": "https://arxiv.org/abs/2208.06032", "pdf": "https://arxiv.org/pdf/2208.06032", "abs": "https://arxiv.org/abs/2208.06032", "authors": ["Mukul Singh", "Jos\u00e9 Cambronero", "Sumit Gulwani", "Vu Le", "Carina Negreanu", "Mohammad Raza", "Gust Verbruggen"], "categories": ["cs.AI", "cs.DB", "cs.SE"], "comment": "12 pages content, 2 pages references", "summary": "Spreadsheets are widely used for table manipulation and presentation.\nStylistic formatting of these tables is an important property for both\npresentation and analysis. As a result, popular spreadsheet software, such as\nExcel, supports automatically formatting tables based on rules. Unfortunately,\nwriting such formatting rules can be challenging for users as it requires\nknowledge of the underlying rule language and data logic. We present CORNET, a\nsystem that tackles the novel problem of automatically learning such formatting\nrules from user examples in the form of formatted cells. CORNET takes\ninspiration from advances in inductive programming and combines symbolic rule\nenumeration with a neural ranker to learn conditional formatting rules. To\nmotivate and evaluate our approach, we extracted tables with over 450K unique\nformatting rules from a corpus of over 1.8M real worksheets. Since we are the\nfirst to introduce conditional formatting, we compare CORNET to a wide range of\nsymbolic and neural baselines adapted from related domains. Our results show\nthat CORNET accurately learns rules across varying evaluation setups.\nAdditionally, we show that CORNET finds shorter rules than those that a user\nhas written and discovers rules in spreadsheets that users have manually\nformatted.", "AI": {"tldr": "CORNET learns spreadsheet formatting rules from examples, outperforming other methods and finding more concise rules.", "motivation": "Writing stylistic formatting rules in spreadsheets is challenging for users due to the need for knowledge of rule languages and data logic. CORNET aims to automate this process.", "method": "CORNET combines symbolic rule enumeration with a neural ranker to learn conditional formatting rules from user-provided examples (formatted cells).", "result": "CORNET accurately learns rules, finds shorter rules than users write, and discovers rules in manually formatted spreadsheets. It was evaluated on over 450K unique formatting rules extracted from 1.8M worksheets.", "conclusion": "CORNET can accurately learn formatting rules across different evaluation settings, discover shorter rules than human-written ones, and identify rules in manually formatted spreadsheets."}}
{"id": "2211.04128", "title": "Active Learning with Tabular Language Models", "url": "https://arxiv.org/abs/2211.04128", "pdf": "https://arxiv.org/pdf/2211.04128", "abs": "https://arxiv.org/abs/2211.04128", "authors": ["Martin Ringsquandl", "Aneta Koleva"], "categories": ["cs.CL"], "comment": "8 pages", "summary": "Despite recent advancements in tabular language model research, real-world\napplications are still challenging. In industry, there is an abundance of\ntables found in spreadsheets, but acquisition of substantial amounts of labels\nis expensive, since only experts can annotate the often highly technical and\ndomain-specific tables. Active learning could potentially reduce labeling\ncosts, however, so far there are no works related to active learning in\nconjunction with tabular language models. In this paper we investigate\ndifferent acquisition functions in a real-world industrial tabular language\nmodel use case for sub-cell named entity recognition. Our results show that\ncell-level acquisition functions with built-in diversity can significantly\nreduce the labeling effort, while enforced table diversity is detrimental. We\nfurther see open fundamental questions concerning computational efficiency and\nthe perspective of human annotators.", "AI": {"tldr": "\u5728\u8868\u683c\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u5177\u6709\u5185\u7f6e\u591a\u6837\u6027\u7684\u7ec6\u80de\u7ea7\u91c7\u96c6\u51fd\u6570\u53ef\u4ee5\u51cf\u5c11\u6807\u6ce8\u6210\u672c\uff0c\u4f46\u5f3a\u5236\u8868\u591a\u6837\u6027\u4f1a\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002", "motivation": "\u5728\u8868\u683c\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u53d6\u5f97\u8fdb\u5c55\u7684\u80cc\u666f\u4e0b\uff0c\u73b0\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u4ecd\u7136\u9762\u4e34\u6311\u6218\uff0c\u4e3b\u8981\u5728\u4e8e\u83b7\u53d6\u5927\u91cf\u6807\u7b7e\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u4e3a\u53ea\u6709\u4e13\u5bb6\u624d\u80fd\u6807\u6ce8\u6280\u672f\u6027\u5f3a\u3001\u9886\u57df\u7279\u5b9a\u7684\u8868\u683c\u3002\u4e3b\u52a8\u5b66\u4e60\u6709\u671b\u964d\u4f4e\u6807\u6ce8\u6210\u672c\uff0c\u4f46\u76ee\u524d\u5c1a\u672a\u6709\u5c06\u4e3b\u52a8\u5b66\u4e60\u4e0e\u8868\u683c\u8bed\u8a00\u6a21\u578b\u76f8\u7ed3\u5408\u7684\u7814\u7a76\u3002", "method": "\u7814\u7a76\u4e86\u5728\u771f\u5b9e\u4e16\u754c\u7684\u5de5\u4e1a\u8868\u683c\u8bed\u8a00\u6a21\u578b\u7528\u4f8b\u4e2d\uff0c\u7528\u4e8e\u4e9a\u5355\u5143\u683c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u4e0d\u540c\u91c7\u96c6\u51fd\u6570\u3002", "result": "\u7ec6\u80de\u7ea7\u91c7\u96c6\u51fd\u6570\u5185\u7f6e\u591a\u6837\u6027\u53ef\u663e\u8457\u964d\u4f4e\u6807\u6ce8\u5de5\u4f5c\u91cf\uff0c\u800c\u5f3a\u5236\u8868\u591a\u6837\u6027\u5219\u9002\u5f97\u5176\u53cd\u3002\u6b64\u5916\uff0c\u8ba1\u7b97\u6548\u7387\u548c\u4eba\u7c7b\u6807\u6ce8\u8005\u7684\u89c6\u89d2\u7b49\u65b9\u9762\u4ecd\u5b58\u5728\u4e00\u4e9b\u6839\u672c\u6027\u95ee\u9898\u6709\u5f85\u89e3\u51b3\u3002", "conclusion": "\u7ec6\u80de\u7ea7\u91c7\u96c6\u51fd\u6570\u5185\u7f6e\u591a\u6837\u6027\u53ef\u663e\u8457\u964d\u4f4e\u6807\u6ce8\u5de5\u4f5c\u91cf\uff0c\u800c\u5f3a\u5236\u8868\u591a\u6837\u6027\u5219\u9002\u5f97\u5176\u53cd\u3002"}}
{"id": "2211.06333", "title": "Excel Spreadsheet Analyzer", "url": "https://arxiv.org/abs/2211.06333", "pdf": "https://arxiv.org/pdf/2211.06333", "abs": "https://arxiv.org/abs/2211.06333", "authors": ["Amir Nassereldine", "Patrick Chen", "Jinjun Xiong"], "categories": ["cs.SE", "cs.PL"], "comment": "10 pages, 9 figures", "summary": "Spreadsheets are widely used in various fields to do large numerical\nanalysis. While several companies have relied on spreadsheets for decades, data\nscientists are going in the direction of using scientific programming languages\nsuch as python to do their data analysis due to the support, community, and\nvast amount of libraries. While using python to analyze a company's\nspreadsheets, some information such as the formulas and dependencies of a cell\nare lost. We propose a tool that creates an abstract intermediate\nrepresentation (AIR) of a spreadsheet. This representation facilitates the\ntransfer from spreadsheets into scientific programming languages while\npreserving inter-dependency information about data. In addition to that, we\nbuild a python library on top of our tool to perform some data analysis in\npython.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u5efa\u7535\u5b50\u8868\u683c\u62bd\u8c61\u4e2d\u95f4\u8868\u793a\uff08AIR\uff09\u7684\u5de5\u5177\uff0c\u4ee5\u89e3\u51b3\u4ece\u7535\u5b50\u8868\u683c\u8fc1\u79fb\u5230Python\u7b49\u79d1\u5b66\u7f16\u7a0b\u8bed\u8a00\u65f6\u4e22\u5931\u4f9d\u8d56\u5173\u7cfb\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2aPython\u5e93\u7528\u4e8e\u6570\u636e\u5206\u6790\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u88ab\u5e7f\u6cdb\u7528\u4e8e\u8fdb\u884c\u5927\u91cf\u7684\u6570\u503c\u5206\u6790\uff0c\u4f46\u8bb8\u591a\u516c\u53f8\u5728\u6570\u636e\u5206\u6790\u65b9\u9762\uff0c\u7279\u522b\u662f\u6570\u636e\u79d1\u5b66\u9886\u57df\uff0c\u6b63\u9010\u6e10\u8f6c\u5411\u4f7f\u7528Python\u7b49\u79d1\u5b66\u7f16\u7a0b\u8bed\u8a00\u3002\u7136\u800c\uff0c\u5728\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\uff0c\u4e00\u4e9b\u4fe1\u606f\uff0c\u5982\u5355\u5143\u683c\u7684\u516c\u5f0f\u548c\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f1a\u4e22\u5931\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u521b\u5efa\u7535\u5b50\u8868\u683c\u62bd\u8c61\u4e2d\u95f4\u8868\u793a\uff08AIR\uff09\u7684\u5de5\u5177\uff0c\u4ee5\u65b9\u4fbf\u5c06\u7535\u5b50\u8868\u683c\u8fc1\u79fb\u5230\u79d1\u5b66\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Python\uff09\u5e76\u4fdd\u7559\u6570\u636e\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u4fe1\u606f\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u7535\u5b50\u8868\u683c\u7684\u62bd\u8c61\u4e2d\u95f4\u8868\u793a\uff08AIR\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8be5AIR\u7684Python\u5e93\uff0c\u4ee5\u5728Python\u4e2d\u8fdb\u884c\u6570\u636e\u5206\u6790\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u6570\u636e\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u4fe1\u606f\u3002", "conclusion": "\u8be5\u5de5\u5177\u80fd\u591f\u4fdd\u7559\u7535\u5b50\u8868\u683c\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u4fe1\u606f\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2aPython\u5e93\uff0c\u7528\u4e8e\u5728Python\u4e2d\u8fdb\u884c\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2210.09928", "title": "Team OS's System for Dialogue Robot Competition 2022", "url": "https://arxiv.org/abs/2210.09928", "pdf": "https://arxiv.org/pdf/2210.09928", "abs": "https://arxiv.org/abs/2210.09928", "authors": ["Yuki Kubo", "Ryo Yanagimoto", "Hayato Futase", "Mikio Nakano", "Zhaojie Luo", "Kazunori Komatani"], "categories": ["cs.HC"], "comment": "This paper is part of the proceedings of the Dialogue Robot\n  Competition 2022", "summary": "This paper describes our dialogue robot system, OSbot, developed for Dialogue\nRobot Competition 2022. The dialogue flow is based on state transitions\ndescribed manually and the transition conditions use the results of keyword\nextraction and sentiment analysis. The transitions can be easily viewed and\nedited by managing them on a spreadsheet. The keyword extraction is based on\nnamed entity extraction and our predefined keyword set. The sentiment analysis\nis text-based and uses SVM, which was trained with the multimodal dialogue\ncorpus Hazumi. We quickly checked and edited a dialogue flow by using a logging\nfunction. In the competition's preliminary round, our system ended up in third\nplace.", "AI": {"tldr": "OSbot\u662f\u4e00\u4e2a\u57fa\u4e8e\u72b6\u6001\u8f6c\u6362\u7684\u5bf9\u8bdd\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u5173\u952e\u8bcd\u63d0\u53d6\u548c\u60c5\u611f\u5206\u6790\u63a7\u5236\u5bf9\u8bdd\u6d41\uff0c\u5e76\u57282022\u5e74\u5bf9\u8bdd\u673a\u5668\u4eba\u7ade\u8d5b\u9884\u8d5b\u4e2d\u83b7\u5f97\u7b2c\u4e09\u540d\u3002", "motivation": "\u4e3a\u5bf9\u8bdd\u673a\u5668\u4eba\u7ade\u8d5b2022\u5f00\u53d1OSbot\u5bf9\u8bdd\u673a\u5668\u4eba\u7cfb\u7edf\u3002", "method": "\u8be5\u5bf9\u8bdd\u7cfb\u7edf\u7684\u5bf9\u8bdd\u6d41\u57fa\u4e8e\u624b\u52a8\u63cf\u8ff0\u7684\u72b6\u6001\u8f6c\u6362\uff0c\u5e76\u7ed3\u5408\u4e86\u5173\u952e\u8bcd\u63d0\u53d6\u548c\u60c5\u611f\u5206\u6790\u7684\u7ed3\u679c\u3002\u5173\u952e\u8bcd\u63d0\u53d6\u57fa\u4e8e\u547d\u540d\u5b9e\u4f53\u63d0\u53d6\u548c\u9884\u5b9a\u4e49\u5173\u952e\u8bcd\u96c6\uff0c\u60c5\u611f\u5206\u6790\u5219\u57fa\u4e8e\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\uff0c\u5e76\u4f7f\u7528\u591a\u6a21\u6001\u5bf9\u8bdd\u8bed\u6599\u5e93Hazumi\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u901a\u8fc7\u65e5\u5fd7\u529f\u80fd\u5feb\u901f\u68c0\u67e5\u548c\u7f16\u8f91\u5bf9\u8bdd\u6d41\uff0c\u5e76\u5728\u6bd4\u8d5b\u9884\u8d5b\u4e2d\u53d6\u5f97\u7b2c\u4e09\u540d\u7684\u6210\u7ee9\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u6bd4\u8d5b\u9884\u8d5b\u4e2d\u83b7\u5f97\u7b2c\u4e09\u540d\u3002"}}
{"id": "2210.09162", "title": "Table-To-Text generation and pre-training with TabT5", "url": "https://arxiv.org/abs/2210.09162", "pdf": "https://arxiv.org/pdf/2210.09162", "abs": "https://arxiv.org/abs/2210.09162", "authors": ["Ewa Andrejczuk", "Julian Martin Eisenschlos", "Francesco Piccinno", "Syrine Krichene", "Yasemin Altun"], "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to Findings of EMNLP 2022", "summary": "Encoder-only transformer models have been successfully applied to different\ntable understanding tasks, as in TAPAS (Herzig et al., 2020). A major\nlimitation of these architectures is that they are constrained to\nclassification-like tasks such as cell selection or entailment detection. We\npresent TABT5, an encoder-decoder model that generates natural language text\nbased on tables and textual inputs. TABT5 overcomes the encoder-only limitation\nby incorporating a decoder component and leverages the input structure with\ntable specific embeddings and pre-training. TABT5 achieves new state-of-the-art\nresults on several domains, including spreadsheet formula prediction with a 15%\nincrease in sequence accuracy, QA with a 2.5% increase in sequence accuracy and\ndata-to-text generation with a 2.5% increase in BLEU.", "AI": {"tldr": "TABT5 \u662f\u4e00\u4e2a encoder-decoder \u6a21\u578b\uff0c\u5728\u8868\u683c\u7406\u89e3\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u65b0\u7684 state-of-the-art \u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684 encoder-only transformer \u6a21\u578b\u5728\u8868\u683c\u7406\u89e3\u4efb\u52a1\u4e2d\u53d7\u5230\u9650\u5236\uff0c\u4e3b\u8981\u7528\u4e8e\u7c7b\u4f3c\u5206\u7c7b\u7684\u4efb\u52a1\u3002", "method": "TABT5 \u662f\u4e00\u4e2a encoder-decoder \u6a21\u578b\uff0c\u5b83\u901a\u8fc7\u7ed3\u5408\u89e3\u7801\u5668\u7ec4\u4ef6\u3001\u4f7f\u7528\u7279\u5b9a\u4e8e\u8868\u7684\u5d4c\u5165\u548c\u9884\u8bad\u7ec3\u6765\u514b\u670d encoder-only \u67b6\u6784\u7684\u9650\u5236\u3002", "result": "TABT5 \u5728\u7535\u5b50\u8868\u683c\u516c\u5f0f\u9884\u6d4b\u65b9\u9762\u63d0\u9ad8\u4e86 15% \u7684\u5e8f\u5217\u51c6\u786e\u7387\uff0c\u5728\u95ee\u7b54\u65b9\u9762\u63d0\u9ad8\u4e86 2.5% \u7684\u5e8f\u5217\u51c6\u786e\u7387\uff0c\u5728\u6570\u636e\u5230\u6587\u672c\u751f\u6210\u65b9\u9762\u63d0\u9ad8\u4e86 2.5% \u7684 BLEU \u5206\u6570\u3002", "conclusion": "TABT5 \u5b9e\u73b0\u4e86\u5728\u7535\u5b50\u8868\u683c\u516c\u5f0f\u9884\u6d4b\u3001\u95ee\u7b54\u548c\u6570\u636e\u5230\u6587\u672c\u751f\u6210\u7b49\u591a\u4e2a\u9886\u57df\u7684\u65b0 state-of-the-art \u7ed3\u679c\u3002"}}
{"id": "2208.06213", "title": "What is it like to program with artificial intelligence?", "url": "https://arxiv.org/abs/2208.06213", "pdf": "https://arxiv.org/pdf/2208.06213", "abs": "https://arxiv.org/abs/2208.06213", "authors": ["Advait Sarkar", "Andrew D. Gordon", "Carina Negreanu", "Christian Poelitz", "Sruti Srinivasa Ragavan", "Ben Zorn"], "categories": ["cs.HC", "cs.AI", "cs.PL", "D.2.3; D.2.6; I.2.5; I.2.7; H.5.2"], "comment": "Proceedings of the 33rd Annual Conference of the Psychology of\n  Programming Interest Group (PPIG 2022)", "summary": "Large language models, such as OpenAI's codex and Deepmind's AlphaCode, can\ngenerate code to solve a variety of problems expressed in natural language.\nThis technology has already been commercialised in at least one widely-used\nprogramming editor extension: GitHub Copilot.\n  In this paper, we explore how programming with large language models\n(LLM-assisted programming) is similar to, and differs from, prior\nconceptualisations of programmer assistance. We draw upon publicly available\nexperience reports of LLM-assisted programming, as well as prior usability and\ndesign studies. We find that while LLM-assisted programming shares some\nproperties of compilation, pair programming, and programming via search and\nreuse, there are fundamental differences both in the technical possibilities as\nwell as the practical experience. Thus, LLM-assisted programming ought to be\nviewed as a new way of programming with its own distinct properties and\nchallenges.\n  Finally, we draw upon observations from a user study in which non-expert end\nuser programmers use LLM-assisted tools for solving data tasks in spreadsheets.\nWe discuss the issues that might arise, and open research challenges, in\napplying large language models to end-user programming, particularly with users\nwho have little or no programming expertise.", "AI": {"tldr": "LLM-assisted programming is a new way to code, different from older methods. It has unique challenges, especially for beginners using tools like spreadsheets. More research is needed.", "motivation": "To explore the similarities and differences between LLM-assisted programming and previous conceptualizations of programmer assistance, and to identify potential issues and research challenges in applying LLMs to end-user programming.", "method": "The study analyzes publicly available experience reports and prior usability studies on LLM-assisted programming. It also draws on observations from a user study involving non-expert end-user programmers using LLM-assisted tools in spreadsheets.", "result": "LLM-assisted programming shares some properties with compilation, pair programming, and programming via search and reuse, but possesses fundamental differences in both technical capabilities and practical experience. Applying LLMs to end-user programming, especially for users with limited programming expertise, presents specific challenges.", "conclusion": "LLM-assisted programming represents a new paradigm with distinct properties and challenges, particularly when applied to end-user programming with non-expert users."}}
{"id": "2209.14812", "title": "Named Entity Recognition in Industrial Tables using Tabular Language Models", "url": "https://arxiv.org/abs/2209.14812", "pdf": "https://arxiv.org/pdf/2209.14812", "abs": "https://arxiv.org/abs/2209.14812", "authors": ["Aneta Koleva", "Martin Ringsquandl", "Mark Buckley", "Rakebul Hasan", "Volker Tresp"], "categories": ["cs.AI", "cs.CL"], "comment": "EMNLP 2022 Industry Track", "summary": "Specialized transformer-based models for encoding tabular data have gained\ninterest in academia. Although tabular data is omnipresent in industry,\napplications of table transformers are still missing. In this paper, we study\nhow these models can be applied to an industrial Named Entity Recognition (NER)\nproblem where the entities are mentioned in tabular-structured spreadsheets.\nThe highly technical nature of spreadsheets as well as the lack of labeled data\npresent major challenges for fine-tuning transformer-based models. Therefore,\nwe develop a dedicated table data augmentation strategy based on available\ndomain-specific knowledge graphs. We show that this boosts performance in our\nlow-resource scenario considerably. Further, we investigate the benefits of\ntabular structure as inductive bias compared to tables as linearized sequences.\nOur experiments confirm that a table transformer outperforms other baselines\nand that its tabular inductive bias is vital for convergence of\ntransformer-based models.", "AI": {"tldr": "Table transformers are effective for industrial NER on spreadsheets, especially with data augmentation. The model", "motivation": "To address the lack of applications of table transformers in industry, specifically for Named Entity Recognition (NER) on tabular-structured spreadsheets, despite the prevalence of tabular data in industry.", "method": "A dedicated table data augmentation strategy using domain-specific knowledge graphs was developed and applied to a table transformer model. The performance was compared against other baselines, investigating the benefits of tabular structure versus linearized sequences.", "result": "The table transformer model significantly outperformed other baselines, demonstrating the effectiveness of the augmentation strategy in a low-resource scenario and highlighting the importance of the tabular inductive bias for convergence.", "conclusion": "Transformer-based models can be successfully applied to industrial NER problems on tabular data, especially when augmented with domain-specific knowledge graphs. The tabular structure provides a vital inductive bias for model convergence."}}
{"id": "2209.14457", "title": "Consensus-Free Spreadsheet Integration", "url": "https://arxiv.org/abs/2209.14457", "pdf": "https://arxiv.org/pdf/2209.14457", "abs": "https://arxiv.org/abs/2209.14457", "authors": ["Brandon Baylor", "Eric Daimler", "James Hansen", "Esteban Montero", "Ryan Wisnesky"], "categories": ["cs.DB", "cs.SE"], "comment": null, "summary": "We describe a method for merging multiple spreadsheets into one sheet, and/or\nexchanging data among the sheets, by expressing each sheet's formulae as an\nalgebraic (equational) theory and each sheet's values as a model of its theory,\nexpressing the overlap between the sheets as theory and model morphisms, and\nthen performing colimit, lifting, and Kan-extension constructions from category\ntheory to compute a canonically universal integrated theory and model, which\ncan then be expressed as a spreadsheet. Our motivation is to find methods of\nmerging engineering models that do not require consensus (agreement) among the\nauthors of the models being merged, a condition fulfilled by our method because\ntheory and model morphisms are semantics-preserving. We describe a case study\nof this methodology on a real-world oil and gas calculation at a major energy\ncompany, describing the theories and models that arise when integrating two\ndifferent casing pressure test (MASP) calculation spreadsheets constructed by\ntwo non-interacting engineers. We also describe the automated theorem proving\nburden associated with both verifying the semantics preservation of the overlap\nmappings as well as verifying the conservativity/consistency of the resulting\nintegrated sheet. We conclude with thoughts on how to apply the methodology to\nscale engineering efforts across the enterprise.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8303\u7574\u8bba\u6765\u5408\u5e76\u7535\u5b50\u8868\u683c\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u7535\u5b50\u8868\u683c\u8868\u793a\u4e3a\u4ee3\u6570\u7406\u8bba\u548c\u6a21\u578b\u6765\u5de5\u4f5c\u3002\u8be5\u65b9\u6cd5\u4e0d\u9700\u8981\u4f5c\u8005\u4e4b\u95f4\u7684\u5171\u8bc6\uff0c\u5e76\u5df2\u5728\u6cb9\u6c14\u884c\u4e1a\u7684\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u4e2d\u8fdb\u884c\u4e86\u6f14\u793a\u3002\u8fd8\u8ba8\u8bba\u4e86\u4e0e\u9a8c\u8bc1\u6b64\u8fc7\u7a0b\u76f8\u5173\u7684\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u3002", "motivation": "\u5bfb\u627e\u4e00\u79cd\u5408\u5e76\u5de5\u7a0b\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0d\u9700\u8981\u6a21\u578b\u4f5c\u8005\u4e4b\u95f4\u8fbe\u6210\u5171\u8bc6\uff08\u540c\u610f\uff09\uff0c\u800c\u6211\u4eec\u7684\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u4fdd\u6301\u8bed\u4e49\u7684\u7406\u8bba\u548c\u6a21\u578b\u6001\u5c04\u6765\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "method": "\u901a\u8fc7\u5c06\u7535\u5b50\u8868\u683c\u516c\u5f0f\u8868\u8fbe\u4e3a\u4ee3\u6570\u7406\u8bba\uff0c\u5c06\u503c\u8868\u8fbe\u4e3a\u6a21\u578b\uff0c\u5e76\u5c06\u91cd\u53e0\u8868\u8fbe\u4e3a\u7406\u8bba\u548c\u6a21\u578b\u6001\u5c04\uff0c\u7136\u540e\u6267\u884c\u8303\u7574\u8bba\u4e2d\u7684\u4f59\u6781\u9650\u3001\u63d0\u5347\u548cKan\u6269\u5c55\u6784\u9020\uff0c\u6765\u5408\u5e76\u591a\u4e2a\u7535\u5b50\u8868\u683c\u6216\u5728\u7535\u5b50\u8868\u683c\u4e4b\u95f4\u4ea4\u6362\u6570\u636e\u3002", "result": "\u6211\u4eec\u63cf\u8ff0\u4e86\u5728\u4e00\u5bb6\u4e3b\u8981\u80fd\u6e90\u516c\u53f8\u7684\u4e00\u4e2a\u5b9e\u9645\u6cb9\u6c14\u8ba1\u7b97\u6848\u4f8b\u7814\u7a76\uff0c\u5176\u4e2d\u6574\u5408\u4e86\u4e24\u4e2a\u7531\u4e24\u540d\u4e0d\u76f8\u5173\u7684\u5de5\u7a0b\u5e08\u521b\u5efa\u7684\u4e0d\u540c\u5957\u7ba1\u538b\u529b\u6d4b\u8bd5\uff08MASP\uff09\u8ba1\u7b97\u7535\u5b50\u8868\u683c\uff0c\u5e76\u63cf\u8ff0\u4e86\u7531\u6b64\u4ea7\u751f\u7684\u7406\u8bba\u548c\u6a21\u578b\u3002", "conclusion": "\u5c06\u65b9\u6cd5\u8bba\u5e94\u7528\u4e8e\u4f01\u4e1a\u89c4\u6a21\u7684\u5de5\u7a0b\u5de5\u4f5c\uff0c\u5e76\u8ba8\u8bba\u4e86\u4e0e\u9a8c\u8bc1\u8bed\u4e49\u4fdd\u6301\u548c\u96c6\u6210\u8868\u4e00\u81f4\u6027\u76f8\u5173\u7684\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u8d1f\u62c5\u3002"}}
{"id": "2209.12560", "title": "Hazard Analysis of Collaborative Automation Systems: A Two-layer Approach based on Supervisory Control and Simulation", "url": "https://arxiv.org/abs/2209.12560", "pdf": "https://arxiv.org/pdf/2209.12560", "abs": "https://arxiv.org/abs/2209.12560", "authors": ["Tom P. Huck", "Yuvaraj Selvaraj", "Constantin Cronrath", "Christoph Ledermann", "Martin Fabian", "Bengt Lennartson", "Torsten Kr\u00f6ger"], "categories": ["cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Safety critical systems are typically subjected to hazard analysis before\ncommissioning to identify and analyse potentially hazardous system states that\nmay arise during operation. Currently, hazard analysis is mainly based on human\nreasoning, past experiences, and simple tools such as checklists and\nspreadsheets. Increasing system complexity makes such approaches decreasingly\nsuitable. Furthermore, testing-based hazard analysis is often not suitable due\nto high costs or dangers of physical faults. A remedy for this are model-based\nhazard analysis methods, which either rely on formal models or on simulation\nmodels, each with their own benefits and drawbacks. This paper proposes a\ntwo-layer approach that combines the benefits of exhaustive analysis using\nformal methods with detailed analysis using simulation. Unsafe behaviours that\nlead to unsafe states are first synthesised from a formal model of the system\nusing Supervisory Control Theory. The result is then input to the simulation\nwhere detailed analyses using domain-specific risk metrics are performed.\nThough the presented approach is generally applicable, this paper demonstrates\nthe benefits of the approach on an industrial human-robot collaboration system.", "AI": {"tldr": "\u4e00\u79cd\u7ed3\u5408\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u4eff\u771f\uff0c\u7528\u4e8e\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u5371\u9669\u5206\u6790\u7684\u4e24\u5c42\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u65e5\u76ca\u590d\u6742\u7684\u7cfb\u7edf\u548c\u4f20\u7edf\u57fa\u4e8e\u63a8\u7406\u3001\u7ecf\u9a8c\u548c\u7b80\u5355\u5de5\u5177\u7684\u5371\u9669\u5206\u6790\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u53ca\u6d4b\u8bd5\u65b9\u6cd5\u7684\u9ad8\u6210\u672c\u548c\u5371\u9669\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u5c42\u65b9\u6cd5\uff0c\u9996\u5148\u4f7f\u7528\u76d1\u7763\u63a7\u5236\u7406\u8bba\u4ece\u5f62\u5f0f\u5316\u6a21\u578b\u7efc\u5408\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u8f93\u5165\u4eff\u771f\uff0c\u4ee5\u8fdb\u884c\u8be6\u7ec6\u7684\u3001\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u98ce\u9669\u5ea6\u91cf\u7684\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u4eff\u771f\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u7684\u66f4\u5168\u9762\u548c\u8be6\u7ec6\u7684\u5371\u9669\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u4eff\u771f\u7684\u4f18\u70b9\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u573a\u666f\uff0c\u5e76\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4e86\u6f14\u793a\u3002"}}
{"id": "2208.04738", "title": "Long-Term Mentoring for Computer Science Researchers", "url": "https://arxiv.org/abs/2208.04738", "pdf": "https://arxiv.org/pdf/2208.04738", "abs": "https://arxiv.org/abs/2208.04738", "authors": ["Emily Ruppel", "Sihang Liu", "Elba Garza", "Sukyoung Ryu", "Alexandra Silva", "Talia Ringer"], "categories": ["cs.CY", "cs.GL", "cs.PL"], "comment": null, "summary": "Early in the pandemic, we -- leaders in the research areas of programming\nlanguages (PL) and computer architecture (CA) -- realized that we had a\nproblem: the only way to form new lasting connections in the community was to\nalready have lasting connections in the community. Both of our academic\ncommunities had wonderful short-term mentoring programs to address this\nproblem, but it was clear that we needed long-term mentoring programs.\n  Those of us in CA approached this scientifically, making an evidence-backed\ncase for community-wide long-term mentoring. In the meantime, one of us in PL\nhad impulsively launched an unofficial long-term mentoring program, founded on\nchaos and spreadsheets. In January 2021, the latter grew to an official\ncross-institutional long-term mentoring program called SIGPLAN-M; in January\n2022, the former grew to Computer Architecture Long-term Mentoring (CALM).\n  The impacts have been strong: SIGPLAN-M reaches 328 mentees and 234 mentors\nacross 41 countries, and mentees have described it as \"life changing\" and \"a\ncareer saver.\" And while CALM is in its pilot phase -- with 13 mentors and 21\nmentees across 7 countries -- it has received very positive feedback. The\nleaders of SIGPLAN-M and CALM shared our designs, impacts, and challenges along\nthe way. Now, we wish to share those with you. We hope this will kick-start a\nlarger long-term mentoring effort across all of computer science.", "AI": {"tldr": "PL\u548cCA\u9886\u57df\u56e0\u5e94\u75ab\u60c5\u671f\u95f4\u793e\u533a\u8054\u7cfb\u7f3a\u5931\u95ee\u9898\uff0c\u5206\u522b\u63a8\u51fa\u4e86SIGPLAN-M\u548cCALM\u4e24\u4e2a\u957f\u671f\u6307\u5bfc\u8ba1\u5212\uff0c\u5e76\u53d6\u5f97\u4e86\u79ef\u6781\u6210\u6548\uff0c\u5e0c\u671b\u6b64\u4e3e\u80fd\u4fc3\u8fdb\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u5185\u66f4\u5e7f\u6cdb\u7684\u6307\u5bfc\u5408\u4f5c\u3002", "motivation": "\u89e3\u51b3PL\u548cCA\u9886\u57df\u5728\u75ab\u60c5\u671f\u95f4\u793e\u533a\u5185\u7f3a\u4e4f\u957f\u671f\u8054\u7cfb\u548c\u6307\u5bfc\u7684\u95ee\u9898\uff0c\u5373\u53ea\u6709\u5728\u793e\u533a\u5185\u5df2\u6709\u8054\u7cfb\u7684\u4eba\u624d\u80fd\u5efa\u7acb\u65b0\u7684\u957f\u671f\u8054\u7cfb\u3002", "method": "\u6587\u7ae0\u4ecb\u7ecd\u4e86PL\uff08\u7f16\u7a0b\u8bed\u8a00\uff09\u548cCA\uff08\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\uff09\u4e24\u4e2a\u5b66\u672f\u9886\u57df\u5728\u75ab\u60c5\u671f\u95f4\u4e3a\u89e3\u51b3\u793e\u533a\u5185\u7f3a\u4e4f\u957f\u671f\u8054\u7cfb\u548c\u6307\u5bfc\u7684\u95ee\u9898\u800c\u521b\u5efa\u7684\u6307\u5bfc\u8ba1\u5212\u3002PL\u9886\u57df\u521b\u5efa\u4e86SIGPLAN-M\uff0cCA\u9886\u57df\u521b\u5efa\u4e86CALM\u3002SIGPLAN-M\u5df2\u7ecf\u8986\u76d6\u4e86328\u540d\u53d7\u6307\u5bfc\u8005\u548c234\u540d\u6307\u5bfc\u8005\uff0c\u904d\u5e0341\u4e2a\u56fd\u5bb6\uff0c\u5e76\u88ab\u8bc4\u4ef7\u4e3a\u201c\u6539\u53d8\u4eba\u751f\u201d\u548c\u201c\u804c\u4e1a\u6551\u661f\u201d\u3002CALM\u76ee\u524d\u5904\u4e8e\u8bd5\u70b9\u9636\u6bb5\uff0c\u670913\u540d\u6307\u5bfc\u8005\u548c21\u540d\u53d7\u6307\u5bfc\u8005\uff0c\u904d\u5e037\u4e2a\u56fd\u5bb6\uff0c\u53cd\u9988\u79ef\u6781\u3002\u6587\u7ae0\u5206\u4eab\u4e86\u8fd9\u4e24\u4e2a\u8ba1\u5212\u7684\u8bbe\u8ba1\u3001\u5f71\u54cd\u548c\u6311\u6218\u3002", "result": "SIGPLAN-M\u5df2\u8986\u76d6328\u540d\u53d7\u6307\u5bfc\u8005\u548c234\u540d\u6307\u5bfc\u8005\uff0c\u904d\u5e0341\u4e2a\u56fd\u5bb6\uff0c\u53d7\u6307\u5bfc\u8005\u8bc4\u4ef7\u79ef\u6781\u3002CALM\u5904\u4e8e\u8bd5\u70b9\u9636\u6bb5\uff0c\u5df2\u670913\u540d\u6307\u5bfc\u8005\u548c21\u540d\u53d7\u6307\u5bfc\u8005\uff0c\u904d\u5e037\u4e2a\u56fd\u5bb6\uff0c\u53cd\u9988\u79ef\u6781\u3002", "conclusion": "\u5e0c\u671b\u8fd9\u9879\u5de5\u4f5c\u80fd\u63a8\u52a8\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u66f4\u5e7f\u6cdb\u7684\u957f\u671f\u6307\u5bfc\u8ba1\u5212\u3002"}}
{"id": "2209.05739", "title": "MetaGlyph: Automatic Generation of Metaphoric Glyph-based Visualization", "url": "https://arxiv.org/abs/2209.05739", "pdf": "https://arxiv.org/pdf/2209.05739", "abs": "https://arxiv.org/abs/2209.05739", "authors": ["Lu Ying", "Xinhuan Shu", "Dazhen Deng", "Yuchen Yang", "Tan Tang", "Lingyun Yu", "Yingcai Wu"], "categories": ["cs.HC"], "comment": null, "summary": "Glyph-based visualization achieves an impressive graphic design when\nassociated with comprehensive visual metaphors, which help audiences\neffectively grasp the conveyed information through revealing data semantics.\nHowever, creating such metaphoric glyph-based visualization (MGV) is not an\neasy task, as it requires not only a deep understanding of data but also\nprofessional design skills. This paper proposes MetaGlyph, an automatic system\nfor generating MGVs from a spreadsheet. To develop MetaGlyph, we first conduct\na qualitative analysis to understand the design of current MGVs from the\nperspectives of metaphor embodiment and glyph design. Based on the results, we\nintroduce a novel framework for generating MGVs by metaphoric image selection\nand an MGV construction. Specifically, MetaGlyph automatically selects\nmetaphors with corresponding images from online resources based on the input\ndata semantics. We then integrate a Monte Carlo tree search algorithm that\nexplores the design of an MGV by associating visual elements with data\ndimensions given the data importance, semantic relevance, and glyph\nnon-overlap. The system also provides editing feedback that allows users to\ncustomize the MGVs according to their design preferences. We demonstrate the\nuse of MetaGlyph through a set of examples, one usage scenario, and validate\nits effectiveness through a series of expert interviews.", "AI": {"tldr": "MetaGlyph\u662f\u4e00\u4e2a\u80fd\u81ea\u52a8\u4ece\u7535\u5b50\u8868\u683c\u751f\u6210\u89c6\u89c9\u9690\u55bb\u56fe\u5f62\uff08MGV\uff09\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u6790\u73b0\u6709\u8bbe\u8ba1\u3001\u81ea\u52a8\u9009\u62e9\u9690\u55bb\u56fe\u50cf\u5e76\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\u6765\u4f18\u5316\u8bbe\u8ba1\uff0c\u540c\u65f6\u5141\u8bb8\u7528\u6237\u81ea\u5b9a\u4e49\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u624b\u52a8\u521b\u5efaMGV\u7684\u96be\u9898\u3002", "motivation": "\u81ea\u52a8\u521b\u5efa\u9690\u55bb\u56fe\u5f62\u53ef\u89c6\u5316\uff08MGV\uff09\u5e76\u975e\u6613\u4e8b\uff0c\u5b83\u9700\u8981\u5bf9\u6570\u636e\u7684\u6df1\u5165\u7406\u89e3\u548c\u4e13\u4e1a\u7684\u8bbe\u8ba1\u6280\u80fd\u3002\u6b64\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "1. \u5b9a\u6027\u5206\u6790\uff1a\u4ece\u9690\u55bb\u4f53\u73b0\u548c\u56fe\u5f62\u8bbe\u8ba1\u89d2\u5ea6\u5bf9\u73b0\u6709MGV\u8fdb\u884c\u5206\u6790\u3002\n2. \u6846\u67b6\u8bbe\u8ba1\uff1a\u63d0\u51fa\u4e00\u79cd\u65b0\u7684MGV\u751f\u6210\u6846\u67b6\uff0c\u5305\u62ec\u9690\u55bb\u56fe\u50cf\u9009\u62e9\u548cMGV\u6784\u5efa\u3002\n3. \u81ea\u52a8\u9009\u62e9\u9690\u55bb\uff1a\u57fa\u4e8e\u8f93\u5165\u6570\u636e\u7684\u8bed\u4e49\u81ea\u52a8\u9009\u62e9\u5177\u6709\u76f8\u5e94\u56fe\u50cf\u7684\u9690\u55bb\u3002\n4. \u96c6\u6210MCTS\u7b97\u6cd5\uff1a\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\u63a2\u7d22MGV\u8bbe\u8ba1\uff0c\u5173\u8054\u89c6\u89c9\u5143\u7d20\u548c\u6570\u636e\u7ef4\u5ea6\uff0c\u5e76\u8003\u8651\u6570\u636e\u91cd\u8981\u6027\u3001\u8bed\u4e49\u76f8\u5173\u6027\u548c\u56fe\u5f62\u4e0d\u91cd\u53e0\u3002\n5. \u63d0\u4f9b\u7f16\u8f91\u53cd\u9988\uff1a\u5141\u8bb8\u7528\u6237\u6839\u636e\u8bbe\u8ba1\u504f\u597d\u81ea\u5b9a\u4e49MGV\u3002", "result": "MetaGlyph\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u751f\u6210MGV\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u3001\u4f7f\u7528\u573a\u666f\u3001\u4e13\u5bb6\u8bbf\u8c08\u7b49\u65b9\u5f0f\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "MetaGlyph\u7cfb\u7edf\u80fd\u591f\u6839\u636e\u7528\u6237\u8f93\u5165\u7684\u7535\u5b50\u8868\u683c\u6570\u636e\uff0c\u81ea\u52a8\u751f\u6210\u5177\u6709\u56fe\u5f62\u8868\u73b0\u529b\u548c\u4fe1\u606f\u4f20\u8fbe\u80fd\u529b\u7684\u89c6\u89c9\u9690\u55bb\u56fe\u5f62\uff08MGV\uff09\u3002"}}
{"id": "2204.03128", "title": "Sigma Workbook: A Spreadsheet for Cloud Data Warehouses", "url": "https://arxiv.org/abs/2204.03128", "pdf": "https://arxiv.org/pdf/2204.03128", "abs": "https://arxiv.org/abs/2204.03128", "authors": ["James Gale", "Max Seiden", "Deepanshu Utkarsh", "Jason Frantz", "Rob Woollen", "\u00c7a\u011fatay Demiralp"], "categories": ["cs.DB", "cs.HC"], "comment": "VLDB'22 Demonstrations", "summary": "Cloud data warehouses (CDWs) bring large-scale data and compute power closer\nto users in enterprises. However, existing tools for analyzing data in CDWs are\neither limited in ad-hoc transformations or difficult to use for business\nusers. Here we introduce Sigma Workbook, a new interactive system that enables\nbusiness users to easily perform a visual analysis of data in CDWs at scale.\nFor this, Sigma Workbook provides an accessible spreadsheet-like interface for\nanalysis through direct manipulation. Sigma Workbook dynamically constructs\nmatching SQL queries from user interactions, building on the versatility and\nexpressivity of SQL. Constructed queries are directly executed on CDWs,\nleveraging the superior characteristics of the new generation CDWs, including\nscalability. We demonstrate Sigma Workbook through 3 real-life use cases --\ncohort analysis, sessionization, and data augmentation -- and underline\nWorkbook's ease of use, scalability, and expressivity.", "AI": {"tldr": "Sigma Workbook is a new system with a spreadsheet-like interface that allows business users to easily analyze large datasets in cloud data warehouses by automatically generating and running SQL queries.", "motivation": "Existing tools for analyzing data in cloud data warehouses are either limited in ad-hoc transformations or difficult for business users, necessitating a more accessible and powerful system.", "method": "Sigma Workbook constructs SQL queries dynamically from user interactions within a spreadsheet-like interface, executing them directly on cloud data warehouses to leverage their scalability.", "result": "Demonstrated through 3 real-life use cases (cohort analysis, sessionization, and data augmentation), Sigma Workbook showed ease of use, scalability, and expressivity.", "conclusion": "Sigma Workbook enables business users to easily perform visual analysis of data in CDWs at scale through a spreadsheet-like interface and dynamic SQL query construction, demonstrated by its ease of use, scalability, and expressivity in real-life use cases."}}
{"id": "2204.00598", "title": "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language", "url": "https://arxiv.org/abs/2204.00598", "pdf": "https://arxiv.org/pdf/2204.00598", "abs": "https://arxiv.org/abs/2204.00598", "authors": ["Andy Zeng", "Maria Attarian", "Brian Ichter", "Krzysztof Choromanski", "Adrian Wong", "Stefan Welker", "Federico Tombari", "Aveek Purohit", "Michael Ryoo", "Vikas Sindhwani", "Johnny Lee", "Vincent Vanhoucke", "Pete Florence"], "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "https://socraticmodels.github.io/", "summary": "Large pretrained (e.g., \"foundation\") models exhibit distinct capabilities\ndepending on the domain of data they are trained on. While these domains are\ngeneric, they may only barely overlap. For example, visual-language models\n(VLMs) are trained on Internet-scale image captions, but large language models\n(LMs) are further trained on Internet-scale text with no images (e.g.,\nspreadsheets, SAT questions, code). As a result, these models store different\nforms of commonsense knowledge across different domains. In this work, we show\nthat this diversity is symbiotic, and can be leveraged through Socratic Models\n(SMs): a modular framework in which multiple pretrained models may be composed\nzero-shot i.e., via multimodal-informed prompting, to exchange information with\neach other and capture new multimodal capabilities, without requiring\nfinetuning. With minimal engineering, SMs are not only competitive with\nstate-of-the-art zero-shot image captioning and video-to-text retrieval, but\nalso enable new applications such as (i) answering free-form questions about\negocentric video, (ii) engaging in multimodal assistive dialogue with people\n(e.g., for cooking recipes) by interfacing with external APIs and databases\n(e.g., web search), and (iii) robot perception and planning.", "AI": {"tldr": "Socratic Models (SMs) combine different pretrained models without finetuning to create new multimodal capabilities, outperforming existing methods and enabling novel applications in egocentric video analysis, assistive dialogue, and robot applications.", "motivation": "Leveraging the diverse commonsense knowledge stored in different pretrained models (e.g., visual-language models vs. language models) which are trained on different data domains.", "method": "Socratic Models (SMs) is a framework where multiple pretrained models are composed zero-shot via multimodal-informed prompting to exchange information and capture new multimodal capabilities without finetuning.", "result": "SMs are competitive with state-of-the-art zero-shot image captioning and video-to-text retrieval, and enable new applications like egocentric video QA, multimodal assistive dialogue, and robot perception and planning.", "conclusion": "Socratic Models (SMs) are a modular framework that leverages the diversity of pretrained models to achieve new multimodal capabilities without finetuning. SMs enable new applications such as egocentric video question answering, multimodal assistive dialogue, and robot perception and planning."}}
{"id": "2201.09745", "title": "Table Pre-training: A Survey on Model Architectures, Pre-training Objectives, and Downstream Tasks", "url": "https://arxiv.org/abs/2201.09745", "pdf": "https://arxiv.org/pdf/2201.09745", "abs": "https://arxiv.org/abs/2201.09745", "authors": ["Haoyu Dong", "Zhoujun Cheng", "Xinyi He", "Mengyu Zhou", "Anda Zhou", "Fan Zhou", "Ao Liu", "Shi Han", "Dongmei Zhang"], "categories": ["cs.CL", "cs.IR"], "comment": "Accepted by IJCAI'2022 survey track", "summary": "Since a vast number of tables can be easily collected from web pages,\nspreadsheets, PDFs, and various other document types, a flurry of table\npre-training frameworks have been proposed following the success of text and\nimages, and they have achieved new state-of-the-arts on various tasks such as\ntable question answering, table type recognition, column relation\nclassification, table search, formula prediction, etc. To fully use the\nsupervision signals in unlabeled tables, a variety of pre-training objectives\nhave been designed and evaluated, for example, denoising cell values,\npredicting numerical relationships, and implicitly executing SQLs. And to best\nleverage the characteristics of (semi-)structured tables, various tabular\nlanguage models, particularly with specially-designed attention mechanisms,\nhave been explored. Since tables usually appear and interact with free-form\ntext, table pre-training usually takes the form of table-text joint\npre-training, which attracts significant research interests from multiple\ndomains. This survey aims to provide a comprehensive review of different model\ndesigns, pre-training objectives, and downstream tasks for table pre-training,\nand we further share our thoughts and vision on existing challenges and future\nopportunities.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u56de\u987e\u4e86\u8868\u683c\u9884\u8bad\u7ec3\u7684\u7814\u7a76\uff0c\u5305\u62ec\u6a21\u578b\u3001\u76ee\u6807\u548c\u4efb\u52a1\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u4e0a\u8868\u683c\u6570\u636e\u7684\u6fc0\u589e\uff0c\u8868\u683c\u9884\u8bad\u7ec3\u6846\u67b6\u5f97\u5230\u4e86\u5e7f\u6cdb\u7814\u7a76\uff0c\u5e76\u5728\u8868\u683c\u95ee\u7b54\u3001\u7c7b\u578b\u8bc6\u522b\u3001\u5173\u7cfb\u5206\u7c7b\u3001\u641c\u7d22\u548c\u516c\u5f0f\u9884\u6d4b\u7b49\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002\u4e3a\u4e86\u5145\u5206\u5229\u7528\u65e0\u6807\u7b7e\u8868\u683c\u4e2d\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u7814\u7a76\u8005\u4eec\u8bbe\u8ba1\u4e86\u591a\u79cd\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u5982\u5355\u5143\u683c\u53bb\u566a\u3001\u6570\u503c\u5173\u7cfb\u9884\u6d4b\u548cSQL\u6267\u884c\u7b49\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u5229\u7528\u8868\u683c\u7684\uff08\u534a\uff09\u7ed3\u6784\u5316\u7279\u6027\uff0c\u7814\u7a76\u8005\u4eec\u63a2\u7d22\u4e86\u591a\u79cd\u8868\u683c\u8bed\u8a00\u6a21\u578b\uff0c\u7279\u522b\u662f\u5e26\u6709\u7279\u6b8a\u8bbe\u8ba1\u6ce8\u610f\u529b\u673a\u5236\u7684\u6a21\u578b\u3002\u7531\u4e8e\u8868\u683c\u901a\u5e38\u4e0e\u81ea\u7531\u683c\u5f0f\u6587\u672c\u4e00\u8d77\u51fa\u73b0\u548c\u4ea4\u4e92\uff0c\u8868\u683c\u9884\u8bad\u7ec3\u901a\u5e38\u91c7\u7528\u8868\u683c-\u6587\u672c\u8054\u5408\u9884\u8bad\u7ec3\u7684\u5f62\u5f0f\uff0c\u8fd9\u5f15\u8d77\u4e86\u591a\u4e2a\u9886\u57df\u7684\u7814\u7a76\u5174\u8da3\u3002", "method": "\u5bf9\u8868\u683c\u9884\u8bad\u7ec3\u6a21\u578b\u8bbe\u8ba1\u3001\u9884\u8bad\u7ec3\u76ee\u6807\u548c\u4e0b\u6e38\u4efb\u52a1\u8fdb\u884c\u4e86\u56de\u987e\u548c\u5206\u6790\u3002", "result": "\u8868\u683c\u9884\u8bad\u7ec3\u6846\u67b6\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u65b0\u7684\u6280\u672f\u6c34\u5e73\u3002", "conclusion": "\u672c\u6587\u5bf9\u8868\u683c\u9884\u8bad\u7ec3\u8fdb\u884c\u4e86\u5168\u9762\u7684\u56de\u987e\uff0c\u6db5\u76d6\u4e86\u6a21\u578b\u8bbe\u8ba1\u3001\u9884\u8bad\u7ec3\u76ee\u6807\u548c\u4e0b\u6e38\u4efb\u52a1\uff0c\u5e76\u5bf9\u73b0\u6709\u6311\u6218\u548c\u672a\u6765\u673a\u9047\u8fdb\u884c\u4e86\u5c55\u671b\u3002"}}
{"id": "2109.07323", "title": "FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining", "url": "https://arxiv.org/abs/2109.07323", "pdf": "https://arxiv.org/pdf/2109.07323", "abs": "https://arxiv.org/abs/2109.07323", "authors": ["Zhoujun Cheng", "Haoyu Dong", "Ran Jia", "Pengfei Wu", "Shi Han", "Fan Cheng", "Dongmei Zhang"], "categories": ["cs.IR", "cs.LG"], "comment": "Accepted by ACL'22 main track", "summary": "Tables store rich numerical data, but numerical reasoning over tables is\nstill a challenge. In this paper, we find that the spreadsheet formula, which\nperforms calculations on numerical values in tables, is naturally a strong\nsupervision of numerical reasoning. More importantly, large amounts of\nspreadsheets with expert-made formulae are available on the web and can be\nobtained easily. FORTAP is the first method for numerical-reasoning-aware table\npretraining by leveraging large corpus of spreadsheet formulae. We design two\nformula pretraining tasks to explicitly guide FORTAP to learn numerical\nreference and calculation in semi-structured tables. FORTAP achieves\nstate-of-the-art results on two representative downstream tasks, cell type\nclassification and formula prediction, showing great potential of\nnumerical-reasoning-aware pretraining.", "AI": {"tldr": "FORTAP\u662f\u4e00\u79cd\u65b0\u9896\u7684\u8868\u683c\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u7535\u5b50\u8868\u683c\u516c\u5f0f\u6765\u589e\u5f3a\u6570\u503c\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u9886\u5148\u7684\u6210\u679c\u3002", "motivation": "\u8868\u683c\u5b58\u50a8\u4e30\u5bcc\u7684\u6570\u503c\u6570\u636e\uff0c\u4f46\u5bf9\u8868\u683c\u8fdb\u884c\u6570\u503c\u63a8\u7406\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u6267\u884c\u8ba1\u7b97\u7684\u7535\u5b50\u8868\u683c\u516c\u5f0f\u662f\u5bf9\u6570\u503c\u63a8\u7406\u7684\u81ea\u7136\u76d1\u7763\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u7f51\u7edc\u4e0a\u6709\u5927\u91cf\u7684\u5305\u542b\u4e13\u5bb6\u5236\u4f5c\u516c\u5f0f\u7684\u7535\u5b50\u8868\u683c\uff0c\u5e76\u4e14\u53ef\u4ee5\u8f7b\u677e\u83b7\u5f97\u3002", "method": "FORTAP\u662f\u7b2c\u4e00\u4e2a\u5229\u7528\u5927\u578b\u7535\u5b50\u8868\u683c\u516c\u5f0f\u8bed\u6599\u5e93\u8fdb\u884c\u6570\u503c\u63a8\u7406\u611f\u77e5\u8868\u9884\u8bad\u7ec3\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u516c\u5f0f\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u4ee5\u660e\u786e\u6307\u5bfcFORTAP\u5b66\u4e60\u534a\u7ed3\u6784\u5316\u8868\u4e2d\u7684\u6570\u503c\u5f15\u7528\u548c\u8ba1\u7b97\u3002", "result": "FORTAP\u5728\u4e24\u4e2a\u4ee3\u8868\u6027\u4e0b\u6e38\u4efb\u52a1\uff08\u5355\u5143\u683c\u7c7b\u578b\u5206\u7c7b\u548c\u516c\u5f0f\u9884\u6d4b\uff09\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "FORTAP\u5728\u4e24\u4e2a\u4ee3\u8868\u6027\u4e0b\u6e38\u4efb\u52a1\uff08\u5355\u5143\u683c\u7c7b\u578b\u5206\u7c7b\u548c\u516c\u5f0f\u9884\u6d4b\uff09\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u663e\u793a\u4e86\u6570\u503c\u63a8\u7406\u611f\u77e5\u9884\u8bad\u7ec3\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2202.13189", "title": "Efficient Specialized Spreadsheet Parsing for Data Science", "url": "https://arxiv.org/abs/2202.13189", "pdf": "https://arxiv.org/pdf/2202.13189", "abs": "https://arxiv.org/abs/2202.13189", "authors": ["Felix Henze", "Haralampos Gavriilidis", "Eleni Tzirita Zacharatou", "Volker Markl"], "categories": ["cs.DB"], "comment": "Accepted at the 24th International Workshop on Design, Optimization,\n  Languages and Analytical Processing of Big Data (DOLAP 2022), March 29, 2022,\n  Edinburgh, UK", "summary": "Spreadsheets are widely used for data exploration. Since spreadsheet systems\nhave limited capabilities, users often need to load spreadsheets to other data\nscience environments to perform advanced analytics. However, current approaches\nfor spreadsheet loading suffer from either high runtime or memory usage, which\nhinders data exploration on commodity systems. To make spreasheet loading\npractical on commodity systems, we introduce a novel parser that minimizes\nmemory usage by tightly coupling decompression and parsing. Furthermore, to\nreduce the runtime, we introduce optimized spreadsheet-specific parsing\nroutines and employ parallelism. To evaluate our approach, we implement a\nprototype for loading Excel spreadsheets into R environments. Our evaluation\nshows that our novel approach is up to 3x faster while consuming up to 40x less\nmemory than state-of-the-art approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7535\u5b50\u8868\u683c\u52a0\u8f7d\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u7d27\u5bc6\u7ed3\u5408\u89e3\u538b\u548c\u89e3\u6790\u6765\u6700\u5c0f\u5316\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7684\u4f8b\u7a0b\u548c\u5e76\u884c\u5904\u7406\u6765\u51cf\u5c11\u8fd0\u884c\u65f6\uff0c\u4ece\u800c\u5728\u5546\u54c1\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u9ad8\u6548\u7684\u6570\u636e\u63a2\u7d22\u3002", "motivation": "\u7528\u6237\u7ecf\u5e38\u9700\u8981\u5c06\u7535\u5b50\u8868\u683c\u52a0\u8f7d\u5230\u6570\u636e\u79d1\u5b66\u73af\u5883\u4e2d\u4ee5\u6267\u884c\u9ad8\u7ea7\u5206\u6790\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8fd0\u884c\u65f6\u6216\u5185\u5b58\u4f7f\u7528\u9ad8\u7684\u95ee\u9898\uff0c\u8fd9\u5728\u5546\u54c1\u7cfb\u7edf\u4e0a\u963b\u788d\u4e86\u6570\u636e\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5c06\u89e3\u538b\u548c\u89e3\u6790\u7d27\u5bc6\u7ed3\u5408\u6765\u6700\u5c0f\u5316\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u5f15\u5165\u4f18\u5316\u7684\u7279\u5b9a\u4e8e\u7535\u5b50\u8868\u683c\u7684\u89e3\u6790\u4f8b\u7a0b\u548c\u5e76\u884c\u5904\u7406\u6765\u51cf\u5c11\u8fd0\u884c\u65f6\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb3\u500d\uff0c\u5185\u5b58\u5360\u7528\u5c1140\u500d\u3002", "conclusion": "\u7528\u6237\u53ef\u4ee5\u5c06\u7535\u5b50\u8868\u683c\u52a0\u8f7d\u5230R\u73af\u5883\u4e2d\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5feb\uff0c\u5185\u5b58\u5360\u7528\u66f4\u5c11\u3002"}}
{"id": "2203.16346", "title": "Enhanced Spreadsheet Computing with Finite-Domain Constraint Satisfaction", "url": "https://arxiv.org/abs/2203.16346", "pdf": "https://arxiv.org/pdf/2203.16346", "abs": "https://arxiv.org/abs/2203.16346", "authors": ["Ezana N. Beyenne", "Hai-Feng Guo"], "categories": ["cs.PL", "cs.AI", "I.2"], "comment": null, "summary": "The spreadsheet application is among the most widely used computing tools in\nmodern society. It provides excellent usability and usefulness, and it easily\nenables a non-programmer to perform programming-like tasks in a visual tabular\n\"pen and paper\" approach. However, spreadsheets are mostly limited to\nbookkeeping-like applications due to their mono-directional data flow. This\npaper shows how the spreadsheet computing paradigm is extended to break this\nlimitation for solving constraint satisfaction problems. We present an enhanced\nspreadsheet system where finite-domain constraint solving is well supported in\na visual environment. Furthermore, a spreadsheet-specific constraint language\nis constructed for general users to specify constraints among data cells in a\ndeclarative and scalable way. The new spreadsheet system significantly\nsimplifies the development of many constraint-based applications using a visual\ntabular interface. Examples are given to illustrate the usability and\nusefulness of the extended spreadsheet paradigm.\n  KEYWORDS: Spreadsheet computing, Finite-domain constraint satisfaction,\nConstraint logic programming", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u7535\u5b50\u8868\u683c\u7684\u8ba1\u7b97\u8303\u5f0f\u6269\u5c55\u5230\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff0c\u901a\u8fc7\u589e\u5f3a\u7cfb\u7edf\u548c\u5f15\u5165\u65b0\u7684\u7ea6\u675f\u8bed\u8a00\uff0c\u7b80\u5316\u4e86\u5f00\u53d1\u8fc7\u7a0b\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u56e0\u5176\u6613\u7528\u6027\u548c\u5e7f\u6cdb\u5e94\u7528\u6027\u800c\u6210\u4e3a\u5e38\u7528\u7684\u8ba1\u7b97\u5de5\u5177\uff0c\u4f46\u5176\u5355\u5411\u6570\u636e\u6d41\u7684\u9650\u5236\u4e86\u5176\u5728\u8bb0\u8d26\u7c7b\u5e94\u7528\u4e4b\u5916\u7684\u5e7f\u6cdb\u4f7f\u7528\u3002\u672c\u7814\u7a76\u65e8\u5728\u6253\u7834\u8fd9\u4e00\u9650\u5236\uff0c\u5c06\u7535\u5b50\u8868\u683c\u8ba1\u7b97\u8303\u4f8b\u6269\u5c55\u5230\u89e3\u51b3\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u7684\u7535\u5b50\u8868\u683c\u7cfb\u7edf\uff0c\u4e3a\u6709\u9650\u57df\u7ea6\u675f\u6c42\u89e3\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u53ef\u89c6\u5316\u73af\u5883\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u79cd\u7535\u5b50\u8868\u683c\u7279\u5b9a\u7684\u7ea6\u675f\u8bed\u8a00\uff0c\u4ee5\u4fbf\u7528\u6237\u4ee5\u58f0\u660e\u5f0f\u548c\u53ef\u6269\u5c55\u7684\u65b9\u5f0f\u6307\u5b9a\u6570\u636e\u5355\u5143\u4e4b\u95f4\u7684\u7ea6\u675f\u3002", "result": "\u65b0\u7684\u7535\u5b50\u8868\u683c\u7cfb\u7edf\u901a\u8fc7\u53ef\u89c6\u5316\u8868\u683c\u754c\u9762\u663e\u8457\u7b80\u5316\u4e86\u8bb8\u591a\u57fa\u4e8e\u7ea6\u675f\u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u5f00\u53d1\uff0c\u5e76\u4e14\u6613\u7528\u6027\u548c\u5b9e\u7528\u6027\u5f97\u5230\u4e86\u4f8b\u8bc1\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u589e\u5f3a\u7535\u5b50\u8868\u683c\u7cfb\u7edf\u548c\u6784\u5efa\u7279\u5b9a\u4e8e\u7535\u5b50\u8868\u683c\u7684\u7ea6\u675f\u8bed\u8a00\uff0c\u6210\u529f\u5730\u5c06\u7535\u5b50\u8868\u683c\u8ba1\u7b97\u8303\u4f8b\u6269\u5c55\u5230\u89e3\u51b3\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff0c\u7b80\u5316\u4e86\u8bb8\u591a\u57fa\u4e8e\u7ea6\u675f\u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u5f00\u53d1\u3002"}}
{"id": "2203.10944", "title": "Spreadsheet computing with Finite Domain Constraint Enhancements", "url": "https://arxiv.org/abs/2203.10944", "pdf": "https://arxiv.org/pdf/2203.10944", "abs": "https://arxiv.org/abs/2203.10944", "authors": ["Ezana N. Beyenne"], "categories": ["cs.AI", "I.2"], "comment": "2008 Master's thesis", "summary": "Spreadsheet computing is one of the more popular computing methodologies in\ntoday's modern society. The spreadsheet application's ease of use and\nusefulness has enabled non-programmers to perform programming-like tasks in a\nfamiliar setting modeled after the tabular \"pen and paper\" approach. However,\nspreadsheet applications are limited to bookkeeping-like tasks due to their\nsingle-direction data flow. This thesis demonstrates an extension of the\nspreadsheet computing paradigm in overcoming this limitation to solve\nconstraint satisfaction problems. We present a framework seamlessly\nincorporating a finite constraint solver with the spreadsheet computing\nparadigm. This framework allows the individual cells in the spreadsheet to be\nattached to either a finite domain or a constraint specifying the relationship\namong the cells. The framework provides an interface for constraint solving and\nfurther enhances the spreadsheet computing paradigm by providing a set of\nspreadsheet-specific constraints that will aid in controlling the scalability\nof large spreadsheet applications implementations. Finally, we provide examples\nto demonstrate the usability and usefulness of the extended spreadsheet\nparadigm.\n  Keywords: Spreadsheet computing, Constraint Logic Programming, Constraint\nsatisfaction, Domain-Specific language, Excel, SWI Prolog, C#", "AI": {"tldr": "Spreadsheets can now solve complex problems beyond simple bookkeeping by incorporating a constraint solver, making them more powerful for non-programmers.", "motivation": "Spreadsheet applications are popular due to their ease of use but are limited to bookkeeping-like tasks because of their single-direction data flow. This thesis aims to extend the paradigm to handle more complex problems like constraint satisfaction.", "method": "A framework is presented that seamlessly incorporates a finite constraint solver with the spreadsheet computing paradigm. Cells can be attached to finite domains or constraints, and the framework provides an interface for constraint solving and spreadsheet-specific constraints to manage scalability.", "result": "The extended spreadsheet paradigm enhances usability and usefulness by allowing non-programmers to solve constraint satisfaction problems in a familiar spreadsheet setting, with examples provided to demonstrate its effectiveness.", "conclusion": "This thesis demonstrates an extension of the spreadsheet computing paradigm to overcome the limitation of single-direction data flow, enabling the solution of constraint satisfaction problems by incorporating a finite constraint solver."}}
{"id": "2202.00454", "title": "TableQuery: Querying tabular data with natural language", "url": "https://arxiv.org/abs/2202.00454", "pdf": "https://arxiv.org/pdf/2202.00454", "abs": "https://arxiv.org/abs/2202.00454", "authors": ["Abhijith Neil Abraham", "Fariz Rahman", "Damanpreet Kaur"], "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": "11 pages, 1 figures", "summary": "This paper presents TableQuery, a novel tool for querying tabular data using\ndeep learning models pre-trained to answer questions on free text. Existing\ndeep learning methods for question answering on tabular data have various\nlimitations, such as having to feed the entire table as input into a neural\nnetwork model, making them unsuitable for most real-world applications. Since\nreal-world data might contain millions of rows, it may not entirely fit into\nthe memory. Moreover, data could be stored in live databases, which are updated\nin real-time, and it is impractical to serialize an entire database to a neural\nnetwork-friendly format each time it is updated. In TableQuery, we use deep\nlearning models pre-trained for question answering on free text to convert\nnatural language queries to structured queries, which can be run against a\ndatabase or a spreadsheet. This method eliminates the need for fitting the\nentire data into memory as well as serializing databases. Furthermore, deep\nlearning models pre-trained for question answering on free text are readily\navailable on platforms such as HuggingFace Model Hub (7). TableQuery does not\nrequire re-training; when a newly trained model for question answering with\nbetter performance is available, it can replace the existing model in\nTableQuery.", "AI": {"tldr": "TableQuery queries large tables using text-based AI models, avoiding memory issues and database serialization problems of older methods. It's flexible and uses readily available technology.", "motivation": "Existing deep learning methods for tabular data question answering struggle with large, real-world datasets that may exceed memory capacity or are stored in frequently updated live databases. TableQuery aims to overcome these practical limitations.", "method": "TableQuery employs deep learning models pre-trained for question answering on free text to translate natural language queries into executable structured queries. This approach bypasses the requirement of fitting large datasets into memory or serializing databases.", "result": "TableQuery enables efficient querying of large or live tabular datasets by converting natural language questions into structured queries, leveraging readily available pre-trained language models without the need for retraining and allowing for easy model upgrades.", "conclusion": "TableQuery uses pre-trained deep learning models for question answering on free text to convert natural language queries into structured queries, effectively addressing limitations of existing methods by avoiding the need to load entire tables into memory or serialize databases."}}
{"id": "2201.06337", "title": "PoVRPoint: Authoring Presentations in Mobile Virtual Reality", "url": "https://arxiv.org/abs/2201.06337", "pdf": "https://arxiv.org/pdf/2201.06337", "abs": "https://arxiv.org/abs/2201.06337", "authors": ["Verena Biener", "Travis Gesslein", "Daniel Schneider", "Felix Kawala", "Alexander Otte", "Per Ola Kristensson", "Michel Pahud", "Eyal Ofek", "Cuauhtli Campos", "Matja\u017e Kljun", "Klen \u010copi\u010d Pucihar", "Jens Grubert"], "categories": ["cs.HC", "I.3.7"], "comment": "IEEE VR 2022; to appear in IEEE transactions on visualization and\n  computer graphics, 2022", "summary": "Virtual Reality (VR) has the potential to support mobile knowledge workers by\ncomplementing traditional input devices with a large three-dimensional output\nspace and spatial input. Previous research on supporting VR knowledge work\nexplored domains such as text entry using physical keyboards and spreadsheet\ninteraction using combined pen and touch input. Inspired by such work, this\npaper probes the VR design space for authoring presentations in mobile\nsettings. We propose PoVRPoint -- a set of tools coupling pen- and touch-based\nediting of presentations on mobile devices, such as tablets, with the\ninteraction capabilities afforded by VR. We study the utility of extended\ndisplay space to, for example, assist users in identifying target slides,\nsupporting spatial manipulation of objects on a slide, creating animations, and\nfacilitating arrangements of multiple, possibly occluded, shapes. Among other\nthings, our results indicate that 1) the wide field of view afforded by VR\nresults in significantly faster target slide identification times compared to a\ntablet-only interface for visually salient targets; and 2) the\nthree-dimensional view in VR enables significantly faster object reordering in\nthe presence of occlusion compared to two baseline interfaces. A user study\nfurther confirmed that the interaction techniques were found to be usable and\nenjoyable.", "AI": {"tldr": "PoVRPoint\u5de5\u5177\u96c6\u5229\u7528VR\u6280\u672f\u6539\u8fdb\u4e86\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u6f14\u793a\u6587\u7a3f\u521b\u4f5c\u4f53\u9a8c\uff0c\u901a\u8fc7VR\u7684\u5bbd\u5e7f\u89c6\u91ce\u548c\u4e09\u7ef4\u89c6\u56fe\uff0c\u63d0\u9ad8\u4e86\u5e7b\u706f\u7247\u8bc6\u522b\u548c\u7269\u4f53\u64cd\u4f5c\u7684\u6548\u7387\uff0c\u5e76\u83b7\u5f97\u4e86\u7528\u6237\u7684\u79ef\u6781\u53cd\u9988\u3002", "motivation": "\u4e3a\u4e86\u63a2\u7d22VR\u5728\u79fb\u52a8\u529e\u516c\u573a\u666f\u4e0b\u652f\u6301\u77e5\u8bc6\u5de5\u4f5c\u8005\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6f14\u793a\u6587\u7a3f\u521b\u4f5c\u8fd9\u4e00\u7279\u5b9a\u9886\u57df\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6539\u8fdb\u4f20\u7edf\u7684\u8f93\u5165\u8bbe\u5907\uff0c\u5229\u7528VR\u63d0\u4f9b\u7684\u4e09\u7ef4\u8f93\u51fa\u7a7a\u95f4\u548c\u7a7a\u95f4\u8f93\u5165\u80fd\u529b\u3002", "method": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u5728\u79fb\u52a8\u573a\u666f\u4e0b\u4f7f\u7528VR\u8fdb\u884c\u6f14\u793a\u6587\u7a3f\u521b\u4f5c\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPoVRPoint\u7684\u5de5\u5177\u96c6\u3002\u8be5\u5de5\u5177\u96c6\u5c06\u5e73\u677f\u7535\u8111\u7684\u89e6\u7b14\u548c\u89e6\u6478\u7f16\u8f91\u529f\u80fd\u4e0eVR\u7684\u4ea4\u4e92\u80fd\u529b\u76f8\u7ed3\u5408\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4ec5\u4f7f\u7528\u5e73\u677f\u7535\u8111\u7684\u754c\u9762\u76f8\u6bd4\uff0cVR\u63d0\u4f9b\u7684\u5bbd\u5e7f\u89c6\u91ce\u80fd\u663e\u8457\u7f29\u77ed\u7528\u6237\u8bc6\u522b\u76ee\u6807\u5e7b\u706f\u7247\u7684\u65f6\u95f4\uff08\u7279\u522b\u662f\u5bf9\u4e8e\u89c6\u89c9\u663e\u8457\u7684\u76ee\u6807\uff09\u3002\u6b64\u5916\uff0c\u4e0e\u4e24\u4e2a\u57fa\u7ebf\u754c\u9762\u76f8\u6bd4\uff0cVR\u7684\u4e09\u7ef4\u89c6\u56fe\u80fd\u591f\u66f4\u6709\u6548\u5730\u5904\u7406\u7269\u4f53\u906e\u6321\u95ee\u9898\uff0c\u5b9e\u73b0\u66f4\u5feb\u7684\u7269\u4f53\u91cd\u6392\u3002\u7528\u6237\u7814\u7a76\u4e5f\u8bc1\u5b9e\u4e86\u6240\u63d0\u51fa\u7684\u4ea4\u4e92\u6280\u672f\u662f\u53ef\u7528\u4e14\u4ee4\u4eba\u6109\u5feb\u7684\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684PoVRPoint\u5de5\u5177\u96c6\u901a\u8fc7\u7ed3\u5408\u5e73\u677f\u7535\u8111\u7684\u89e6\u7b14\u548c\u89e6\u6478\u7f16\u8f91\u4e0eVR\u7684\u4ea4\u4e92\u80fd\u529b\uff0c\u4e3a\u79fb\u52a8\u573a\u666f\u4e0b\u7684\u6f14\u793a\u6587\u7a3f\u521b\u4f5c\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cVR\u7684\u5bbd\u5e7f\u89c6\u91ce\u663e\u8457\u63d0\u9ad8\u4e86\u76ee\u6807\u5e7b\u706f\u7247\u7684\u8bc6\u522b\u901f\u5ea6\uff0c\u800c\u4e09\u7ef4\u89c6\u56fe\u5219\u6709\u6548\u5730\u89e3\u51b3\u4e86\u7269\u4f53\u906e\u6321\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u7269\u4f53\u91cd\u6392\u3002\u7528\u6237\u7814\u7a76\u4e5f\u8bc1\u5b9e\u4e86\u8be5\u4ea4\u4e92\u6280\u672f\u7684\u53ef\u7528\u6027\u548c\u8da3\u5473\u6027\u3002"}}
{"id": "2201.01654", "title": "TableParser: Automatic Table Parsing with Weak Supervision from Spreadsheets", "url": "https://arxiv.org/abs/2201.01654", "pdf": "https://arxiv.org/pdf/2201.01654", "abs": "https://arxiv.org/abs/2201.01654", "authors": ["Susie Xi Rao", "Johannes Rausch", "Peter Egger", "Ce Zhang"], "categories": ["cs.CV"], "comment": "accepted in the AAAI-22 Workshop on Scientific Document Understanding\n  at the Thirty-Sixth AAAI Conference on Artificial Intelligence (SDU@AAAI-22)", "summary": "Tables have been an ever-existing structure to store data. There exist now\ndifferent approaches to store tabular data physically. PDFs, images,\nspreadsheets, and CSVs are leading examples. Being able to parse table\nstructures and extract content bounded by these structures is of high\nimportance in many applications. In this paper, we devise TableParser, a system\ncapable of parsing tables in both native PDFs and scanned images with high\nprecision. We have conducted extensive experiments to show the efficacy of\ndomain adaptation in developing such a tool. Moreover, we create TableAnnotator\nand ExcelAnnotator, which constitute a spreadsheet-based weak supervision\nmechanism and a pipeline to enable table parsing. We share these resources with\nthe research community to facilitate further research in this interesting\ndirection.", "AI": {"tldr": "A new system, TableParser, precisely extracts data from tables in PDFs and scanned images using domain adaptation. It also includes annotation tools (TableAnnotator, ExcelAnnotator) for weak supervision, with all resources shared for research.", "motivation": "Extracting data from various table formats like PDFs, images, spreadsheets, and CSVs is crucial for many applications. The paper aims to provide a precise and efficient solution for parsing table structures and extracting content.", "method": "The paper devises a system called TableParser for parsing tables in native PDFs and scanned images. It also creates TableAnnotator and ExcelAnnotator, which form a spreadsheet-based weak supervision mechanism and a pipeline to enable table parsing. The efficacy of domain adaptation is shown through extensive experiments.", "result": "The paper shows the efficacy of domain adaptation in developing a high-precision table parsing tool (TableParser) for native PDFs and scanned images. The created resources (TableAnnotator and ExcelAnnotator) facilitate table parsing through weak supervision.", "conclusion": "The paper presents TableParser, a system for parsing tables in native PDFs and scanned images, demonstrating the effectiveness of domain adaptation. It also introduces TableAnnotator and ExcelAnnotator for weak supervision, sharing these resources to aid further research."}}
{"id": "2201.07696", "title": "Exploring Spreadsheet Use and Practices in a Technologically Constrained Setting", "url": "https://arxiv.org/abs/2201.07696", "pdf": "https://arxiv.org/pdf/2201.07696", "abs": "https://arxiv.org/abs/2201.07696", "authors": ["Khwima Mckinley Mkamanga", "Simon Thorne"], "categories": ["cs.SE"], "comment": "23 pages, 7 colour figures, 17 Tables and a Sample Questionnaire", "summary": "This paper explores the impacts of spreadsheets on business operations in a\nwater utility parastatal in Malawi, Sub-Saharan Africa. The organisation is a\ntypical example of a semi-government body operating in a technologically\nunderdeveloped country. The study focused on spreadsheet scope of use and life\ncycle as well as organisational policy and governance. The results will help\ndefine future spreadsheet usage by influencing new approaches for managing\npotential risks associated with spreadsheets in the organization. Generally,\nfindings indicate that the proliferation of spreadsheets in the organization\nhas provided an enabling environment for business automation. The paper also\nhighlights management, technological and human factor issues contributing to\nhigh risks associated with the pervasive spreadsheet use. The conclusions drawn\nfrom the research confirms that there is ample room for improvement in many\nareas such as implementation of comprehensive policies and regulations\ngoverning spreadsheet development processes and adoption.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u7535\u5b50\u8868\u683c\u5728\u9a6c\u62c9\u7ef4\u4e00\u5bb6\u4f9b\u6c34\u516c\u5171\u4e8b\u4e1a\u673a\u6784\u4e2d\u7684\u5e94\u7528\u60c5\u51b5\uff0c\u6307\u51fa\u4e86\u5176\u5bf9\u4e1a\u52a1\u81ea\u52a8\u5316\u7684\u79ef\u6781\u5f71\u54cd\uff0c\u540c\u65f6\u4e5f\u5f3a\u8c03\u4e86\u4e0e\u7535\u5b50\u8868\u683c\u5e7f\u6cdb\u4f7f\u7528\u76f8\u5173\u7684\u7ba1\u7406\u3001\u6280\u672f\u548c\u4eba\u4e3a\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u9700\u8981\u6539\u8fdb\u653f\u7b56\u548c\u6cbb\u7406\u3002", "motivation": "\u4e3a\u4e86\u89e3\u7535\u5b50\u8868\u683c\u5bf9\u9a6c\u62c9\u7ef4\u4e00\u5bb6\u4f9b\u6c34\u516c\u5171\u4e8b\u4e1a\u673a\u6784\u7684\u4e1a\u52a1\u8fd0\u8425\u4ea7\u751f\u7684\u5f71\u54cd\uff0c\u8be5\u673a\u6784\u662f\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u5730\u533a\u4e00\u4e2a\u5178\u578b\u7684\u5728\u6280\u672f\u6b20\u53d1\u8fbe\u56fd\u5bb6\u8fd0\u8425\u7684\u534a\u653f\u5e9c\u673a\u6784\u3002", "method": "\u672c\u7814\u7a76\u805a\u7126\u4e8e\u5bf9\u9a6c\u62c9\u7ef4\u4e00\u5bb6\u4f9b\u6c34\u516c\u5171\u4e8b\u4e1a\u673a\u6784\u7684\u7535\u5b50\u8868\u683c\u7684\u5e94\u7528\u8303\u56f4\u3001\u751f\u547d\u5468\u671f\u4ee5\u53ca\u76f8\u5173\u7684\u7ec4\u7ec7\u653f\u7b56\u548c\u6cbb\u7406\u8fdb\u884c\u4e86\u63a2\u8ba8\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u666e\u904d\u8868\u660e\uff0c\u7535\u5b50\u8868\u683c\u5728\u8be5\u7ec4\u7ec7\u7684\u5e7f\u6cdb\u5e94\u7528\u4e3a\u4e1a\u52a1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5229\u73af\u5883\uff0c\u4f46\u4e5f\u7a81\u663e\u4e86\u5bfc\u81f4\u7535\u5b50\u8868\u683c\u666e\u904d\u4f7f\u7528\u4f34\u968f\u9ad8\u98ce\u9669\u7684\u7ba1\u7406\u3001\u6280\u672f\u548c\u4eba\u4e3a\u56e0\u7d20\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\uff0c\u5728\u52a0\u5f3a\u7ec4\u7ec7\u5185\u90e8\u7684\u7535\u5b50\u8868\u683c\u4f7f\u7528\u653f\u7b56\u548c\u6cd5\u89c4\u7684\u5236\u5b9a\u4e0e\u91c7\u7eb3\u65b9\u9762\uff0c\u4ecd\u6709\u5f88\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2110.12829", "title": "Spread2RML: Constructing Knowledge Graphs by Predicting RML Mappings on Messy Spreadsheets", "url": "https://arxiv.org/abs/2110.12829", "pdf": "https://arxiv.org/pdf/2110.12829", "abs": "https://arxiv.org/abs/2110.12829", "authors": ["Markus Schr\u00f6der", "Christian Jilek", "Andreas Dengel"], "categories": ["cs.DB"], "comment": "17 pages, 1 figure, 2 tables, accepted at K-CAP 2021", "summary": "The RDF Mapping Language (RML) allows to map semi-structured data to RDF\nknowledge graphs. Besides CSV, JSON and XML, this also includes the mapping of\nspreadsheet tables. Since spreadsheets have a complex data model and can become\nrather messy, their mapping creation tends to be very time consuming. In order\nto reduce such efforts, this paper presents Spread2RML which predicts RML\nmappings on messy spreadsheets. This is done with an extensible set of RML\nobject map templates which are applied for each column based on heuristics. In\nour evaluation, three datasets are used ranging from very messy synthetic data\nto spreadsheets from data.gov which are less messy. We obtained first promising\nresults especially with regard to our approach being fully automatic and\ndealing with rather messy data.", "AI": {"tldr": "Spread2RML\u81ea\u52a8\u9884\u6d4b\u6df7\u4e71\u7535\u5b50\u8868\u683c\u7684RML\u6620\u5c04\u3002", "motivation": "\u7531\u4e8e\u7535\u5b50\u8868\u683c\u7684\u6570\u636e\u6a21\u578b\u590d\u6742\u4e14\u53ef\u80fd\u6df7\u4e71\uff0c\u56e0\u6b64\u521b\u5efa\u7535\u5b50\u8868\u683c\u5230RDF\u77e5\u8bc6\u56fe\u7684\u6620\u5c04\u8fc7\u7a0b\u975e\u5e38\u8017\u65f6\u3002Spread2RML\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u9884\u6d4b\u6620\u5c04\u6765\u51cf\u5c11\u8fd9\u4e9b\u5de5\u4f5c\u3002", "method": "Spread2RML\u901a\u8fc7\u5c06\u4e00\u7ec4\u5408\u9002\u7684RML\u5bf9\u8c61\u6620\u5c04\u6a21\u677f\u5e94\u7528\u4e8e\u6bcf\u4e00\u5217\u6765\u9884\u6d4bRML\u6620\u5c04\uff0c\u8fd9\u4e9b\u6a21\u677f\u662f\u6839\u636e\u542f\u53d1\u5f0f\u65b9\u6cd5\u9009\u62e9\u7684\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u4e0d\u540c\u6df7\u4e71\u7a0b\u5ea6\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u53d6\u5f97\u4e86\u521d\u6b65\u7684\u3001\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u6df7\u4e71\u6570\u636e\u548c\u5b9e\u73b0\u5168\u81ea\u52a8\u5316\u65b9\u9762\u3002", "conclusion": "Spread2RML\u901a\u8fc7\u57fa\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u7684RML\u5bf9\u8c61\u6620\u5c04\u6a21\u677f\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6df7\u4e71\u7684\u7535\u5b50\u8868\u683c\u7684RML\u6620\u5c04\u7684\u81ea\u52a8\u9884\u6d4b\uff0c\u5e76\u5728\u5305\u542b\u5404\u79cd\u6df7\u4e71\u7a0b\u5ea6\u7684\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002"}}
{"id": "2110.11575", "title": "Methodology for Assessing the State of the Practice for Domain X", "url": "https://arxiv.org/abs/2110.11575", "pdf": "https://arxiv.org/pdf/2110.11575", "abs": "https://arxiv.org/abs/2110.11575", "authors": ["Spencer Smith", "Jacques Carette", "Peter Michalski", "Ao Dong", "Olu Owojaiye"], "categories": ["cs.SE", "D.2.0"], "comment": "35 pages, 3 figures", "summary": "To improve software development methods and tools for research software, we\nfirst need to understand the current state of the practice. Therefore, we have\ndeveloped a methodology for assessing the state of the software development\npractices for a given research software domain. For each domain we wish to\nanswer questions such as: i) What artifacts (documents, code, test cases, etc.)\nare present? ii) What tools are used? iii) What principles, process and\nmethodologies are used? iv) What are the pain points for developers? v) What\nactions are used to improve qualities like maintainability and reproducibility?\nTo answer these questions, our methodology prescribes the following steps: i)\nIdentify the domain; ii) Identify a list of candidate software packages; iii)\nFilter the list to a length of about 30 packages; iv) Gather source code and\ndocumentation for each package; v) Collect repository related data on each\nsoftware package, like number of stars, number of open issues, number of lines\nof code; vi) Fill in the measurement template (the template consists of 108\nquestions to assess 9 qualities (including the qualities of installability,\nusability and visibility)); vii) Interview developers (the interview consists\nof 20 questions and takes about an hour); viii) Rank the software using the\nAnalytic Hierarchy Process (AHP); and, ix) Analyze the data to answer the\nquestions posed above. A domain expert should be engaged throughout the\nprocess, to ensure that implicit information about the domain is properly\nrepresented and to assist with conducting an analysis of the commonalities and\nvariabilities between the 30 selected packages. Using our methodology,\nspreadsheet templates and AHP tool, we estimate (based on our experience with\nusing the process) the time to complete an assessment for a given domain at 173\nperson hours.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u79cd\u65b9\u6cd5\u6765\u8bc4\u4f30\u7814\u7a76\u8f6f\u4ef6\u7684\u5f00\u53d1\u5b9e\u8df5\uff0c\u5305\u62ec\u6536\u96c6\u6570\u636e\u3001\u8bbf\u8c08\u5f00\u53d1\u8005\u548c\u4f7f\u7528AHP\u8fdb\u884c\u6392\u540d\uff0c\u4ee5\u6539\u8fdb\u8f6f\u4ef6\u5f00\u53d1\u3002", "motivation": "\u4e3a\u4e86\u6539\u8fdb\u7814\u7a76\u8f6f\u4ef6\u7684\u5f00\u53d1\u65b9\u6cd5\u548c\u5de5\u5177\uff0c\u9996\u5148\u9700\u8981\u4e86\u89e3\u5176\u76ee\u524d\u7684\u5b9e\u8df5\u72b6\u51b5\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u62ec\u8bc6\u522b\u9886\u57df\u3001\u7b5b\u9009\u8f6f\u4ef6\u5305\u3001\u6536\u96c6\u6e90\u4ee3\u7801\u548c\u6587\u6863\u3001\u6536\u96c6\u5b58\u50a8\u5e93\u6570\u636e\u3001\u586b\u5199\u5305\u542b108\u4e2a\u95ee\u9898\u7684\u6d4b\u91cf\u6a21\u677f\u3001\u8fdb\u884c\u5305\u542b20\u4e2a\u95ee\u9898\u7684\u5f00\u53d1\u8005\u8bbf\u8c08\u3001\u4f7f\u7528\u5206\u6790\u5c42\u6b21\u8fc7\u7a0b\uff08AHP\uff09\u5bf9\u8f6f\u4ef6\u8fdb\u884c\u6392\u540d\uff0c\u6700\u540e\u5206\u6790\u6570\u636e\u4ee5\u56de\u7b54\u9884\u5b9a\u95ee\u9898\u3002\u6574\u4e2a\u8fc7\u7a0b\u9700\u8981\u9886\u57df\u4e13\u5bb6\u7684\u53c2\u4e0e\uff0c\u5e76\u4f30\u8ba1\u5b8c\u6210\u4e00\u9879\u8bc4\u4f30\u9700\u8981173\u4e2a\u4eba\u65f6\u3002", "result": "\u8be5\u65b9\u6cd5\u4e3a\u8bc4\u4f30\u7814\u7a76\u8f6f\u4ef6\u7684\u5f00\u53d1\u5b9e\u8df5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u6d41\u7a0b\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u5c42\u6b21\u8fc7\u7a0b\uff08AHP\uff09\u5bf9\u8f6f\u4ef6\u8fdb\u884c\u6392\u540d\uff0c\u4ee5\u8bc6\u522b\u5404\u4e2a\u9886\u57df\u8f6f\u4ef6\u5f00\u53d1\u7684\u901a\u7528\u6027\u548c\u5dee\u5f02\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u7814\u7a76\u8f6f\u4ef6\u9886\u57df\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u72b6\u51b5\u7684\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5e94\u7684\u5de5\u5177\u548c\u6a21\u677f\u3002"}}
{"id": "2110.08993", "title": "Typed Image-based Programming with Structure Editing", "url": "https://arxiv.org/abs/2110.08993", "pdf": "https://arxiv.org/pdf/2110.08993", "abs": "https://arxiv.org/abs/2110.08993", "authors": ["Jonathan Edwards", "Tomas Petricek"], "categories": ["cs.PL", "cs.SE"], "comment": "Accepted to: Human Aspects of Types and Reasoning Assistants\n  (HATRA'21), Oct 19, 2021, Chicago, US", "summary": "Many beloved programming systems are image-based: self-contained worlds that\npersist both code and data in a single file. Examples include Smalltalk, LISP,\nHyperCard, Flash, and spreadsheets. Image-based programming avoids much of the\ncomplexity of modern programming technology stacks and encourages more casual\nand exploratory programming. However conventional file-based programming has\nbetter support for collaboration and deployment. These problems have been\nblamed for the limited commercial success of Smalltalk. We propose to enable\ncollaboration in image-based programming via types and structure editing.\n  We focus on the problem of schema change on persistent data. We turn to\nstatic types, which paradoxically require more schema change but also provide a\nmechanism to express and execute those changes. To determine those changes we\nturn to structure editing, so that we can capture changes in type definitions\nwith sufficient fidelity to automatically adapt the data to suit. We conjecture\nthat typical schema changes can be handled through structure editing of static\ntypes.\n  That positions us to tackle collaboration with what could be called version\ncontrol for structure editing. We present a theory realizing this idea, which\nis our main technical contribution. While we focus here on editing types, if we\ncan extend the approach to cover the entire programming experience then it\nwould offer a new way to collaborate in image-based programming.", "AI": {"tldr": "Image-based programming (like Smalltalk) is simple but bad for collaboration. We fix this using static types and structure editing to manage data changes, creating a version control system for these edits.", "motivation": "Image-based programming systems offer a simpler and more exploratory programming experience but lack collaboration and deployment support compared to file-based systems. This limits their commercial success.", "method": "Using static types to manage schema changes and structure editing to capture type definition changes, enabling automatic data adaptation. Developing a theory for version control of structure editing to support collaboration.", "result": "The paper proposes a method to enable collaboration in image-based programming through static types and structure editing, focusing on schema change management for persistent data. A theory for version control of structure editing is presented as the main technical contribution, with the potential to extend to the entire programming experience.", "conclusion": "We present a theory for version control of structure editing, which can enable collaboration in image-based programming by handling schema changes in persistent data."}}
{"id": "2109.06630", "title": "Detecting Layout Templates in Complex Multiregion Files", "url": "https://arxiv.org/abs/2109.06630", "pdf": "https://arxiv.org/pdf/2109.06630", "abs": "https://arxiv.org/abs/2109.06630", "authors": ["Gerardo Vitagliano", "Lan Jiang", "Felix Naumann"], "categories": ["cs.IR"], "comment": null, "summary": "Spreadsheets are among the most commonly used file formats for data\nmanagement, distribution, and analysis. Their widespread employment makes it\neasy to gather large collections of data, but their flexible canvas-based\nstructure makes automated analysis difficult without heavy preparation. One of\nthe common problems that practitioners face is the presence of multiple,\nindependent regions in a single spreadsheet, possibly separated by repeated\nempty cells. We define such files as \"multiregion\" files. In collections of\nvarious spreadsheets, we can observe that some share the same layout. We\npresent the Mondrian approach to automatically identify layout templates across\nmultiple files and systematically extract the corresponding regions. Our\napproach is composed of three phases: first, each file is rendered as an image\nand inspected for elements that could form regions; then, using a clustering\nalgorithm, the identified elements are grouped to form regions; finally, every\nfile layout is represented as a graph and compared with others to find layout\ntemplates. We compare our method to state-of-the-art table recognition\nalgorithms on two corpora of real-world enterprise spreadsheets. Our approach\nshows the best performances in detecting reliable region boundaries within each\nfile and can correctly identify recurring layouts across files.", "AI": {"tldr": "Mondrian \u662f\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u53ef\u4ee5\u81ea\u52a8\u8bc6\u522b\u7535\u5b50\u8868\u683c\u4e2d\u7684\u5e03\u5c40\u6a21\u677f\uff0c\u5e76\u4ece\u5355\u4e2a\u6587\u4ef6\u4e2d\u63d0\u53d6\u76f8\u5e94\u7684\u533a\u57df\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u5e38\u7528\u4e8e\u6570\u636e\u7ba1\u7406\u3001\u5206\u53d1\u548c\u5206\u6790\uff0c\u4f46\u5176\u7075\u6d3b\u7684\u753b\u5e03\u7ed3\u6784\u7ed9\u81ea\u52a8\u5316\u5206\u6790\u5e26\u6765\u4e86\u6311\u6218\uff0c\u5c24\u5176\u662f\u5f53\u5355\u4e2a\u7535\u5b50\u8868\u683c\u5305\u542b\u591a\u4e2a\u3001\u7531\u7a7a\u5355\u5143\u683c\u5206\u9694\u7684\u72ec\u7acb\u533a\u57df\u65f6\uff08\u5373\u201c\u591a\u533a\u57df\u201d\u6587\u4ef6\uff09\u3002", "method": "Mondrian \u65b9\u6cd5\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a1. \u5c06\u7535\u5b50\u8868\u683c\u6e32\u67d3\u6210\u56fe\u50cf\u5e76\u68c0\u67e5\u53ef\u80fd\u6784\u6210\u533a\u57df\u7684\u5143\u7d20\uff1b2. \u4f7f\u7528\u805a\u7c7b\u7b97\u6cd5\u5c06\u8bc6\u522b\u51fa\u7684\u5143\u7d20\u5206\u7ec4\u5f62\u6210\u533a\u57df\uff1b3. \u5c06\u6bcf\u4e2a\u6587\u4ef6\u5e03\u5c40\u8868\u793a\u4e3a\u56fe\u5e76\u8fdb\u884c\u6bd4\u8f83\u4ee5\u67e5\u627e\u5e03\u5c40\u6a21\u677f\u3002", "result": "Mondrian \u65b9\u6cd5\u5728\u4e24\u4e2a\u771f\u5b9e\u7684\u4f01\u4e1a\u7535\u5b50\u8868\u683c\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u8868\u683c\u8bc6\u522b\u7b97\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u6bcf\u4e2a\u6587\u4ef6\u5185\u7684\u53ef\u9760\u533a\u57df\u8fb9\u754c\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u80fd\u6b63\u786e\u8bc6\u522b\u8de8\u6587\u4ef6\u7684\u91cd\u590d\u5e03\u5c40\u3002", "conclusion": "Mondrian \u65b9\u6cd5\u5728\u68c0\u6d4b\u53ef\u9760\u7684\u533a\u57df\u8fb9\u754c\u548c\u8de8\u6587\u4ef6\u8bc6\u522b\u91cd\u590d\u5e03\u5c40\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u8868\u683c\u8bc6\u522b\u7b97\u6cd5\u3002"}}
{"id": "2109.07267", "title": "JUBILEE: Secure Debt Relief and Forgiveness", "url": "https://arxiv.org/abs/2109.07267", "pdf": "https://arxiv.org/pdf/2109.07267", "abs": "https://arxiv.org/abs/2109.07267", "authors": ["David Cerezo S\u00e1nchez"], "categories": ["cs.CR", "cs.GT", "econ.GN", "q-fin.EC"], "comment": null, "summary": "JUBILEE is a securely computed mechanism for debt relief and forgiveness in a\nfrictionless manner without involving trusted third parties, leading to more\nharmonious debt settlements by incentivising the parties to truthfully reveal\ntheir private information. JUBILEE improves over all previous methods:\n  - individually rational, incentive-compatible, truthful/strategy-proof,\nex-post efficient, optimal mechanism for debt relief and forgiveness with\nprivate information\n  - by the novel introduction of secure computation techniques to debt relief,\nthe \"blessing of the debtor\" is hereby granted for the first time: debt\nsettlements with higher expected profits and a higher probability of success\nthan without using secure computation\n  A simple and practical implementation is included for \"The Secure\nSpreadsheet\". Another implementation is realised using Raziel smart contracts\non a blockchain with Pravuil consensus.", "AI": {"tldr": "JUBILEE\u662f\u4e00\u79cd\u5b89\u5168\u3001\u514d\u6469\u64e6\u7684\u503a\u52a1\u51cf\u514d\u673a\u5236\uff0c\u5229\u7528\u5b89\u5168\u8ba1\u7b97\u6fc0\u52b1\u4fe1\u606f\u62ab\u9732\uff0c\u63d0\u9ad8\u4e86\u503a\u52a1\u7ed3\u7b97\u7684\u6548\u7387\u548c\u6210\u529f\u7387\u3002", "motivation": "JUBILEE\u65e8\u5728\u89e3\u51b3\u503a\u52a1\u7ed3\u7b97\u4e2d\u7684\u75db\u70b9\uff0c\u901a\u8fc7\u5b89\u5168\u8ba1\u7b97\u6280\u672f\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u201c\u503a\u52a1\u4eba\u7684\u795d\u798f\u201d\uff0c\u5373\u5728\u4e0d\u4f7f\u7528\u5b89\u5168\u8ba1\u7b97\u7684\u60c5\u51b5\u4e0b\uff0c\u503a\u52a1\u7ed3\u7b97\u7684\u9884\u671f\u5229\u6da6\u66f4\u9ad8\uff0c\u6210\u529f\u7387\u66f4\u9ad8\u3002", "method": "JUBILEE\u662f\u4e00\u79cd\u5b89\u5168\u7684\u3001\u514d\u6469\u64e6\u7684\u503a\u52a1\u51cf\u514d\u548c\u8c41\u514d\u673a\u5236\uff0c\u5b83\u901a\u8fc7\u6fc0\u52b1\u5404\u65b9\u62ab\u9732\u79c1\u4eba\u4fe1\u606f\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u548c\u8c10\u7684\u503a\u52a1\u7ed3\u7b97\u3002", "result": "JUBILEE\u7684\u5b9e\u73b0\u57fa\u4e8e\u201c\u5b89\u5168\u7535\u5b50\u8868\u683c\u201d\u548c\u57fa\u4e8eRaziel\u667a\u80fd\u5408\u7ea6\u7684\u533a\u5757\u94fe\uff0c\u5b83\u5728\u4e2a\u4f53\u7406\u6027\u3001\u6fc0\u52b1\u76f8\u5bb9\u3001\u771f\u5b9e/\u7b56\u7565\u8bc1\u660e\u3001\u4e8b\u540e\u6548\u7387\u548c\u6700\u4f18\u673a\u5236\u65b9\u9762\u4f18\u4e8e\u6240\u6709\u5148\u524d\u7684\u65b9\u6cd5\u3002", "conclusion": "JUBILEE\u901a\u8fc7\u5f15\u5165\u5b89\u5168\u8ba1\u7b97\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u53ef\u4fe1\u7b2c\u4e09\u65b9\u5373\u53ef\u8fdb\u884c\u503a\u52a1\u51cf\u514d\u548c\u503a\u52a1\u8c41\u514d\uff0c\u80fd\u591f\u6fc0\u52b1\u5404\u65b9\u62ab\u9732\u79c1\u4eba\u4fe1\u606f\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u548c\u8c10\u7684\u503a\u52a1\u7ed3\u7b97\u3002"}}
{"id": "2108.11525", "title": "Supercomputing Enabled Deployable Analytics for Disaster Response", "url": "https://arxiv.org/abs/2108.11525", "pdf": "https://arxiv.org/pdf/2108.11525", "abs": "https://arxiv.org/abs/2108.11525", "authors": ["Kaira Samuel", "Jeremy Kepner", "Michael Jones", "Lauren Milechin", "Vijay Gadepally", "William Arcand", "David Bestor", "William Bergeron", "Chansup Byun", "Matthew Hubbell", "Michael Houle", "Anna Klein", "Victor Lopez", "Julie Mullen", "Andrew Prout", "Albert Reuther", "Antonio Rosa", "Sid Samsi", "Charles Yee", "Peter Michaleas"], "categories": ["cs.DB", "cs.DC", "cs.GR", "cs.HC", "cs.MM"], "comment": "5 pages, 11 figures, 17 references, accepted to IEEE HPEC 2021", "summary": "First responders and other forward deployed essential workers can benefit\nfrom advanced analytics. Limited network access and software security\nrequirements prevent the usage of standard cloud based microservice analytic\nplatforms that are typically used in industry. One solution is to precompute a\nwide range of analytics as files that can be used with standard preinstalled\nsoftware that does not require network access or additional software and can\nrun on a wide range of legacy hardware. In response to the COVID-19 pandemic,\nthis approach was tested for providing geo-spatial census data to allow quick\nanalysis of demographic data for better responding to emergencies. These data\nwere processed using the MIT SuperCloud to create several thousand Google Earth\nand Microsoft Excel files representative of many advanced analytics. The fast\nmapping of census data using Google Earth and Microsoft Excel has the potential\nto give emergency responders a powerful tool to improve emergency preparedness.\nOur approach displays relevant census data (total population, population under\n15, population over 65, median age) per census block, sorted by county, through\na Microsoft Excel spreadsheet (xlsx file) and Google Earth map (kml file). The\nspreadsheet interface includes features that allow users to convert between\ndifferent longitude and latitude coordinate units. For the Google Earth files,\na variety of absolute and relative colors maps of population density have been\nexplored to provide an intuitive and meaningful interface. Using several\nhundred cores on the MIT SuperCloud, new analytics can be generated in a few\nminutes.", "AI": {"tldr": "\u5728\u7f51\u7edc\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u9884\u8ba1\u7b97\u5206\u6790\u6570\u636e\uff08\u5982\u4eba\u53e3\u666e\u67e5\u6570\u636e\uff09\u4e3aExcel\u548cGoogle Earth\u751f\u6210\u6587\u4ef6\uff0c\u53ef\u4ee5\u4e3a\u7d27\u6025\u54cd\u5e94\u8005\u63d0\u4f9b\u5feb\u901f\u7684\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5206\u6790\u5de5\u5177\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728COVID-19\u5927\u6d41\u884c\u671f\u95f4\uff0c\u4e00\u7ebf\u5e94\u6025\u54cd\u5e94\u8005\u9762\u4e34\u7684\u7f51\u7edc\u8bbf\u95ee\u53d7\u9650\u548c\u8f6f\u4ef6\u5b89\u5168\u8981\u6c42\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u4e0d\u9700\u8981\u7f51\u7edc\u8fde\u63a5\u6216\u989d\u5916\u8f6f\u4ef6\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u5730\u7406\u7a7a\u95f4\u4eba\u53e3\u666e\u67e5\u6570\u636e\uff08\u5305\u62ec\u603b\u4eba\u53e3\u300115\u5c81\u4ee5\u4e0b\u4eba\u53e3\u300165\u5c81\u4ee5\u4e0a\u4eba\u53e3\u548c\u5e73\u5747\u5e74\u9f84\uff09\u5904\u7406\u6210Excel\u6587\u4ef6\uff08xlsx\uff09\u548cGoogle Earth\u6587\u4ef6\uff08kml\uff09\uff0c\u5e76\u80fd\u5728MIT SuperCloud\u4e0a\u5feb\u901f\u751f\u6210\u3002", "result": "\u6210\u529f\u5c06\u4eba\u53e3\u666e\u67e5\u6570\u636e\u4ee5Excel\u548cGoogle Earth\u6587\u4ef6\u7684\u5f62\u5f0f\u63d0\u4f9b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4eba\u53e3\u5bc6\u5ea6\u6570\u636e\u7684\u5feb\u901f\u6620\u5c04\u548c\u53ef\u89c6\u5316\u5206\u6790\uff0c\u7528\u6237\u53ef\u4ee5\u65b9\u4fbf\u5730\u8fdb\u884c\u5750\u6807\u5355\u4f4d\u8f6c\u6362\uff0c\u5e76\u63a2\u7d22\u4e0d\u540c\u989c\u8272\u6620\u5c04\u65b9\u6848\u4ee5\u76f4\u89c2\u5c55\u793a\u4eba\u53e3\u5bc6\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u5206\u6790\u9884\u5148\u8ba1\u7b97\u4e3a\u6587\u4ef6\uff0c\u4e3a\u7f51\u7edc\u8bbf\u95ee\u53d7\u9650\u7684\u7d27\u6025\u54cd\u5e94\u8005\u63d0\u4f9b\u4e86\u5730\u7406\u7a7a\u95f4\u4eba\u53e3\u666e\u67e5\u6570\u636e\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4ece\u800c\u80fd\u591f\u5728\u5404\u79cd\u786c\u4ef6\u4e0a\u8fdb\u884c\u5feb\u901f\u5206\u6790\u3002"}}
{"id": "2108.00567", "title": "Agile Elicitation of Scalability Requirements for Open Systems: A Case Study", "url": "https://arxiv.org/abs/2108.00567", "pdf": "https://arxiv.org/pdf/2108.00567", "abs": "https://arxiv.org/abs/2108.00567", "authors": ["Gunnar Brataas", "Antonio Martini", "Geir Kjetil Hanssen", "Georg R\u00e6der"], "categories": ["cs.SE", "cs.PF", "C.4; D.2.1"], "comment": "36 pages, 7 figures, 6 tables, accepted for publication in Journal of\n  Systems and Software", "summary": "Eliciting scalability requirements during agile software development is\ncomplicated and poorly described in previous research. This article presents a\nlightweight artifact for eliciting scalability requirements during agile\nsoftware development: the ScrumScale model. The ScrumScale model is a simple\nspreadsheet. The scalability concepts underlying the ScrumScale model are\nclarified in this design science research, which also utilizes coordination\ntheory. This paper describes the open banking case study, where a legacy\nbanking system becomes open. This challenges the scalability of this legacy\nsystem. The first step in understanding this challenge is to elicit the new\nscalability requirements. In the open banking case study, key stakeholders from\nTietoEVRY spent 55 hours eliciting TietoEVRY's open banking project's\nscalability requirements. According to TietoEVRY, the ScrumScale model provided\na systematic way of producing scalability requirements. For TietoEVRY, the\nscalability concepts behind the ScrumScale model also offered significant\nadvantages in dialogues with other stakeholders.", "AI": {"tldr": "\u63d0\u51faScrumScale\u6a21\u578b\uff0c\u4e00\u79cd\u83b7\u53d6\u654f\u6377\u5f00\u53d1\u4e2d\u53ef\u6269\u5c55\u6027\u9700\u6c42\u7684\u7b80\u4fbf\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5f00\u653e\u94f6\u884c\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5bf9\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u53ef\u6269\u5c55\u6027\u9700\u6c42\u83b7\u53d6\u7684\u63cf\u8ff0\u4e0d\u8db3\u4e14\u590d\u6742\uff0c\u9700\u8981\u66f4\u8f7b\u91cf\u7ea7\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u7ed3\u5408\u534f\u8c03\u7406\u8bba\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86ScrumScale\u6a21\u578b\uff08\u4e00\u4e2a\u7b80\u5355\u7684\u7535\u5b50\u8868\u683c\uff09\uff0c\u7528\u4e8e\u83b7\u53d6\u53ef\u6269\u5c55\u6027\u9700\u6c42\u3002", "result": "ScrumScale\u6a21\u578b\u88ab\u8bc1\u660e\u80fd\u7cfb\u7edf\u6027\u5730\u751f\u6210\u53ef\u6269\u5c55\u6027\u9700\u6c42\uff0c\u5e76\u5728\u5f00\u653e\u94f6\u884c\u6848\u4f8b\u7814\u7a76\u4e2d\uff08\u6d89\u53ca55\u5c0f\u65f6\u7684\u9700\u6c42\u83b7\u53d6\uff09\u663e\u793a\u51fa\u4f18\u52bf\uff0c\u63d0\u9ad8\u4e86\u5229\u76ca\u76f8\u5173\u8005\u4e4b\u95f4\u7684\u6c9f\u901a\u6548\u7387\u3002", "conclusion": "ScrumScale\u6a21\u578b\u4e3a\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u7b80\u5316\u7684\u53ef\u6269\u5c55\u6027\u9700\u6c42\u83b7\u53d6\u65b9\u6cd5\uff0c\u5e76\u5728\u5f00\u653e\u94f6\u884c\u6848\u4f8b\u7814\u7a76\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u4e3a\u5229\u76ca\u76f8\u5173\u8005\u5bf9\u8bdd\u63d0\u4f9b\u4e86\u4f18\u52bf\u3002"}}
{"id": "2107.13957", "title": "Towards Semantic Interoperability in Historical Research: Documenting Research Data and Knowledge with Synthesis", "url": "https://arxiv.org/abs/2107.13957", "pdf": "https://arxiv.org/pdf/2107.13957", "abs": "https://arxiv.org/abs/2107.13957", "authors": ["Pavlos Fafalios", "Konstantina Konsolaki", "Lida Charami", "Kostas Petrakis", "Manos Paterakis", "Dimitris Angelakis", "Yannis Tzitzikas", "Chrysoula Bekiari", "Martin Doerr"], "categories": ["cs.DL", "cs.DB"], "comment": "This is a preprint of an article accepted for publication at the 20th\n  International Semantic Web Conference (ISWC 2021)", "summary": "A vast area of research in historical science concerns the documentation and\nstudy of artefacts and related evidence. Current practice mostly uses\nspreadsheets or simple relational databases to organise the information as rows\nwith multiple columns of related attributes. This form offers itself for data\nanalysis and scholarly interpretation, however it also poses problems including\ni) the difficulty for collaborative but controlled documentation by a large\nnumber of users, ii) the lack of representation of the details from which the\ndocumented relations are inferred, iii) the difficulty to extend the underlying\ndata structures as well as to combine and integrate data from multiple and\ndiverse information sources, and iv) the limitation to reuse the data beyond\nthe context of a particular research activity. To support historians to cope\nwith these problems, in this paper we describe the Synthesis documentation\nsystem and its use by a large number of historians in the context of an ongoing\nresearch project in the field of History of Art. The system is Web-based and\ncollaborative, and makes use of existing standards for information\ndocumentation and publication (CIDOC-CRM, RDF), focusing on semantic\ninteroperability and the production of data of high value and long-term\nvalidity.", "AI": {"tldr": "Synthesis\u662f\u4e00\u4e2a\u57fa\u4e8eWeb\u7684\u534f\u4f5c\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6587\u7269\u8bb0\u5f55\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u8d28\u91cf\u548c\u4e92\u64cd\u4f5c\u6027\uff0c\u5e76\u5df2\u5728\u827a\u672f\u53f2\u7814\u7a76\u9879\u76ee\u4e2d\u6210\u529f\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u7684\u6587\u7269\u8bb0\u5f55\u5b9e\u8df5\uff08\u5982\u4f7f\u7528\u7535\u5b50\u8868\u683c\u6216\u5173\u7cfb\u6570\u636e\u5e93\uff09\u5b58\u5728\u8bf8\u591a\u95ee\u9898\uff0c\u5305\u62ec\u534f\u4f5c\u6027\u5dee\u3001\u96be\u4ee5\u8868\u793a\u63a8\u65ad\u5173\u7cfb\u7684\u7ec6\u8282\u3001\u6570\u636e\u7ed3\u6784\u6269\u5c55\u548c\u6574\u5408\u56f0\u96be\u4ee5\u53ca\u6570\u636e\u91cd\u7528\u6027\u4f4e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSynthesis\u7684\u57fa\u4e8eWeb\u7684\u534f\u4f5c\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5229\u7528CIDOC-CRM\u548cRDF\u7b49\u73b0\u6709\u6807\u51c6\uff0c\u652f\u6301\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\uff0c\u65e8\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u957f\u4e45\u6709\u6548\u7684\u6570\u636e\u3002", "result": "Synthesis\u7cfb\u7edf\u5df2\u88ab\u827a\u672f\u53f2\u9886\u57df\u7684\u4e00\u4e2a\u5927\u578b\u7814\u7a76\u9879\u76ee\u91c7\u7528\uff0c\u5e76\u6709\u5927\u91cf\u5386\u53f2\u5b66\u5bb6\u4f7f\u7528\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u52a9\u4e8e\u5386\u53f2\u5b66\u5bb6\u5e94\u5bf9\u6587\u7269\u548c\u76f8\u5173\u8bc1\u636e\u7684\u8bb0\u5f55\u548c\u7814\u7a76\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2010.12537", "title": "TUTA: Tree-based Transformers for Generally Structured Table Pre-training", "url": "https://arxiv.org/abs/2010.12537", "pdf": "https://arxiv.org/pdf/2010.12537", "abs": "https://arxiv.org/abs/2010.12537", "authors": ["Zhiruo Wang", "Haoyu Dong", "Ran Jia", "Jia Li", "Zhiyi Fu", "Shi Han", "Dongmei Zhang"], "categories": ["cs.IR", "cs.AI", "cs.DB"], "comment": "KDD'21", "summary": "Tables are widely used with various structures to organize and present data.\nRecent attempts on table understanding mainly focus on relational tables, yet\noverlook to other common table structures. In this paper, we propose TUTA, a\nunified pre-training architecture for understanding generally structured\ntables. Noticing that understanding a table requires spatial, hierarchical, and\nsemantic information, we enhance transformers with three novel structure-aware\nmechanisms. First, we devise a unified tree-based structure, called a\nbi-dimensional coordinate tree, to describe both the spatial and hierarchical\ninformation of generally structured tables. Upon this, we propose tree-based\nattention and position embedding to better capture the spatial and hierarchical\ninformation. Moreover, we devise three progressive pre-training objectives to\nenable representations at the token, cell, and table levels. We pre-train TUTA\non a wide range of unlabeled web and spreadsheet tables and fine-tune it on two\ncritical tasks in the field of table structure understanding: cell type\nclassification and table type classification. Experiments show that TUTA is\nhighly effective, achieving state-of-the-art on five widely-studied datasets.", "AI": {"tldr": "TUTA\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u7406\u89e3\u901a\u7528\u7ed3\u6784\u5316\u8868\uff0c\u901a\u8fc7\u5176\u65b0\u9896\u7684\u7ed3\u6784\u611f\u77e5\u673a\u5236\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\u3002", "motivation": "\u73b0\u6709\u8868\u7406\u89e3\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5173\u7cfb\u8868\uff0c\u800c\u5ffd\u7565\u4e86\u5176\u4ed6\u5e38\u89c1\u7684\u8868\u7ed3\u6784\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u7406\u89e3\u901a\u7528\u7ed3\u6784\u5316\u8868\u3002", "method": "TUTA\u91c7\u7528\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u3001\u57fa\u4e8e\u6811\u7684\u7ed3\u6784\uff08\u53cc\u7ef4\u5ea6\u5750\u6807\u6811\uff09\u6765\u63cf\u8ff0\u901a\u7528\u7ed3\u6784\u5316\u8868\u7684\u7a7a\u95f4\u548c\u5c42\u6b21\u4fe1\u606f\uff0c\u5e76\u7ed3\u5408\u4e86\u57fa\u4e8e\u6811\u7684\u6ce8\u610f\u529b\u548c\u4f4d\u7f6e\u5d4c\u5165\u3002\u6b64\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u4e09\u79cd\u6e10\u8fdb\u5f0f\u7684\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u4ee5\u5b9e\u73b0\u4ee4\u724c\u3001\u5355\u5143\u683c\u548c\u8868\u7ea7\u522b\u7684\u8868\u793a\u3002", "result": "TUTA\u5728\u4e24\u4e2a\u5173\u952e\u4efb\u52a1\u4e0a\u90fd\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\uff0c\u5728\u4e94\u4e2a\u5e7f\u6cdb\u7814\u7a76\u7684\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "TUTA\u5728\u5355\u5143\u683c\u7c7b\u578b\u5206\u7c7b\u548c\u8868\u7c7b\u578b\u5206\u7c7b\u4e24\u4e2a\u5173\u952e\u7684\u8868\u7ed3\u6784\u7406\u89e3\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\uff0c\u5728\u4e94\u4e2a\u5e7f\u6cdb\u7814\u7a76\u7684\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2106.15005", "title": "Untidy Data: The Unreasonable Effectiveness of Tables", "url": "https://arxiv.org/abs/2106.15005", "pdf": "https://arxiv.org/pdf/2106.15005", "abs": "https://arxiv.org/abs/2106.15005", "authors": ["Lyn Bartram", "Michael Correll", "Melanie Tory"], "categories": ["cs.HC"], "comment": null, "summary": "Working with data in table form is usually considered a preparatory and\ntedious step in the sensemaking pipeline; a way of getting the data ready for\nmore sophisticated visualization and analytical tools. But for many people,\nspreadsheets -- the quintessential table tool -- remain a critical part of\ntheir information ecosystem, allowing them to interact with their data in ways\nthat are hidden or abstracted in more complex tools. This is particularly true\nfor data workers: people who work with data as part of their job but do not\nidentify as professional analysts or data scientists. We report on a\nqualitative study of how these workers interact with and reason about their\ndata. Our findings show that data tables serve a broader purpose beyond data\ncleanup at the initial stage of a linear analytic flow: users want to see and\n\"get their hands on\" the underlying data throughout the analytics process,\nreshaping and augmenting it to support sensemaking. They reorganize, mark up,\nlayer on levels of detail, and spawn alternatives within the context of the\nbase data. These direct interactions and human-readable table representations\nform a rich and cognitively important part of building understanding of what\nthe data mean and what they can do with it. We argue that interactive tables\nare an important visualization idiom in their own right; that the direct data\ninteraction they afford offers a fertile design space for visual analytics; and\nthat sense making can be enriched by more flexible human-data interaction than\nis currently supported in visual analytics tools.", "AI": {"tldr": "\u7535\u5b50\u8868\u683c\u4e0d\u4ec5\u4ec5\u662f\u6570\u636e\u6e05\u7406\u5de5\u5177\uff0c\u7528\u6237\u5e0c\u671b\u5728\u6574\u4e2a\u5206\u6790\u8fc7\u7a0b\u4e2d\u90fd\u80fd\u76f4\u63a5\u64cd\u4f5c\u6570\u636e\u3002\u4ea4\u4e92\u5f0f\u8868\u683c\u662f\u4e00\u79cd\u91cd\u8981\u7684\u53ef\u89c6\u5316\u5f62\u5f0f\uff0c\u503c\u5f97\u5728\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\u4e2d\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002", "motivation": "\u8bb8\u591a\u6570\u636e\u5de5\u4f5c\u8005\u5728\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\u4e2d\u4ecd\u7136\u4f9d\u8d56\u7535\u5b50\u8868\u683c\u7b49\u8868\u683c\u5de5\u5177\uff0c\u8fd9\u4e9b\u5de5\u5177\u80fd\u8ba9\u4ed6\u4eec\u4ee5\u66f4\u590d\u6742\u5de5\u5177\u6240\u9690\u85cf\u6216\u62bd\u8c61\u7684\u65b9\u5f0f\u4e0e\u6570\u636e\u8fdb\u884c\u4ea4\u4e92\u3002", "method": "\u5b9a\u6027\u7814\u7a76\uff0c\u65e8\u5728\u89c2\u5bdf\u6570\u636e\u5de5\u4f5c\u8005\u5982\u4f55\u4e0e\u6570\u636e\u4ea4\u4e92\u548c\u63a8\u7406\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6570\u636e\u8868\u4e0d\u4ec5\u5728\u5206\u6790\u6d41\u7a0b\u7684\u521d\u59cb\u9636\u6bb5\u7528\u4e8e\u6570\u636e\u6e05\u7406\uff0c\u5728\u6574\u4e2a\u5206\u6790\u8fc7\u7a0b\u4e2d\uff0c\u7528\u6237\u90fd\u5e0c\u671b\u80fd\u591f\u76f4\u63a5\u64cd\u4f5c\u3001\u91cd\u5851\u548c\u589e\u5f3a\u6570\u636e\uff0c\u4ee5\u4fbf\u652f\u6301\u5176\u5206\u6790\u8fc7\u7a0b\u3002\u7528\u6237\u5728\u57fa\u672c\u6570\u636e\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u91cd\u7ec4\u3001\u6807\u8bb0\u3001\u6dfb\u52a0\u8be6\u7ec6\u4fe1\u606f\u548c\u751f\u6210\u4e0d\u540c\u7248\u672c\u7684\u6570\u636e\u3002\u8fd9\u4e9b\u76f4\u63a5\u4ea4\u4e92\u548c\u4eba\u7c7b\u53ef\u8bfb\u7684\u8868\u683c\u8868\u793a\u6784\u6210\u4e86\u7406\u89e3\u6570\u636e\u542b\u4e49\u548c\u53ef\u64cd\u4f5c\u6027\u7684\u91cd\u8981\u8ba4\u77e5\u7ec4\u6210\u90e8\u5206\u3002", "conclusion": "\u4ea4\u4e92\u5f0f\u8868\u683c\u672c\u8eab\u5c31\u662f\u4e00\u79cd\u91cd\u8981\u7684\u53ef\u89c6\u5316\u5f62\u5f0f\uff0c\u5b83\u4eec\u63d0\u4f9b\u7684\u76f4\u63a5\u6570\u636e\u4ea4\u4e92\u4e3a\u53ef\u89c6\u5316\u5206\u6790\u5f00\u8f9f\u4e86\u4e30\u5bcc\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5e76\u4e14\u66f4\u7075\u6d3b\u7684\u4eba-\u6570\u636e\u4ea4\u4e92\u53ef\u4ee5\u4e30\u5bcc\u5206\u6790\u8fc7\u7a0b\u3002"}}
{"id": "2008.11015", "title": "Table2Charts: Recommending Charts by Learning Shared Table Representations", "url": "https://arxiv.org/abs/2008.11015", "pdf": "https://arxiv.org/pdf/2008.11015", "abs": "https://arxiv.org/abs/2008.11015", "authors": ["Mengyu Zhou", "Qingtao Li", "Xinyi He", "Yuejiang Li", "Yibo Liu", "Wei Ji", "Shi Han", "Yining Chen", "Daxin Jiang", "Dongmei Zhang"], "categories": ["cs.DB", "cs.CL", "cs.HC"], "comment": "9 + 2(appendix) pages, accepted by KDD'21 conference", "summary": "It is common for people to create different types of charts to explore a\nmulti-dimensional dataset (table). However, to recommend commonly composed\ncharts in real world, one should take the challenges of efficiency, imbalanced\ndata and table context into consideration. In this paper, we propose\nTable2Charts framework which learns common patterns from a large corpus of\n(table, charts) pairs. Based on deep Q-learning with copying mechanism and\nheuristic searching, Table2Charts does table-to-sequence generation, where each\nsequence follows a chart template. On a large spreadsheet corpus with 165k\ntables and 266k charts, we show that Table2Charts could learn a shared\nrepresentation of table fields so that recommendation tasks on different chart\ntypes could mutually enhance each other. Table2Charts outperforms other chart\nrecommendation systems in both multi-type task (with doubled recall numbers\nR@3=0.61 and R@1=0.43) and human evaluations.", "AI": {"tldr": "Table2Charts framework uses deep Q-learning and heuristic searching to recommend charts from tables, outperforming existing systems by a large margin.", "motivation": "Recommending commonly composed charts in real-world scenarios faces challenges such as efficiency, imbalanced data, and table context. This paper addresses these challenges.", "method": "Table2Charts framework uses deep Q-learning with a copying mechanism and heuristic searching to perform table-to-sequence generation, where each sequence follows a chart template. It learns common patterns from a large corpus of (table, charts) pairs.", "result": "Table2Charts could learn a shared representation of table fields, enabling recommendation tasks across different chart types to mutually enhance each other. It significantly outperforms other chart recommendation systems.", "conclusion": "Table2Charts framework outperforms other chart recommendation systems in both multi-type task and human evaluations, achieving doubled recall numbers (R@3=0.61 and R@1=0.43)."}}
{"id": "2106.15339", "title": "SpreadsheetCoder: Formula Prediction from Semi-structured Context", "url": "https://arxiv.org/abs/2106.15339", "pdf": "https://arxiv.org/pdf/2106.15339", "abs": "https://arxiv.org/abs/2106.15339", "authors": ["Xinyun Chen", "Petros Maniatis", "Rishabh Singh", "Charles Sutton", "Hanjun Dai", "Max Lin", "Denny Zhou"], "categories": ["cs.SE", "cs.LG", "cs.PL"], "comment": "Published in ICML 2021", "summary": "Spreadsheet formula prediction has been an important program synthesis\nproblem with many real-world applications. Previous works typically utilize\ninput-output examples as the specification for spreadsheet formula synthesis,\nwhere each input-output pair simulates a separate row in the spreadsheet.\nHowever, this formulation does not fully capture the rich context in real-world\nspreadsheets. First, spreadsheet data entries are organized as tables, thus\nrows and columns are not necessarily independent from each other. In addition,\nmany spreadsheet tables include headers, which provide high-level descriptions\nof the cell data. However, previous synthesis approaches do not consider\nheaders as part of the specification. In this work, we present the first\napproach for synthesizing spreadsheet formulas from tabular context, which\nincludes both headers and semi-structured tabular data. In particular, we\npropose SpreadsheetCoder, a BERT-based model architecture to represent the\ntabular context in both row-based and column-based formats. We train our model\non a large dataset of spreadsheets, and demonstrate that SpreadsheetCoder\nachieves top-1 prediction accuracy of 42.51%, which is a considerable\nimprovement over baselines that do not employ rich tabular context. Compared to\nthe rule-based system, SpreadsheetCoder assists 82% more users in composing\nformulas on Google Sheets.", "AI": {"tldr": "SpreadsheetCoder\u5229\u7528\u8868\u683c\u7684\u884c\u5217\u4e0a\u4e0b\u6587\uff08\u5305\u62ec\u8868\u5934\uff09\u6765\u5408\u6210\u7535\u5b50\u8868\u683c\u516c\u5f0f\uff0c\u5728\u51c6\u786e\u6027\u548c\u7528\u6237\u8f85\u52a9\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4e4b\u524d\u7684\u8868\u683c\u516c\u5f0f\u5408\u6210\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u771f\u5b9e\u8868\u683c\u4e2d\u7684\u4e30\u5bcc\u4e0a\u4e0b\u6587\uff0c\u4f8b\u5982\u8868\u5934\u548c\u975e\u72ec\u7acb\u7684\u884c\u5217\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpreadsheetCoder\u7684\u57fa\u4e8eBERT\u7684\u6a21\u578b\u67b6\u6784\uff0c\u8be5\u6a21\u578b\u4ee5\u884c\u548c\u5217\u4e3a\u57fa\u7840\u8868\u793a\u8868\u683c\u4e0a\u4e0b\u6587\u3002", "result": "SpreadsheetCoder\u5b9e\u73b0\u4e8642.51%\u7684Top-1\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u672a\u4f7f\u7528\u4e30\u5bcc\u8868\u683c\u4e0a\u4e0b\u6587\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "SpreadsheetCoder\u5728Google\u8868\u683c\u4e2d\u8f85\u52a9\u4e8682%\u7684\u516c\u5f0f\u7ec4\u5408\u7528\u6237\uff0c\u76f8\u6bd4\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\u6709\u6240\u63d0\u5347\u3002"}}
{"id": "2106.13500", "title": "TableSense: Spreadsheet Table Detection with Convolutional Neural Networks", "url": "https://arxiv.org/abs/2106.13500", "pdf": "https://arxiv.org/pdf/2106.13500", "abs": "https://arxiv.org/abs/2106.13500", "authors": ["Haoyu Dong", "Shijie Liu", "Shi Han", "Zhouyu Fu", "Dongmei Zhang"], "categories": ["cs.IR"], "comment": null, "summary": "Spreadsheet table detection is the task of detecting all tables on a given\nsheet and locating their respective ranges. Automatic table detection is a key\nenabling technique and an initial step in spreadsheet data intelligence.\nHowever, the detection task is challenged by the diversity of table structures\nand table layouts on the spreadsheet. Considering the analogy between a cell\nmatrix as spreadsheet and a pixel matrix as image, and encouraged by the\nsuccessful application of Convolutional Neural Networks (CNN) in computer\nvision, we have developed TableSense, a novel end-to-end framework for\nspreadsheet table detection. First, we devise an effective cell featurization\nscheme to better leverage the rich information in each cell; second, we develop\nan enhanced convolutional neural network model for table detection to meet the\ndomain-specific requirement on precise table boundary detection; third, we\npropose an effective uncertainty metric to guide an active learning based smart\nsampling algorithm, which enables the efficient build-up of a training dataset\nwith 22,176 tables on 10,220 sheets with broad coverage of diverse table\nstructures and layouts. Our evaluation shows that TableSense is highly\neffective with 91.3\\% recall and 86.5\\% precision in EoB-2 metric, a\nsignificant improvement over both the current detection algorithm that are used\nin commodity spreadsheet tools and state-of-the-art convolutional neural\nnetworks in computer vision.", "AI": {"tldr": "TableSense is a novel CNN-based framework for detecting tables in spreadsheets, achieving high accuracy by employing a unique cell featurization scheme, an enhanced CNN model, and an active learning approach for dataset creation.", "motivation": "The diversity of table structures and layouts in spreadsheets poses a challenge for automatic table detection, a crucial step in spreadsheet data intelligence.", "method": "TableSense, an end-to-end framework using a cell featurization scheme, an enhanced CNN model for precise boundary detection, and an uncertainty metric for active learning-based smart sampling.", "result": "The developed framework achieved 91.3% recall and 86.5% precision on the EoB-2 metric, demonstrating significant improvement over commodity spreadsheet tools and state-of-the-art computer vision CNNs. A training dataset of 22,176 tables from 10,220 sheets was efficiently built.", "conclusion": "TableSense is highly effective for spreadsheet table detection, significantly outperforming existing methods with 91.3% recall and 86.5% precision on the EoB-2 metric."}}
{"id": "2106.03096", "title": "TabularNet: A Neural Network Architecture for Understanding Semantic Structures of Tabular Data", "url": "https://arxiv.org/abs/2106.03096", "pdf": "https://arxiv.org/pdf/2106.03096", "abs": "https://arxiv.org/abs/2106.03096", "authors": ["Lun Du", "Fei Gao", "Xu Chen", "Ran Jia", "Junshan Wang", "Jiang Zhang", "Shi Han", "Dongmei Zhang"], "categories": ["cs.LG"], "comment": "10 pages, 7 figures, to be published in the proceedings of KDD 2021", "summary": "Tabular data are ubiquitous for the widespread applications of tables and\nhence have attracted the attention of researchers to extract underlying\ninformation. One of the critical problems in mining tabular data is how to\nunderstand their inherent semantic structures automatically. Existing studies\ntypically adopt Convolutional Neural Network (CNN) to model the spatial\ninformation of tabular structures yet ignore more diverse relational\ninformation between cells, such as the hierarchical and paratactic\nrelationships. To simultaneously extract spatial and relational information\nfrom tables, we propose a novel neural network architecture, TabularNet. The\nspatial encoder of TabularNet utilizes the row/column-level Pooling and the\nBidirectional Gated Recurrent Unit (Bi-GRU) to capture statistical information\nand local positional correlation, respectively. For relational information, we\ndesign a new graph construction method based on the WordNet tree and adopt a\nGraph Convolutional Network (GCN) based encoder that focuses on the\nhierarchical and paratactic relationships between cells. Our neural network\narchitecture can be a unified neural backbone for different understanding tasks\nand utilized in a multitask scenario. We conduct extensive experiments on three\nclassification tasks with two real-world spreadsheet data sets, and the results\ndemonstrate the effectiveness of our proposed TabularNet over state-of-the-art\nbaselines.", "AI": {"tldr": "\u63d0\u51faTabularNet\uff0c\u4e00\u79cd\u7ed3\u5408\u7a7a\u95f4\u548c\u5173\u7cfb\u4fe1\u606f\u63d0\u53d6\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u8868\u683c\u6570\u636e\u7406\u89e3\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u4e3a\u4e86\u81ea\u52a8\u7406\u89e3\u8868\u683c\u6570\u636e\u4e2d\u56fa\u6709\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u5f25\u8865\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u7a7a\u95f4\u4fe1\u606f\u800c\u5ffd\u7565\u5173\u7cfb\u4fe1\u606f\uff08\u5982\u5c42\u7ea7\u548c\u5e76\u5217\u5173\u7cfb\uff09\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTabularNet\u7684\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5305\u62ec\u4e00\u4e2a\u7a7a\u95f4\u7f16\u7801\u5668\uff08\u5229\u7528\u884c/\u5217\u6c60\u5316\u548c\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff09\u548c\u4e00\u4e2a\u57fa\u4e8e\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u7684\u7f16\u7801\u5668\uff08\u57fa\u4e8eWordNet\u6811\u6784\u5efa\u56fe\uff09\uff0c\u4ee5\u540c\u65f6\u63d0\u53d6\u7a7a\u95f4\u548c\u5173\u7cfb\u4fe1\u606f\u3002", "result": "TabularNet\u5728\u4e09\u4e2a\u5206\u7c7b\u4efb\u52a1\u548c\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u8868\u683c\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u63d0\u51fa\u7684TabularNet\u5728\u4e09\u4e2a\u5206\u7c7b\u4efb\u52a1\u548c\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u8868\u683c\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u3002"}}
{"id": "2105.13733", "title": "FAST CAT: Collaborative Data Entry and Curation for Semantic Interoperability in Digital Humanities", "url": "https://arxiv.org/abs/2105.13733", "pdf": "https://arxiv.org/pdf/2105.13733", "abs": "https://arxiv.org/abs/2105.13733", "authors": ["Pavlos Fafalios", "Kostas Petrakis", "Georgios Samaritakis", "Korina Doerr", "Athina Kritsotaki", "Yannis Tzitzikas", "Martin Doerr"], "categories": ["cs.DL", "cs.DB"], "comment": "This is a preprint of an article accepted for publication at the ACM\n  Journal on Computing and Cultural Heritage (JOCCH)", "summary": "Descriptive and empirical sciences, such as History, are the sciences that\ncollect, observe and describe phenomena in order to explain them and draw\ninterpretative conclusions about influences, driving forces and impacts under\ngiven circumstances. Spreadsheet software and relational database management\nsystems are still the dominant tools for quantitative analysis and overall data\nmanagement in these these sciences, allowing researchers to directly analyse\nthe gathered data and perform scholarly interpretation. However, this current\npractice has a set of limitations, including the high dependency of the\ncollected data on the initial research hypothesis, usually useless for other\nresearch, the lack of representation of the details from which the registered\nrelations are inferred, and the difficulty to revisit the original data sources\nfor verification, corrections or improvements. To cope with these problems, in\nthis paper we present FAST CAT, a collaborative system for assistive data entry\nand curation in Digital Humanities and similar forms of empirical research. We\ndescribe the related challenges, the overall methodology we follow for\nsupporting semantic interoperability, and discuss the use of FAST CAT in the\ncontext of a European (ERC) project of Maritime History, called SeaLiT, which\nexamines economic, social and demographic impacts of the introduction of\nsteamboats in the Mediterranean area between the 1850s and the 1920s.", "AI": {"tldr": "FAST CAT\u7cfb\u7edf\u901a\u8fc7\u652f\u6301\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\uff0c\u89e3\u51b3\u4e86\u6570\u5b57\u4eba\u6587\u548c\u5b9e\u8bc1\u7814\u7a76\u4e2d\u7684\u6570\u636e\u5f55\u5165\u548c\u7ba1\u7406\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u7684\u53ef\u7528\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u5e76\u4ee5\u6d77\u4e8b\u53f2\u9879\u76ee\u4e3a\u4f8b\u8fdb\u884c\u4e86\u8bf4\u660e\u3002", "motivation": "\u5f53\u524d\u5386\u53f2\u5b66\u7b49\u63cf\u8ff0\u6027\u548c\u7ecf\u9a8c\u79d1\u5b66\u5728\u6570\u636e\u7ba1\u7406\u548c\u5206\u6790\u65b9\u9762\u4f9d\u8d56\u7535\u5b50\u8868\u683c\u548c\u5173\u7cfb\u6570\u636e\u5e93\uff0c\u5b58\u5728\u6570\u636e\u4f9d\u8d56\u7814\u7a76\u5047\u8bbe\u3001\u7f3a\u4e4f\u7ec6\u8282\u8868\u5f81\u3001\u96be\u4ee5\u9a8c\u8bc1\u539f\u59cb\u6570\u636e\u7b49\u5c40\u9650\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u6570\u636e\u7ba1\u7406\u7cfb\u7edf\u3002", "method": "\u4ecb\u7ecd\u4e86FAST CAT\u7cfb\u7edf\uff0c\u4e00\u4e2a\u534f\u4f5c\u5f0f\u7cfb\u7edf\uff0c\u7528\u4e8e\u6570\u5b57\u4eba\u6587\u548c\u7c7b\u4f3c\u5b9e\u8bc1\u7814\u7a76\u4e2d\u7684\u8f85\u52a9\u6570\u636e\u5f55\u5165\u548c\u7ba1\u7406\u3002\u8be5\u7cfb\u7edf\u652f\u6301\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\uff0c\u5e76\u7ed3\u5408\u4e86\u6b27\u6d32\u7814\u7a76\u7406\u4e8b\u4f1a\uff08ERC\uff09\u7684\u6d77\u4e8b\u53f2\u9879\u76ee\u201cSeaLiT\u201d\u7684\u6848\u4f8b\uff0c\u8be5\u9879\u76ee\u7814\u7a76\u4e861850\u5e74\u4ee3\u81f31920\u5e74\u4ee3\u5730\u4e2d\u6d77\u5730\u533a\u84b8\u6c7d\u8f6e\u8239\u5f15\u5165\u6240\u5e26\u6765\u7684\u7ecf\u6d4e\u3001\u793e\u4f1a\u548c\u4eba\u53e3\u5f71\u54cd\u3002", "result": "FAST CAT\u7cfb\u7edf\u80fd\u591f\u5e94\u5bf9\u6570\u636e\u5f55\u5165\u548c\u7ba1\u7406\u65b9\u9762\u7684\u6311\u6218\uff0c\u63d0\u9ad8\u6570\u636e\u7684\u4e92\u64cd\u4f5c\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u4e3a\u5386\u53f2\u5b66\u7b49\u5b9e\u8bc1\u7814\u7a76\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "FAST CAT\u4f5c\u4e3a\u4e00\u4e2a\u534f\u4f5c\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u6570\u5b57\u4eba\u6587\u548c\u7c7b\u4f3c\u5b9e\u8bc1\u7814\u7a76\u4e2d\u7684\u6570\u636e\u5f55\u5165\u548c\u7ba1\u7406\u6311\u6218\uff0c\u901a\u8fc7\u652f\u6301\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u7684\u53ef\u7528\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002"}}
{"id": "2012.00697", "title": "Sigma Worksheet: Interactive Construction of OLAP Queries", "url": "https://arxiv.org/abs/2012.00697", "pdf": "https://arxiv.org/pdf/2012.00697", "abs": "https://arxiv.org/abs/2012.00697", "authors": ["James Gale", "Max Seiden", "Gretchen Atwood", "Jason Frantz", "Rob Woollen", "\u00c7a\u011fatay Demiralp"], "categories": ["cs.DB", "cs.HC"], "comment": null, "summary": "The new generation of cloud data warehouses (CDWs) brings large amounts of\ndata and compute power closer to users in enterprises. The ability to directly\naccess the warehouse data, interactively analyze and explore it at scale can\nempower users to improve their decision making cycles. However, existing tools\nfor analyzing data in CDWs are either limited in ad-hoc transformations or\ndifficult to use for business users, the largest user segment in enterprises.\nHere we introduce Sigma Worksheet, a new interactive system that enables users\nto easily perform ad-hoc visual analysis of data in CDWs at scale. For this,\nSigma Worksheet provides an accessible spreadsheet-like interface for data\nanalysis through direct manipulation. Sigma Worksheet dynamically constructs\nmatching SQL queries from user interactions on this familiar interface,\nbuilding on the versatility and expressivity of SQL. Sigma Worksheet executes\nconstructed queries directly on CDWs, leveraging the superior characteristics\nof the new generation CDWs, including scalability. To evaluate Sigma Worksheet,\nwe first demonstrate its expressivity through two real life use cases, cohort\nanalysis and sessionization. We then measure the performance of the Worksheet\ngenerated queries with a set of experiments using the TPC-H benchmark. Results\nshow the performance of our compiled SQL queries is comparable to that of the\nreference queries of the benchmark. Finally, to assess the usefulness of Sigma\nWorksheet in deployment, we elicit feedback through a 100-person survey\nfollowed by a semi-structured interview study with 70 participants. We find\nthat Sigma Worksheet is easier to use and learn, improving the productivity of\nusers. Our findings also suggest Sigma Worksheet can further improve user\nexperience by providing guidance to users at various steps of data analysis.", "AI": {"tldr": "Sigma Worksheet \u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u5b83\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u7535\u5b50\u8868\u683c\u7684\u76f4\u89c2\u754c\u9762\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u8f7b\u677e\u5730\u5bf9\u4e91\u6570\u636e\u4ed3\u5e93\u4e2d\u7684\u6570\u636e\u8fdb\u884c\u5373\u5e2d\u53ef\u89c6\u5316\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u7684\u4e91\u6570\u636e\u4ed3\u5e93\u5206\u6790\u5de5\u5177\u5728\u5373\u5e2d\u8f6c\u6362\u65b9\u9762\u529f\u80fd\u6709\u9650\uff0c\u6216\u8005\u5bf9\u4e8e\u4f01\u4e1a\u4e2d\u6700\u5e7f\u6cdb\u7684\u7528\u6237\u7fa4\u4f53\u2014\u2014\u4e1a\u52a1\u7528\u6237\u6765\u8bf4\uff0c\u96be\u4ee5\u4f7f\u7528\u3002", "method": "Sigma Worksheet \u63d0\u4f9b\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u7535\u5b50\u8868\u683c\u7684\u76f4\u89c2\u754c\u9762\uff0c\u901a\u8fc7\u76f4\u63a5\u64cd\u4f5c\u6765\u5206\u6790\u6570\u636e\uff0c\u5e76\u5229\u7528 SQL \u7684\u591a\u529f\u80fd\u6027\u548c\u8868\u8fbe\u80fd\u529b\u52a8\u6001\u6784\u5efa SQL \u67e5\u8be2\u3002Sigma Worksheet \u76f4\u63a5\u5728\u4e91\u6570\u636e\u4ed3\u5e93\u4e0a\u6267\u884c\u6784\u5efa\u7684\u67e5\u8be2\uff0c\u5229\u7528\u4e86\u65b0\u4e00\u4ee3\u4e91\u6570\u636e\u4ed3\u5e93\u7684\u53ef\u6269\u5c55\u6027\u7b49\u7279\u6027\u3002", "result": "Sigma Worksheet \u751f\u6210\u7684 SQL \u67e5\u8be2\u5728 TPC-H \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6027\u80fd\u4e0e\u53c2\u8003\u67e5\u8be2\u76f8\u5f53\u3002\u7528\u6237\u8c03\u67e5\u548c\u8bbf\u8c08\u663e\u793a\uff0cSigma Worksheet \u6613\u4e8e\u4f7f\u7528\u548c\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u7528\u6237\u751f\u4ea7\u529b\u3002", "conclusion": "Sigma Worksheet \u6613\u4e8e\u4f7f\u7528\u548c\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u7528\u6237\u751f\u4ea7\u529b\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u5728\u6570\u636e\u5206\u6790\u7684\u5404\u4e2a\u9636\u6bb5\u4e3a\u7528\u6237\u63d0\u4f9b\u6307\u5bfc\u6765\u8fdb\u4e00\u6b65\u6539\u5584\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2104.13600", "title": "Mapping Spreadsheets to RDF: Supporting Excel in RML", "url": "https://arxiv.org/abs/2104.13600", "pdf": "https://arxiv.org/pdf/2104.13600", "abs": "https://arxiv.org/abs/2104.13600", "authors": ["Markus Schr\u00f6der", "Christian Jilek", "Andreas Dengel"], "categories": ["cs.DB"], "comment": "6 pages, submitted to Second International Workshop on Knowledge\n  Graph Construction", "summary": "The RDF Mapping Language (RML) enables, among other formats, the mapping of\ntabular data as Comma-Separated Values (CSV) files to RDF graphs.\nUnfortunately, the widely used spreadsheet format is currently neglected by its\nspecification and well-known implementations. Therefore, we extended one of the\ntools which is RML Mapper to support Microsoft Excel spreadsheet files and\ndemonstrate its capabilities in an interactive online demo. Our approach allows\nto access various meta data of spreadsheet cells in typical RML maps. Some\nexperimental features for more specific use cases are also provided. The\nimplementation code is publicly available in a GitHub fork.", "AI": {"tldr": "\u6269\u5c55\u4e86RML Mapper\u4ee5\u652f\u6301Excel\u6587\u4ef6\uff0c\u5e76\u63d0\u4f9b\u4e86\u5728\u7ebf\u6f14\u793a\u3002", "motivation": "\u76ee\u524dRML\u89c4\u8303\u548c\u5e38\u7528\u5b9e\u73b0\u5ffd\u7565\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684Excel\u7535\u5b50\u8868\u683c\u683c\u5f0f\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u5176\u8fdb\u884c\u652f\u6301\u3002", "method": "\u901a\u8fc7\u6269\u5c55RML Mapper\u5de5\u5177\u6765\u652f\u6301Excel\u6587\u4ef6\uff0c\u5e76\u5b9e\u73b0\u4e86\u8bbf\u95ee\u7535\u5b50\u8868\u683c\u5355\u5143\u683c\u5143\u6570\u636e\u7684\u80fd\u529b\u3002", "result": "\u8be5\u7814\u7a76\u6210\u529f\u5730\u6269\u5c55\u4e86RML Mapper\u4ee5\u652f\u6301Excel\u6587\u4ef6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5728\u7ebf\u6f14\u793a\uff0c\u5141\u8bb8\u7528\u6237\u8bbf\u95ee\u7535\u5b50\u8868\u683c\u5355\u5143\u683c\u7684\u5143\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e9b\u5b9e\u9a8c\u6027\u529f\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86RML Mapper\u4ee5\u652f\u6301Microsoft Excel\u7535\u5b50\u8868\u683c\u6587\u4ef6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5728\u7ebf\u6f14\u793a\u3002"}}
{"id": "2104.13576", "title": "Dataset Generation Patterns for Evaluating Knowledge Graph Construction", "url": "https://arxiv.org/abs/2104.13576", "pdf": "https://arxiv.org/pdf/2104.13576", "abs": "https://arxiv.org/abs/2104.13576", "authors": ["Markus Schr\u00f6der", "Christian Jilek", "Andreas Dengel"], "categories": ["cs.DB"], "comment": "5 pages, submitted to ESWC demo track", "summary": "Confidentiality hinders the publication of authentic, labeled datasets of\npersonal and enterprise data, although they could be useful for evaluating\nknowledge graph construction approaches in industrial scenarios. Therefore, our\nplan is to synthetically generate such data in a way that it appears as\nauthentic as possible. Based on our assumption that knowledge workers have\ncertain habits when they produce or manage data, generation patterns could be\ndiscovered which can be utilized by data generators to imitate real datasets.\nIn this paper, we initially derived 11 distinct patterns found in real\nspreadsheets from industry and demonstrate a suitable generator called Data\nSprout that is able to reproduce them. We describe how the generator produces\nspreadsheets in general and what altering effects the implemented patterns\nhave.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u5de5\u4e1a\u573a\u666f\u4e2d\u771f\u5b9e\u6570\u636e\u96c6\u7684\u83b7\u53d6\u96be\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDataSprout\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5668\uff0c\u8be5\u751f\u6210\u5668\u901a\u8fc7\u6a21\u4eff\u771f\u5b9e\u6570\u636e\u4e2d\u768411\u79cd\u6a21\u5f0f\u6765\u751f\u6210\u53ef\u7528\u7684\u6570\u636e\u96c6\u3002", "motivation": "\u7531\u4e8e\u4fdd\u5bc6\u6027\u9650\u5236\uff0c\u96be\u4ee5\u83b7\u53d6\u5de5\u4e1a\u573a\u666f\u4e2d\u7528\u4e8e\u8bc4\u4f30\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\u7684\u771f\u5b9e\u6807\u6ce8\u6570\u636e\u96c6\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u771f\u5b9e\u7535\u5b50\u8868\u683c\u4e2d\u7684\u6570\u636e\u751f\u6210\u6a21\u5f0f\uff0c\u5e76\u5f00\u53d1DataSprout\u751f\u6210\u5668\u6765\u590d\u73b0\u8fd9\u4e9b\u6a21\u5f0f\u3002", "result": "\u6210\u529f\u4ece\u5de5\u4e1a\u754c\u771f\u5b9e\u7535\u5b50\u8868\u683c\u4e2d\u63d0\u53d6\u4e8611\u79cd\u6570\u636e\u6a21\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86DataSprout\u751f\u6210\u5668\u6765\u590d\u73b0\u8fd9\u4e9b\u6a21\u5f0f\uff0c\u4e3a\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u5408\u6210\u6570\u636e\u96c6\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aDataSprout\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5668\uff0c\u8be5\u751f\u6210\u5668\u80fd\u591f\u6a21\u4eff\u771f\u5b9e\u7535\u5b50\u8868\u683c\u4e2d\u768411\u79cd\u6570\u636e\u6a21\u5f0f\uff0c\u4ee5\u89e3\u51b3\u5de5\u4e1a\u573a\u666f\u4e2d\u7f3a\u4e4f\u771f\u5b9e\u6807\u6ce8\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002"}}
{"id": "2103.15203", "title": "Mathematics of Digital Hyperspace", "url": "https://arxiv.org/abs/2103.15203", "pdf": "https://arxiv.org/pdf/2103.15203", "abs": "https://arxiv.org/abs/2103.15203", "authors": ["Jeremy Kepner", "Timothy Davis", "Vijay Gadepally", "Hayden Jananthan", "Lauren Milechin"], "categories": ["cs.MS", "cs.DB", "cs.DM", "cs.NE", "math.RA"], "comment": "9 pages, 8 figures, 2 tables, accepted to GrAPL 2021. arXiv admin\n  note: text overlap with arXiv:1807.03165, arXiv:2004.01181, arXiv:1909.05631,\n  arXiv:1708.02937", "summary": "Social media, e-commerce, streaming video, e-mail, cloud documents, web\npages, traffic flows, and network packets fill vast digital lakes, rivers, and\noceans that we each navigate daily. This digital hyperspace is an amorphous\nflow of data supported by continuous streams that stretch standard concepts of\ntype and dimension. The unstructured data of digital hyperspace can be\nelegantly represented, traversed, and transformed via the mathematics of\nhypergraphs, hypersparse matrices, and associative array algebra. This paper\nexplores a novel mathematical concept, the semilink, that combines pairs of\nsemirings to provide the essential operations for graph analytics, database\noperations, and machine learning. The GraphBLAS standard currently supports\nhypergraphs, hypersparse matrices, the mathematics required for semilinks, and\nseamlessly performs graph, network, and matrix operations. With the addition of\nkey based indices (such as pointers to strings) and semilinks, GraphBLAS can\nbecome a richer associative array algebra and be a plug-in replacement for\nspreadsheets, database tables, and data centric operating systems, enhancing\nthe navigation of unstructured data found in digital hyperspace.", "AI": {"tldr": "GraphBLAS\u901a\u8fc7\u5f15\u5165\u201c\u534a\u94fe\u201d\u6982\u5ff5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u8d85\u56fe\u3001\u8d85\u7a00\u758f\u77e9\u9635\u7b49\uff0c\u5e76\u6709\u671b\u6210\u4e3a\u66ff\u4ee3\u7535\u5b50\u8868\u683c\u3001\u6570\u636e\u5e93\u548c\u6570\u636e\u4e2d\u5fc3\u64cd\u4f5c\u7cfb\u7edf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u4f18\u5316\u5bf9\u6d77\u91cf\u975e\u7ed3\u6784\u5316\u6570\u636e\u7684\u5bfc\u822a\u3002", "motivation": "\u6570\u5b57\u5047\u60f3\u7a7a\u95f4\u4e2d\u7684\u975e\u7ed3\u6784\u5316\u6570\u636e\u53ef\u4ee5\u901a\u8fc7\u8d85\u56fe\u3001\u8d85\u7a00\u758f\u77e9\u9635\u548c\u5173\u8054\u6570\u7ec4\u4ee3\u6570\u7684\u6570\u5b66\u539f\u7406\u8fdb\u884c\u8868\u793a\u3001\u904d\u5386\u548c\u8f6c\u6362\u3002\u76ee\u524d\u7684GraphBLAS\u6807\u51c6\u652f\u6301\u8d85\u56fe\u3001\u8d85\u7a00\u758f\u77e9\u9635\u4ee5\u53ca\u534a\u94fe\u6240\u9700\u7684\u6570\u5b66\u8fd0\u7b97\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u534a\u94fe\u201d\u7684\u65b0\u6570\u5b66\u6982\u5ff5\uff0c\u5b83\u7ed3\u5408\u4e86\u6210\u5bf9\u7684\u534a\u73af\uff0c\u4e3a\u56fe\u5206\u6790\u3001\u6570\u636e\u5e93\u64cd\u4f5c\u548c\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u57fa\u672c\u8fd0\u7b97\u3002", "result": "\u901a\u8fc7\u6dfb\u52a0\u57fa\u4e8e\u952e\u7684\u7d22\u5f15\uff08\u5982\u6307\u5411\u5b57\u7b26\u4e32\u7684\u6307\u9488\uff09\u548c\u534a\u94fe\uff0cGraphBLAS\u53ef\u4ee5\u6210\u4e3a\u4e00\u4e2a\u66f4\u4e30\u5bcc\u7684\u5173\u8054\u6570\u7ec4\u4ee3\u6570\u3002", "conclusion": "GraphBLAS\u901a\u8fc7\u652f\u6301\u8d85\u56fe\u3001\u8d85\u7a00\u758f\u77e9\u9635\u548c\u534a\u94fe\u7684\u6570\u5b66\u8fd0\u7b97\uff0c\u53ef\u4ee5\u6210\u4e3a\u4e00\u4e2a\u66f4\u4e30\u5bcc\u7684\u5173\u8054\u6570\u7ec4\u4ee3\u6570\uff0c\u5e76\u53ef\u4f5c\u4e3a\u7535\u5b50\u8868\u683c\u3001\u6570\u636e\u5e93\u8868\u548c\u6570\u636e\u4e2d\u5fc3\u64cd\u4f5c\u7cfb\u7edf\u7684\u5373\u63d2\u5373\u7528\u66ff\u4ee3\u54c1\uff0c\u4ece\u800c\u589e\u5f3a\u5bf9\u6570\u5b57\u5047\u60f3\u7a7a\u95f4\u4e2d\u975e\u7ed3\u6784\u5316\u6570\u636e\u7684\u5bfc\u822a\u3002"}}
{"id": "2103.10472", "title": "Dynamic Kernel Matching for Non-conforming Data: A Case Study of T-cell Receptor Datasets", "url": "https://arxiv.org/abs/2103.10472", "pdf": "https://arxiv.org/pdf/2103.10472", "abs": "https://arxiv.org/abs/2103.10472", "authors": ["Jared Ostmeyer", "Scott Christley", "Lindsay Cowell"], "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "Most statistical classifiers are designed to find patterns in data where\nnumbers fit into rows and columns, like in a spreadsheet, but many kinds of\ndata do not conform to this structure. To uncover patterns in non-conforming\ndata, we describe an approach for modifying established statistical classifiers\nto handle non-conforming data, which we call dynamic kernel matching (DKM). As\nexamples of non-conforming data, we consider (i) a dataset of T-cell receptor\n(TCR) sequences labelled by disease antigen and (ii) a dataset of sequenced TCR\nrepertoires labelled by patient cytomegalovirus (CMV) serostatus, anticipating\nthat both datasets contain signatures for diagnosing disease. We successfully\nfit statistical classifiers augmented with DKM to both datasets and report the\nperformance on holdout data using standard metrics and metrics allowing for\nindeterminant diagnoses. Finally, we identify the patterns used by our\nstatistical classifiers to generate predictions and show that these patterns\nagree with observations from experimental studies.", "AI": {"tldr": "This paper presents dynamic kernel matching (DKM), a method for modifying statistical classifiers to handle non-conforming data, such as TCR sequences and repertoires. The method was successfully applied to two datasets, showing good performance and identifying patterns consistent with experimental observations.", "motivation": "Most statistical classifiers are designed to find patterns in data where numbers fit into rows and columns, like in a spreadsheet, but many kinds of data do not conform to this structure. To uncover patterns in non-conforming data, we describe an approach for modifying established statistical classifiers to handle non-conforming data, which we call dynamic kernel matching (DKM).", "method": "We describe an approach for modifying established statistical classifiers to handle non-conforming data, which we call dynamic kernel matching (DKM).", "result": "We successfully fit statistical classifiers augmented with DKM to both datasets and report the performance on holdout data using standard metrics and metrics allowing for indeterminant diagnoses. Finally, we identify the patterns used by our statistical classifiers to generate predictions and show that these patterns agree with observations from experimental studies.", "conclusion": "We successfully fit statistical classifiers augmented with DKM to both datasets and report the performance on holdout data using standard metrics and metrics allowing for indeterminant diagnoses. Finally, we identify the patterns used by our statistical classifiers to generate predictions and show that these patterns agree with observations from experimental studies."}}
{"id": "2103.03537", "title": "Interactively Constructing Knowledge Graphs from Messy User-Generated Spreadsheets", "url": "https://arxiv.org/abs/2103.03537", "pdf": "https://arxiv.org/pdf/2103.03537", "abs": "https://arxiv.org/abs/2103.03537", "authors": ["Markus Schr\u00f6der", "Christian Jilek", "Michael Schulze", "Andreas Dengel"], "categories": ["cs.DB"], "comment": "15 pages", "summary": "When spreadsheets are filled freely by knowledge workers, they can contain\nrather unstructured content. For humans and especially machines it becomes\ndifficult to interpret such data properly. Therefore, spreadsheets are often\nconverted to a more explicit, formal and structured form, for example, to a\nknowledge graph. However, if a data maintenance strategy has been missing and\nuser-generated data becomes \"messy\", the construction of knowledge graphs will\nbe a challenging task. In this paper, we catalog several of those challenges\nand propose an interactive approach to solve them. Our approach includes a\ngraphical user interface which enables knowledge engineers to bulk-annotate\nspreadsheet cells with extracted information. Based on the cells' annotations a\nknowledge graph is ultimately formed. Using five spreadsheets from an\nindustrial scenario, we built a 25k-triple graph during our evaluation. We\ncompared our method with the state-of-the-art RDF Mapping Language (RML)\nattempt. The comparison highlights contributions of our approach.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u4e92\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u5f62\u7528\u6237\u754c\u9762\u6279\u91cf\u6ce8\u91ca\u7535\u5b50\u8868\u683c\u5355\u5143\u683c\uff0c\u4ee5\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\uff0c\u89e3\u51b3\u4e86\u975e\u7ed3\u6784\u5316\u6570\u636e\u5e26\u6765\u7684\u6311\u6218\u3002", "motivation": "\u81ea\u7531\u8f93\u5165\u7684\u7535\u5b50\u8868\u683c\u53ef\u80fd\u5305\u542b\u975e\u7ed3\u6784\u5316\u5185\u5bb9\uff0c\u96be\u4ee5\u88ab\u673a\u5668\u89e3\u91ca\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u5176\u8f6c\u6362\u4e3a\u77e5\u8bc6\u56fe\u8c31\u7b49\u663e\u5f0f\u3001\u5f62\u5f0f\u5316\u548c\u7ed3\u6784\u5316\u7684\u5f62\u5f0f\u3002\u7136\u800c\uff0c\u5728\u7f3a\u4e4f\u6570\u636e\u7ef4\u62a4\u7b56\u7565\u7684\u60c5\u51b5\u4e0b\uff0c\u7528\u6237\u751f\u6210\u7684\u6570\u636e\u4f1a\u53d8\u5f97\u6df7\u4e71\uff0c\u7ed9\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u5e26\u6765\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u4e92\u5f0f\u65b9\u6cd5\uff0c\u5305\u62ec\u4e00\u4e2a\u56fe\u5f62\u7528\u6237\u754c\u9762\uff0c\u5141\u8bb8\u77e5\u8bc6\u5de5\u7a0b\u5e08\u6279\u91cf\u6ce8\u91ca\u63d0\u53d6\u4fe1\u606f\u7684\u7535\u5b50\u8868\u683c\u5355\u5143\u683c\u3002", "result": "\u4f7f\u7528\u6765\u81ea\u5de5\u4e1a\u573a\u666f\u7684\u4e94\u4e2a\u7535\u5b50\u8868\u683c\uff0c\u5728\u8bc4\u4f30\u4e2d\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b 25,000 \u4e2a\u4e09\u5143\u7ec4\u7684\u56fe\u8c31\u3002", "conclusion": "\u57fa\u4e8e\u5bf9\u63d0\u53d6\u4fe1\u606f\u7684\u5355\u5143\u683c\u6ce8\u91ca\uff0c\u6700\u7ec8\u5f62\u6210\u77e5\u8bc6\u56fe\u8c31\u3002\u8be5\u65b9\u6cd5\u4e0e\u6700\u65b0\u7684 RDF \u6620\u5c04\u8bed\u8a00 (RML) \u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u7ed3\u679c\u7a81\u51fa\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u52bf\u3002"}}
{"id": "2102.09461", "title": "Optimization Helps Scheduling Nursing Staff at the Long-Term Care Homes of the City of Toronto", "url": "https://arxiv.org/abs/2102.09461", "pdf": "https://arxiv.org/pdf/2102.09461", "abs": "https://arxiv.org/abs/2102.09461", "authors": ["Manion Anderson", "Merve Bodur", "Scott Rathwell", "Vahid Sarhangian"], "categories": ["cs.CY", "math.OC"], "comment": null, "summary": "The City of Toronto Long Term Care Homes & Services (LTCH&S) division is one\nof the largest providers of long-term care in the Canadian province of Ontario,\nproviding care to 2,640 residents at 10 homes across Toronto. Our collaboration\nwith LTCH&S was initiated to facilitate the increasingly challenging task of\nscheduling nursing staff and reduce high absenteeism rate observed among the\npart-time nurses. We developed a spreadsheet-based scheduling tool to automate\nthe generation of schedules and incorporate nurses' preferences for different\nshifts into the schedules. At the core of the scheduling tool is a hierarchical\noptimization model that generates a feasible schedule with the highest total\npreference score while satisfying the maximum possible demand. Feasible\nschedules had to abide by a set of complex seniority requirements which\nprioritized more senior nurses when allocating the available shifts. Our\nscheduling tool was implemented in a 391-bed home in Toronto. The tool allowed\nnursing managers to generate feasible schedules within a fraction of an hour,\nin contrast to the status-quo manual approach which could took up to tens of\nhours. In addition, the schedules successfully accounted for preferences with\non average above 94% of the allocated shifts ranked as most preferred.", "AI": {"tldr": "\u591a\u4f26\u591a\u5e02\u8001\u5e74\u62a4\u7406\u673a\u6784\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u6392\u73ed\u5de5\u5177\uff0c\u901a\u8fc7\u4f18\u5316\u6a21\u578b\u6ee1\u8db3\u62a4\u58eb\u504f\u597d\u548c\u8d44\u5386\u8981\u6c42\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6392\u73ed\u6548\u7387\u548c\u62a4\u58eb\u6ee1\u610f\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u591a\u4f26\u591a\u5e02\u8001\u5e74\u62a4\u7406\u673a\u6784\u5728\u5b89\u6392\u62a4\u7406\u4eba\u5458\u65b9\u9762\u65e5\u76ca\u589e\u957f\u7684\u6311\u6218\uff0c\u5e76\u964d\u4f4e\u517c\u804c\u62a4\u58eb\u7684\u9ad8\u7f3a\u52e4\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u7684\u6392\u73ed\u5de5\u5177\uff0c\u5176\u6838\u5fc3\u662f\u4e00\u4e2a\u5206\u5c42\u4f18\u5316\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\uff08\u5982\u8d44\u5386\u8981\u6c42\uff09\u7684\u524d\u63d0\u4e0b\uff0c\u6700\u5927\u5316\u603b\u504f\u597d\u5f97\u5206\u5e76\u5c3d\u53ef\u80fd\u6ee1\u8db3\u9700\u6c42\u3002", "result": "\u8be5\u5de5\u5177\u5728\u4e00\u5bb6391\u5f20\u5e8a\u4f4d\u7684\u62a4\u7406\u9662\u5b9e\u65bd\u540e\uff0c\u5c06\u751f\u6210\u53ef\u884c\u6392\u73ed\u8868\u7684\u65f6\u95f4\u4ece\u6570\u5c0f\u65f6\u7f29\u77ed\u5230\u4e0d\u5230\u4e00\u5c0f\u65f6\uff0c\u5e76\u4e14\u5e73\u5747\u670994%\u7684\u6392\u73ed\u83b7\u5f97\u4e86\u62a4\u58eb\u7684\u9996\u9009\u3002", "conclusion": "\u8be5\u6392\u73ed\u5de5\u5177\u80fd\u591f\u81ea\u52a8\u5316\u751f\u6210\u6ee1\u8db3\u590d\u6742\u4f18\u5148\u987a\u5e8f\u8981\u6c42\u7684\u53ef\u884c\u6392\u73ed\u8868\uff0c\u540c\u65f6\u6700\u5927\u5316\u6ee1\u8db3\u62a4\u58eb\u7684\u504f\u597d\u3002"}}
{"id": "2012.01571", "title": "Online Model Swapping in Architectural Simulation", "url": "https://arxiv.org/abs/2012.01571", "pdf": "https://arxiv.org/pdf/2012.01571", "abs": "https://arxiv.org/abs/2012.01571", "authors": ["Patrick Lavin", "Jeffrey Young", "Rich Vuduc", "Jonathan Beard"], "categories": ["cs.AR"], "comment": null, "summary": "As systems and applications grow more complex, detailed simulation takes an\never increasing amount of time. The prospect of increased simulation time\nresulting in slower design iteration forces architects to use simpler models,\nsuch as spreadsheets, when they want to iterate quickly on a design. However,\nthe task of migrating from a simple simulation to one with more detail often\nrequires multiple executions to find where simple models could be effective,\nwhich could be more expensive than running the detailed model in the first\nplace. Also, architects must often rely on intuition to choose these simpler\nmodels, further complicating the problem.\n  In this work, we present a method of bridging the gap between simple and\ndetailed simulation by monitoring simulation behavior online and automatically\nswapping out detailed models with simpler statistical approximations. We\ndemonstrate the potential of our methodology by implementing it in the\nopen-source simulator SVE-Cachesim to swap out the level one data cache (L1D)\nwithin a memory hierarchy. This proof of concept demonstrates that our\ntechnique can handle a non-trivial use-case in not just approximation of local\ntime-invariant statistics, but also those that vary with time (e.g., the L1D is\na form of a time-series function), and downstream side-effects (e.g., the L1D\nfilters accesses for the level two cache). Our simulation swaps out the\nbuilt-in cache model with only an 8% error in the simulated cycle count while\nusing the approximated cache models for over 90% of the simulation, and our\nsimpler models require two to eight times less computation per \"execution\" of\nthe model", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5728\u7ebf\u76d1\u63a7\u548c\u81ea\u52a8\u66ff\u6362\u6a21\u578b\u6765\u52a0\u901f\u590d\u6742\u7cfb\u7edf\u4eff\u771f\u7684\u65b9\u6cd5\uff0c\u5728\u7f13\u5b58\u4eff\u771f\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u91cf\u5e76\u4fdd\u6301\u4e86\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u548c\u5e94\u7528\u7684\u590d\u6742\u6027\u589e\u52a0\uff0c\u8be6\u7ec6\u4eff\u771f\u8017\u65f6\u8fc7\u957f\uff0c\u8feb\u4f7f\u67b6\u6784\u5e08\u5728\u9700\u8981\u5feb\u901f\u8fed\u4ee3\u8bbe\u8ba1\u65f6\u4f7f\u7528\u7535\u5b50\u8868\u683c\u7b49\u7b80\u5355\u6a21\u578b\uff0c\u4f46\u4ece\u7b80\u5355\u4eff\u771f\u8fc1\u79fb\u5230\u8be6\u7ec6\u4eff\u771f\u8fc7\u7a0b\u590d\u6742\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u5e76\u4e14\u67b6\u6784\u5e08\u5e38\u5e38\u4f9d\u8d56\u76f4\u89c9\u9009\u62e9\u7b80\u5355\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u5728\u7ebf\u76d1\u63a7\u4eff\u771f\u884c\u4e3a\uff0c\u5e76\u81ea\u52a8\u5c06\u8be6\u7ec6\u6a21\u578b\u66ff\u6362\u4e3a\u66f4\u7b80\u5355\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u5904\u7406\u4e86\u65f6\u95f4\u76f8\u5173\u7684\u7edf\u8ba1\u6570\u636e\u548c\u4e0b\u6e38\u7684\u526f\u4f5c\u7528\u3002", "result": "\u5728SVE-Cachesim\u4e2d\u5b9e\u73b0\u7684\u8be5\u65b9\u6cd5\uff0c\u5728\u8fd1\u4f3cL1D\u7f13\u5b58\u6a21\u578b\u65f6\uff0c\u4eff\u771f\u5468\u671f\u8ba1\u6570\u8bef\u5dee\u4ec5\u4e3a8%\uff0c\u540c\u65f6\u4f7f\u7528\u4e8690%\u4ee5\u4e0a\u7684\u8fd1\u4f3c\u7f13\u5b58\u6a21\u578b\uff0c\u5e76\u4e14\u66f4\u7b80\u5355\u7684\u6a21\u578b\u6bcf\u6b21\u201c\u6267\u884c\u201d\u6240\u9700\u7684\u8ba1\u7b97\u91cf\u51cf\u5c11\u4e862\u52308\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u7ebf\u76d1\u63a7\u4eff\u771f\u884c\u4e3a\u5e76\u81ea\u52a8\u7528\u66f4\u7b80\u5355\u7684\u7edf\u8ba1\u6a21\u578b\u66ff\u6362\u8be6\u7ec6\u6a21\u578b\uff0c\u6210\u529f\u5730\u5728\u7b80\u5355\u548c\u8be6\u7ec6\u4eff\u771f\u4e4b\u95f4\u67b6\u8d77\u4e86\u6865\u6881\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "1909.00855", "title": "Defining and Adopting an End User Computing Policy: A Case Study", "url": "https://arxiv.org/abs/1909.00855", "pdf": "https://arxiv.org/pdf/1909.00855", "abs": "https://arxiv.org/abs/1909.00855", "authors": ["Roger Turner"], "categories": ["cs.HC", "cs.CY"], "comment": "25 Pages, 12 Colour Figures. 1 Table. First presented at the EuSpRIG\n  2018 Conference at Imperial College, London. Revised and updated following a\n  further presentation at the EuSpRIG 2019 Conference also at Imperial College,\n  London", "summary": "End User Computing carries significant risks if not well controlled. This\npaper is a case study of the introduction of an updated End User Computing\npolicy at the Wesleyan Assurance Society. The paper outlines the plan and\nidentifies various challenges. The paper explains how these challenges were\novercome. We wrote an End User Computing Risk Assessment Application which\ncalculates a risk rating band based on the Complexity, Materiality and Control\n(or lack of it) pertaining to any given application and the basis of assessment\nis given in this paper. The policy uses a risk based approach for assessing and\nmitigating against the highest risks first and obtaining the quickest benefit.", "AI": {"tldr": "\u8be5\u7814\u7a76\u62a5\u544a\u4e86\u97e6\u65af\u5229\u5b89\u4fdd\u9669\u534f\u4f1a\u5982\u4f55\u901a\u8fc7\u5236\u5b9a\u65b0\u653f\u7b56\u548c\u98ce\u9669\u8bc4\u4f30\u5e94\u7528\u7a0b\u5e8f\u6765\u7ba1\u7406\u6700\u7ec8\u7528\u6237\u8ba1\u7b97\u7684\u98ce\u9669\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u6700\u7ec8\u7528\u6237\u8ba1\u7b97\uff08EUC\uff09\u5e26\u6765\u7684\u91cd\u5927\u98ce\u9669\uff0c\u5e76\u4e3a\u5176\u4ed6\u7ec4\u7ec7\u63d0\u4f9b\u5982\u4f55\u7ba1\u7406\u548c\u51cf\u8f7b\u8fd9\u4e9b\u98ce\u9669\u7684\u5b9e\u8df5\u6307\u5bfc\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u97e6\u65af\u5229\u5b89\u4fdd\u9669\u534f\u4f1a\u66f4\u65b0\u5176\u6700\u7ec8\u7528\u6237\u8ba1\u7b97\u7b56\u7565\u7684\u5b9e\u9645\u60c5\u51b5\u3002\u7814\u7a76\u4e2d\u5f00\u53d1\u4e86\u4e00\u6b3e\u6700\u7ec8\u7528\u6237\u8ba1\u7b97\u98ce\u9669\u8bc4\u4f30\u5e94\u7528\u7a0b\u5e8f\uff0c\u8be5\u5e94\u7528\u7a0b\u5e8f\u6839\u636e\u5e94\u7528\u7a0b\u5e8f\u7684\u590d\u6742\u6027\u3001\u91cd\u8981\u6027\u548c\u63a7\u5236\u60c5\u51b5\uff08\u6216\u5176\u7f3a\u5931\uff09\u6765\u8ba1\u7b97\u98ce\u9669\u7b49\u7ea7\u3002", "result": "\u6210\u529f\u5b9e\u65bd\u4e86\u66f4\u65b0\u7684\u6700\u7ec8\u7528\u6237\u8ba1\u7b97\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u98ce\u9669\u8bc4\u4f30\u5e94\u7528\u7a0b\u5e8f\u6709\u6548\u7ba1\u7406\u4e86\u76f8\u5173\u98ce\u9669\u3002\u8be5\u7b56\u7565\u91c7\u7528\u57fa\u4e8e\u98ce\u9669\u7684\u65b9\u6cd5\uff0c\u4f18\u5148\u5904\u7406\u548c\u7f13\u89e3\u6700\u9ad8\u98ce\u9669\uff0c\u4ece\u800c\u6700\u5feb\u5730\u83b7\u76ca\u3002", "conclusion": "\u8be5\u6587\u4ef6\u6982\u8ff0\u4e86\u5728\u97e6\u65af\u5229\u5b89\u4fdd\u9669\u534f\u4f1a\u5b9e\u65bd\u66f4\u65b0\u7684\u6700\u7ec8\u7528\u6237\u8ba1\u7b97\u7b56\u7565\u7684\u8ba1\u5212\u3001\u6311\u6218\u53ca\u5176\u514b\u670d\u65b9\u6cd5\u3002"}}
{"id": "2011.05978", "title": "The Impact of Text Presentation on Translator Performance", "url": "https://arxiv.org/abs/2011.05978", "pdf": "https://arxiv.org/pdf/2011.05978", "abs": "https://arxiv.org/abs/2011.05978", "authors": ["Samuel L\u00e4ubli", "Patrick Simianer", "Joern Wuebker", "Geza Kovacs", "Rico Sennrich", "Spence Green"], "categories": ["cs.CL", "cs.HC"], "comment": "Accepted for publication in Target", "summary": "Widely used computer-aided translation (CAT) tools divide documents into\nsegments such as sentences and arrange them in a side-by-side, spreadsheet-like\nview. We present the first controlled evaluation of these design choices on\ntranslator performance, measuring speed and accuracy in three experimental text\nprocessing tasks. We find significant evidence that sentence-by-sentence\npresentation enables faster text reproduction and within-sentence error\nidentification compared to unsegmented text, and that a top-and-bottom\narrangement of source and target sentences enables faster text reproduction\ncompared to a side-by-side arrangement. For revision, on the other hand, our\nresults suggest that presenting unsegmented text results in the highest\naccuracy and time efficiency. Our findings have direct implications for best\npractices in designing CAT tools.", "AI": {"tldr": "\u4e0e\u5e76\u6392\u663e\u793a\u548c\u9010\u53e5\u5448\u73b0\u76f8\u6bd4\uff0c\u672a\u5206\u6bb5\u6587\u672c\u5728\u4fee\u8ba2\u65f6\u66f4\u51c6\u786e\u3001\u66f4\u9ad8\u6548\uff0c\u800c\u9010\u53e5\u5448\u73b0\u548c\u9876\u90e8/\u5e95\u90e8\u6392\u5217\u5728\u6587\u672c\u590d\u5236\u548c\u9519\u8bef\u8bc6\u522b\u65b9\u9762\u901f\u5ea6\u66f4\u5feb\u3002", "motivation": "\u8bc4\u4f30\u73b0\u6709\u8ba1\u7b97\u673a\u8f85\u52a9\u7ffb\u8bd1\uff08CAT\uff09\u5de5\u5177\u7684\u8bbe\u8ba1\u9009\u62e9\uff08\u5982\u9010\u53e5\u5448\u73b0\u548c\u5e76\u6392\u89c6\u56fe\uff09\u5bf9\u8bd1\u8005\u7ee9\u6548\uff08\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff09\u7684\u5f71\u54cd\uff0c\u4e3a\u6539\u8fdb CAT \u5de5\u5177\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u901a\u8fc7\u5728\u4e09\u4e2a\u5b9e\u9a8c\u6027\u6587\u672c\u5904\u7406\u4efb\u52a1\u4e2d\u6d4b\u91cf\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u5bf9\u8ba1\u7b97\u673a\u8f85\u52a9\u7ffb\u8bd1\uff08CAT\uff09\u5de5\u5177\u7684\u8bbe\u8ba1\u9009\u62e9\uff08\u5982\u9010\u53e5\u5448\u73b0\u548c\u9876\u90e8/\u5e95\u90e8\u6392\u5217\uff09\u8fdb\u884c\u4e86\u53d7\u63a7\u8bc4\u4f30\u3002", "result": "\u4e0e\u672a\u5206\u6bb5\u6587\u672c\u76f8\u6bd4\uff0c\u9010\u53e5\u5448\u73b0\u53ef\u63d0\u9ad8\u6587\u672c\u590d\u5236\u901f\u5ea6\u548c\u53e5\u5185\u9519\u8bef\u8bc6\u522b\u80fd\u529b\uff1b\u4e0e\u5e76\u6392\u663e\u793a\u76f8\u6bd4\uff0c\u9876\u90e8/\u5e95\u90e8\u6392\u5217\u53ef\u63d0\u9ad8\u6587\u672c\u590d\u5236\u901f\u5ea6\u3002\u7136\u800c\uff0c\u5728\u4fee\u8ba2\u65b9\u9762\uff0c\u672a\u5206\u6bb5\u6587\u672c\u5728\u51c6\u786e\u6027\u548c\u65f6\u95f4\u6548\u7387\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u73b0\u6709\u5e7f\u6cdb\u4f7f\u7528\u7684\u8ba1\u7b97\u673a\u8f85\u52a9\u7ffb\u8bd1\uff08CAT\uff09\u5de5\u5177\u5c06\u6587\u6863\u5206\u5272\u6210\u53e5\u5b50\u7b49\u6bb5\u843d\uff0c\u5e76\u4ee5\u7c7b\u4f3c\u7535\u5b50\u8868\u683c\u7684\u89c6\u56fe\u5e76\u6392\u663e\u793a\u3002\u672c\u7814\u7a76\u9996\u6b21\u5bf9\u8fd9\u4e9b\u8bbe\u8ba1\u9009\u62e9\u5bf9\u8bd1\u8005\u7ee9\u6548\u7684\u5f71\u54cd\u8fdb\u884c\u4e86\u53d7\u63a7\u8bc4\u4f30\uff0c\u8861\u91cf\u4e86\u4e09\u4e2a\u5b9e\u9a8c\u6027\u6587\u672c\u5904\u7406\u4efb\u52a1\u7684\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u672a\u5206\u6bb5\u6587\u672c\u76f8\u6bd4\uff0c\u9010\u53e5\u5448\u73b0\u53ef\u5b9e\u73b0\u66f4\u5feb\u7684\u6587\u672c\u590d\u5236\u548c\u53e5\u5185\u9519\u8bef\u8bc6\u522b\uff1b\u4e0e\u5e76\u6392\u663e\u793a\u76f8\u6bd4\uff0c\u6e90\u8bed\u8a00\u548c\u76ee\u6807\u8bed\u8a00\u53e5\u5b50\u5728\u9876\u90e8\u548c\u5e95\u90e8\u7684\u6392\u5217\u53ef\u5b9e\u73b0\u66f4\u5feb\u7684\u6587\u672c\u590d\u5236\u3002\u7136\u800c\uff0c\u5728\u4fee\u8ba2\u65b9\u9762\uff0c\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5448\u73b0\u672a\u5206\u6bb5\u6587\u672c\u53ef\u5b9e\u73b0\u6700\u9ad8\u7684\u51c6\u786e\u6027\u548c\u65f6\u95f4\u6548\u7387\u3002\u672c\u7814\u7a76\u7ed3\u679c\u5bf9\u8bbe\u8ba1 CAT \u5de5\u5177\u7684\u6700\u4f73\u5b9e\u8df5\u6709\u76f4\u63a5\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2010.09975", "title": "Calliope: Automatic Visual Data Story Generation from a Spreadsheet", "url": "https://arxiv.org/abs/2010.09975", "pdf": "https://arxiv.org/pdf/2010.09975", "abs": "https://arxiv.org/abs/2010.09975", "authors": ["Danqing Shi", "Xinyue Xu", "Fuling Sun", "Yang Shi", "Nan Cao"], "categories": ["cs.HC"], "comment": null, "summary": "Visual data stories shown in the form of narrative visualizations such as a\nposter or a data video, are frequently used in data-oriented storytelling to\nfacilitate the understanding and memorization of the story content. Although\nuseful, technique barriers, such as data analysis, visualization, and\nscripting, make the generation of a visual data story difficult. Existing\nauthoring tools rely on users' skills and experiences, which are usually\ninefficient and still difficult. In this paper, we introduce a novel visual\ndata story generating system, Calliope, which creates visual data stories from\nan input spreadsheet through an automatic process and facilities the easy\nrevision of the generated story based on an online story editor. Particularly,\nCalliope incorporates a new logic-oriented Monte Carlo tree search algorithm\nthat explores the data space given by the input spreadsheet to progressively\ngenerate story pieces (i.e., data facts) and organize them in a logical order.\nThe importance of data facts is measured based on information theory, and each\ndata fact is visualized in a chart and captioned by an automatically generated\ndescription. We evaluate the proposed technique through three example stories,\ntwo controlled experiments, and a series of interviews with 10 domain experts.\nOur evaluation shows that Calliope is beneficial to efficient visual data story\ngeneration.", "AI": {"tldr": "Calliope\u662f\u4e00\u4e2a\u80fd\u4ece\u7535\u5b50\u8868\u683c\u81ea\u52a8\u751f\u6210\u53ef\u89c6\u5316\u6570\u636e\u6545\u4e8b\u7684\u7cfb\u7edf\uff0c\u5b83\u4f7f\u7528\u4e00\u79cd\u521b\u65b0\u7684\u641c\u7d22\u7b97\u6cd5\u6765\u6392\u5e8f\u6570\u636e\u4e8b\u5b9e\uff0c\u5e76\u901a\u8fc7\u56fe\u8868\u548c\u6587\u5b57\u8fdb\u884c\u53ef\u89c6\u5316\uff0c\u5927\u5927\u63d0\u9ad8\u4e86\u6570\u636e\u6545\u4e8b\u7684\u751f\u6210\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u53ef\u89c6\u5316\u6570\u636e\u6545\u4e8b\u751f\u6210\u5de5\u5177\u901a\u5e38\u4f9d\u8d56\u7528\u6237\u7684\u6280\u80fd\u548c\u7ecf\u9a8c\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u4f7f\u7528\uff0c\u5b58\u5728\u6280\u672f\u95e8\u69db\uff08\u5982\u6570\u636e\u5206\u6790\u3001\u53ef\u89c6\u5316\u548c\u811a\u672c\u7f16\u5199\uff09\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u4fbf\u6377\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCalliope\u7684\u65b0\u578b\u53ef\u89c6\u5316\u6570\u636e\u6545\u4e8b\u751f\u6210\u7cfb\u7edf\u3002\u8be5\u7cfb\u7edf\u80fd\u591f\u4ece\u8f93\u5165\u7684\u7535\u5b50\u8868\u683c\u81ea\u52a8\u751f\u6210\u53ef\u89c6\u5316\u6570\u636e\u6545\u4e8b\uff0c\u5e76\u901a\u8fc7\u5728\u7ebf\u7f16\u8f91\u5668\u65b9\u4fbf\u7528\u6237\u4fee\u6539\u3002\u5176\u6838\u5fc3\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u903b\u8f91\u5bfc\u5411\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u63a2\u7d22\u8f93\u5165\u7535\u5b50\u8868\u683c\u63d0\u4f9b\u7684\u6570\u636e\u7a7a\u95f4\uff0c\u9010\u6b65\u751f\u6210\u6545\u4e8b\u7247\u6bb5\uff08\u6570\u636e\u4e8b\u5b9e\uff09\u5e76\u8fdb\u884c\u903b\u8f91\u6392\u5e8f\u3002\u6570\u636e\u4e8b\u5b9e\u7684\u91cd\u8981\u6027\u901a\u8fc7\u4fe1\u606f\u8bba\u8fdb\u884c\u5ea6\u91cf\uff0c\u6bcf\u4e2a\u6570\u636e\u4e8b\u5b9e\u90fd\u914d\u6709\u81ea\u52a8\u751f\u6210\u7684\u56fe\u8868\u548c\u63cf\u8ff0\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u793a\u4f8b\u6545\u4e8b\u3001\u4e24\u6b21\u5bf9\u7167\u5b9e\u9a8c\u548c\u5bf910\u4f4d\u9886\u57df\u4e13\u5bb6\u7684\u8bbf\u8c08\u8bc4\u4f30\u8868\u660e\uff0cCalliope\u7cfb\u7edf\u6709\u52a9\u4e8e\u9ad8\u6548\u751f\u6210\u53ef\u89c6\u5316\u6570\u636e\u6545\u4e8b\u3002", "conclusion": "Calliope\u7cfb\u7edf\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u5229\u7528\u57fa\u4e8e\u4fe1\u606f\u8bba\u91cd\u8981\u6027\u5ea6\u91cf\u7684\u903b\u8f91\u5bfc\u5411\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\uff0c\u4ece\u7535\u5b50\u8868\u683c\u751f\u6210\u53ef\u89c6\u5316\u6570\u636e\u6545\u4e8b\uff0c\u5e76\u4e14\u5141\u8bb8\u7528\u6237\u901a\u8fc7\u5728\u7ebf\u7f16\u8f91\u5668\u8f7b\u677e\u4fee\u6539\uff0c\u6700\u7ec8\u8bc1\u660e\u4e86\u5176\u5728\u9ad8\u6548\u751f\u6210\u53ef\u89c6\u5316\u6570\u636e\u6545\u4e8b\u65b9\u9762\u7684\u4f18\u52bf\u3002"}}
{"id": "2009.03520", "title": "Leam: An Interactive System for In-situ Visual Text Analysis", "url": "https://arxiv.org/abs/2009.03520", "pdf": "https://arxiv.org/pdf/2009.03520", "abs": "https://arxiv.org/abs/2009.03520", "authors": ["Sajjadur Rahman", "Peter Griggs", "\u00c7a\u011fatay Demiralp"], "categories": ["cs.DB", "cs.CL", "cs.HC"], "comment": null, "summary": "With the increase in scale and availability of digital text generated on the\nweb, enterprises such as online retailers and aggregators often use text\nanalytics to mine and analyze the data to improve their services and products\nalike. Text data analysis is an iterative, non-linear process with diverse\nworkflows spanning multiple stages, from data cleaning to visualization.\nExisting text analytics systems usually accommodate a subset of these stages\nand often fail to address challenges related to data heterogeneity, provenance,\nworkflow reusability and reproducibility, and compatibility with established\npractices. Based on a set of design considerations we derive from these\nchallenges, we propose Leam, a system that treats the text analysis process as\na single continuum by combining advantages of computational notebooks,\nspreadsheets, and visualization tools. Leam features an interactive user\ninterface for running text analysis workflows, a new data model for managing\nmultiple atomic and composite data types, and an expressive algebra that\ncaptures diverse sets of operations representing various stages of text\nanalysis and enables coordination among different components of the system,\nincluding data, code, and visualizations. We report our current progress in\nLeam development while demonstrating its usefulness with usage examples.\nFinally, we outline a number of enhancements to Leam and identify several\nresearch directions for developing an interactive visual text analysis system.", "AI": {"tldr": "Leam\u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u8ba1\u7b97\u7b14\u8bb0\u672c\u3001\u7535\u5b50\u8868\u683c\u548c\u53ef\u89c6\u5316\u5de5\u5177\u7684\u6587\u672c\u5206\u6790\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u7684\u4e0d\u8db3\uff0c\u80fd\u591f\u5904\u7406\u6570\u636e\u5f02\u6784\u6027\u3001\u6570\u636e\u6765\u6e90\u3001\u5de5\u4f5c\u6d41\u53ef\u91cd\u7528\u6027\u548c\u53ef\u590d\u73b0\u6027\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5206\u6790\u7cfb\u7edf\u901a\u5e38\u53ea\u652f\u6301\u90e8\u5206\u5206\u6790\u9636\u6bb5\uff0c\u5e76\u4e14\u96be\u4ee5\u5e94\u5bf9\u6570\u636e\u5f02\u6784\u6027\u3001\u6570\u636e\u6765\u6e90\u3001\u5de5\u4f5c\u6d41\u53ef\u91cd\u7528\u6027\u548c\u53ef\u590d\u73b0\u6027\u4ee5\u53ca\u4e0e\u65e2\u6709\u5b9e\u8df5\u7684\u517c\u5bb9\u6027\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLeam\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5177\u6709\u4ea4\u4e92\u5f0f\u7528\u6237\u754c\u9762\u3001\u7528\u4e8e\u7ba1\u7406\u591a\u79cd\u539f\u5b50\u548c\u590d\u5408\u6570\u636e\u7c7b\u578b\u7684\u65b0\u578b\u6570\u636e\u6a21\u578b\uff0c\u4ee5\u53ca\u80fd\u591f\u6355\u83b7\u6587\u672c\u5206\u6790\u5404\u4e2a\u9636\u6bb5\u7684\u591a\u79cd\u64cd\u4f5c\u5e76\u5b9e\u73b0\u6570\u636e\u3001\u4ee3\u7801\u548c\u53ef\u89c6\u5316\u7b49\u4e0d\u540c\u7cfb\u7edf\u7ec4\u4ef6\u4e4b\u95f4\u534f\u8c03\u7684\u8868\u8fbe\u6027\u4ee3\u6570\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u793a\u4f8b\u5c55\u793a\u4e86Leam\u7684\u6709\u7528\u6027\uff0c\u5e76\u62a5\u544a\u4e86Leam\u7684\u5f00\u53d1\u8fdb\u5c55\u3002", "conclusion": "Leam\u7cfb\u7edf\u901a\u8fc7\u7ed3\u5408\u8ba1\u7b97\u7b14\u8bb0\u672c\u3001\u7535\u5b50\u8868\u683c\u548c\u53ef\u89c6\u5316\u5de5\u5177\u7684\u4f18\u70b9\uff0c\u5c06\u6587\u672c\u5206\u6790\u8fc7\u7a0b\u89c6\u4e3a\u4e00\u4e2a\u5355\u4e00\u7684\u8fde\u7eed\u4f53\uff0c\u4ee5\u5e94\u5bf9\u6570\u636e\u5f02\u6784\u6027\u3001\u6570\u636e\u6765\u6e90\u3001\u5de5\u4f5c\u6d41\u53ef\u91cd\u7528\u6027\u548c\u53ef\u590d\u73b0\u6027\u4ee5\u53ca\u4e0e\u65e2\u6709\u5b9e\u8df5\u7684\u517c\u5bb9\u6027\u7b49\u6311\u6218\u3002"}}
{"id": "2008.04543", "title": "Pen-based Interaction with Spreadsheets in Mobile Virtual Reality", "url": "https://arxiv.org/abs/2008.04543", "pdf": "https://arxiv.org/pdf/2008.04543", "abs": "https://arxiv.org/abs/2008.04543", "authors": ["Travis Gesslein", "Verena Biener", "Philipp Gagel", "Daniel Schneider", "Per Ola Kristensson", "Eyal Ofek", "Michel Pahud", "Jens Grubert"], "categories": ["cs.HC", "I.3.7"], "comment": "10 pages, 11 figures, ISMAR 2020", "summary": "Virtual Reality (VR) can enhance the display and interaction of mobile\nknowledge work and in particular, spreadsheet applications. While spreadsheets\nare widely used yet are challenging to interact with, especially on mobile\ndevices, using them in VR has not been explored in depth. A special uniqueness\nof the domain is the contrast between the immersive and large display space\nafforded by VR, contrasted by the very limited interaction space that may be\nafforded for the information worker on the go, such as an airplane seat or a\nsmall work-space. To close this gap, we present a tool-set for enhancing\nspreadsheet interaction on tablets using immersive VR headsets and pen-based\ninput. This combination opens up many possibilities for enhancing the\nproductivity for spreadsheet interaction. We propose to use the space around\nand in front of the tablet for enhanced visualization of spreadsheet data and\nmeta-data. For example, extending sheet display beyond the bounds of the\nphysical screen, or easier debugging by uncovering hidden dependencies between\nsheet's cells. Combining the precise on-screen input of a pen with spatial\nsensing around the tablet, we propose tools for the efficient creation and\nediting of spreadsheets functions such as off-the-screen layered menus,\nvisualization of sheets dependencies, and gaze-and-touch-based switching\nbetween spreadsheet tabs. We study the feasibility of the proposed tool-set\nusing a video-based online survey and an expert-based assessment of indicative\nhuman performance potential.", "AI": {"tldr": "VR\u7ed3\u5408\u5e73\u677f\u548c\u7b14\u8f93\u5165\uff0c\u589e\u5f3a\u7535\u5b50\u8868\u683c\u4ea4\u4e92\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u79fb\u52a8\u8bbe\u5907\u4e0a\u7535\u5b50\u8868\u683c\u4ea4\u4e92\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5229\u7528VR\u7684\u6c89\u6d78\u5f0f\u5927\u5c4f\u5e55\u663e\u793a\u7a7a\u95f4\u4e0e\u6709\u9650\u7684\u4ea4\u4e92\u7a7a\u95f4\u4e4b\u95f4\u7684\u5bf9\u6bd4\uff0c\u4ee5\u63d0\u9ad8\u79fb\u52a8\u77e5\u8bc6\u5de5\u4f5c\u8005\u7684\u751f\u4ea7\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u7ed3\u5408\u6c89\u6d78\u5f0fVR\u5934\u663e\u548c\u7b14\u5f0f\u8f93\u5165\u7684\u5de5\u5177\u96c6\uff0c\u5229\u7528\u5e73\u677f\u7535\u8111\u5468\u56f4\u548c\u524d\u65b9\u7684\u7a7a\u95f4\u6765\u589e\u5f3a\u7535\u5b50\u8868\u683c\u6570\u636e\u7684\u53ef\u89c6\u5316\u548c\u4ea4\u4e92\uff0c\u4f8b\u5982\u6269\u5c55\u8868\u683c\u663e\u793a\u3001\u53ef\u89c6\u5316\u5355\u5143\u683c\u4f9d\u8d56\u5173\u7cfb\u3001\u4ee5\u53ca\u57fa\u4e8e\u6ce8\u89c6\u548c\u89e6\u6478\u7684\u5207\u6362\u3002", "result": "\u901a\u8fc7\u89c6\u9891\u5728\u7ebf\u8c03\u67e5\u548c\u4e13\u5bb6\u8bc4\u4f30\uff0c\u521d\u6b65\u7814\u7a76\u4e86\u6240\u63d0\u51fa\u5de5\u5177\u96c6\u7684\u53ef\u884c\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u63d0\u9ad8\u7535\u5b50\u8868\u683c\u4ea4\u4e92\u6548\u7387\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u589e\u5f3aVR\u73af\u5883\u4e2d\u5e73\u677f\u7535\u8111\u4e0a\u7535\u5b50\u8868\u683c\u4ea4\u4e92\u7684\u5de5\u5177\u96c6\uff0c\u5e76\u901a\u8fc7\u89c6\u9891\u5728\u7ebf\u8c03\u67e5\u548c\u4e13\u5bb6\u8bc4\u4f30\u5bf9\u5176\u53ef\u884c\u6027\u8fdb\u884c\u4e86\u7814\u7a76\u3002"}}
{"id": "2005.05227", "title": "ObjTables: structured spreadsheets that promote data quality, reuse, and integration", "url": "https://arxiv.org/abs/2005.05227", "pdf": "https://arxiv.org/pdf/2005.05227", "abs": "https://arxiv.org/abs/2005.05227", "authors": ["Jonathan R. Karr", "Wolfram Liebermeister", "Arthur P. Goldberg", "John A. P. Sekar", "Bilal Shaikh"], "categories": ["cs.DB", "q-bio.QM"], "comment": "5 pages, 1 figures, 18 pages of supplementary information, 3\n  supplementary datasets", "summary": "A central challenge in science is to understand how systems behaviors emerge\nfrom complex networks. This often requires aggregating, reusing, and\nintegrating heterogeneous information. Supplementary spreadsheets to articles\nare a key data source. Spreadsheets are popular because they are easy to read\nand write. However, spreadsheets are often difficult to reanalyze because they\ncapture data ad hoc without schemas that define the objects, relationships, and\nattributes that they represent. To help researchers reuse and compose\nspreadsheets, we developed ObjTables, a toolkit that makes spreadsheets human-\nand machine-readable by combining spreadsheets with schemas and an\nobject-relational mapping system. ObjTables includes a format for schemas;\nmarkup for indicating the class and attribute represented by each spreadsheet\nand column; numerous data types for scientific information; and high-level\nsoftware for using schemas to read, write, validate, compare, merge, revision,\nand analyze spreadsheets. By making spreadsheets easier to reuse, ObjTables\ncould enable unprecedented secondary meta-analyses. By making it easy to build\nnew formats and associated software for new types of data, ObjTables can also\naccelerate emerging scientific fields.", "AI": {"tldr": "ObjTables\u662f\u4e00\u4e2a\u5de5\u5177\u5305\uff0c\u5b83\u4f7f\u7535\u5b50\u8868\u683c\u5177\u6709\u4eba\u7c7b\u548c\u673a\u5668\u53ef\u8bfb\u6027\uff0c\u901a\u8fc7\u7ed3\u5408\u6a21\u5f0f\u548c\u5bf9\u8c61\u5173\u7cfb\u6620\u5c04\u7cfb\u7edf\uff0c\u4ece\u800c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u91cd\u7528\u548c\u7ec4\u5408\u7535\u5b50\u8868\u683c\u3002", "motivation": "\u79d1\u5b66\u4e2d\u7684\u4e00\u4e2a\u4e2d\u5fc3\u6311\u6218\u662f\u4ece\u590d\u6742\u7f51\u7edc\u4e2d\u7406\u89e3\u7cfb\u7edf\u884c\u4e3a\u7684\u51fa\u73b0\uff0c\u8fd9\u901a\u5e38\u9700\u8981\u805a\u5408\u3001\u91cd\u7528\u548c\u96c6\u6210\u5f02\u6784\u4fe1\u606f\u3002\u6587\u7ae0\u7684\u8865\u5145\u7535\u5b50\u8868\u683c\u662f\u4e00\u4e2a\u5173\u952e\u7684\u6570\u636e\u6e90\u3002\u7535\u5b50\u8868\u683c\u4e4b\u6240\u4ee5\u53d7\u6b22\u8fce\uff0c\u662f\u56e0\u4e3a\u5b83\u4eec\u6613\u4e8e\u8bfb\u5199\u3002\u7136\u800c\uff0c\u7535\u5b50\u8868\u683c\u901a\u5e38\u96be\u4ee5\u91cd\u65b0\u5206\u6790\uff0c\u56e0\u4e3a\u5b83\u4eec\u662f\u4e34\u65f6\u521b\u5efa\u7684\uff0c\u6ca1\u6709\u5b9a\u4e49\u5b83\u4eec\u6240\u8868\u793a\u7684\u5bf9\u8c61\u3001\u5173\u7cfb\u548c\u5c5e\u6027\u7684\u6a21\u5f0f\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aObjTables\u7684\u5de5\u5177\u5305\uff0c\u5b83\u7ed3\u5408\u4e86\u6a21\u5f0f\u548c\u5bf9\u8c61\u5173\u7cfb\u6620\u5c04\u7cfb\u7edf\uff0c\u4f7f\u7535\u5b50\u8868\u683c\u5177\u6709\u4eba\u7c7b\u548c\u673a\u5668\u53ef\u8bfb\u6027\u3002ObjTables\u5305\u542b\u7528\u4e8e\u6a21\u5f0f\u7684\u683c\u5f0f\u3001\u7528\u4e8e\u6307\u793a\u6bcf\u4e2a\u7535\u5b50\u8868\u683c\u548c\u5217\u6240\u4ee3\u8868\u7684\u7c7b\u522b\u548c\u5c5e\u6027\u7684\u6807\u8bb0\u3001\u591a\u79cd\u79d1\u5b66\u4fe1\u606f\u6570\u636e\u7c7b\u578b\u4ee5\u53ca\u7528\u4e8e\u4f7f\u7528\u6a21\u5f0f\u8bfb\u53d6\u3001\u5199\u5165\u3001\u9a8c\u8bc1\u3001\u6bd4\u8f83\u3001\u5408\u5e76\u3001\u4fee\u8ba2\u548c\u5206\u6790\u7535\u5b50\u8868\u683c\u7684\u9ad8\u7ea7\u8f6f\u4ef6\u3002", "result": "ObjTables\u4f7f\u7535\u5b50\u8868\u683c\u66f4\u6613\u4e8e\u91cd\u7528\uff0c\u53ef\u80fd\u5b9e\u73b0\u524d\u6240\u672a\u6709\u7684\u4e8c\u6b21\u5143\u5206\u6790\u3002\u901a\u8fc7\u8f7b\u677e\u6784\u5efa\u65b0\u683c\u5f0f\u548c\u76f8\u5173\u8f6f\u4ef6\u4ee5\u652f\u6301\u65b0\u7c7b\u578b\u6570\u636e\uff0cObjTables\u8fd8\u53ef\u4ee5\u52a0\u901f\u65b0\u5174\u79d1\u5b66\u9886\u57df\u3002", "conclusion": "ObjTables\u5de5\u5177\u5305\u901a\u8fc7\u7ed3\u5408\u6a21\u5f0f\u548c\u5bf9\u8c61\u5173\u7cfb\u6620\u5c04\u7cfb\u7edf\uff0c\u4f7f\u7535\u5b50\u8868\u683c\u5177\u6709\u4eba\u7c7b\u548c\u673a\u5668\u53ef\u8bfb\u6027\uff0c\u4ece\u800c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u91cd\u7528\u548c\u7ec4\u5408\u7535\u5b50\u8868\u683c\uff0c\u4ece\u800c\u5b9e\u73b0\u524d\u6240\u672a\u6709\u7684\u4e8c\u6b21\u5143\u5206\u6790\uff0c\u5e76\u52a0\u901f\u65b0\u5174\u79d1\u5b66\u9886\u57df\u3002"}}
{"id": "2007.00003", "title": "EQUS -- helping to see formulae", "url": "https://arxiv.org/abs/2007.00003", "pdf": "https://arxiv.org/pdf/2007.00003", "abs": "https://arxiv.org/abs/2007.00003", "authors": ["Chris Roast"], "categories": ["cs.HC", "cs.SE"], "comment": "12 Pages, 7 Colour Figures", "summary": "Visualisation is often presented as a means of simplifying information and\nhelping people understand complex data. In this paper we describe the design,\ndevelopment and evaluation of an interactive visualisation for spreadsheet\nformulae (EQUS). The work is justified on the grounds that these are widely\nused tools for significant numerical processing and modeling, yet the formula\ndeveloped can be easily misunderstood. The development process was one of\niterative refinement engaging an initial target audience of mid-teen learners,\ninvolving re-design and formative evaluation. The resulting visualisation\ntechniques have been found to be broadly relevant to spreadsheet users beyond\nthe initial target audience. EQUS has since been developed as fully integrated\nplug-in for MS Excel.", "AI": {"tldr": "EQUS is an interactive visualisation tool for spreadsheet formulae, designed to simplify information and aid understanding of complex data. It was developed through iterative refinement with mid-teen learners and is relevant to a broader audience, now available as an MS Excel plug-in.", "motivation": "Spreadsheet formulae are widely used tools for significant numerical processing and modeling, yet the formulae developed can be easily misunderstood.", "method": "The development process involved iterative refinement, engaging an initial target audience of mid-teen learners, involving re-design and formative evaluation.", "result": "The resulting visualisation techniques have been found to be broadly relevant to spreadsheet users beyond the initial target audience. EQUS has since been developed as a fully integrated plug-in for MS Excel.", "conclusion": "EQUS visualisation techniques are broadly relevant to spreadsheet users beyond the initial target audience."}}
{"id": "2006.14694", "title": "From webtables to datatables", "url": "https://arxiv.org/abs/2006.14694", "pdf": "https://arxiv.org/pdf/2006.14694", "abs": "https://arxiv.org/abs/2006.14694", "authors": ["M\u00e1ria Csernoch"], "categories": ["cs.SE"], "comment": "22 pages, 34 Formulae & 21 Colour Figures", "summary": "Webtables -- tables and table-like structures on webpages -- are excellent\nsources for teaching spreadsheeting, in commercial and professional\norganisations by utilizing and developing knowledge-transfer items, presenting\nand handling various real-world problems and solutions, discussing and\ndebugging, and in general, developing and utilizing computational thinking\nskills. In the present paper the conversion process of one of the LOL Boards\n(League of Legends, Riot Games Inc. 2019) is detailed. After presenting the\nalgorithm of the conversion, two solutions are offered -- one in a word\nprocessor, the other purely in a spreadsheet application -- leaving space for\ndiscussions, inventing other solutions and combining them.", "AI": {"tldr": "This paper shows how to convert League of Legends leaderboards into spreadsheets for educational purposes, offering two methods to help develop computational thinking skills.", "motivation": "Webtables are valuable resources for teaching spreadsheet skills, knowledge transfer, problem-solving, and computational thinking in professional and educational settings.", "method": "The paper presents an algorithm for converting web data and offers two distinct implementation solutions for the conversion process.", "result": "Two solutions for converting a League of Legends leaderboard are provided: one using a word processor and the other solely within a spreadsheet application, allowing for further discussion and innovation.", "conclusion": "The paper details the conversion process of a League of Legends leaderboard, offering two implementation solutions (word processor and spreadsheet) to foster discussion and the development of computational thinking skills."}}
{"id": "2006.08224", "title": "Needles in the 'Sheet'stack: Augmented Analytics to get Insights from Spreadsheets", "url": "https://arxiv.org/abs/2006.08224", "pdf": "https://arxiv.org/pdf/2006.08224", "abs": "https://arxiv.org/abs/2006.08224", "authors": ["Medha Atre", "Anand Deshpande", "Reshma Godse", "Pooja Deokar", "Sandip Moharir", "Dhruva Ray", "Akshay Chitlangia", "Trupti Phadnis", "Yugansh Goyal"], "categories": ["cs.DB", "cs.HC", "H.2.8"], "comment": null, "summary": "Business intelligence (BI) tools for database analytics have come a long way\nand nowadays also provide ready insights or visual query explorations, e.g.\nQuickInsights by Microsoft Power BI, SpotIQ by ThoughtSpot, Zenvisage, etc. In\nthis demo, we focus on providing insights by examining periodic spreadsheets of\ndifferent reports (aka views), without prior knowledge of the schema of the\ndatabase or reports, or data information. Such a solution is targeted at users\nwithout the familiarity with the database schema or resources to conduct\nanalytics in the contemporary way.", "AI": {"tldr": "\u63d0\u4f9b\u4e00\u79cd\u65e0\u9700\u6570\u636e\u5e93\u77e5\u8bc6\u5373\u53ef\u4ece\u7535\u5b50\u8868\u683c\u4e2d\u83b7\u53d6\u89c1\u89e3\u7684\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\u7684\u5546\u4e1a\u667a\u80fd\u5de5\u5177\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u901a\u5e38\u9700\u8981\u7528\u6237\u5177\u5907\u4e00\u5b9a\u7684\u6570\u636e\u5e93\u77e5\u8bc6\u548c\u8d44\u6e90\u3002", "method": "\u901a\u8fc7\u68c0\u67e5\u4e0d\u540c\u62a5\u544a\uff08\u4e5f\u79f0\u4e3a\u89c6\u56fe\uff09\u7684\u5b9a\u671f\u7535\u5b50\u8868\u683c\u6765\u63d0\u4f9b\u89c1\u89e3\uff0c\u800c\u65e0\u9700\u9884\u5148\u4e86\u89e3\u6570\u636e\u5e93\u6a21\u5f0f\u6216\u62a5\u544a\uff0c\u6216\u6570\u636e\u4fe1\u606f\u3002", "result": "\u7528\u6237\u53ef\u4ee5\u8f7b\u677e\u5730\u4ece\u5b9a\u671f\u7535\u5b50\u8868\u683c\u4e2d\u83b7\u5f97\u6709\u4ef7\u503c\u7684\u6570\u636e\u89c1\u89e3\uff0c\u5373\u4f7f\u4ed6\u4eec\u4e0d\u719f\u6089\u6570\u636e\u5e93\u7ed3\u6784\u6216\u7f3a\u4e4f\u4e13\u95e8\u7684\u5206\u6790\u5de5\u5177\u3002", "conclusion": "\u8be5\u89e3\u51b3\u65b9\u6848\u7684\u76ee\u6807\u662f\u9762\u5411\u4e0d\u719f\u6089\u6570\u636e\u5e93\u6a21\u5f0f\u6216\u6ca1\u6709\u8d44\u6e90\u4ee5\u4f20\u7edf\u65b9\u5f0f\u8fdb\u884c\u5206\u6790\u7684\u7528\u6237\u3002"}}
{"id": "2006.05814", "title": "Implementation Strategies for Multidimensional Spreadsheets", "url": "https://arxiv.org/abs/2006.05814", "pdf": "https://arxiv.org/pdf/2006.05814", "abs": "https://arxiv.org/abs/2006.05814", "authors": ["Paul Mireault"], "categories": ["cs.SE"], "comment": "12 Pages, 18 Colour Figures. arXiv admin note: text overlap with\n  arXiv:1801.09777", "summary": "Seasoned Excel developers were invited to participate in a challenge to\nimplement a spreadsheet with multi-dimensional variables. We analyzed their\nspreadsheet to see the different implement strategies employed. We identified\ntwo strategies: most participants used a projection of three or\nfour-dimensional variables on the two-dimensional plane used by Excel. A few\nparticipants used a database approach where the multi-dimensional variables are\npresented in the form of a dataset table with the appropriate primary key. This\napproach leads to simpler formulas.", "AI": {"tldr": "Excel\u5f00\u53d1\u8005\u5904\u7406\u591a\u7ef4\u53d8\u91cf\u7684\u4e24\u79cd\u7b56\u7565\uff1a\u6295\u5f71\u548c\u6570\u636e\u5e93\u65b9\u6cd5\u3002\u6570\u636e\u5e93\u65b9\u6cd5\u516c\u5f0f\u66f4\u7b80\u5355\u3002", "motivation": "\u63a2\u8ba8Excel\u5f00\u53d1\u8005\u5728\u5904\u7406\u591a\u7ef4\u53d8\u91cf\u65f6\u7684\u4e0d\u540c\u5b9e\u73b0\u7b56\u7565\u3002", "method": "\u5bf9Excel\u5f00\u53d1\u8005\u5b9e\u73b0\u591a\u7ef4\u53d8\u91cf\u7535\u5b50\u8868\u683c\u7684\u7b56\u7565\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5927\u591a\u6570\u53c2\u4e0e\u8005\u91c7\u7528\u6295\u5f71\u7b56\u7565\uff0c\u5c11\u6570\u53c2\u4e0e\u8005\u91c7\u7528\u6570\u636e\u5e93\u65b9\u6cd5\uff0c\u540e\u8005\u516c\u5f0f\u66f4\u7b80\u5355\u3002", "conclusion": "Excel\u5f00\u53d1\u8005\u5728\u5b9e\u73b0\u591a\u7ef4\u53d8\u91cf\u7535\u5b50\u8868\u683c\u65f6\uff0c\u4e3b\u8981\u91c7\u7528\u4e86\u4e24\u79cd\u7b56\u7565\uff1a\u5c06\u591a\u7ef4\u53d8\u91cf\u6295\u5f71\u5230\u4e8c\u7ef4\u5e73\u9762\uff0c\u6216\u4f7f\u7528\u6570\u636e\u5e93\u65b9\u6cd5\u3002\u6570\u636e\u5e93\u65b9\u6cd5\u80fd\u7b80\u5316\u516c\u5f0f\u3002"}}
{"id": "2006.04794", "title": "Abstracting spreadsheet data flow through hypergraph redrawing", "url": "https://arxiv.org/abs/2006.04794", "pdf": "https://arxiv.org/pdf/2006.04794", "abs": "https://arxiv.org/abs/2006.04794", "authors": ["David Birch", "Nicolai Stawinoga", "Jack Binks", "Bruno Nicoletti", "Paul Kelly"], "categories": ["cs.SE"], "comment": "23 Pages, 12 Colour Figures", "summary": "We believe the error prone nature of traditional spreadsheets is due to their\nlow level of abstraction. End user programmers are forced to construct their\ndata models from low level cells which we define as \"a data container or\nmanipulator linked by user-intent to model their world and positioned to\nreflect its structure\". Spreadsheet cells are limited in what they may contain\n(scalar values) and the links between them are inherently hidden. This paper\nproposes a method of raising the level of abstraction of spreadsheets by\n\"redrawing the boundary\" of the cell. To expose the hidden linkage structure we\ntransform spreadsheets into fine-grained graphs with operators and values as\nnodes. \"cells\" are then represented as hypergraph edges by drawing a boundary\n\"wall\" around a set of operator/data nodes. To extend what cells may contain\nand to create a higher level model of the spreadsheet we propose that\nresearchers should seek techniques to redraw these boundaries to create higher\nlevel \"cells\" which will more faithfully represent the end-user's real\nworld/mental model. We illustrate this approach via common sub-expression\nidentification and the application of sub-tree isomorphisms for the detection\nof vector (array) operations.", "AI": {"tldr": "\u63d0\u9ad8\u7535\u5b50\u8868\u683c\u62bd\u8c61\u7ea7\u522b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u91cd\u6784\u548c\u5355\u5143\u683c\u8fb9\u754c\u91cd\u7ed8\u6765\u51cf\u5c11\u9519\u8bef\uff0c\u5e76\u66f4\u597d\u5730\u53cd\u6620\u7528\u6237\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u7684\u7535\u5b50\u8868\u683c\u5bb9\u6613\u51fa\u9519\uff0c\u56e0\u4e3a\u5176\u62bd\u8c61\u7ea7\u522b\u4f4e\uff0c\u7528\u6237\u88ab\u8feb\u4f7f\u7528\u4f4e\u7ea7\u7684\u5355\u5143\u683c\u6765\u6784\u5efa\u6570\u636e\u6a21\u578b\uff0c\u800c\u5355\u5143\u683c\u7684\u529f\u80fd\u6709\u9650\u4e14\u94fe\u63a5\u9690\u85cf\u3002", "method": "\u5c06\u7535\u5b50\u8868\u683c\u8f6c\u6362\u4e3a\u7ec6\u7c92\u5ea6\u56fe\uff0c\u5c06\u64cd\u4f5c\u7b26\u548c\u503c\u4f5c\u4e3a\u8282\u70b9\uff0c\u5c06\u5355\u5143\u683c\u8868\u793a\u4e3a\u5305\u542b\u4e00\u7ec4\u64cd\u4f5c\u7b26/\u6570\u636e\u8282\u70b9\u7684\u8d85\u56fe\u8fb9\u3002\u901a\u8fc7\u8bc6\u522b\u5e38\u89c1\u5b50\u8868\u8fbe\u5f0f\u548c\u5e94\u7528\u5b50\u6811\u540c\u6784\u6765\u68c0\u6d4b\u5411\u91cf\uff08\u6570\u7ec4\uff09\u64cd\u4f5c\u3002", "result": "\u8bf4\u660e\u4e86\u901a\u8fc7\u8bc6\u522b\u5e38\u89c1\u5b50\u8868\u8fbe\u5f0f\u548c\u5b50\u6811\u540c\u6784\u6765\u68c0\u6d4b\u5411\u91cf\uff08\u6570\u7ec4\uff09\u64cd\u4f5c\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u7535\u5b50\u8868\u683c\u7684\u62bd\u8c61\u7ea7\u522b\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7535\u5b50\u8868\u683c\u8f6c\u6362\u4e3a\u7ec6\u7c92\u5ea6\u56fe\uff0c\u5e76\u5141\u8bb8\u5355\u5143\u683c\u5305\u542b\u66f4\u591a\u5185\u5bb9\uff0c\u53ef\u4ee5\u63d0\u9ad8\u7535\u5b50\u8868\u683c\u7684\u62bd\u8c61\u7ea7\u522b\uff0c\u4f7f\u5176\u66f4\u5fe0\u5b9e\u5730\u53cd\u6620\u6700\u7ec8\u7528\u6237\u7684\u6a21\u578b\u3002"}}
{"id": "2006.04793", "title": "Developing Excel Thought Leadership", "url": "https://arxiv.org/abs/2006.04793", "pdf": "https://arxiv.org/pdf/2006.04793", "abs": "https://arxiv.org/abs/2006.04793", "authors": ["David Lyford-Smith"], "categories": ["cs.CY"], "comment": "8 Pages", "summary": "Over a period of five years, the Institute of Chartered Accountants in\nEngland and Wales (ICAEW) has developed a suite of three 'thought leadership'\npapers surrounding good practice in spreadsheet use and spreadsheet work\nenvironments. We will review the history of these three papers, the key lessons\nwhich each has to teach, and discuss how the process of making them has helped\nICAEW to develop its position in the field.", "AI": {"tldr": "ICAEW developed three papers on spreadsheet best practices over five years, establishing their expertise in the field.", "motivation": "To understand the evolution and impact of ICAEW's work on promoting good practice in spreadsheet environments.", "method": "Review the history and key lessons of three ICAEW 'thought leadership' papers on spreadsheet use and discuss the development process.", "result": "ICAEW has developed a suite of three 'thought leadership' papers and gained a stronger position in the field.", "conclusion": "ICAEW has established a leading position in promoting good practice in spreadsheet use through its 'thought leadership' papers."}}
{"id": "2004.11113", "title": "Human-Machine Collaboration for Democratizing Data Science", "url": "https://arxiv.org/abs/2004.11113", "pdf": "https://arxiv.org/pdf/2004.11113", "abs": "https://arxiv.org/abs/2004.11113", "authors": ["Cl\u00e9ment Gautrais", "Yann Dauxais", "Stefano Teso", "Samuel Kolb", "Gust Verbruggen", "Luc De Raedt"], "categories": ["cs.AI", "cs.HC", "I.2.1; H.5.2"], "comment": "26 pages", "summary": "Everybody wants to analyse their data, but only few posses the data science\nexpertise to to this. Motivated by this observation we introduce a novel\nframework and system \\textsc{VisualSynth} for human-machine collaboration in\ndata science.\n  It wants to democratize data science by allowing users to interact with\nstandard spreadsheet software in order to perform and automate various data\nanalysis tasks ranging from data wrangling, data selection, clustering,\nconstraint learning, predictive modeling and auto-completion.\n\\textsc{VisualSynth} relies on the user providing colored sketches, i.e.,\ncoloring parts of the spreadsheet, to partially specify data science tasks,\nwhich are then determined and executed using artificial intelligence\ntechniques.", "AI": {"tldr": "VisualSynth is a framework for human-machine collaboration in data science that uses AI to understand colored sketches in spreadsheets, making data analysis accessible to non-experts.", "motivation": "The motivation behind VisualSynth is to address the gap in data science expertise, allowing individuals without specialized knowledge to analyze their data.", "method": "VisualSynth utilizes AI techniques to interpret user-provided colored sketches in spreadsheet software to define and execute data science tasks.", "result": "VisualSynth allows users to interact with spreadsheet software to automate data wrangling, data selection, clustering, constraint learning, predictive modeling, and auto-completion.", "conclusion": "VisualSynth democratizes data science by enabling users to perform and automate various data analysis tasks using spreadsheet software and AI-powered sketch recognition."}}
{"id": "2001.01007", "title": "Automated Discovery of Data Transformations for Robotic Process Automation", "url": "https://arxiv.org/abs/2001.01007", "pdf": "https://arxiv.org/pdf/2001.01007", "abs": "https://arxiv.org/abs/2001.01007", "authors": ["Volodymyr Leno", "Marlon Dumas", "Marcello La Rosa", "Fabrizio Maria Maggi", "Artem Polyvyanyy"], "categories": ["cs.AI"], "comment": "8 pages, 5 figures. To be published in proceedings of AAAI-20\n  workshop on Intelligent Process Automation", "summary": "Robotic Process Automation (RPA) is a technology for automating repetitive\nroutines consisting of sequences of user interactions with one or more\napplications. In order to fully exploit the opportunities opened by RPA,\ncompanies need to discover which specific routines may be automated, and how.\nIn this setting, this paper addresses the problem of analyzing User Interaction\n(UI) logs in order to discover routines where a user transfers data from one\nspreadsheet or (Web) form to another. The paper maps this problem to that of\ndiscovering data transformations by example - a problem for which several\ntechniques are available. The paper shows that a naive application of a\nstate-of-the-art technique for data transformation discovery is computationally\ninefficient. Accordingly, the paper proposes two optimizations that take\nadvantage of the information in the UI log and the fact that data transfers\nacross applications typically involve copying alphabetic and numeric tokens\nseparately. The proposed approach and its optimizations are evaluated using UI\nlogs that replicate a real-life repetitive data transfer routine.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5206\u6790UI\u65e5\u5fd7\u6765\u53d1\u73b0\u53ef\u81ea\u52a8\u5316\u7684\u6570\u636e\u4f20\u8f93\u4f8b\u7a0b\u7684\u65b9\u6cd5\uff0c\u5e76\u9488\u5bf9\u73b0\u6709\u6280\u672f\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u63d0\u51fa\u4e86\u4f18\u5316\u65b9\u6848\u3002", "motivation": "\u4e3a\u4e86\u5145\u5206\u5229\u7528RPA\uff08\u673a\u5668\u4eba\u6d41\u7a0b\u81ea\u52a8\u5316\uff09\u6280\u672f\uff0c\u9700\u8981\u53d1\u73b0\u53ef\u81ea\u52a8\u5316\u7684\u5177\u4f53\u4f8b\u7a0b\u3002", "method": "\u5c06UI\u65e5\u5fd7\u5206\u6790\u95ee\u9898\u6620\u5c04\u5230\u901a\u8fc7\u793a\u4f8b\u53d1\u73b0\u6570\u636e\u8f6c\u6362\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u4f18\u5316\u65b9\u6848\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u4f18\u5316\u65b9\u6848\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u91cd\u590d\u6570\u636e\u4f20\u8f93\u4f8b\u7a0b\u7684UI\u65e5\u5fd7\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7UI\u65e5\u5fd7\u5206\u6790\u548c\u6570\u636e\u8f6c\u6362\u53d1\u73b0\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u91cd\u590d\u6027\u6570\u636e\u4f20\u8f93\u4f8b\u7a0b\u3002"}}
{"id": "1912.09209", "title": "Comprehensive review for common types of errors using spreadsheets", "url": "https://arxiv.org/abs/1912.09209", "pdf": "https://arxiv.org/pdf/1912.09209", "abs": "https://arxiv.org/abs/1912.09209", "authors": ["Ali Aburas"], "categories": ["cs.SE"], "comment": null, "summary": "Thanks to their flexibility and capability to perform different tasks and\norganize data in the best form and format, spreadsheets are widely used in\ndifferent organizations and by different end users. Many business organizations\nrely on spreadsheets to fulfill their various tasks. On the other hand, the\nnumber of spreadsheets that contain errors are very high, thus researchers have\ndeveloped different tools aimed at the prevention, detection, and correction of\nerrors in spreadsheets. This research work is a comprehensive review that\ndescribes and classifies approaches on finding and fixing errors in\nspreadsheets. The paper discusses up-to-date research work approaches in terms\nof definition, how they work, and kinds of errors they can find in\nspreadsheets. The paper looks also for the kinds of errors that end users\ncommonly make in spreadsheets.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5168\u9762\u56de\u987e\u4e86\u7535\u5b50\u8868\u683c\u9519\u8bef\u67e5\u627e\u548c\u4fee\u590d\u7684\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u7528\u6237\u5e38\u72af\u7684\u9519\u8bef\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u56e0\u5176\u7075\u6d3b\u6027\u548c\u7ec4\u7ec7\u6570\u636e\u7684\u80fd\u529b\u800c\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u4e2d\u5305\u542b\u5927\u91cf\u9519\u8bef\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u9519\u8bef\u9884\u9632\u3001\u68c0\u6d4b\u548c\u7ea0\u6b63\u7684\u5de5\u5177\u3002", "method": "\u5bf9\u73b0\u6709\u7814\u7a76\u5de5\u4f5c\u8fdb\u884c\u4e86\u63cf\u8ff0\u548c\u5206\u7c7b\uff0c\u8ba8\u8bba\u4e86\u5404\u79cd\u65b9\u6cd5\u7684\u5b9a\u4e49\u3001\u5de5\u4f5c\u539f\u7406\u4ee5\u53ca\u5b83\u4eec\u80fd\u53d1\u73b0\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u540c\u65f6\u4e5f\u5173\u6ce8\u4e86\u7528\u6237\u5e38\u72af\u7684\u9519\u8bef\u3002", "result": "\u5bf9\u5f53\u524d\u7535\u5b50\u8868\u683c\u9519\u8bef\u67e5\u627e\u548c\u4fee\u590d\u7684\u7814\u7a76\u5de5\u4f5c\u8fdb\u884c\u4e86\u5168\u9762\u7684\u68b3\u7406\u548c\u603b\u7ed3\uff0c\u5e76\u6307\u51fa\u4e86\u7528\u6237\u5e38\u72af\u7684\u9519\u8bef\u7c7b\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5bf9\u7535\u5b50\u8868\u683c\u9519\u8bef\u67e5\u627e\u548c\u4fee\u590d\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u56de\u987e\u548c\u5206\u7c7b\u3002"}}
{"id": "1910.05685", "title": "A Coding-free Software Framework of Developing Web Data Management Systems", "url": "https://arxiv.org/abs/1910.05685", "pdf": "https://arxiv.org/pdf/1910.05685", "abs": "https://arxiv.org/abs/1910.05685", "authors": ["Can Yang", "Shiying Pan", "Runmin Li", "Yu Liu", "Lizhang Peng"], "categories": ["cs.SE"], "comment": "16pages, 11 figures, 2 tables", "summary": "More and more enterprises recently intend to deploy data management systems\nin the cloud. Due to the professionalism of software development, it has still\nbeen difficult for non-programmers to develop this kind of systems, even a\nsmall one. However, the development of SaaS brings forth the more feasibility\nof coding-free software development than before. Based on the SaaS\narchitecture, this paper presents a set of theory and method for coding-free\nconstruction of a data management system, on which our contributions involve in\na practical application platform, a set of construction method and a set of\ninterface on data exchange. By abstracting the common features of data\nmanagement systems, we design a universal web platform to quickly generate and\npublish customized system instances. Moreover, we propose a kind of method to\ndevelop a data management system using a specific requirements table in\nspreadsheet. The corresponding platform maps the requirements table into a\nsystem instance through parsing the table model and implementing the objective\nsystem in the running stage. Finally, we implement the proposed framework and\ndeploy it on web. The empirical result demonstrates the feasibility and\navailability of the coding-free method in developing web data management\nsystems.", "AI": {"tldr": "A coding-free method for developing data management systems using SaaS architecture and a requirements table in spreadsheet has been developed and proven feasible.", "motivation": "Enterprises intend to deploy data management systems in the cloud, but it is difficult for non-programmers to develop such systems. SaaS has made coding-free software development more feasible.", "method": "Based on the SaaS architecture, this paper presents a set of theory and method for coding-free construction of a data management system, which involves a practical application platform, a set of construction method, and a set of interface on data exchange. The platform abstracts common features of data management systems to generate customized system instances, and the method uses a requirements table in spreadsheet to develop the system. The platform maps the requirements table into a system instance by parsing the table model and implementing the objective system.", "result": "A universal web platform and a method for coding-free development of data management systems were implemented and deployed on the web. Empirical results showed the method is feasible and available.", "conclusion": "The empirical result demonstrates the feasibility and availability of the coding-free method in developing web data management systems."}}
{"id": "1712.05944", "title": "Taggle: Combining Overview and Details in Tabular Data Visualizations", "url": "https://arxiv.org/abs/1712.05944", "pdf": "https://arxiv.org/pdf/1712.05944", "abs": "https://arxiv.org/abs/1712.05944", "authors": ["Katarina Furmanova", "Samuel Gratzl", "Holger Stitz", "Thomas Zichner", "Miroslava Jaresova", "Alexander Lex", "Marc Streit"], "categories": ["cs.HC"], "comment": null, "summary": "Most tabular data visualization techniques focus on overviews, yet many\npractical analysis tasks are concerned with investigating individual items of\ninterest. At the same time, relating an item to the rest of a potentially large\ntable is important. In this work we present Taggle, a tabular visualization\ntechnique for exploring and presenting large and complex tables. Taggle takes\nan item-centric, spreadsheet-like approach, visualizing each row in the source\ndata individually using visual encodings for the cells. At the same time,\nTaggle introduces data-driven aggregation of data subsets. The aggregation\nstrategy is complemented by interaction methods tailored to answer specific\nanalysis questions, such as sorting based on multiple columns and rich data\nselection and filtering capabilities. We demonstrate Taggle using a case study\nconducted by a domain expert on complex genomics data analysis for the purpose\nof drug discovery.", "AI": {"tldr": "Taggle\u662f\u4e00\u79cd\u7528\u4e8e\u5927\u578b\u590d\u6742\u8868\u683c\u7684\u53ef\u89c6\u5316\u6280\u672f\uff0c\u5b83\u4ee5\u9010\u884c\u53ef\u89c6\u5316\u548c\u6570\u636e\u805a\u5408\u4e3a\u7279\u70b9\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u529f\u80fd\u589e\u5f3a\u4e86\u6570\u636e\u63a2\u7d22\u80fd\u529b\u3002", "motivation": "\u8bb8\u591a\u8868\u683c\u6570\u636e\u53ef\u89c6\u5316\u6280\u672f\u4fa7\u91cd\u4e8e\u6982\u89c8\uff0c\u800c\u5ffd\u7565\u4e86\u5bf9\u4e2a\u4f53\u6570\u636e\u9879\u7684\u6df1\u5165\u7814\u7a76\uff0c\u800c\u5173\u8054\u6570\u636e\u9879\u4e0e\u5927\u578b\u8868\u683c\u7684\u5176\u4f59\u90e8\u5206\u5bf9\u4e8e\u5b9e\u9645\u5206\u6790\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002", "method": "Taggle\u901a\u8fc7\u53ef\u89c6\u5316\u6bcf\u884c\u6570\u636e\uff0c\u5e76\u5f15\u5165\u6570\u636e\u9a71\u52a8\u7684\u805a\u5408\u548c\u4ea4\u4e92\u65b9\u6cd5\uff08\u5982\u591a\u5217\u6392\u5e8f\u3001\u6570\u636e\u9009\u62e9\u548c\u8fc7\u6ee4\uff09\uff0c\u6765\u89e3\u51b3\u5927\u578b\u8868\u683c\u7684\u63a2\u7d22\u548c\u5448\u73b0\u95ee\u9898\u3002", "result": "Taggle\u901a\u8fc7\u4e00\u4e2a\u9886\u57df\u4e13\u5bb6\u5728\u590d\u6742\u7684\u57fa\u56e0\u7ec4\u6570\u636e\u5206\u6790\uff08\u7528\u4e8e\u836f\u7269\u53d1\u73b0\uff09\u6848\u4f8b\u7814\u7a76\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5904\u7406\u5927\u578b\u590d\u6742\u8868\u683c\u65b9\u9762\u7684\u80fd\u529b\u3002", "conclusion": "Taggle\u662f\u4e00\u79cd\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u3001\u7c7b\u4f3c\u7535\u5b50\u8868\u683c\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u6bcf\u884c\u6570\u636e\u5e76\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u7684\u805a\u5408\u4ee5\u53ca\u4e13\u95e8\u7684\u4ea4\u4e92\u65b9\u6cd5\uff0c\u6765\u63a2\u7d22\u548c\u5448\u73b0\u5927\u578b\u590d\u6742\u8868\u683c\uff0c\u9002\u7528\u4e8e\u836f\u7269\u53d1\u73b0\u7b49\u9886\u57df\u3002"}}
{"id": "1909.07462", "title": "A Case Study of Spreadsheet Use within the Finance and Academic Registry units within a Higher Education Institution", "url": "https://arxiv.org/abs/1909.07462", "pdf": "https://arxiv.org/pdf/1909.07462", "abs": "https://arxiv.org/abs/1909.07462", "authors": ["Simon Thorne", "Jamie Hancock"], "categories": ["cs.CY"], "comment": "15 Pages, 20 Tables", "summary": "This paper presents the findings of a case study of spreadsheet use in a\nhigher education institution in the UK. The paper considers the use of\nspreadsheets in two units of the organisation, academic registry and finance.\nSpreadsheet use is explored in terms of importance, training, experience,\npurpose, techniques deployed, size of spreadsheets created and sharing of\nspreadsheets. The implications of the results are then considered in terms of\naccurate reporting to external funding bodies such the funding councils,\ninternal data integrity and internal data efficiencies. The results show a\nlarge volume of spreadsheets being created and used, that the profile of\nspreadsheet developers is typical of other studies of spreadsheet use and the\nneed for the organisation to have clear principles and guidelines for the\ndevelopment of spreadsheet models in the organisation to ensure data integrity,\nreduce duplication of effort and to optimise the use of spreadsheets to meet\nthe institutions goals.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u82f1\u56fd\u4e00\u6240\u9ad8\u7b49\u6559\u80b2\u673a\u6784\u4e2d\u7535\u5b50\u8868\u683c\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u5f3a\u8c03\u4e86\u5236\u5b9a\u660e\u786e\u7684\u7535\u5b50\u8868\u683c\u5f00\u53d1\u6307\u5357\u4ee5\u786e\u4fdd\u6570\u636e\u5b8c\u6574\u6027\u548c\u63d0\u9ad8\u6548\u7387\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u63a2\u8ba8\u7535\u5b50\u8868\u683c\u5728\u9ad8\u7b49\u6559\u80b2\u673a\u6784\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u5e76\u8003\u8651\u5176\u5bf9\u51c6\u786e\u62a5\u544a\u3001\u6570\u636e\u5b8c\u6574\u6027\u548c\u6570\u636e\u6548\u7387\u7684\u5f71\u54cd\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u82f1\u56fd\u4e00\u6240\u9ad8\u7b49\u6559\u80b2\u673a\u6784\u4e2d\u7535\u5b50\u8868\u683c\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u91cd\u70b9\u5173\u6ce8\u4e86\u5b66\u672f\u6ce8\u518c\u548c\u8d22\u52a1\u4e24\u4e2a\u90e8\u95e8\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u673a\u6784\u521b\u5efa\u548c\u4f7f\u7528\u7684\u7535\u5b50\u8868\u683c\u6570\u91cf\u5e9e\u5927\uff0c\u7535\u5b50\u8868\u683c\u5f00\u53d1\u8005\u7684\u6784\u6210\u4e0e\u5176\u4ed6\u76f8\u5173\u7814\u7a76\u4e00\u81f4\uff0c\u5e76\u5f3a\u8c03\u4e86\u5236\u5b9a\u660e\u786e\u7684\u7535\u5b50\u8868\u683c\u5f00\u53d1\u539f\u5219\u548c\u6307\u5357\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7ec4\u7ec7\u9700\u8981\u5236\u5b9a\u660e\u786e\u7684\u7535\u5b50\u8868\u683c\u6a21\u578b\u5f00\u53d1\u539f\u5219\u548c\u6307\u5357\uff0c\u4ee5\u786e\u4fdd\u6570\u636e\u5b8c\u6574\u6027\u3001\u51cf\u5c11\u5de5\u4f5c\u91cd\u590d\u5e76\u4f18\u5316\u7535\u5b50\u8868\u683c\u7684\u4f7f\u7528\u4ee5\u5b9e\u73b0\u673a\u6784\u76ee\u6807\u3002"}}
{"id": "1909.00891", "title": "Structured Spreadsheet Modelling and Implementation with Multiple Dimensions -- Part 2: Implementation", "url": "https://arxiv.org/abs/1909.00891", "pdf": "https://arxiv.org/pdf/1909.00891", "abs": "https://arxiv.org/abs/1909.00891", "authors": ["Paul Mireault"], "categories": ["cs.SE"], "comment": "14 Pages, 12 Colour Figures, 3 Tables. First presented at EuSpRIG\n  2018, Imperial College, London", "summary": "In Part 1, we showed how to develop a conceptual model of a problem involving\nvariables of multiple dimensions, like Products, Regions, Sectors and Months.\nThe conceptual model is presented as a Formula Diagram, giving a global view of\nthe interaction between all the variables, and a Formula List, giving a precise\nview of the interaction between the variables. In this paper, we present\nprecise steps to implement a multi-dimensional problem in a way that will\nproduce a spreadsheet that is easy to maintain", "AI": {"tldr": "This paper provides practical steps to implement multi-dimensional problems in a spreadsheet, making it easy to maintain.", "motivation": "To provide practical steps for implementing multi-dimensional problems in an easily maintainable spreadsheet format, extending previous conceptual work.", "method": "The paper describes the implementation of a multi-dimensional problem using a spreadsheet, building upon a conceptual model presented as a Formula Diagram and Formula List from a previous part.", "result": "A spreadsheet that is easy to maintain for multi-dimensional problems, based on a conceptual model with Formula Diagrams and Formula Lists.", "conclusion": "The paper presents precise steps to implement a multi-dimensional problem in a spreadsheet for easy maintenance."}}
{"id": "1909.00865", "title": "Are digital natives spreadsheet natives?", "url": "https://arxiv.org/abs/1909.00865", "pdf": "https://arxiv.org/pdf/1909.00865", "abs": "https://arxiv.org/abs/1909.00865", "authors": ["Maria Csernoch", "Piroska Bir\u00f3"], "categories": ["cs.HC"], "comment": "13 Pages, 6 Colour Figures, 9 Tables. First Presented at the EuSpRIG\n  2018 conference, Imperial College, London", "summary": "The present paper reports the results of testing first year students of\nInformatics on their algorithmic skills and knowledge transfer abilities in\nspreadsheet environments. The selection of students plays a crucial role in the\nproject. On the one hand, they have officially finished their spreadsheet\ntraining - they know everything - while on the other hand, they do not need any\ntraining, since they are digital natives, to whom digital skills are assigned\nby birth. However, we found that the students had serious difficulties in\nsolving the spreadsheet problems presented: so low were their results that it\nallowed us to form broad tendencies. Considering computational thinking,\nalgorithmic skills, and knowledge transfer abilities, it is clear that those\nstudents performed better who used algorithm-based, multilevel array formulas\ninstead of problem specific, unconnected built-in functions. Furthermore, we\ncan conclude that students, regardless of their birth date and digital\ngeneration assigned to them, are in great need of official, high-mathability,\nalgorithm-based training with expert teachers.", "AI": {"tldr": "\u6570\u5b57\u539f\u751f\u4ee3\u5b66\u751f\u5728\u7535\u5b50\u8868\u683c\u95ee\u9898\u89e3\u51b3\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u4f7f\u7528\u57fa\u4e8e\u7b97\u6cd5\u7684\u516c\u5f0f\u6bd4\u4f7f\u7528\u5185\u7f6e\u51fd\u6570\u6548\u679c\u66f4\u597d\uff0c\u8868\u660e\u9700\u8981\u8fdb\u884c\u6b63\u5f0f\u7684\u3001\u57fa\u4e8e\u7b97\u6cd5\u7684\u57f9\u8bad\u3002", "motivation": "\u8bc4\u4f30\u6570\u5b57\u539f\u751f\u4ee3\u5b66\u751f\u5728\u7535\u5b50\u8868\u683c\u73af\u5883\u4e2d\u7684\u7b97\u6cd5\u6280\u80fd\u548c\u77e5\u8bc6\u8f6c\u79fb\u80fd\u529b\u3002", "method": "\u6d4b\u8bd5\u4e00\u5e74\u7ea7\u4fe1\u606f\u5b66\u5b66\u751f\u5728\u7535\u5b50\u8868\u683c\u73af\u5883\u4e2d\u7684\u7b97\u6cd5\u6280\u80fd\u548c\u77e5\u8bc6\u8f6c\u79fb\u80fd\u529b\u3002", "result": "\u5373\u4f7f\u662f\u6570\u5b57\u539f\u751f\u4ee3\u5b66\u751f\u5728\u89e3\u51b3\u7535\u5b50\u8868\u683c\u95ee\u9898\u65f6\u4e5f\u9047\u5230\u4e86\u56f0\u96be\u3002\u4f7f\u7528\u57fa\u4e8e\u7b97\u6cd5\u7684\u591a\u5c42\u6570\u7ec4\u516c\u5f0f\u7684\u5b66\u751f\u6bd4\u4f7f\u7528\u7279\u5b9a\u4e8e\u95ee\u9898\u7684\u3001\u4e0d\u76f8\u5173\u7684\u5185\u7f6e\u51fd\u6570 Thus, the study highlights the need for more structured and in-depth training in computational thinking and algorithmic skills, even for students who are considered digital natives.", "conclusion": "\u5b66\u751f\u9700\u8981\u9ad8\u9636\u6570\u5b66\u80fd\u529b\u3001\u57fa\u4e8e\u7b97\u6cd5\u7684\u5b98\u65b9\u57f9\u8bad\u548c\u4e13\u5bb6\u6559\u5e08\u7684\u6307\u5bfc\u3002"}}
{"id": "1909.02960", "title": "Real-time stock analysis for blending recipes in industrial plants", "url": "https://arxiv.org/abs/1909.02960", "pdf": "https://arxiv.org/pdf/1909.02960", "abs": "https://arxiv.org/abs/1909.02960", "authors": ["Florin Zamfir", "Nicolae Paraschiv", "Emil Pricop"], "categories": ["cs.OH"], "comment": "Accepted for presentation at 23rd International Conference on System\n  Theory, Control and Computing (ICSTCC 2019), October 9-11, 2019, Sinaia,\n  Romania", "summary": "Many companies use Excel spreadsheets to keep stock records and to calculate\nprocess-specific data. These spreadsheets are often hard to understand and\ntrack. And if the user does not protect them, there is a risk that the user\nrandomly changes or erase formulas. The paper focuses on the stocks of products\nused in a blending process with a known recipe. Developing an application that\ncan bring this data in a centralized form and that can assist the operator in\ndecide is a necessity. When a programmer implements an application that uses\ndata from plants he needs to consider one fundamental aspect as reading\nreal-time data from the process. The real-time stock analysis application takes\ninto account all the above elements. The application is easy to use by an\noperator in the command room of installation because of the planning algorithms\nintegrated into it. The algorithms proposed and implemented in this paper have\nwell-defined goals: identifying the ingredients needed to achieve the blending\nprocess for required quantities, determine the quantities of the finished\nproduct that can be made with the existing ingredients and determine the\noptimum quantities of the finished product. The application implemented in C#\nintensively uses these algorithms and gives the user the ability to build the\nresult step by step.", "AI": {"tldr": "\u4e3a\u89e3\u51b3Excel\u5728\u5e93\u5b58\u7ba1\u7406\u4e2d\u7684\u7f3a\u9677\uff0c\u5f00\u53d1\u4e86\u4e00\u6b3eC#\u5e94\u7528\u7a0b\u5e8f\uff0c\u8be5\u7a0b\u5e8f\u4f7f\u7528\u89c4\u5212\u7b97\u6cd5\u6765\u4f18\u5316\u751f\u4ea7\u548c\u5e93\u5b58\u7ba1\u7406\u3002", "motivation": "\u5f53\u524d\u516c\u53f8\u4f7f\u7528\u7684Excel\u7535\u5b50\u8868\u683c\u5728\u5e93\u5b58\u8bb0\u5f55\u548c\u6d41\u7a0b\u6570\u636e\u8ba1\u7b97\u65b9\u9762\u5b58\u5728\u96be\u4ee5\u7406\u89e3\u3001\u8ddf\u8e2a\u56f0\u96be\u4ee5\u53ca\u6613\u88ab\u968f\u610f\u66f4\u6539\u6216\u5220\u9664\u516c\u5f0f\u7684\u98ce\u9669\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u4e2a\u96c6\u4e2d\u5f0f\u5e94\u7528\u7a0b\u5e8f\u6765\u7ba1\u7406\u6b64\u6570\u636e\uff0c\u5e76\u534f\u52a9\u64cd\u4f5c\u5458\u8fdb\u884c\u51b3\u7b56\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b9e\u65f6\u5e93\u5b58\u5206\u6790\u5e94\u7528\u7a0b\u5e8f\uff0c\u8be5\u5e94\u7528\u7a0b\u5e8f\u4f7f\u7528C#\u7f16\u7a0b\u8bed\u8a00\uff0c\u5e76\u96c6\u6210\u4e86\u7528\u4e8e\u786e\u5b9a\u6240\u9700\u6210\u5206\u3001\u53ef\u751f\u4ea7\u7684\u6210\u54c1\u6570\u91cf\u4ee5\u53ca\u4f18\u5316\u6210\u54c1\u6570\u91cf\u7684\u89c4\u5212\u7b97\u6cd5\u3002", "result": "\u8be5\u5e94\u7528\u7a0b\u5e8f\u80fd\u591f\u8bc6\u522b\u751f\u4ea7\u6240\u9700\u6570\u91cf\u7684\u6df7\u5408\u8fc7\u7a0b\u6240\u9700\u7684\u6210\u5206\uff0c\u786e\u5b9a\u73b0\u6709\u6210\u5206\u53ef\u751f\u4ea7\u7684\u6210\u54c1\u6570\u91cf\uff0c\u4ee5\u53ca\u4f18\u5316\u6210\u54c1\u6570\u91cf\u3002\u64cd\u4f5c\u5458\u53ef\u4ee5\u901a\u8fc7\u8be5\u5e94\u7528\u7a0b\u5e8f\u9010\u6b65\u6784\u5efa\u7ed3\u679c\u3002", "conclusion": "\u8be5\u5e94\u7528\u7a0b\u5e8f\u5229\u7528C#\u548c\u96c6\u6210\u7684\u89c4\u5212\u7b97\u6cd5\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9010\u6b65\u6784\u5efa\u7ed3\u679c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86Excel\u7535\u5b50\u8868\u683c\u5728\u4ea7\u54c1\u5e93\u5b58\u8bb0\u5f55\u548c\u6d41\u7a0b\u6570\u636e\u8ba1\u7b97\u4e2d\u7684\u4e0d\u8db3\u3002"}}
{"id": "1908.08187", "title": "A CNN toolbox for skin cancer classification", "url": "https://arxiv.org/abs/1908.08187", "pdf": "https://arxiv.org/pdf/1908.08187", "abs": "https://arxiv.org/abs/1908.08187", "authors": ["Fabrizio Nunnari", "Daniel Sonntag"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "DFKI Technical Report", "summary": "We describe a software toolbox for the configuration of deep neural networks\nin the domain of skin cancer classification. The implemented software\narchitecture allows developers to quickly set up new convolutional neural\nnetwork (CNN) architectures and hyper-parameter configurations. At the same\ntime, the user interface, manageable as a simple spreadsheet, allows\nnon-technical users to explore different configuration settings that need to be\nexplored when switching to different data sets. In future versions, meta\nleaning frameworks can be added, or AutoML systems that continuously improve\nover time. Preliminary results, conducted with two CNNs in the context melanoma\ndetection on dermoscopic images, quantify the impact of image augmentation,\nimage resolution, and rescaling filter on the overall detection performance and\ntraining time.", "AI": {"tldr": "\u4e00\u4e2a\u7528\u4e8e\u76ae\u80a4\u764c\u5206\u7c7b\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u914d\u7f6e\u8f6f\u4ef6\u5de5\u5177\u7bb1\u3002", "motivation": "\u65e8\u5728\u4e3a\u76ae\u80a4\u764c\u5206\u7c7b\u9886\u57df\u63d0\u4f9b\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u8f6f\u4ef6\u5de5\u5177\u7bb1\uff0c\u4ee5\u7b80\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u914d\u7f6e\u8fc7\u7a0b\u3002", "method": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u8f6f\u4ef6\u5de5\u5177\u7bb1\uff0c\u8be5\u5de5\u5177\u7bb1\u5177\u6709\u5141\u8bb8\u5f00\u53d1\u8005\u5feb\u901f\u8bbe\u7f6e\u65b0\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u67b6\u6784\u548c\u8d85\u53c2\u6570\u914d\u7f6e\u7684\u8f6f\u4ef6\u67b6\u6784\u3002", "result": "\u901a\u8fc7\u5728\u9ed1\u8272\u7d20\u7624\u68c0\u6d4b\u4e2d\u4f7f\u7528\u4e24\u4e2aCNN\u8fdb\u884c\u7684\u521d\u6b65\u7ed3\u679c\uff0c\u91cf\u5316\u4e86\u56fe\u50cf\u589e\u5f3a\u3001\u56fe\u50cf\u5206\u8fa8\u7387\u548c\u91cd\u7f29\u653e\u6ee4\u6ce2\u5668\u5bf9\u6574\u4f53\u68c0\u6d4b\u6027\u80fd\u548c\u8bad\u7ec3\u65f6\u95f4\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u8f6f\u4ef6\u5de5\u5177\u7bb1\u80fd\u591f\u5e2e\u52a9\u5f00\u53d1\u8005\u5feb\u901f\u914d\u7f6e\u7528\u4e8e\u76ae\u80a4\u764c\u5206\u7c7b\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u4e14\u5176\u7528\u6237\u754c\u9762\u5141\u8bb8\u975e\u6280\u672f\u7528\u6237\u8fdb\u884c\u914d\u7f6e\u3002"}}
{"id": "1907.03595", "title": "Recommending Related Tables", "url": "https://arxiv.org/abs/1907.03595", "pdf": "https://arxiv.org/pdf/1907.03595", "abs": "https://arxiv.org/abs/1907.03595", "authors": ["Shuo Zhang", "Krisztian Balog"], "categories": ["cs.IR"], "comment": null, "summary": "Tables are an extremely powerful visual and interactive tool for structuring\nand manipulating data, making spreadsheet programs one of the most popular\ncomputer applications. In this paper we introduce and address the task of\nrecommending related tables: given an input table, identifying and returning a\nranked list of relevant tables. One of the many possible application scenarios\nfor this task is to provide users of a spreadsheet program proactively with\nrecommendations for related structured content on the Web. At its core, the\nrelated table recommendation task boils down to computing the similarity\nbetween a pair of tables. We develop a theoretically sound framework for\nperforming table matching. Our approach hinges on the idea of representing\ntable elements in multiple semantic spaces, and then combining element-level\nsimilarities using a discriminative learning model. Using a purpose-built test\ncollection from Wikipedia tables, we demonstrate that the proposed approach\ndelivers state-of-the-art performance.", "AI": {"tldr": "This paper introduces and addresses the task of recommending related tables by computing the similarity between tables using a novel framework that represents table elements in multiple semantic spaces and combines them using a discriminative learning model. The approach achieves state-of-the-art performance on a Wikipedia tables test collection.", "motivation": "The motivation is to recommend related tables, which can be used to proactively provide users of spreadsheet programs with recommendations for related structured content on the Web.", "method": "The approach hinges on the idea of representing table elements in multiple semantic spaces, and then combining element-level similarities using a discriminative learning model.", "result": "The proposed approach delivers state-of-the-art performance.", "conclusion": "We demonstrate that the proposed approach delivers state-of-the-art performance using a purpose-built test collection from Wikipedia tables."}}
{"id": "1907.04827", "title": "Hillview: A trillion-cell spreadsheet for big data", "url": "https://arxiv.org/abs/1907.04827", "pdf": "https://arxiv.org/pdf/1907.04827", "abs": "https://arxiv.org/abs/1907.04827", "authors": ["Mihai Budiu", "Parikshit Gopalan", "Lalith Suresh", "Udi Wieder", "Han Kruiger", "Marcos K. Aguilera"], "categories": ["cs.DC"], "comment": null, "summary": "Hillview is a distributed spreadsheet for browsing very large datasets that\ncannot be handled by a single machine. As a spreadsheet, Hillview provides a\nhigh degree of interactivity that permits data analysts to explore information\nquickly along many dimensions while switching visualizations on a whim. To\nprovide the required responsiveness, Hillview introduces visualization\nsketches, or vizketches, as a simple idea to produce compact data\nvisualizations. Vizketches combine algorithmic techniques for data\nsummarization with computer graphics principles for efficient rendering. While\nsimple, vizketches are effective at scaling the spreadsheet by parallelizing\ncomputation, reducing communication, providing progressive visualizations, and\noffering precise accuracy guarantees. Using Hillview running on eight servers,\nwe can navigate and visualize datasets of tens of billions of rows and\ntrillions of cells, much beyond the published capabilities of competing\nsystems.", "AI": {"tldr": "Hillview is a distributed spreadsheet for massive datasets, using 'vizketches' for fast, interactive visualization and analysis, scaling far beyond existing systems.", "motivation": "The motivation is to create an interactive spreadsheet system, Hillview, that can browse and analyze very large datasets that exceed the capacity of a single machine, while maintaining a high degree of interactivity for data exploration.", "method": "Hillview utilizes 'vizketches,' which are compact data visualizations combining data summarization algorithms and efficient rendering techniques. This approach enables parallel computation, reduced communication, progressive visualization, and precise accuracy guarantees, allowing it to scale effectively.", "result": "Hillview, running on eight servers, successfully navigates and visualizes datasets with tens of billions of rows and trillions of cells, outperforming published capabilities of competing systems.", "conclusion": "Hillview is a distributed spreadsheet capable of handling massive datasets (tens of billions of rows, trillions of cells) beyond competing systems, due to its innovative vizsketch approach."}}
{"id": "1907.04217", "title": "Streaming 1.9 Billion Hypersparse Network Updates per Second with D4M", "url": "https://arxiv.org/abs/1907.04217", "pdf": "https://arxiv.org/pdf/1907.04217", "abs": "https://arxiv.org/abs/1907.04217", "authors": ["Jeremy Kepner", "Vijay Gadepally", "Lauren Milechin", "Siddharth Samsi", "William Arcand", "David Bestor", "William Bergeron", "Chansup Byun", "Matthew Hubbell", "Michael Houle", "Michael Jones", "Anne Klein", "Peter Michaleas", "Julie Mullen", "Andrew Prout", "Antonio Rosa", "Charles Yee", "Albert Reuther"], "categories": ["cs.DC", "cs.DB", "cs.DS", "cs.IR", "cs.PF"], "comment": "6 pages; 6 figures; accepted to IEEE High Performance Extreme\n  Computing (HPEC) Conference 2019. arXiv admin note: text overlap with\n  arXiv:1807.05308, arXiv:1902.00846", "summary": "The Dynamic Distributed Dimensional Data Model (D4M) library implements\nassociative arrays in a variety of languages (Python, Julia, and Matlab/Octave)\nand provides a lightweight in-memory database implementation of hypersparse\narrays that are ideal for analyzing many types of network data. D4M relies on\nassociative arrays which combine properties of spreadsheets, databases,\nmatrices, graphs, and networks, while providing rigorous mathematical\nguarantees, such as linearity. Streaming updates of D4M associative arrays put\nenormous pressure on the memory hierarchy. This work describes the design and\nperformance optimization of an implementation of hierarchical associative\narrays that reduces memory pressure and dramatically increases the update rate\ninto an associative array. The parameters of hierarchical associative arrays\nrely on controlling the number of entries in each level in the hierarchy before\nan update is cascaded. The parameters are easily tunable to achieve optimal\nperformance for a variety of applications. Hierarchical arrays achieve over\n40,000 updates per second in a single instance. Scaling to 34,000 instances of\nhierarchical D4M associative arrays on 1,100 server nodes on the MIT SuperCloud\nachieved a sustained update rate of 1,900,000,000 updates per second. This\ncapability allows the MIT SuperCloud to analyze extremely large streaming\nnetwork data sets.", "AI": {"tldr": "D4M \u5e93\u7684\u5c42\u6b21\u5316\u5b9e\u73b0\u663e\u8457\u63d0\u9ad8\u4e86\u5904\u7406\u7f51\u7edc\u6570\u636e\u7684\u80fd\u529b\u3002", "motivation": "\u5206\u6790\u6d77\u91cf\u7f51\u7edc\u6570\u636e\u5bf9 D4M \u5e93\u7684\u5185\u5b58\u5c42\u7ea7\u548c\u66f4\u65b0\u901f\u7387\u5e26\u6765\u4e86\u5de8\u5927\u538b\u529b\uff0c\u9700\u8981\u8fdb\u884c\u4f18\u5316\u3002", "method": "\u901a\u8fc7\u5b9e\u73b0\u5c42\u6b21\u5316\u5173\u8054\u6570\u7ec4\u6765\u4f18\u5316 D4M \u5e93\uff0c\u901a\u8fc7\u63a7\u5236\u5c42\u7ea7\u6761\u76ee\u6570\u91cf\u6765\u7ba1\u7406\u5185\u5b58\u548c\u66f4\u65b0\u3002", "result": "\u5c42\u6b21\u5316\u6570\u7ec4\u5728\u5355\u5b9e\u4f8b\u4e2d\u8fbe\u5230\u6bcf\u79d2 40,000 \u6b21\u66f4\u65b0\uff0c\u5728 1,100 \u4e2a\u670d\u52a1\u5668\u8282\u70b9\u4e0a\u6269\u5c55\u5230 34,000 \u4e2a\u5b9e\u4f8b\u65f6\uff0c\u5b9e\u73b0\u4e86\u6bcf\u79d2 1,900,000,000 \u6b21\u66f4\u65b0\u3002", "conclusion": "D4M \u5e93\u7684\u5c42\u6b21\u5316\u5b9e\u73b0\u901a\u8fc7\u51cf\u5c11\u5185\u5b58\u538b\u529b\u548c\u63d0\u9ad8\u66f4\u65b0\u901f\u7387\uff0c\u80fd\u591f\u5904\u7406\u6d77\u91cf\u6d41\u5f0f\u7f51\u7edc\u6570\u636e\u3002"}}
{"id": "1907.02099", "title": "GeoGebra e situa\u00e7\u00f5es que envolvem modela\u00e7\u00e3o numa abordagem STEAM", "url": "https://arxiv.org/abs/1907.02099", "pdf": "https://arxiv.org/pdf/1907.02099", "abs": "https://arxiv.org/abs/1907.02099", "authors": ["J. M. D. S. Dos Santos", "A. P. Silveira", "A. E. S. Trocado"], "categories": ["math.HO", "cs.CY", "00A35, 97C70", "G.4; K.3.1"], "comment": "in Portuguese", "summary": "In order to implement a STEAM approach including the use of technology,\nnamely the use of interactive mathematics software GeoGebra, in mathematics\nclasses, in the lusophone space, the materials presented here were conceived,\nto be implemented in a first phase among teachers. Later, with the necessary\nadaptations, these tasks will be applied to the students. The tasks deal with\nmodeling situations, in two- and three-dimensional geometric problems, in order\nto apply GeoGebra software in its analysis to illustrate its capabilities. The\ndifferent windows of this software are used, namely the 2D and 3D windows, CAS\nwindow, spreadsheet and extra two dimensional windows in order to study cutting\nplanes in solids and some surfaces. The tasks are presented so that any user,\nregardless of the degree of knowledge they have of the software, can follow\nthem, being supported in scripts with some indications of the tools and\ncommands to use. Designed for the teaching and learning of Mathematics, from a\nSTEAM approach, these tasks allow connections with other Sciences and the Arts,\nand allow the development of projects using and consolidating relevant\nmathematical contents. These tasks are part of the proposals of activities of\nthe participants of the Training Courses for Trainers in GeoGebra for\nPortuguese Speaking Countries, which from 2019 have an impact on the STEAM\napproach. These courses are carried out with the high sponsorship of the\nOrganization of Ibero-American States for Education, Science and Culture (OEI).\nGiven the interest that the tasks have for the users of the Iberian space, as\nwell as their dissemination at a global level, the materials initially\ndeveloped in Portuguese language will be adapted for Spanish and English\nspeakers.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7GeoGebra\u8f6f\u4ef6\u5728\u6570\u5b66\u6559\u5b66\u4e2d\u5b9e\u65bdSTEAM\u6559\u80b2\uff0c\u63d0\u4f9b\u4e92\u52a8\u5f0f\u6559\u5b66\u6750\u6599\uff0c\u4fc3\u8fdb\u8de8\u5b66\u79d1\u5b66\u4e60\u548c\u9879\u76ee\u53d1\u5c55\uff0c\u5e76\u8ba1\u5212\u5c06\u6750\u6599\u7ffb\u8bd1\u6210\u897f\u73ed\u7259\u8bed\u548c\u82f1\u8bed\u4ee5\u6269\u5927\u5f71\u54cd\u3002", "motivation": "\u4e3a\u4e86\u5728\u6570\u5b66\u8bfe\u7a0b\u4e2d\u5b9e\u65bd\u5305\u62ec\u6280\u672f\uff08\u7279\u522b\u662f\u4e92\u52a8\u6570\u5b66\u8f6f\u4ef6GeoGebra\uff09\u5728\u5185\u7684STEAM\u6559\u5b66\u6cd5\uff0c\u7279\u522b\u662f\u5728\u8461\u8bed\u56fd\u5bb6\uff0c\u672c\u7814\u7a76\u65e8\u5728\u4e3a\u6559\u5e08\u63d0\u4f9b\u4e00\u5957\u5b8c\u6574\u7684\u6559\u5b66\u6750\u6599\uff0c\u8ba9\u4ed6\u4eec\u80fd\u591f\u638c\u63e1GeoGebra\u7684\u4f7f\u7528\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5b66\u751f\u6559\u5b66\u4e2d\u3002", "method": "\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4e92\u52a8\u6570\u5b66\u8f6f\u4ef6GeoGebra\uff0c\u5728\u6570\u5b66\u8bfe\u7a0b\u4e2d\u5b9e\u65bdSTEAM\u6559\u5b66\u6cd5\uff0c\u5e76\u91cd\u70b9\u4ecb\u7ecd\u8be5\u8f6f\u4ef6\u5728\u4e8c\u7ef4\u548c\u4e09\u7ef4\u51e0\u4f55\u95ee\u9898\u5efa\u6a21\u548c\u5206\u6790\u4e2d\u7684\u5e94\u7528\u3002\u7814\u7a76\u4eba\u5458\u5c06\u4f7f\u7528GeoGebra\u76842D\u548c3D\u7a97\u53e3\u3001CAS\u7a97\u53e3\u3001\u7535\u5b50\u8868\u683c\u548c\u989d\u5916\u7684\u4e8c\u7ef4\u7a97\u53e3\u6765\u7814\u7a76\u622a\u9762\u548c\u66f2\u9762\u3002", "result": "\u6240\u63d0\u4f9b\u7684\u4efb\u52a1\u80fd\u591f\u5e2e\u52a9\u7528\u6237\uff08\u65e0\u8bba\u5176GeoGebra\u77e5\u8bc6\u6c34\u5e73\u5982\u4f55\uff09\u5b66\u4e60\u548c\u4f7f\u7528\u8be5\u8f6f\u4ef6\uff0c\u901a\u8fc7\u811a\u672c\u63d0\u4f9b\u5de5\u5177\u548c\u547d\u4ee4\u7684\u6307\u793a\u3002\u8be5\u7814\u7a76\u7684\u6210\u679c\u4e0d\u4ec5\u652f\u6301\u4e86\u6570\u5b66\u7684\u6559\u4e0e\u5b66\uff0c\u800c\u4e14\u4fc3\u8fdb\u4e86\u4e0e\u5176\u4ed6\u79d1\u5b66\u548c\u827a\u672f\u5b66\u79d1\u7684\u8054\u7cfb\uff0c\u5e76\u4e3a\u5b66\u751f\u53d1\u5c55\u548c\u5de9\u56fa\u76f8\u5173\u6570\u5b66\u5185\u5bb9\u7684\u5b66\u4e60\u9879\u76ee\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "conclusion": "\u8be5\u7814\u7a76\u7684\u6210\u679c\u5c06\u4ee5\u591a\u79cd\u8bed\u8a00\u63d0\u4f9b\uff0c\u5305\u62ec\u8461\u8404\u7259\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u82f1\u8bed\uff0c\u5e76\u5f97\u5230\u4f0a\u6bd4\u5229\u4e9a\u7f8e\u6d32\u56fd\u5bb6\u6559\u80b2\u3001\u79d1\u5b66\u548c\u6587\u5316\u7ec4\u7ec7\u7684\u8d5e\u52a9\u3002"}}
{"id": "1906.04011", "title": "Visual Backpropagation", "url": "https://arxiv.org/abs/1906.04011", "pdf": "https://arxiv.org/pdf/1906.04011", "abs": "https://arxiv.org/abs/1906.04011", "authors": ["Roy S. Freedman"], "categories": ["cs.LG", "cs.PL"], "comment": null, "summary": "We show how a declarative functional programming specification of\nbackpropagation yields a visual and transparent implementation within\nspreadsheets. We call our method Visual Backpropagation. This backpropagation\nimplementation exploits array worksheet formulas, manual calculation, and has a\nsequential order of computation similar to the processing of a systolic array.\nThe implementation uses no hidden macros nor user-defined functions; there are\nno loops, assignment statements, or links to any procedural programs written in\nconventional languages. As an illustration, we compare a Visual Backpropagation\nsolution to a Tensorflow (Python) solution on a standard regression problem.", "AI": {"tldr": "\u53ef\u89c6\u5316\u53cd\u5411\u4f20\u64ad\u662f\u4e00\u79cd\u5229\u7528\u7535\u5b50\u8868\u683c\u7684\u58f0\u660e\u5f0f\u51fd\u6570\u5f0f\u7f16\u7a0b\u89c4\u8303\u7684\u53cd\u5411\u4f20\u64ad\u5b9e\u73b0\u3002", "motivation": "\u5c55\u793a\u58f0\u660e\u5f0f\u51fd\u6570\u5f0f\u7f16\u7a0b\u89c4\u8303\u7684\u53cd\u5411\u4f20\u64ad\u5982\u4f55\u4ea7\u751f\u53ef\u89c6\u5316\u7684\u3001\u900f\u660e\u7684\u7535\u5b50\u8868\u683c\u5b9e\u73b0\u3002", "method": "\u53ef\u89c6\u5316\u53cd\u5411\u4f20\u64ad\u5229\u7528\u6570\u7ec4\u5de5\u4f5c\u8868\u516c\u5f0f\u3001\u624b\u52a8\u8ba1\u7b97\u548c\u7c7b\u4f3c\u8ba1\u7b97\u9635\u5217\u7684\u5904\u7406\u987a\u5e8f\u3002", "result": "\u901a\u8fc7\u5c06\u53ef\u89c6\u5316\u53cd\u5411\u4f20\u64ad\u89e3\u51b3\u65b9\u6848\u4e0e Tensorflow\uff08Python\uff09\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u6bd4\u8f83\u6765\u8bf4\u660e\u3002", "conclusion": "\u58f0\u660e\u5f0f\u51fd\u6570\u5f0f\u7f16\u7a0b\u89c4\u8303\u7684\u53cd\u5411\u4f20\u64ad\u53ef\u4ee5\u4ea7\u751f\u53ef\u89c6\u5316\u7684\u3001\u900f\u660e\u7684\u7535\u5b50\u8868\u683c\u5b9e\u73b0\uff0c\u79f0\u4e3a\u53ef\u89c6\u5316\u53cd\u5411\u4f20\u64ad\u3002"}}
{"id": "1905.13072", "title": "Somewhere Around That Number: An Interview Study of How Spreadsheet Users Manage Uncertainty", "url": "https://arxiv.org/abs/1905.13072", "pdf": "https://arxiv.org/pdf/1905.13072", "abs": "https://arxiv.org/abs/1905.13072", "authors": ["Judith Borghouts", "Andrew D. Gordon", "Advait Sarkar", "Kenton P. O'Hara", "Neil Toronto"], "categories": ["cs.HC"], "comment": null, "summary": "Spreadsheet users regularly deal with uncertainty in their data, for example\ndue to errors and estimates. While an insight into data uncertainty can help in\nmaking better informed decisions, prior research suggests that people often use\ninformal heuristics to reason with probabilities, which leads to incorrect\nconclusions. Moreover, people often ignore or simplify uncertainty. To\nunderstand how people currently encounter and deal with uncertainty in\nspreadsheets, we conducted an interview study with 11 spreadsheet users from a\nrange of domains. We found that how people deal with uncertainty is influenced\nby the role the spreadsheet plays in people's work and the user's aims.\nSpreadsheets are used as a database, template, calculation tool, notepad and\nexploration tool. In doing so, participants' aims were to compute and compare\ndifferent scenarios, understand something about the nature of the uncertainty\nin their situation, and translate the complexity of data uncertainty into\nsimplified presentations to other people, usually decision-makers. Spreadsheets\ncurrently provide limited tools to support these aims, and participants had\nvarious workarounds.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u7528\u6237\u5904\u7406\u7535\u5b50\u8868\u683c\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u5f0f\u56e0\u7535\u5b50\u8868\u683c\u7684\u89d2\u8272\u548c\u7528\u6237\u76ee\u6807\u800c\u5f02\uff0c\u800c\u76ee\u524d\u7684\u7535\u5b50\u8868\u683c\u5de5\u5177\u5bf9\u7528\u6237\u7684\u9700\u6c42\u652f\u6301\u6709\u9650\u3002", "motivation": "\u4e3a\u4e86\u89e3\u7528\u6237\u5728\u7535\u5b50\u8868\u683c\u4e2d\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u7684\u73b0\u72b6\uff0c\u56e0\u4e3a\u7528\u6237\u5728\u5904\u7406\u6982\u7387\u65f6\u5e38\u4f7f\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5bfc\u81f4\u9519\u8bef\u7ed3\u8bba\uff0c\u5e76\u4e14\u5e38\u5e38\u5ffd\u7565\u6216\u7b80\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u901a\u8fc7\u5bf911\u4f4d\u6765\u81ea\u4e0d\u540c\u9886\u57df\u7684\u7535\u5b50\u8868\u683c\u7528\u6237\u8fdb\u884c\u8bbf\u8c08\u7814\u7a76\uff0c\u4e86\u89e3\u7528\u6237\u5f53\u524d\u5982\u4f55\u5904\u7406\u7535\u5b50\u8868\u683c\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u7528\u6237\u7684\u76ee\u6807\u5305\u62ec\u8ba1\u7b97\u548c\u6bd4\u8f83\u4e0d\u540c\u60c5\u666f\u3001\u4e86\u89e3\u4e0d\u786e\u5b9a\u6027\u7684\u6027\u8d28\u4ee5\u53ca\u5c06\u590d\u6742\u7684\u4e0d\u786e\u5b9a\u6027\u6570\u636e\u7b80\u5316\u5448\u73b0\u7ed9\u51b3\u7b56\u8005\u3002\u7528\u6237\u5728\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u65f6\uff0c\u4f1a\u53d7\u5230\u7535\u5b50\u8868\u683c\u5728\u5de5\u4f5c\u4e2d\u7684\u89d2\u8272\u4ee5\u53ca\u7528\u6237\u76ee\u6807\u7684\u5f71\u54cd\u3002", "conclusion": "\u7528\u6237\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u5f0f\u53d7\u5230\u7535\u5b50\u8868\u683c\u5728\u5de5\u4f5c\u4e2d\u7684\u4f5c\u7528\u548c\u7528\u6237\u76ee\u6807\u7684\u5f71\u54cd\u3002\u7535\u5b50\u8868\u683c\u76ee\u524d\u63d0\u4f9b\u7684\u5de5\u5177\u6709\u9650\uff0c\u7528\u6237\u9700\u8981\u91c7\u7528\u5404\u79cd\u53d8\u901a\u65b9\u6cd5\u3002"}}
{"id": "1902.00846", "title": "A Billion Updates per Second Using 30,000 Hierarchical In-Memory D4M Databases", "url": "https://arxiv.org/abs/1902.00846", "pdf": "https://arxiv.org/pdf/1902.00846", "abs": "https://arxiv.org/abs/1902.00846", "authors": ["Jeremy Kepner", "Vijay Gadepally", "Lauren Milechin", "Siddharth Samsi", "William Arcand", "David Bestor", "William Bergeron", "Chansup Byun", "Matthew Hubbell", "Micheal Houle", "Micheal Jones", "Anne Klein", "Peter Michaleas", "Julie Mullen", "Andrew Prout", "Antonio Rosa", "Charles Yee", "Albert Reuther"], "categories": ["cs.DB", "cs.DC", "cs.DS", "cs.NI"], "comment": "Northeast Database Data 2019 (MIT)", "summary": "Analyzing large scale networks requires high performance streaming updates of\ngraph representations of these data. Associative arrays are mathematical\nobjects combining properties of spreadsheets, databases, matrices, and graphs,\nand are well-suited for representing and analyzing streaming network data. The\nDynamic Distributed Dimensional Data Model (D4M) library implements associative\narrays in a variety of languages (Python, Julia, and Matlab/Octave) and\nprovides a lightweight in-memory database. Associative arrays are designed for\nblock updates. Streaming updates to a large associative array requires a\nhierarchical implementation to optimize the performance of the memory\nhierarchy. Running 34,000 instances of a hierarchical D4M associative arrays on\n1,100 server nodes on the MIT SuperCloud achieved a sustained update rate of\n1,900,000,000 updates per second. This capability allows the MIT SuperCloud to\nanalyze extremely large streaming network data sets.", "AI": {"tldr": "D4M \u5e93\u901a\u8fc7\u5176\u5206\u5e03\u5f0f\u5c42\u6b21\u5316\u5173\u8054\u6570\u7ec4\u5b9e\u73b0\u4e86\u5bf9\u5927\u89c4\u6a21\u6d41\u5f0f\u7f51\u7edc\u6570\u636e\u7684\u6bcf\u79d2\u8fd1 20 \u4ebf\u6b21\u66f4\u65b0\u3002", "motivation": "\u4e3a\u4e86\u5728\u5904\u7406\u5927\u89c4\u6a21\u7f51\u7edc\u6570\u636e\u65f6\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u6d41\u5f0f\u66f4\u65b0\u56fe\u8868\u793a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u5206\u5e03\u5f0f\u7ef4\u5ea6\u6570\u636e\u6a21\u578b\uff08D4M\uff09\u5e93\uff0c\u8be5\u5e93\u5728\u591a\u79cd\u8bed\u8a00\u4e2d\u5b9e\u73b0\u4e86\u7ed3\u5408\u4e86\u7535\u5b50\u8868\u683c\u3001\u6570\u636e\u5e93\u3001\u77e9\u9635\u548c\u56fe\u5c5e\u6027\u7684\u5173\u8054\u6570\u7ec4\uff0c\u5e76\u9488\u5bf9\u5185\u5b58\u5c42\u7ea7\u7ed3\u6784\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u6d41\u5f0f\u7f51\u7edc\u6570\u636e\u7684\u6d41\u5f0f\u66f4\u65b0\u3002", "result": "\u5728 MIT SuperCloud \u4e0a\u8fd0\u884c 34,000 \u4e2a D4M \u5173\u8054\u6570\u7ec4\u5b9e\u4f8b\uff0c\u5b9e\u73b0\u4e86\u6bcf\u79d2 1,900,000,000 \u6b21\u7684\u6301\u7eed\u66f4\u65b0\u901f\u7387\u3002", "conclusion": "D4M \u5e93\u7684\u5206\u5e03\u5f0f\u5c42\u6b21\u5316\u5b9e\u73b0\u80fd\u591f\u652f\u6301\u5927\u89c4\u6a21\u6d41\u5f0f\u7f51\u7edc\u6570\u636e\u7684\u5206\u6790\u3002"}}
{"id": "1901.11100", "title": "ExceLint: Automatically Finding Spreadsheet Formula Errors", "url": "https://arxiv.org/abs/1901.11100", "pdf": "https://arxiv.org/pdf/1901.11100", "abs": "https://arxiv.org/abs/1901.11100", "authors": ["Daniel W. Barowy", "Emery D. Berger", "Benjamin Zorn"], "categories": ["cs.PL", "cs.SE"], "comment": "Appeared at OOPSLA 2018", "summary": "Spreadsheets are one of the most widely used programming environments, and\nare widely deployed in domains like finance where errors can have catastrophic\nconsequences. We present a static analysis specifically designed to find\nspreadsheet formula errors. Our analysis directly leverages the rectangular\ncharacter of spreadsheets. It uses an information-theoretic approach to\nidentify formulas that are especially surprising disruptions to nearby\nrectangular regions. We present ExceLint, an implementation of our static\nanalysis for Microsoft Excel. We demonstrate that ExceLint is fast and\neffective: across a corpus of 70 spreadsheets, ExceLint takes a median of 5\nseconds per spreadsheet, and it significantly outperforms the state of the art\nanalysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a ExceLint \u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u67e5\u627e\u7535\u5b50\u8868\u683c\u4e2d\u7684\u516c\u5f0f\u9519\u8bef\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u7535\u5b50\u8868\u683c\u7684\u77e9\u5f62\u7279\u6027\u548c\u4fe1\u606f\u8bba\u6765\u8bc6\u522b\u610f\u5916\u516c\u5f0f\uff0c\u5e76\u88ab\u8bc1\u660e\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5feb\u66f4\u6709\u6548\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u662f\u4e00\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u7f16\u7a0b\u73af\u5883\uff0c\u5728\u91d1\u878d\u7b49\u9886\u57df\u6709\u7740\u5e7f\u6cdb\u7684\u5e94\u7528\uff0c\u5728\u8fd9\u4e9b\u9886\u57df\u4e2d\u9519\u8bef\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u540e\u679c\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u67e5\u627e\u7535\u5b50\u8868\u683c\u516c\u5f0f\u9519\u8bef\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u95e8\u7528\u4e8e\u67e5\u627e\u7535\u5b50\u8868\u683c\u516c\u5f0f\u9519\u8bef\u3001\u76f4\u63a5\u5229\u7528\u7535\u5b50\u8868\u683c\u77e9\u5f62\u7279\u6027\u5e76\u4f7f\u7528\u4fe1\u606f\u8bba\u65b9\u6cd5\u6765\u8bc6\u522b\u90a3\u4e9b\u7834\u574f\u9644\u8fd1\u77e9\u5f62\u533a\u57df\u7684\u610f\u5916\u516c\u5f0f\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\u3002", "result": "ExceLint \u901f\u5ea6\u5feb\u4e14\u6709\u6548\uff0c\u5728\u4e00\u4e2a\u5305\u542b 70 \u4e2a\u7535\u5b50\u8868\u683c\u7684\u8bed\u6599\u5e93\u4e2d\uff0cExceLint \u5904\u7406\u6bcf\u4e2a\u7535\u5b50\u8868\u683c\u7684\u4e2d\u4f4d\u65f6\u95f4\u4e3a 5 \u79d2\uff0c\u5e76\u4e14\u5176\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5206\u6790\u3002", "conclusion": "ExceLint \u901f\u5ea6\u5feb\u4e14\u6709\u6548\uff0c\u5728\u4e00\u4e2a\u5305\u542b 70 \u4e2a\u7535\u5b50\u8868\u683c\u7684\u8bed\u6599\u5e93\u4e2d\uff0cExceLint \u5904\u7406\u6bcf\u4e2a\u7535\u5b50\u8868\u683c\u7684\u4e2d\u4f4d\u65f6\u95f4\u4e3a 5 \u79d2\uff0c\u5e76\u4e14\u5176\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5206\u6790\u3002"}}
{"id": "1807.00018", "title": "Computer Simulation of Neural Networks Using Spreadsheets: The Dawn of the Age of Camelot", "url": "https://arxiv.org/abs/1807.00018", "pdf": "https://arxiv.org/pdf/1807.00018", "abs": "https://arxiv.org/abs/1807.00018", "authors": ["Serhiy O. Semerikov", "Illia O. Teplytskyi", "Yuliia V. Yechkalo", "Arnold E. Kiv"], "categories": ["cs.CY", "68T99", "K.3.1; I.2.6; K.2"], "comment": "26 pages, 8 figures; submitted to the 1st International Workshop on\n  Augmented Reality in Education (AREdu 2018)", "summary": "The article substantiates the necessity to develop training methods of\ncomputer simulation of neural networks in the spreadsheet environment. The\nsystematic review of their application to simulating artificial neural networks\nis performed. The authors distinguish basic approaches to solving the problem\nof network computer simulation training in the spreadsheet environment, joint\napplication of spreadsheets and tools of neural network simulation, application\nof third-party add-ins to spreadsheets, development of macros using the\nembedded languages of spreadsheets; use of standard spreadsheet add-ins for\nnon-linear optimization, creation of neural networks in the spreadsheet\nenvironment without add-ins and macros. After analyzing a collection of\nwritings of 1890-1950, the research determines the role of the scientific\njournal \"Bulletin of Mathematical Biophysics\", its founder Nicolas Rashevsky\nand the scientific community around the journal in creating and developing\nmodels and methods of computational neuroscience. There are identified\npsychophysical basics of creating neural networks, mathematical foundations of\nneural computing and methods of neuroengineering (image recognition, in\nparticular). The role of Walter Pitts in combining the descriptive and\nquantitative theories of training is discussed. It is shown that to acquire\nneural simulation competences in the spreadsheet environment, one should master\nthe models based on the historical and genetic approach. It is indicated that\nthere are three groups of models, which are promising in terms of developing\ncorresponding methods - the continuous two-factor model of Rashevsky, the\ndiscrete model of McCulloch and Pitts, and the discrete-continuous models of\nHouseholder and Landahl.", "AI": {"tldr": "\u5728\u7535\u5b50\u8868\u683c\u4e2d\u6a21\u62df\u795e\u7ecf\u7f51\u7edc\u7684\u57f9\u8bad\u65b9\u6cd5\u5f88\u91cd\u8981\uff0c\u5e76\u4e14\u6709\u51e0\u79cd\u6709\u524d\u9014\u7684\u65b9\u6cd5\u548c\u6a21\u578b\u3002", "motivation": "\u8bc1\u5b9e\u4e86\u5728\u7535\u5b50\u8868\u683c\u73af\u5883\u4e2d\u5f00\u53d1\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u673a\u6a21\u62df\u57f9\u8bad\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\u3002", "method": "\u5bf9\u5728\u7535\u5b50\u8868\u683c\u73af\u5883\u4e2d\u6a21\u62df\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u56de\u987e\uff0c\u5e76\u533a\u5206\u4e86\u51e0\u79cd\u89e3\u51b3\u6b64\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "result": "\u8be5\u7814\u7a76\u786e\u5b9a\u4e86\u5728\u7535\u5b50\u8868\u683c\u73af\u5883\u4e2d\u6a21\u62df\u795e\u7ecf\u7f51\u7edc\u7684\u5404\u79cd\u65b9\u6cd5\uff0c\u5e76\u5f3a\u8c03\u4e86\u5386\u53f2\u548c\u9057\u4f20\u65b9\u6cd5\u4ee5\u53ca\u7279\u5b9a\u6a21\u578b\uff08Rashevsky\u3001McCulloch-Pitts\u3001Householder\u548cLandahl\uff09\u5728\u57f9\u517b\u795e\u7ecf\u7f51\u7edc\u6a21\u62df\u80fd\u529b\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u7535\u5b50\u8868\u683c\u73af\u5883\u4e2d\u5f00\u53d1\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u673a\u6a21\u62df\u57f9\u8bad\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff0c\u5e76\u786e\u5b9a\u4e86\u57fa\u4e8e\u5386\u53f2\u548c\u9057\u4f20\u65b9\u6cd5\u4ee5\u53caRashevsky\u3001McCulloch-Pitts\u3001Householder\u548cLandahl\u6a21\u578b\u7684\u6a21\u578b\u5bf9\u4e8e\u57f9\u517b\u76f8\u5173\u80fd\u529b\u5f88\u6709\u524d\u666f\u3002"}}
{"id": "1810.04542", "title": "On the Refinement of Spreadsheet Smells by means of Structure Information", "url": "https://arxiv.org/abs/1810.04542", "pdf": "https://arxiv.org/pdf/1810.04542", "abs": "https://arxiv.org/abs/1810.04542", "authors": ["Patrick Koch", "Birgit Hofer", "Franz Wotawa"], "categories": ["cs.SE"], "comment": null, "summary": "Spreadsheet users are often unaware of the risks imposed by poorly designed\nspreadsheets. One way to assess spreadsheet quality is to detect smells which\nattempt to identify parts of spreadsheets that are hard to comprehend or\nmaintain and which are more likely to be the root source of bugs.\nUnfortunately, current spreadsheet smell detection techniques suffer from a\nnumber of drawbacks that lead to incorrect or redundant smell reports. For\nexample, the same quality issue is often reported for every copy of a cell,\nwhich may overwhelm users. To deal with these issues, we propose to refine\nspreadsheet smells by exploiting inferred structural information for smell\ndetection. We therefore first provide a detailed description of our static\nanalysis approach to infer clusters and blocks of related cells. We then\nelaborate on how to improve existing smells by providing three example\nrefinements of existing smells that incorporate information about cell groups\nand computation blocks. Furthermore, we propose three novel smell detection\ntechniques that make use of the inferred spreadsheet structures. Empirical\nevaluation of the proposed techniques suggests that the refinements\nsuccessfully reduce the number of incorrectly and redundantly reported smells,\nand novel deficits are revealed by the newly introduced smells.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7535\u5b50\u8868\u683c\u574f\u5473\u9053\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5355\u5143\u683c\u7684\u7ed3\u6784\u4fe1\u606f\u6765\u51cf\u5c11\u9519\u8bef\u548c\u5197\u4f59\u7684\u62a5\u544a\uff0c\u5e76\u53d1\u73b0\u65b0\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u7535\u5b50\u8868\u683c\u201c\u574f\u5473\u9053\u201d\u68c0\u6d4b\u6280\u672f\u5b58\u5728\u62a5\u544a\u4e0d\u51c6\u786e\u6216\u5197\u4f59\u7684\u95ee\u9898\uff0c\u4f8b\u5982\u5c06\u540c\u4e00\u4e2a\u95ee\u9898\u62a5\u544a\u7ed9\u591a\u4e2a\u5355\u5143\u683c\uff0c\u4f7f\u7528\u6237\u4e0d\u77e5\u6240\u63aa\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9759\u6001\u5206\u6790\u65b9\u6cd5\u6765\u63a8\u65ad\u76f8\u5173\u5355\u5143\u683c\u7684\u7c07\u548c\u5757\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u7ed3\u6784\u4fe1\u606f\u6539\u8fdb\u4e86\u73b0\u6709\u7684\u201c\u574f\u5473\u9053\u201d\u68c0\u6d4b\u6280\u672f\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u7684\u57fa\u4e8e\u7ed3\u6784\u4fe1\u606f\u7684\u574f\u5473\u9053\u68c0\u6d4b\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6539\u8fdb\u63aa\u65bd\u80fd\u6709\u6548\u51cf\u5c11\u9519\u8bef\u548c\u5197\u4f59\u7684\u574f\u5473\u9053\u62a5\u544a\u6570\u91cf\uff0c\u5e76\u4e14\u65b0\u63d0\u51fa\u7684\u574f\u5473\u9053\u68c0\u6d4b\u6280\u672f\u80fd\u591f\u53d1\u73b0\u65b0\u7684\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5229\u7528\u63a8\u65ad\u51fa\u7684\u7ed3\u6784\u4fe1\u606f\u6765\u6539\u8fdb\u7535\u5b50\u8868\u683c\u7684\u201c\u574f\u5473\u9053\u201d\u68c0\u6d4b\uff0c\u6210\u529f\u51cf\u5c11\u4e86\u9519\u8bef\u548c\u5197\u4f59\u7684\u574f\u5473\u9053\u62a5\u544a\uff0c\u5e76\u63ed\u793a\u4e86\u65b0\u7684\u6f5c\u5728\u95ee\u9898\u3002"}}
{"id": "1809.03435", "title": "Now You're Thinking With Structures: A Concept for Structure-based Interactions with Spreadsheets", "url": "https://arxiv.org/abs/1809.03435", "pdf": "https://arxiv.org/pdf/1809.03435", "abs": "https://arxiv.org/abs/1809.03435", "authors": ["Patrick Koch"], "categories": ["cs.SE"], "comment": "In Proceedings of the 5th International Workshop on Software\n  Engineering Methods in Spreadsheets (arXiv:1808.09174)", "summary": "Spreadsheets are the go-to tool for computerized calculation and modelling,\nbut are hard to comprehend and adapt after reaching a certain complexity. In\ngeneral, cognition of complex systems is facilitated by having a higher order\nmental model of the system in question to work with. We therefore present a\nconcept for structure-aware understanding of and interaction with spreadsheets\nthat extends previous work on structure inference in the domain. Following this\nconcept, structural information is used to enrich visualizations, reactively\nenhance traditional user actions, and provide tools to proactively alter the\noverall spreadsheet makeup instead of individual cells The intended systems\nshould, in first approximation, not replace common spreadsheet tools, but\nprovide an additional layer of functionality alongside the established\ninterface. In ongoing work, we therefore implemented a tool for structure\ninference and visualization along the common spreadsheet layout. Based on this\nframework, we plan to introduce the envisioned proactive and reactive\ninteraction mechanics, and finally provide structure-aware unctionality as an\nadd-in for common spreadsheet processors. We believe that providing the tools\nfor thinking about and interacting with spreadsheets in this manner will\nbenefit users both in terms of productivity and overall spreadsheet quality.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u7535\u5b50\u8868\u683c\u7ed3\u6784\u4fe1\u606f\u6765\u6539\u8fdb\u5176\u53ef\u89c6\u5316\u3001\u4ea4\u4e92\u548c\u7f16\u8f91\u65b9\u5f0f\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u9ad8\u7528\u6237\u751f\u4ea7\u529b\u548c\u7535\u5b50\u8868\u683c\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u7535\u5b50\u8868\u683c\u5728\u590d\u6742\u6027\u589e\u52a0\u540e\u96be\u4ee5\u7406\u89e3\u548c\u4fee\u6539\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u4f9b\u66f4\u9ad8\u9636\u7684\u5fc3\u667a\u6a21\u578b\u6765\u4fc3\u8fdb\u590d\u6742\u7cfb\u7edf\u7684\u8ba4\u77e5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u7406\u89e3\u548c\u4ea4\u4e92\u7684\u6982\u5ff5\uff0c\u8be5\u6982\u5ff5\u5229\u7528\u7ed3\u6784\u4fe1\u606f\u6765\u4e30\u5bcc\u53ef\u89c6\u5316\u3001\u54cd\u5e94\u5f0f\u5730\u589e\u5f3a\u4f20\u7edf\u7528\u6237\u64cd\u4f5c\uff0c\u5e76\u63d0\u4f9b\u4e3b\u52a8\u66f4\u6539\u7535\u5b50\u8868\u683c\u7ec4\u6210\u90e8\u5206\u7684\u5de5\u5177\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7528\u4e8e\u7ed3\u6784\u63a8\u65ad\u548c\u53ef\u89c6\u5316\u7684\u5de5\u5177\uff0c\u5e76\u8ba1\u5212\u5728\u6b64\u6846\u67b6\u57fa\u7840\u4e0a\u5f15\u5165\u4e3b\u52a8\u548c\u54cd\u5e94\u5f0f\u4ea4\u4e92\u673a\u5236\uff0c\u6700\u7ec8\u5c06\u7ed3\u6784\u611f\u77e5\u529f\u80fd\u4f5c\u4e3a\u63d2\u4ef6\u63d0\u4f9b\u7ed9\u5e38\u7528\u7684\u7535\u5b50\u8868\u683c\u5904\u7406\u5668\u3002", "conclusion": "\u63d0\u4f9b\u5173\u4e8e\u7535\u5b50\u8868\u683c\u7684\u7ed3\u6784\u611f\u77e5\u529f\u80fd\uff0c\u4ee5\u63d0\u9ad8\u7528\u6237\u751f\u4ea7\u529b\u548c\u7535\u5b50\u8868\u683c\u8d28\u91cf\u3002"}}
{"id": "1804.01186", "title": "Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples", "url": "https://arxiv.org/abs/1804.01186", "pdf": "https://arxiv.org/pdf/1804.01186", "abs": "https://arxiv.org/abs/1804.01186", "authors": ["Ashwin Kalyan", "Abhishek Mohta", "Oleksandr Polozov", "Dhruv Batra", "Prateek Jain", "Sumit Gulwani"], "categories": ["cs.AI", "cs.LG", "cs.PL"], "comment": "Published in ICLR 2018, International Conference on Learning\n  Representations (2018)", "summary": "Synthesizing user-intended programs from a small number of input-output\nexamples is a challenging problem with several important applications like\nspreadsheet manipulation, data wrangling and code refactoring. Existing\nsynthesis systems either completely rely on deductive logic techniques that are\nextensively hand-engineered or on purely statistical models that need massive\namounts of data, and in general fail to provide real-time synthesis on\nchallenging benchmarks. In this work, we propose Neural Guided Deductive Search\n(NGDS), a hybrid synthesis technique that combines the best of both symbolic\nlogic techniques and statistical models. Thus, it produces programs that\nsatisfy the provided specifications by construction and generalize well on\nunseen examples, similar to data-driven systems. Our technique effectively\nutilizes the deductive search framework to reduce the learning problem of the\nneural component to a simple supervised learning setup. Further, this allows us\nto both train on sparingly available real-world data and still leverage\npowerful recurrent neural network encoders. We demonstrate the effectiveness of\nour method by evaluating on real-world customer scenarios by synthesizing\naccurate programs with up to 12x speed-up compared to state-of-the-art systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u795e\u7ecf\u5f15\u5bfc\u5f52\u7eb3\u641c\u7d22\uff08NGDS\uff09\u7684\u6df7\u5408\u7a0b\u5e8f\u5408\u6210\u6280\u672f\uff0c\u7ed3\u5408\u4e86\u903b\u8f91\u548c\u7edf\u8ba1\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u5408\u6210\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5408\u6210\u7cfb\u7edf\u5728\u5b9e\u65f6\u5408\u6210\u548c\u5904\u7406\u590d\u6742\u57fa\u51c6\u6d4b\u8bd5\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u903b\u8f91\u548c\u7edf\u8ba1\u6a21\u578b\u7684\u4f18\u70b9\uff0c\u63d0\u9ad8\u7a0b\u5e8f\u5408\u6210\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u795e\u7ecf\u5f15\u5bfc\u5f52\u7eb3\u641c\u7d22\uff08NGDS\uff09\u7684\u6df7\u5408\u5408\u6210\u6280\u672f\uff0c\u8be5\u6280\u672f\u7ed3\u5408\u4e86\u7b26\u53f7\u903b\u8f91\u6280\u672f\u548c\u7edf\u8ba1\u6a21\u578b\u3002\u901a\u8fc7\u5229\u7528\u5f52\u7eb3\u641c\u7d22\u6846\u67b6\uff0c\u5c06\u5b66\u4e60\u95ee\u9898\u7b80\u5316\u4e3a\u76d1\u7763\u5b66\u4e60\uff0c\u5e76\u5229\u7528\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7f16\u7801\u5668\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u771f\u5b9e\u5ba2\u6237\u573a\u666f\u7684\u8bc4\u4f30\u4e2d\uff0cNGDS\u6280\u672f\u80fd\u591f\u5408\u6210\u51c6\u786e\u7684\u7a0b\u5e8f\uff0c\u5e76\u4e14\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u7cfb\u7edf\u76f8\u6bd4\uff0c\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe12\u500d\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u795e\u7ecf\u5f15\u5bfc\u5f52\u7eb3\u641c\u7d22\uff08NGDS\uff09\u7684\u6df7\u5408\u5408\u6210\u6280\u672f\uff0c\u8be5\u6280\u672f\u7ed3\u5408\u4e86\u7b26\u53f7\u903b\u8f91\u6280\u672f\u548c\u7edf\u8ba1\u6a21\u578b\uff0c\u80fd\u591f\u751f\u6210\u6ee1\u8db3\u7ed9\u5b9a\u89c4\u8303\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u7a0b\u5e8f\uff0c\u5e76\u5728\u771f\u5b9e\u5ba2\u6237\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe12\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002"}}
{"id": "1809.02746", "title": "Typed Table Transformations", "url": "https://arxiv.org/abs/1809.02746", "pdf": "https://arxiv.org/pdf/1809.02746", "abs": "https://arxiv.org/abs/1809.02746", "authors": ["Martin Erwig"], "categories": ["cs.SE"], "comment": "In Proceedings of the 5th International Workshop on Software\n  Engineering Methods in Spreadsheets (arXiv:1808.09174)", "summary": "Spreadsheet tables are often labeled, and these labels effectively constitute\ntypes for the data in the table. In such cases tables can be considered to be\nbuilt from typed data where the placement of values within the table is\ncontrolled by the types used for rows and columns. We present a new approach to\nthe transformations of spreadsheet tables that is based on transformations of\nrow and column types. We illustrate the basic idea of type-based table\nconstruction and transformation and lay out a series of research questions that\nshould be addressed in future work.", "AI": {"tldr": " \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u884c\u5217\u7c7b\u578b\u8f6c\u6362\u7684\u7535\u5b50\u8868\u683c\u8f6c\u6362\u65b0\u65b9\u6cd5\u3002", "motivation": " \u7535\u5b50\u8868\u683c\u4e2d\u7684\u6807\u7b7e\u53ef\u4ee5\u88ab\u89c6\u4e3a\u6570\u636e\u7684\u7c7b\u578b\uff0c\u800c\u8868\u683c\u7684\u7ed3\u6784\u7531\u884c\u5217\u7c7b\u578b\u51b3\u5b9a\u3002\u56e0\u6b64\uff0c\u901a\u8fc7\u8f6c\u6362\u884c\u5217\u7c7b\u578b\uff0c\u53ef\u4ee5\u5b9e\u73b0\u7535\u5b50\u8868\u683c\u7684\u8f6c\u6362\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u884c\u5217\u7c7b\u578b\u8f6c\u6362\u7684\u7535\u5b50\u8868\u683c\u8f6c\u6362\u65b9\u6cd5\u3002", "result": " \u9610\u8ff0\u4e86\u57fa\u4e8e\u7c7b\u578b\u8f6c\u6362\u7684\u8868\u683c\u6784\u5efa\u548c\u8f6c\u6362\u7684\u57fa\u672c\u601d\u60f3\u3002", "conclusion": " \u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u884c\u5217\u7c7b\u578b\u8f6c\u6362\u7684\u7535\u5b50\u8868\u683c\u8f6c\u6362\u65b0\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "1809.00025", "title": "Implementing WHERE and ORDER BY as spreadsheet formulas", "url": "https://arxiv.org/abs/1809.00025", "pdf": "https://arxiv.org/pdf/1809.00025", "abs": "https://arxiv.org/abs/1809.00025", "authors": ["Paul Mireault"], "categories": ["cs.SE"], "comment": "In Proceedings of the 5th International Workshop on Software\n  Engineering Methods in Spreadsheets (arXiv:1808.09174)", "summary": "The WHERE and ORDER BY clauses of the SQL SELECT statement select a subset of\nrows in the result of a database query and present the result in the specified\norder. In a spreadsheet program like Microsoft Excel, one could use the filter\nand sort buttons, or use its Query or its Pivot Table tools to achieve a\nsimilar effect. The disadvantage of using those tools is that they don't react\nautomatically to changes in the calculated values of the spreadsheet. In this\npaper, we develop spreadsheet formulas that implement SQL's WHERE and ORDER BY\nclauses.", "AI": {"tldr": "This paper creates spreadsheet formulas to automatically filter and sort data like SQL, which is better than Excel's manual tools.", "motivation": "To provide spreadsheet users with automatic data subsetting and ordering capabilities similar to SQL, overcoming the limitations of current spreadsheet tools that do not react to changes in calculated values.", "method": "Developing spreadsheet formulas to implement SQL's WHERE and ORDER BY functionality.", "result": "Spreadsheet formulas that replicate the functionality of SQL's WHERE and ORDER BY clauses, providing automatic updates in response to data changes.", "conclusion": "The paper develops spreadsheet formulas that mimic SQL's WHERE and ORDER BY clauses, offering automatic updates unlike existing spreadsheet tools."}}
{"id": "1808.10642", "title": "The use of Charts, Pivot Tables, and Array Formulas in two Popular Spreadsheet Corpora", "url": "https://arxiv.org/abs/1808.10642", "pdf": "https://arxiv.org/pdf/1808.10642", "abs": "https://arxiv.org/abs/1808.10642", "authors": ["Bas Jansen", "Felienne Hermans"], "categories": ["cs.SE"], "comment": "In Proceedings of the 5th International Workshop on Software\n  Engineering Methods in Spreadsheets (arXiv:1808.09174)", "summary": "The use of spreadsheets in industry is widespread. Companies base decisions\non information coming from spreadsheets. Unfortunately, spreadsheets are\nerror-prone and this increases the risk that companies base their decisions on\ninaccurate information, which can lead to incorrect decisions and loss of\nmoney. In general, spreadsheet research is aimed to reduce the error-proneness\nof spreadsheets. Most research is concentrated on the use of formulas. However,\nthere are other constructions in spreadsheets, like charts, pivot tables, and\narray formulas, that are also used to present decision support information to\nthe user. There is almost no research about how these constructions are used.\nTo improve spreadsheet quality it is important to understand how spreadsheets\nare used and to obtain a complete understanding, the use of charts, pivot\ntables, and array formulas should be included in research. In this paper, we\nanalyze two popular spreadsheet corpora: Enron and EUSES on the use of the\naforementioned constructions.", "AI": {"tldr": "\u7535\u5b50\u8868\u683c\u6613\u51fa\u9519\uff0c\u5f71\u54cd\u51b3\u7b56\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u516c\u5f0f\uff0c\u5ffd\u7565\u56fe\u8868\u3001\u6570\u636e\u900f\u89c6\u8868\u548c\u6570\u7ec4\u516c\u5f0f\u3002\u672c\u7814\u7a76\u5206\u6790\u4e86\u8fd9\u4e24\u4e2a\u8bed\u6599\u5e93\u4e2d\u8fd9\u4e9b\u7ec4\u4ef6\u7684\u7528\u6cd5\uff0c\u4ee5\u671f\u6539\u8fdb\u7535\u5b50\u8868\u683c\u8d28\u91cf\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u5728\u5de5\u4e1a\u754c\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5b83\u4eec\u5bb9\u6613\u51fa\u9519\uff0c\u53ef\u80fd\u5bfc\u81f4\u516c\u53f8\u505a\u51fa\u9519\u8bef\u7684\u51b3\u7b56\u3002\u76ee\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u516c\u5f0f\uff0c\u4f46\u5ffd\u7565\u4e86\u56fe\u8868\uff0c\u6570\u636e\u900f\u89c6\u8868\u548c\u6570\u7ec4\u516c\u5f0f\u7b49\u5176\u4ed6\u7ec4\u4ef6\u3002", "method": "\u5206\u6790\u4e86Enron\u548cEUSES\u4e24\u4e2a\u7535\u5b50\u8868\u683c\u8bed\u6599\u5e93\u4e2d\u56fe\u8868\uff0c\u6570\u636e\u900f\u89c6\u8868\u548c\u6570\u7ec4\u516c\u5f0f\u7684\u7528\u6cd5\u3002", "result": "\u8fd9\u9879\u7814\u7a76\u5206\u6790\u4e86Enron\u548cEUSES\u8fd9\u4e24\u4e2a\u7535\u5b50\u8868\u683c\u8bed\u6599\u5e93\u4e2d\u56fe\u8868\uff0c\u6570\u636e\u900f\u89c6\u8868\u548c\u6570\u7ec4\u516c\u5f0f\u7684\u7528\u6cd5\uff0c\u4ee5\u671f\u4e3a\u6539\u8fdb\u7535\u5b50\u8868\u683c\u8d28\u91cf\u63d0\u4f9b\u89c1\u89e3\u3002", "conclusion": "\u4e3a\u4e86\u63d0\u9ad8\u7535\u5b50\u8868\u683c\u7684\u8d28\u91cf\uff0c\u672a\u6765\u7684\u7814\u7a76\u5e94\u8be5\u5305\u62ec\u5bf9\u56fe\u8868\uff0c\u6570\u636e\u900f\u89c6\u8868\u548c\u6570\u7ec4\u516c\u5f0f\u7b49\u7ec4\u4ef6\u7684\u5206\u6790\u3002"}}
{"id": "1808.10231", "title": "Asheetoxy: A Taxonomy for Classifying Negative Spreadsheet-related Phenomena", "url": "https://arxiv.org/abs/1808.10231", "pdf": "https://arxiv.org/pdf/1808.10231", "abs": "https://arxiv.org/abs/1808.10231", "authors": ["Daniel Kulesz", "Stefan Wagner"], "categories": ["cs.SE"], "comment": "In Proceedings of the 5th International Workshop on Software\n  Engineering Methods in Spreadsheets (arXiv:1808.09174)", "summary": "Spreadsheets (sometimes also called Excel programs) are powerful tools which\nplay a business-critical role in many organizations. However, due to faulty\nspreadsheets many bad decisions have been taken in recent years. Since then, a\nnumber of researchers have been studying spreadsheet errors. However, one issue\nthat hinders discussion among researchers and professionals is the lack of a\ncommonly accepted taxonomy.\n  Albeit a number of taxonomies for spreadsheet errors have been proposed in\nprevious work, a major issue is that they use the term error that itself is\nalready ambiguous. Furthermore, to apply most existing taxonomies, detailed\nknowledge about the underlying process and knowledge about the \"brain state\" of\nthe acting spreadsheet users is required. Due to these limitations, known\nerror-like phenomena in freely available spreadsheet corpora cannot be\nclassified with these taxonomies.\n  We propose Asheetoxy, a simple and phenomenon-oriented taxonomy that avoids\nthe problematic term error altogether. An initial study with 7 participants\nindicates that even non-spreadsheet researchers similarly classify real-world\nspreadsheet phenomena using Asheetoxy.", "AI": {"tldr": "\u7535\u5b50\u8868\u683c\u9519\u8bef\u6cdb\u6ee5\uff0c\u73b0\u6709\u5206\u7c7b\u6cd5\u6709\u7f3a\u9677\u3002\u6211\u4eec\u63d0\u51fa\u4e86Asheetoxy\uff0c\u4e00\u79cd\u66f4\u7b80\u5355\u3001\u66f4\u901a\u7528\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u521d\u6b65\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u9519\u8bef\u662f\u5bfc\u81f4\u8bb8\u591a\u7cdf\u7cd5\u51b3\u7b56\u7684\u539f\u56e0\uff0c\u4f46\u73b0\u6709\u5206\u7c7b\u6cd5\u5b58\u5728\u672f\u8bed\u6a21\u7cca\u3001\u9700\u8981\u6df1\u5165\u4e86\u89e3\u7528\u6237\u72b6\u6001\u548c\u5e95\u5c42\u6d41\u7a0b\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5bf9\u73b0\u6709\u8bed\u6599\u5e93\u4e2d\u7684\u73b0\u8c61\u8fdb\u884c\u5206\u7c7b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAsheetoxy\u7684\u5206\u7c7b\u6cd5\uff0c\u8be5\u65b9\u6cd5\u907f\u514d\u4f7f\u7528\u201c\u9519\u8bef\u201d\u4e00\u8bcd\uff0c\u5e76\u4e14\u53ea\u9700\u8981\u5bf9\u73b0\u8c61\u8fdb\u884c\u5206\u7c7b\uff0c\u800c\u4e0d\u9700\u8981\u4e86\u89e3\u5e95\u5c42\u6d41\u7a0b\u6216\u7528\u6237\u72b6\u6001\u3002", "result": "\u521d\u6b65\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u662f\u975e\u7535\u5b50\u8868\u683c\u7814\u7a76\u4eba\u5458\uff0c\u4f7f\u7528Asheetoxy\u4e5f\u53ef\u4ee5\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u7535\u5b50\u8868\u683c\u73b0\u8c61\u8fdb\u884c\u5206\u7c7b\u3002Participants=7", "conclusion": "Asheetoxy\u662f\u4e00\u79cd\u7b80\u5355\u4e14\u9762\u5411\u73b0\u8c61\u7684\u5206\u7c7b\u6cd5\uff0c\u5b83\u5b8c\u5168\u907f\u514d\u4e86\u4f7f\u7528\u201c\u9519\u8bef\u201d\u8fd9\u4e2a\u8bcd\u3002\u4e00\u9879\u67097\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u7684\u521d\u6b65\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u662f\u975e\u7535\u5b50\u8868\u683c\u7814\u7a76\u4eba\u5458\uff0c\u4f7f\u7528Asheetoxy\u4e5f\u53ef\u4ee5\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u7535\u5b50\u8868\u683c\u73b0\u8c61\u8fdb\u884c\u5206\u7c7b\u3002"}}
{"id": "1808.09174", "title": "Proceedings of the 5th International Workshop on Software Engineering Methods in Spreadsheets (SEMS'18)", "url": "https://arxiv.org/abs/1808.09174", "pdf": "https://arxiv.org/pdf/1808.09174", "abs": "https://arxiv.org/abs/1808.09174", "authors": ["Birgit Hofer", "Jorge Mendes"], "categories": ["cs.SE"], "comment": null, "summary": "Proceedings of the 5th International Workshop on Software Engineering Methods\nin Spreadsheets (SEMS'18), held on October 1st, 2018, in Lisbon, Portugal, and\nco-located with the 2018 IEEE Symposium on Visual Languages and Human-Centric\nComputing (VL/HCC).", "AI": {"tldr": "Proceedings of SEMS'18 workshop.", "motivation": "The motivation is to gather research on software engineering methods in spreadsheets.", "method": "This paper is a collection of research presented at a workshop.", "result": "The result is a compilation of papers presented at SEMS'18.", "conclusion": "This paper is part of the proceedings of the 5th International Workshop on Software Engineering Methods in Spreadsheets (SEMS'18)."}}
{"id": "1806.04952", "title": "Towards Semantically Enhanced Data Understanding", "url": "https://arxiv.org/abs/1806.04952", "pdf": "https://arxiv.org/pdf/1806.04952", "abs": "https://arxiv.org/abs/1806.04952", "authors": ["Markus Schr\u00f6der", "Christian Jilek", "J\u00f6rn Hees", "Andreas Dengel"], "categories": ["cs.DB", "cs.AI", "cs.HC"], "comment": "4 pages, 3 figures", "summary": "In the field of machine learning, data understanding is the practice of\ngetting initial insights in unknown datasets. Such knowledge-intensive tasks\nrequire a lot of documentation, which is necessary for data scientists to grasp\nthe meaning of the data. Usually, documentation is separate from the data in\nvarious external documents, diagrams, spreadsheets and tools which causes\nconsiderable look up overhead. Moreover, other supporting applications are not\nable to consume and utilize such unstructured data. That is why we propose a\nmethodology that uses a single semantic model that interlinks data with its\ndocumentation. Hence, data scientists are able to directly look up the\nconnected information about the data by simply following links. Equally, they\ncan browse the documentation which always refers to the data. Furthermore, the\nmodel can be used by other approaches providing additional support, like\nsearching, comparing, integrating or visualizing data. To showcase our approach\nwe also demonstrate an early prototype.", "AI": {"tldr": "\u6570\u636e\u4e0e\u6587\u6863\u5206\u79bb\u5bfc\u81f4\u67e5\u627e\u5f00\u9500\u5927\uff0c\u96be\u4ee5\u5229\u7528\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6570\u636e\u4e0e\u5176\u6587\u6863\u94fe\u63a5\u5728\u5355\u4e00\u8bed\u4e49\u6a21\u578b\u4e2d\u7684\u65b9\u6cd5\uff0c\u65b9\u4fbf\u67e5\u627e\u548c\u5229\u7528\uff0c\u5e76\u5df2\u901a\u8fc7\u539f\u578b\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u7406\u89e3\u5b9e\u8df5\u4e2d\uff0c\u6587\u6863\u901a\u5e38\u4e0e\u6570\u636e\u5206\u79bb\u5728\u4e0d\u540c\u7684\u5916\u90e8\u6587\u6863\u3001\u56fe\u8868\u3001\u7535\u5b50\u8868\u683c\u548c\u5de5\u5177\u4e2d\uff0c\u5bfc\u81f4\u4e86\u663e\u8457\u7684\u67e5\u627e\u5f00\u9500\uff0c\u5e76\u4e14\u4e0d\u5229\u4e8e\u5176\u4ed6\u5e94\u7528\u7a0b\u5e8f\u7684\u5229\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5355\u4e00\u8bed\u4e49\u6a21\u578b\u5c06\u6570\u636e\u4e0e\u5176\u6587\u6863\u76f8\u5173\u8054\u7684\u65b9\u6cd5\u8bba\u3002", "result": "\u5c55\u793a\u4e86\u4e00\u4e2a\u65e9\u671f\u539f\u578b\uff0c\u4ee5\u5c55\u793a\u8be5\u65b9\u6cd5\u8bba\u7684\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bba\u4f7f\u7528\u5355\u4e00\u8bed\u4e49\u6a21\u578b\u5c06\u6570\u636e\u4e0e\u5176\u6587\u6863\u76f8\u5173\u8054\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u6570\u636e\u7406\u89e3\u4e2d\u6570\u636e\u4e0e\u6587\u6863\u5206\u79bb\u7684\u95ee\u9898\uff0c\u964d\u4f4e\u4e86\u67e5\u627e\u5f00\u9500\uff0c\u5e76\u652f\u6301\u5176\u4ed6\u6570\u636e\u5904\u7406\u5e94\u7528\u3002"}}
{"id": "1805.10493", "title": "Combining Spreadsheet Smells for Improved Fault Prediction", "url": "https://arxiv.org/abs/1805.10493", "pdf": "https://arxiv.org/pdf/1805.10493", "abs": "https://arxiv.org/abs/1805.10493", "authors": ["Patrick Koch", "Konstantin Schekotihin", "Dietmar Jannach", "Birgit Hofer", "Franz Wotawa"], "categories": ["cs.SE"], "comment": "4 pages, 1 figure, to be published in 40th International Conference\n  on Software Engineering: New Ideas and Emerging Results Track", "summary": "Spreadsheets are commonly used in organizations as a programming tool for\nbusiness-related calculations and decision making. Since faults in spreadsheets\ncan have severe business impacts, a number of approaches from general software\nengineering have been applied to spreadsheets in recent years, among them the\nconcept of code smells. Smells can in particular be used for the task of fault\nprediction. An analysis of existing spreadsheet smells, however, revealed that\nthe predictive power of individual smells can be limited. In this work we\ntherefore propose a machine learning based approach which combines the\npredictions of individual smells by using an AdaBoost ensemble classifier.\nExperiments on two public datasets containing real-world spreadsheet faults\nshow significant improvements in terms of fault prediction accuracy.", "AI": {"tldr": "Spreadsheet smells can predict faults, but combining them with AdaBoost improves accuracy.", "motivation": "Limited predictive power of individual spreadsheet smells for fault prediction.", "method": "A machine learning based approach using an AdaBoost ensemble classifier to combine predictions of individual spreadsheet smells.", "result": "Significant improvements in fault prediction accuracy compared to individual smells, as shown by experiments on two public datasets.", "conclusion": "Adaboost ensemble classifier combines the predictions of individual smells, showing significant improvements in fault prediction accuracy on real-world spreadsheet faults."}}
{"id": "1805.06353", "title": "SmartTable: A Spreadsheet Program with Intelligent Assistance", "url": "https://arxiv.org/abs/1805.06353", "pdf": "https://arxiv.org/pdf/1805.06353", "abs": "https://arxiv.org/abs/1805.06353", "authors": ["Shuo Zhang", "Vugar Abdul Zada", "Krisztian Balog"], "categories": ["cs.IR"], "comment": "The 41st International ACM SIGIR Conference on Research and\n  Development in Information Retrieval (SIGIR '18)", "summary": "We introduce SmartTable, an online spreadsheet application that is equipped\nwith intelligent assistance capabilities. With a focus on relational tables,\ndescribing entities along with their attributes, we offer assistance in two\nflavors: (i) for populating the table with additional entities (rows) and (ii)\nfor extending it with additional entity attributes (columns). We provide\ndetails of our implementation, which is also released as open source. The\napplication is available at http://smarttable.cc.", "AI": {"tldr": "SmartTable\u662f\u4e00\u4e2a\u667a\u80fd\u5316\u7684\u5728\u7ebf\u7535\u5b50\u8868\u683c\uff0c\u53ef\u4ee5\u5e2e\u52a9\u7528\u6237\u586b\u5145\u884c\u548c\u5217\u3002", "motivation": "\u4ecb\u7ecdSmartTable\uff0c\u4e00\u4e2a\u5177\u6709\u667a\u80fd\u8f85\u52a9\u529f\u80fd\u7684\u5728\u7ebf\u7535\u5b50\u8868\u683c\u5e94\u7528\u7a0b\u5e8f\uff0c\u91cd\u70b9\u5173\u6ce8\u5173\u7cfb\u8868\u3002", "method": "SmartTable\u901a\u8fc7\u63d0\u4f9b\u4e24\u79cd\u667a\u80fd\u8f85\u52a9\u529f\u80fd\u6765\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff1a(i)\u4e3a\u8868\u683c\u586b\u5145\u5176\u4ed6\u5b9e\u4f53\uff08\u884c\uff09\uff0c\u4ee5\u53ca(ii)\u4e3a\u8868\u683c\u6269\u5c55\u5176\u4ed6\u5b9e\u4f53\u5c5e\u6027\uff08\u5217\uff09\u3002", "result": "SmartTable\u5df2\u5b9e\u73b0\u5e76\u5f00\u6e90\uff0c\u53ef\u5728http://smarttable.cc\u4e0a\u627e\u5230\u3002", "conclusion": "SmartTable\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u5728\u7ebf\u7535\u5b50\u8868\u683c\u5e94\u7528\u7a0b\u5e8f\uff0c\u5177\u6709\u667a\u80fd\u8f85\u52a9\u529f\u80fd\uff0c\u53ef\u7528\u4e8e\u586b\u5145\u8868\u683c\u884c\u548c\u6269\u5c55\u8868\u683c\u5217\u3002"}}
{"id": "1804.04175", "title": "An Easy & Collaborative RDF Data Entry Method using the Spreadsheet Metaphor", "url": "https://arxiv.org/abs/1804.04175", "pdf": "https://arxiv.org/pdf/1804.04175", "abs": "https://arxiv.org/abs/1804.04175", "authors": ["Markus Schr\u00f6der", "Christian Jilek", "J\u00f6rn Hees", "Sven Hertling", "Andreas Dengel"], "categories": ["cs.SE"], "comment": "15 pages", "summary": "Spreadsheets are widely used by knowledge workers, especially in the\nindustrial sector. Their methodology enables a well understood, easy and fast\npossibility to enter data. As filling out a spreadsheet is more accessible to\ncommon knowledge workers than defining RDF statements, in this paper, we\npropose an easy-to-use, zero-configuration, web-based spreadsheet editor that\nsimultaneously transfers spreadsheet entries into RDF statements. It enables\nvarious kinds of users to easily create semantic data whether they are RDF\nexperts or novices. The typical scenario we address focuses on creating\ninstance data starting with an empty knowledge base that is filled\nincrementally. In a user study, participants were able to create more\nstatements in shorter time, having similar or even significantly outperforming\nquality, compared to other approaches.", "AI": {"tldr": "\u4e00\u4e2a\u65b9\u4fbf\u7684Web\u7248\u7535\u5b50\u8868\u683c\u7f16\u8f91\u5668\uff0c\u53ef\u5c06\u7535\u5b50\u8868\u683c\u6570\u636e\u8f6c\u6362\u4e3aRDF\uff0c\u7528\u6237\u53ef\u5feb\u901f\u9ad8\u6548\u5730\u521b\u5efa\u8bed\u4e49\u6570\u636e\u3002", "motivation": "\u89e3\u51b3\u666e\u901a\u77e5\u8bc6\u5de5\u4f5c\u8005\u5728\u521b\u5efaRDF\u8bed\u53e5\u65b9\u9762\u9762\u4e34\u7684\u6311\u6218\uff0c\u5229\u7528\u4ed6\u4eec\u719f\u6089\u7684\u7535\u5b50\u8868\u683c\u4f5c\u4e3a\u5de5\u5177\u6765\u521b\u5efa\u8bed\u4e49\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u3001\u96f6\u914d\u7f6e\u7684\u3001\u57fa\u4e8eWeb\u7684\u7535\u5b50\u8868\u683c\u7f16\u8f91\u5668\uff0c\u80fd\u591f\u540c\u65f6\u5c06\u7535\u5b50\u8868\u683c\u6761\u76ee\u8f6c\u6362\u4e3aRDF\u8bed\u53e5\u3002", "result": "\u5728\u7528\u6237\u7814\u7a76\u4e2d\uff0c\u53c2\u4e0e\u8005\u80fd\u591f\u66f4\u5feb\u5730\u521b\u5efa\u66f4\u591a\u8bed\u53e5\uff0c\u5e76\u4e14\u8d28\u91cf\u76f8\u5f53\u6216\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eWeb\u7684\u7535\u5b50\u8868\u683c\u7f16\u8f91\u5668\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5730\u5c06\u7535\u5b50\u8868\u683c\u6761\u76ee\u8f6c\u6362\u4e3aRDF\u8bed\u53e5\uff0c\u4f7f\u5f97\u5404\u79cd\u7528\u6237\u90fd\u80fd\u8f7b\u677e\u521b\u5efa\u8bed\u4e49\u6570\u636e\u3002"}}
{"id": "1801.09777", "title": "Structured Spreadsheet Modelling and Implementation with Multiple Dimensions - Part 1: Modelling", "url": "https://arxiv.org/abs/1801.09777", "pdf": "https://arxiv.org/pdf/1801.09777", "abs": "https://arxiv.org/abs/1801.09777", "authors": ["Paul Mireault"], "categories": ["cs.SE"], "comment": "13 Pages, 17 Tables and Figures", "summary": "Dimensions are an integral part of many models we use every day. Without\nthinking about it, we frequently use the time dimension: many financial and\naccounting spreadsheets have columns representing months or years. Representing\na second dimension is often done by repeating blocs of formulas in a worksheet\nor creating multiple worksheets with the same structure.", "AI": {"tldr": "The abstract discusses the common use of the time dimension in models and the inefficient ways of representing a second dimension in spreadsheets.", "motivation": "The motivation is to address the limitations of representing multiple dimensions in everyday models, such as financial spreadsheets, which often rely on repeating formula blocks or multiple worksheets.", "method": "The abstract does not describe a specific method.", "result": "The abstract highlights the common practice of using time as a primary dimension and the inefficiency of current methods for incorporating a second dimension.", "conclusion": "The abstract does not provide a conclusion."}}
{"id": "1802.01640", "title": "Mitigating Spreadsheet Risk in Complex Multi-Dimensional Models in Excel", "url": "https://arxiv.org/abs/1802.01640", "pdf": "https://arxiv.org/pdf/1802.01640", "abs": "https://arxiv.org/abs/1802.01640", "authors": ["Steve Litt"], "categories": ["cs.SE"], "comment": "13 Pages, 11 Colour Figures", "summary": "Microsoft Excel is the most ubiquitous analytical tool ever built. Companies\naround the world leverage it for its power, flexibility and ease of use.\nHowever, spreadsheets are manually intensive and prone to error, making it\ndifficult for companies to control spreadsheet risk. The following solution is\ndesigned to mitigate spreadsheet risk for a set of problems commonly addressed\nin a spreadsheet defined as \"complex multi-dimensional models\". \"Complex\"\nreferring to certain types of applications that require functionality such as\nsophisticated algorithms, challenging hierarchies and database write-back (i.e.\nplanning, forecasting, etc.) and \"multi-dimensional\" referring to providing\ncapabilities such as reporting, data input forms and ad hoc analysis on the\ndifferent attributes associated with the resulting model. The solution is\ndefined as a \"PivotModel\" because it works similarly to a PivotTable but is\ndesigned to leverage the robust capabilities of the Microsoft Excel platform.", "AI": {"tldr": "PivotModel is a new solution for Excel to reduce risks associated with complex spreadsheets.", "motivation": "Spreadsheets like Microsoft Excel are widely used but are manually intensive and prone to error, leading to difficulties in controlling spreadsheet risk, especially for complex multi-dimensional models.", "method": "The solution, named PivotModel, functions similarly to a PivotTable but is designed to leverage the robust capabilities of the Microsoft Excel platform.", "result": "The PivotModel aims to provide enhanced functionality for complex applications requiring sophisticated algorithms, challenging hierarchies, and database write-back, as well as multi-dimensional capabilities like reporting, data input forms, and ad hoc analysis.", "conclusion": "The proposed PivotModel solution aims to mitigate spreadsheet risk in complex multi-dimensional models within Microsoft Excel."}}
{"id": "1802.01628", "title": "Proposed Spreadsheet Transparency Definition and Measures", "url": "https://arxiv.org/abs/1802.01628", "pdf": "https://arxiv.org/pdf/1802.01628", "abs": "https://arxiv.org/abs/1802.01628", "authors": ["Craig Hatmaker"], "categories": ["cs.SE"], "comment": "13 Pages, 12 Screenshots", "summary": "Auditors demand financial models be transparent yet no consensus exists on\nwhat that means precisely. Without a clear modeling transparency definition we\ncannot know when our models are \"transparent\". The financial modeling community\ndebates which methods are more or less transparent as though transparency is a\nquantifiable entity yet no measures exist. Without a transparency measure\nmodelers cannot objectively evaluate methods and know which improves model\ntransparency.\n  This paper proposes a definition for spreadsheet modeling transparency that\nis specific enough to create measures and automation tools for auditors to\ndetermine if a model meets transparency requirements. The definition also\nprovides modelers the ability to objectively compare spreadsheet modeling\nmethods to select which best meets their goals.", "AI": {"tldr": "\u5ba1\u8ba1\u5e08\u9700\u8981\u6a21\u578b\u900f\u660e\uff0c\u4f46\u7f3a\u4e4f\u660e\u786e\u7684\u5b9a\u4e49\u548c\u8861\u91cf\u6807\u51c6\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5177\u4f53\u7684\u900f\u660e\u5ea6\u5b9a\u4e49\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u4ee5\u5e2e\u52a9\u5ba1\u8ba1\u5e08\u8bc4\u4f30\u6a21\u578b\uff0c\u5e76\u8ba9\u5efa\u6a21\u4eba\u5458\u80fd\u591f\u5ba2\u89c2\u5730\u6bd4\u8f83\u4e0d\u540c\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "motivation": "\u5ba1\u8ba1\u5e08\u8981\u6c42\u8d22\u52a1\u6a21\u578b\u900f\u660e\uff0c\u4f46\u7f3a\u4e4f\u660e\u786e\u7684\u5b9a\u4e49\u548c\u53ef\u8861\u91cf\u7684\u6807\u51c6\uff0c\u5bfc\u81f4\u65e0\u6cd5\u786e\u5b9a\u6a21\u578b\u7684\u900f\u660e\u5ea6\uff0c\u4e5f\u65e0\u6cd5\u5ba2\u89c2\u6bd4\u8f83\u4e0d\u540c\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5177\u4f53\u7684\u3001\u53ef\u8861\u91cf\u7684\u900f\u660e\u5ea6\u5b9a\u4e49\uff0c\u4ee5\u53ca\u76f8\u5e94\u7684\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u7528\u4e8e\u8bc4\u4f30\u7535\u5b50\u8868\u683c\u6a21\u578b\u7684\u900f\u660e\u5ea6\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u660e\u786e\u7684\u900f\u660e\u5ea6\u5b9a\u4e49\uff0c\u4f7f\u5ba1\u8ba1\u5e08\u80fd\u591f\u8bc4\u4f30\u6a21\u578b\u662f\u5426\u6ee1\u8db3\u8981\u6c42\uff0c\u5e76\u4f7f\u5efa\u6a21\u4eba\u5458\u80fd\u591f\u5ba2\u89c2\u5730\u9009\u62e9\u6700\u9002\u5408\u5176\u76ee\u6807\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u7535\u5b50\u8868\u683c\u5efa\u6a21\u7684\u900f\u660e\u5ea6\u5b9a\u4e49\uff0c\u8be5\u5b9a\u4e49\u8db3\u591f\u5177\u4f53\uff0c\u53ef\u4ee5\u521b\u5efa\u5ea6\u91cf\u548c\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u4ee5\u4fbf\u5ba1\u8ba1\u5e08\u80fd\u591f\u786e\u5b9a\u6a21\u578b\u662f\u5426\u6ee1\u8db3\u900f\u660e\u5ea6\u8981\u6c42\u3002\u8be5\u5b9a\u4e49\u8fd8\u4f7f\u5efa\u6a21\u4eba\u5458\u80fd\u591f\u5ba2\u89c2\u5730\u6bd4\u8f83\u7535\u5b50\u8868\u683c\u5efa\u6a21\u65b9\u6cd5\uff0c\u4ee5\u9009\u62e9\u6700\u7b26\u5408\u5176\u76ee\u6807\u7684\u65b9\u6cd5\u3002"}}
{"id": "1802.00496", "title": "Edu-Edition Spreadsheet Competency Framework", "url": "https://arxiv.org/abs/1802.00496", "pdf": "https://arxiv.org/pdf/1802.00496", "abs": "https://arxiv.org/abs/1802.00496", "authors": ["Maria Csernoch", "Piroska Bir\u00f3"], "categories": ["cs.CY"], "comment": null, "summary": "Based on the Spreadsheet Competency Framework for finance professionals, in\nthe present paper we introduce the Edu-Edition of the Spreadsheet Competency\nFramework (E2SCF). We claim that building spreadsheet competences should start\nin education, as early as possible, and this process is a lot more effective if\nsupport arrives from expert teachers. The main feature of E2SCF is high\nmathability computer-supported real world problem solving. This approach is\nbased on - from the very beginning of training - a two-directional knowledge\ntransfer, data and error analysis and handling, and the programming aspect of\nspreadsheets. Based on these features, E2SCF is set up for basic and general\nusers to build up firm spreadsheet knowledge and to develop transferable\nproblem solving skills and competences.", "AI": {"tldr": "\u63d0\u51fa\u6559\u80b2\u7248\u7535\u5b50\u8868\u683c\u80fd\u529b\u6846\u67b6\uff08E2SCF\uff09\uff0c\u5f3a\u8c03\u65e9\u671f\u6559\u80b2\u3001\u4e13\u4e1a\u6559\u5e08\u652f\u6301\u3001\u9ad8\u6570\u5b66\u80fd\u529b\u3001\u8ba1\u7b97\u673a\u652f\u6301\u7684\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u89e3\u51b3\u3001\u53cc\u5411\u77e5\u8bc6\u8f6c\u79fb\u3001\u6570\u636e\u548c\u9519\u8bef\u5206\u6790\u4ee5\u53ca\u7f16\u7a0b\u65b9\u9762\uff0c\u65e8\u5728\u4e3a\u7528\u6237\u6253\u4e0b\u575a\u5b9e\u7684\u7535\u5b50\u8868\u683c\u77e5\u8bc6\u57fa\u7840\u5e76\u57f9\u517b\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u5728\u6559\u80b2\u65e9\u671f\u9636\u6bb5\u57f9\u517b\u7535\u5b50\u8868\u683c\u80fd\u529b\uff0c\u5e76\u7531\u4e13\u4e1a\u6559\u5e08\u63d0\u4f9b\u652f\u6301\uff0c\u4ece\u800c\u63d0\u9ad8\u57f9\u8bad\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7535\u5b50\u8868\u683c\u80fd\u529b\u6846\u67b6\uff08SCF\uff09\u7684\u6559\u80b2\u7248\u7535\u5b50\u8868\u683c\u80fd\u529b\u6846\u67b6\uff08E2SCF\uff09\u3002E2SCF\u7684\u7279\u70b9\u662f\u9ad8\u6570\u5b66\u80fd\u529b\u3001\u8ba1\u7b97\u673a\u652f\u6301\u7684\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u89e3\u51b3\u3001\u53cc\u5411\u77e5\u8bc6\u8f6c\u79fb\u3001\u6570\u636e\u548c\u9519\u8bef\u5206\u6790\u4ee5\u53ca\u7535\u5b50\u8868\u683c\u7684\u7f16\u7a0b\u65b9\u9762\u3002", "result": "E2SCF\u80fd\u591f\u5e2e\u52a9\u521d\u7ea7\u548c\u901a\u7528\u7528\u6237\u5efa\u7acb\u624e\u5b9e\u7684\u7535\u5b50\u8868\u683c\u77e5\u8bc6\uff0c\u5e76\u57f9\u517b\u53ef\u8f6c\u79fb\u7684\u95ee\u9898\u89e3\u51b3\u6280\u80fd\u548c\u80fd\u529b\u3002", "conclusion": "E2SCF\u4e3a\u521d\u7ea7\u548c\u901a\u7528\u7528\u6237\u6253\u4e0b\u575a\u5b9e\u7684\u7535\u5b50\u8868\u683c\u77e5\u8bc6\u57fa\u7840\uff0c\u5e76\u57f9\u517b\u53ef\u8f6c\u79fb\u7684\u95ee\u9898\u89e3\u51b3\u6280\u80fd\u548c\u80fd\u529b\u3002"}}
{"id": "1802.00484", "title": "Alternative Spreadsheet Model Designs for an Operations Management Model Embedded in a Periodic Business Process", "url": "https://arxiv.org/abs/1802.00484", "pdf": "https://arxiv.org/pdf/1802.00484", "abs": "https://arxiv.org/abs/1802.00484", "authors": ["Thomas A. Grossman", "Vijay Mehrotra", "Mouwafac Sidaoui"], "categories": ["cs.SE"], "comment": "12 Pages, 10 Colour Figures", "summary": "We present a widely-used operations management model used in supply and\ndistribution planning, that is typically embedded in a periodic business\nprocess that necessitates model modification and reuse. We consider three\nalternative spreadsheet implementations, a data-driven design, a canonical\n(textbook) design, and a novel (table-driven) technical design. We evaluate\neach regarding suitability for accuracy, modification, analysis, and transfer.\nWe consider the degree of training and technical sophistication required to\nutilize each design. The data-driven design provides insight into poor\nspreadsheet practices by na\\\"ive modelers. The technical design can be modified\nfor new data and new structural elements without manual writing or editing of\ncell formulas, thus speeding modification and reducing risk of error. The\ntechnical design has potential for use with other classes of models. We\nidentify opportunities for future research.", "AI": {"tldr": "Three spreadsheet models for operations management were evaluated. A novel technical design allows for faster, error-free modifications and has broader potential, outperforming data-driven and canonical designs.", "motivation": "The need for model modification and reuse in periodic operations management business processes, specifically within supply and distribution planning.", "method": "Evaluation of three spreadsheet implementations (data-driven, canonical, and technical) based on accuracy, modification, analysis, and transfer suitability, considering required training and technical sophistication.", "result": "The data-driven design highlights poor spreadsheet practices. The technical design allows modification without manual formula editing, improving speed and reducing errors, and shows potential for other model classes.", "conclusion": "The technical design offers advantages in modification speed and error reduction, with potential for broader model application."}}
{"id": "1801.03829", "title": "Characterizing Scalability Issues in Spreadsheet Software using Online Forums", "url": "https://arxiv.org/abs/1801.03829", "pdf": "https://arxiv.org/pdf/1801.03829", "abs": "https://arxiv.org/abs/1801.03829", "authors": ["Kelly Mack", "John Lee", "Kevin Chang", "Karrie Karahalios", "Aditya Parameswaran"], "categories": ["cs.HC"], "comment": null, "summary": "In traditional usability studies, researchers talk to users of tools to\nunderstand their needs and challenges. Insights gained via such interviews\noffer context, detail, and background. Due to costs in time and money, we are\nbeginning to see a new form of tool interrogation that prioritizes scale, cost,\nand breadth by utilizing existing data from online forums. In this case study,\nwe set out to apply this method of using online forum data to a specific\nissue---challenges that users face with Excel spreadsheets. Spreadsheets are a\nversatile and powerful processing tool if used properly. However, with\nversatility and power come errors, from both users and the software, which make\nusing spreadsheets less effective. By scraping posts from the website Reddit,\nwe collected a dataset of questions and complaints about Excel. Specifically,\nwe explored and characterized the issues users were facing with spreadsheet\nsoftware in general, and in particular, as resulting from a large amount of\ndata in their spreadsheets. We discuss the implications of our findings on the\ndesign of next-generation spreadsheet software.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790Reddit\u7528\u6237\u5173\u4e8eExcel\u7684\u8ba8\u8bba\uff0c\u672c\u7814\u7a76\u63ed\u793a\u4e86\u7528\u6237\u5728\u4f7f\u7528\u7535\u5b50\u8868\u683c\u65f6\u9047\u5230\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u4e0e\u5927\u6570\u636e\u5904\u7406\u76f8\u5173\u7684\u6311\u6218\uff0c\u5e76\u4e3a\u6539\u8fdb\u7535\u5b50\u8868\u683c\u8f6f\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5efa\u8bae\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u4f20\u7edf\u7528\u6237\u7814\u7a76\u4e2d\u65f6\u95f4\u6210\u672c\u548c\u91d1\u94b1\u6210\u672c\u7684\u9650\u5236\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u5229\u7528\u5728\u7ebf\u8bba\u575b\u6570\u636e\u6765\u4e86\u89e3\u7528\u6237\u9700\u6c42\u548c\u6311\u6218\u7684\u65b0\u578b\u5de5\u5177\u7814\u7a76\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eExcel\u7535\u5b50\u8868\u683c\u7684\u7528\u6237\u6311\u6218\u7814\u7a76\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u6293\u53d6Reddit\u7f51\u7ad9\u4e0a\u7684\u5e16\u5b50\uff0c\u6536\u96c6\u4e86\u7528\u6237\u5173\u4e8eExcel\u7684\u63d0\u95ee\u548c\u62b1\u6028\u6570\u636e\uff0c\u5e76\u4ee5\u6b64\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u63a2\u8ba8\u548c\u63cf\u8ff0\u4e86\u7528\u6237\u5728\u4f7f\u7528\u7535\u5b50\u8868\u683c\u8f6f\u4ef6\u65f6\u9047\u5230\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u4e0e\u5904\u7406\u5927\u91cf\u6570\u636e\u76f8\u5173\u7684\u6311\u6218\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u7528\u6237\u5728\u4f7f\u7528\u7535\u5b50\u8868\u683c\u8f6f\u4ef6\u65f6\u9047\u5230\u7684\u5177\u4f53\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u5927\u6570\u636e\u91cf\u65b9\u9762\uff0c\u4e3a\u4f18\u5316\u7535\u5b50\u8868\u683c\u8f6f\u4ef6\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "\u672c\u7814\u7a76\u7684\u53d1\u73b0\u5c06\u4e3a\u4e0b\u4e00\u4ee3\u7535\u5b50\u8868\u683c\u8f6f\u4ef6\u7684\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "1801.10249", "title": "The Reification of an Incorrect and Inappropriate Spreadsheet Model", "url": "https://arxiv.org/abs/1801.10249", "pdf": "https://arxiv.org/pdf/1801.10249", "abs": "https://arxiv.org/abs/1801.10249", "authors": ["Grenville J. Croll"], "categories": ["cs.HC"], "comment": "14 Pages, 4 Colour Figures, 2 Tables", "summary": "Once information is loaded into a spreadsheet, it acquires properties that it\nmay not deserve. These properties include believability, correctness,\nappropriateness, concreteness, integrity, tangibility, objectivity and\nauthority. The information becomes reified. We describe a case study through\nwhich we were able to observe at close hand the reification of a demonstrably\nincorrect and inappropriate spreadsheet model within a small non profit\norganisation.", "AI": {"tldr": "\u4fe1\u606f\u8f7d\u5165\u7535\u5b50\u8868\u683c\u4f1a\u83b7\u5f97\u4e0d\u5e94\u6709\u7684\u5c5e\u6027\uff08\u53ef\u4fe1\u5ea6\u3001\u6b63\u786e\u6027\u3001\u9002\u5f53\u6027\u3001\u5177\u4f53\u6027\u3001\u5b8c\u6574\u6027\u3001\u5b9e\u5728\u6027\u3001\u5ba2\u89c2\u6027\u548c\u6743\u5a01\u6027\uff09\uff0c\u4f7f\u5176\u5177\u4f53\u5316\u3002\u7814\u7a76\u89c2\u5bdf\u5230\u4e0d\u6b63\u786e\u7684\u7535\u5b50\u8868\u683c\u6a21\u578b\u5728\u4e00\u4e2a\u5c0f\u578b\u975e\u8425\u5229\u7ec4\u7ec7\u4e2d\u7684\u5177\u4f53\u5316\u3002", "motivation": "\u7814\u7a76\u4fe1\u606f\u4e00\u65e6\u8f7d\u5165\u7535\u5b50\u8868\u683c\uff0c\u5c31\u4f1a\u83b7\u5f97\u4e00\u4e9b\u53ef\u80fd\u4e0d\u5e94\u6709\u7684\u5c5e\u6027\uff0c\u4f8b\u5982\u53ef\u4fe1\u5ea6\u3001\u6b63\u786e\u6027\u3001\u9002\u5f53\u6027\u3001\u5177\u4f53\u6027\u3001\u5b8c\u6574\u6027\u3001\u5b9e\u5728\u6027\u3001\u5ba2\u89c2\u6027\u548c\u6743\u5a01\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u5177\u4f53\u5316\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u4e00\u4e2a\u6848\u4f8b\u7814\u7a76\u6765\u63cf\u8ff0\u3002", "result": "\u6211\u4eec\u89c2\u5bdf\u5230\u4e00\u4e2a\u660e\u663e\u4e0d\u6b63\u786e\u548c\u4e0d\u9002\u5f53\u7684\u7535\u5b50\u8868\u683c\u6a21\u578b\u5728\u4e00\u4e2a\u5c0f\u578b\u975e\u8425\u5229\u7ec4\u7ec7\u4e2d\u7684\u5177\u4f53\u5316\u3002", "conclusion": "\u4fe1\u606f\u4e00\u65e6\u8f7d\u5165\u7535\u5b50\u8868\u683c\uff0c\u5c31\u4f1a\u83b7\u5f97\u4e00\u4e9b\u53ef\u80fd\u4e0d\u5e94\u6709\u7684\u5c5e\u6027\uff0c\u4f8b\u5982\u53ef\u4fe1\u5ea6\u3001\u6b63\u786e\u6027\u3001\u9002\u5f53\u6027\u3001\u5177\u4f53\u6027\u3001\u5b8c\u6574\u6027\u3001\u5b9e\u5728\u6027\u3001\u5ba2\u89c2\u6027\u548c\u6743\u5a01\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u5177\u4f53\u5316\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u63cf\u8ff0\u4e86\u4e00\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u901a\u8fc7\u8be5\u7814\u7a76\uff0c\u6211\u4eec\u80fd\u591f\u8fd1\u8ddd\u79bb\u89c2\u5bdf\u5230\u4e00\u4e2a\u660e\u663e\u4e0d\u6b63\u786e\u548c\u4e0d\u9002\u5f53\u7684\u7535\u5b50\u8868\u683c\u6a21\u578b\u5728\u4e00\u4e2a\u5c0f\u578b\u975e\u8425\u5229\u7ec4\u7ec7\u4e2d\u7684\u5177\u4f53\u5316\u3002"}}
{"id": "1801.10231", "title": "The Future of Spreadsheets in the Big Data Era", "url": "https://arxiv.org/abs/1801.10231", "pdf": "https://arxiv.org/pdf/1801.10231", "abs": "https://arxiv.org/abs/1801.10231", "authors": ["David Birch", "David Lyford-Smith", "Yike Guo"], "categories": ["cs.CY"], "comment": "13 Pages, 1 Table", "summary": "The humble spreadsheet is the most widely used data storage, manipulation and\nmodelling tool. Its ubiquity over the past 30 years has seen its successful\napplication in every area of life. Surprisingly the spreadsheet has remained\nfundamentally unchanged over the past three decades. As spreadsheet technology\nenters its 4th decade a number of drivers of change are beginning to impact\nupon the spreadsheet. The rise of Big Data, increased end-user computing and\nmobile computing will undoubtedly increasingly shape the evolution and use of\nspreadsheet technology.\n  To explore the future of spreadsheet technology a workshop was convened with\nthe aim of \"bringing together academia and industry to examine the future\ndirection of spreadsheet technology and the consequences for users\". This paper\nrecords the views of the participants on the reasons for the success of the\nspreadsheet, the trends driving change and the likely directions of change for\nthe spreadsheet. We then set out key directions for further research in the\nevolution and use of spreadsheets. Finally we look at the implications of these\ntrends for the end users who after all are the reason for the remarkable\nsuccess of the spreadsheet.", "AI": {"tldr": "Spreadsheets remain dominant but are evolving due to Big Data, end-user computing, and mobile computing. A workshop identified future research directions and user implications.", "motivation": "To explore the future of spreadsheet technology and its evolution due to new drivers of change.", "method": "Workshop convened with academia and industry to discuss the future of spreadsheet technology.", "result": "The paper records participants' views on the success factors, trends driving change, and likely future directions for spreadsheets, along with implications for end-users.", "conclusion": "The paper identifies key research directions for spreadsheet evolution and use, considering trends like Big Data, end-user computing, and mobile computing, and discusses the implications for end-users."}}
{"id": "1801.09771", "title": "Mitigating Spreadsheet Model Risk with Python Open Source Infrastructure", "url": "https://arxiv.org/abs/1801.09771", "pdf": "https://arxiv.org/pdf/1801.09771", "abs": "https://arxiv.org/abs/1801.09771", "authors": ["Oliver Beavers"], "categories": ["cs.SE"], "comment": "14 Pages, 15 Colour Diagrams", "summary": "Across an aggregation of EuSpRIG presentation papers, two maxims hold true:\nspreadsheets models are akin to software, yet spreadsheet developers are not\nsoftware engineers. As such, the lack of traditional software engineering tools\nand protocols invites a higher rate of error in the end result. This paper lays\nground work for spreadsheet modelling professionals to develop reproducible\naudit tools using freely available, open source packages built with the Python\nprogramming language, enabling stakeholders to develop clearly defined model\n\"oracles\" with which to test and audit spreadsheet calculations against.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u7535\u5b50\u8868\u683c\u6a21\u578b\u4e2d\u7531\u4e8e\u7f3a\u4e4f\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u548c\u534f\u8bae\u800c\u5bfc\u81f4\u7684\u9519\u8bef\u7387\u8f83\u9ad8\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4f7f\u7528 Python \u548c\u5f00\u6e90\u5305\u6765\u5f00\u53d1\u53ef\u91cd\u73b0\u7684\u5ba1\u8ba1\u5de5\u5177\uff0c\u4ee5\u4f9b\u7535\u5b50\u8868\u683c\u5efa\u6a21\u4e13\u4e1a\u4eba\u58eb\u4f7f\u7528\uff0c\u4f7f\u5229\u76ca\u76f8\u5173\u8005\u80fd\u591f\u5f00\u53d1\u6e05\u6670\u7684\u6a21\u578b\u201cOracle\u201d\u6765\u6d4b\u8bd5\u548c\u5ba1\u8ba1\u7535\u5b50\u8868\u683c\u8ba1\u7b97\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u6a21\u578b\u88ab\u89c6\u4e3a\u8f6f\u4ef6\uff0c\u4f46\u7535\u5b50\u8868\u683c\u5f00\u53d1\u8005\u5e76\u975e\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u8fd9\u5bfc\u81f4\u4e86\u9519\u8bef\u7387\u7684\u589e\u52a0\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528 Python \u7f16\u7a0b\u8bed\u8a00\u548c\u514d\u8d39\u7684\u3001\u5f00\u6e90\u7684\u8f6f\u4ef6\u5305\u3002", "result": "\u4e3a\u7535\u5b50\u8868\u683c\u5efa\u6a21\u4e13\u4e1a\u4eba\u58eb\u5f00\u53d1\u53ef\u91cd\u73b0\u7684\u5ba1\u8ba1\u5de5\u5177\uff0c\u4f7f\u5229\u76ca\u76f8\u5173\u8005\u80fd\u591f\u5f00\u53d1\u6e05\u6670\u5b9a\u4e49\u7684\u6a21\u578b\u201cOracle\u201d\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e9b\u6a21\u578b\u6765\u6d4b\u8bd5\u548c\u5ba1\u8ba1\u7535\u5b50\u8868\u683c\u8ba1\u7b97\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528 Python \u8bed\u8a00\u548c\u5f00\u6e90\u5305\uff0c\u53ef\u4ee5\u4e3a\u7535\u5b50\u8868\u683c\u5efa\u6a21\u4e13\u4e1a\u4eba\u58eb\u5f00\u53d1\u53ef\u91cd\u73b0\u7684\u5ba1\u8ba1\u5de5\u5177\uff0c\u4f7f\u5229\u76ca\u76f8\u5173\u8005\u80fd\u591f\u5f00\u53d1\u6e05\u6670\u5b9a\u4e49\u7684\u6a21\u578b\u201cOracle\u201d\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e9b\u6a21\u578b\u6765\u6d4b\u8bd5\u548c\u5ba1\u8ba1\u7535\u5b50\u8868\u683c\u8ba1\u7b97\u3002"}}
{"id": "1801.08603", "title": "Structuring Spreadsheets with the \"Lish\" Data Model", "url": "https://arxiv.org/abs/1801.08603", "pdf": "https://arxiv.org/pdf/1801.08603", "abs": "https://arxiv.org/abs/1801.08603", "authors": ["Alan Hall", "Michel Wermelinger", "Tony Hirst", "Santi Phithakkitnukoon"], "categories": ["cs.SE"], "comment": "4 colour figures", "summary": "A spreadsheet is remarkably flexible in representing various forms of\nstructured data, but the individual cells have no knowledge of the larger\nstructures of which they may form a part. This can hamper comprehension and\nincrease formula replication, increasing the risk of error on both scores. We\nexplore a novel data model (called the \"lish\") that could form an alternative\nto the traditional grid in a spreadsheet-like environment. Its aim is to\ncapture some of these higher structures while preserving the simplicity that\nmakes a spreadsheet so attractive. It is based on cells organised into nested\nlists, in each of which the user may optionally employ a template to prototype\nrepeating structures. These template elements can be likened to the marginal\n\"cells\" in the borders of a traditional worksheet, but are proper members of\nthe sheet and may themselves contain internal structure. A small demonstration\napplication shows the \"lish\" in operation.", "AI": {"tldr": "lish\u662f\u4e00\u79cd\u65b0\u7684\u6570\u636e\u6a21\u578b\uff0c\u5b83\u4f7f\u7528\u5d4c\u5957\u5217\u8868\u548c\u6a21\u677f\u6765\u6539\u8fdb\u7535\u5b50\u8868\u683c\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u66f4\u590d\u6742\u7684\u7ed3\u6784\uff0c\u540c\u65f6\u4fdd\u6301\u6613\u7528\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u7535\u5b50\u8868\u683c\u4e2d\u5355\u5143\u683c\u7f3a\u4e4f\u5bf9\u66f4\u5927\u7ed3\u6784\u8ba4\u8bc6\u7684\u95ee\u9898\uff0c\u8fd9\u79cd\u95ee\u9898\u4f1a\u963b\u788d\u7406\u89e3\u5e76\u589e\u52a0\u516c\u5f0f\u590d\u5236\u7684\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201clish\u201d\u7684\u65b0\u578b\u6570\u636e\u6a21\u578b\uff0c\u4f5c\u4e3a\u4f20\u7edf\u7535\u5b50\u8868\u683c\u7f51\u683c\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u8be5\u6a21\u578b\u5c06\u5355\u5143\u683c\u7ec4\u7ec7\u6210\u5d4c\u5957\u5217\u8868\uff0c\u5e76\u5141\u8bb8\u4f7f\u7528\u6a21\u677f\u6765\u5b9a\u4e49\u91cd\u590d\u7ed3\u6784\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u5c0f\u578b\u6f14\u793a\u5e94\u7528\u7a0b\u5e8f\u5c55\u793a\u4e86\u201clish\u201d\u7684\u8fd0\u884c\u60c5\u51b5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u6355\u6349\u66f4\u9ad8\u7ed3\u6784\u7684\u540c\u65f6\u4fdd\u6301\u7535\u5b50\u8868\u683c\u7b80\u6d01\u6027\u7684\u6f5c\u529b\u3002", "conclusion": "\u5355\u5143\u683c\u53ef\u4ee5\u88ab\u7ec4\u7ec7\u6210\u5d4c\u5957\u5217\u8868\uff0c\u5e76\u4e14\u7528\u6237\u53ef\u4ee5\u6709\u9009\u62e9\u5730\u4f7f\u7528\u6a21\u677f\u6765\u539f\u578b\u5316\u91cd\u590d\u7684\u7ed3\u6784\uff0c\u8fd9\u4e9b\u6a21\u677f\u5143\u7d20\u53ef\u4ee5\u4e0e\u4f20\u7edf\u5de5\u4f5c\u8868\u8fb9\u754c\u4e2d\u7684\u5355\u5143\u683c\u76f8\u63d0\u5e76\u8bba\uff0c\u4f46\u5b83\u4eec\u662f\u5de5\u4f5c\u8868\u7684proper\u6210\u5458\uff0c\u5e76\u4e14\u53ef\u4ee5\u5305\u542b\u5185\u90e8\u7ed3\u6784\u3002"}}
{"id": "1801.07782", "title": "The Role of Spreadsheets in Clinical Decision Support: A Survey of the Medical Algorithms Company User Community", "url": "https://arxiv.org/abs/1801.07782", "pdf": "https://arxiv.org/pdf/1801.07782", "abs": "https://arxiv.org/abs/1801.07782", "authors": ["Simon Thorne"], "categories": ["cs.CY"], "comment": "13 pages, 6 Colour Figures", "summary": "This paper presents and discusses the results of a small scoping survey of\nClinical Decision Support System (CDSS) users from the Medical Algorithms\nCompany website which hosts 24,000 different CDSS. These results are analysed,\ndiscussed, and compared with other similar studies and contribute to the wider\nunderstanding of how CDSS impact on clinical practice. The results show that\nCDSS provided by Medal are being used by clinical professionals in a variety of\nsettings, both as an operational tool and as a research and reference tool.\nWhilst these tools are implemented and executed in a database, the initial\nlogic is worked out on a spreadsheet. The paper describes that process and\nexamines some of the results of the survey.", "AI": {"tldr": "This paper surveys users of Clinical Decision Support Systems (CDSS) from the Medical Algorithms Company website to understand how CDSS impact clinical practice. The results indicate that CDSS are utilized in various settings for operational, research, and reference purposes, with initial logic often developed on spreadsheets.", "motivation": "To contribute to the wider understanding of how CDSS impact on clinical practice.", "method": "A small scoping survey of Clinical Decision Support System (CDSS) users from the Medical Algorithms Company website.", "result": "The results show that CDSS provided by Medal are being used by clinical professionals in a variety of settings, both as an operational tool and as a research and reference tool. The initial logic is worked out on a spreadsheet, and the paper describes that process and examines some of the results of the survey.", "conclusion": "CDSS provided by Medal are being used by clinical professionals in a variety of settings, both as an operational tool and as a research and reference tool."}}
{"id": "1712.09797", "title": "Automated Refactoring of Nested-IF Formulae in Spreadsheets", "url": "https://arxiv.org/abs/1712.09797", "pdf": "https://arxiv.org/pdf/1712.09797", "abs": "https://arxiv.org/abs/1712.09797", "authors": ["Jie Zhang", "Shi Han", "Dan Hao", "Lu Zhang", "Dongmei Zhang"], "categories": ["cs.SE"], "comment": null, "summary": "Spreadsheets are the most popular end-user programming software, where\nformulae act like programs and also have smells. One well recognized common\nsmell of spreadsheet formulae is nest-IF expressions, which have low\nreadability and high cognitive cost for users, and are error-prone during reuse\nor maintenance. However, end users usually lack essential programming language\nknowledge and skills to tackle or even realize the problem. The previous\nresearch work has made very initial attempts in this aspect, while no effective\nand automated approach is currently available.\n  This paper firstly proposes an AST-based automated approach to systematically\nrefactoring nest-IF formulae. The general idea is two-fold. First, we detect\nand remove logic redundancy on the AST. Second, we identify higher-level\nsemantics that have been fragmented and scattered, and reassemble the syntax\nusing concise built-in functions. A comprehensive evaluation has been conducted\nagainst a real-world spreadsheet corpus, which is collected in a leading IT\ncompany for research purpose. The results with over 68,000 spreadsheets with 27\nmillion nest-IF formulae reveal that our approach is able to relieve the smell\nof over 99\\% of nest-IF formulae. Over 50% of the refactorings have reduced\nnesting levels of the nest-IFs by more than a half. In addition, a survey\ninvolving 49 participants indicates that for most cases the participants prefer\nthe refactored formulae, and agree on that such automated refactoring approach\nis necessary and helpful.", "AI": {"tldr": "\u81ea\u52a8\u5316\u91cd\u6784\u7535\u5b50\u8868\u683c\u4e2d\u7684\u5d4c\u5957IF\u516c\u5f0f\uff0c\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u662f\u5e38\u7528\u7684\u7aef\u7528\u6237\u7f16\u7a0b\u8f6f\u4ef6\uff0c\u4f46\u5176\u516c\u5f0f\uff08\u5c24\u5176\u662f\u5d4c\u5957IF\u8868\u8fbe\u5f0f\uff09\u5b58\u5728\u53ef\u8bfb\u6027\u5dee\u3001\u8ba4\u77e5\u6210\u672c\u9ad8\u3001\u6613\u51fa\u9519\u7b49\u95ee\u9898\uff0c\u800c\u7ec8\u7aef\u7528\u6237\u901a\u5e38\u7f3a\u4e4f\u5fc5\u8981\u7684\u7f16\u7a0b\u77e5\u8bc6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u548c\u79fb\u9664\u903b\u8f91\u5197\u4f59\uff0c\u5e76\u8bc6\u522b\u548c\u91cd\u7ec4\u9ad8\u5c42\u8bed\u4e49\uff08\u4f7f\u7528\u5185\u7f6e\u51fd\u6570\uff09\u6765\u91cd\u6784\u5d4c\u5957IF\u516c\u5f0f\u3002", "result": "\u5728\u5305\u542b2700\u4e07\u4e2a\u5d4c\u5957IF\u516c\u5f0f\u768468000\u4e2a\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u8868\u683c\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u91cd\u6784\u8d85\u8fc799%\u7684\u5d4c\u5957IF\u516c\u5f0f\uff0c\u5176\u4e2d\u8d85\u8fc750%\u7684\u91cd\u6784\u5c06\u5d4c\u5957\u5c42\u7ea7\u51cf\u5c11\u4e86\u4e00\u534a\u4ee5\u4e0a\u3002\u7528\u6237\u8c03\u67e5\u4e5f\u8868\u660e\uff0c\u5927\u591a\u6570\u7528\u6237\u504f\u597d\u91cd\u6784\u540e\u7684\u516c\u5f0f\uff0c\u5e76\u8ba4\u4e3a\u8fd9\u79cd\u81ea\u52a8\u5316\u65b9\u6cd5\u662f\u5fc5\u8981\u4e14\u6709\u7528\u7684\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAST\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u91cd\u6784\u5d4c\u5957IF\u516c\u5f0f\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u53ef\u8bfb\u6027\u5e76\u964d\u4f4e\u7ef4\u62a4\u6210\u672c\uff0c\u7528\u6237\u8c03\u67e5\u4e5f\u663e\u793a\u4e86\u5176\u6709\u6548\u6027\u548c\u5fc5\u8981\u6027\u3002"}}
{"id": "1612.03813", "title": "Spreadsheet Guardian: An Approach to Protecting Semantic Correctness throughout the Evolution of Spreadsheets", "url": "https://arxiv.org/abs/1612.03813", "pdf": "https://arxiv.org/pdf/1612.03813", "abs": "https://arxiv.org/abs/1612.03813", "authors": ["Daniel Kulesz", "Verena K\u00e4fer", "Stefan Wagner"], "categories": ["cs.SE", "cs.PL"], "comment": "30 pages, 15 figures, 4 tables", "summary": "Spreadsheets are powerful tools which play a business-critical role in many\norganizations. However, many bad decisions taken due to faulty spreadsheets\nshow that these tools need serious quality assurance. Furthermore, while\ncollaboration on spreadsheets for maintenance tasks is common, there has been\nalmost no support for ensuring that the spreadsheets remain correct during this\nprocess.\n  We have developed an approach named Spreadsheet Guardian which separates the\nspecification of spreadsheet test rules from their execution. By automatically\nexecuting user-defined test rules, our approach is able to detect semantic\nfaults. It also protects all collaborating spreadsheet users from introducing\nfaults during maintenance, even if only few end-users specify test rules. To\nevaluate Spreadsheet Guardian, we implemented a representative testing\ntechnique as an add-in for Microsoft Excel.\n  We evaluated the testing technique in two empirical evaluations with 29\nend-users and 42 computer science students. The results indicate that the\ntechnique is easy to learn and to apply. Furthermore, after finishing\nmaintenance, participants with spreadsheets \"protected\" by the technique are\nmore realistic about the correctness of their spreadsheets than participants\nwho employ only \"classic\", non-interactive test rules based on static analysis\ntechniques. Hence, we believe Spreadsheet Guardian can be of use for\nbusiness-critical spreadsheets.", "AI": {"tldr": "Spreadsheet Guardian is an approach that separates test rule specification from execution to detect semantic faults and prevent errors during collaborative spreadsheet maintenance. Evaluations show it's user-friendly and improves users' perception of correctness.", "motivation": "Spreadsheets play a business-critical role but are prone to errors, and there is a lack of support for ensuring their correctness during collaborative maintenance.", "method": "Spreadsheet Guardian separates the specification of spreadsheet test rules from their execution. By automatically executing user-defined test rules, it detects semantic faults and protects users from introducing faults during maintenance.", "result": "The technique is easy to learn and apply. Participants using Spreadsheet Guardian are more realistic about their spreadsheet correctness after maintenance compared to those using traditional methods.", "conclusion": "Spreadsheet Guardian can be of use for business-critical spreadsheets."}}
{"id": "1711.05787", "title": "WebRelate: Integrating Web Data with Spreadsheets using Examples", "url": "https://arxiv.org/abs/1711.05787", "pdf": "https://arxiv.org/pdf/1711.05787", "abs": "https://arxiv.org/abs/1711.05787", "authors": ["Jeevana Priya Inala", "Rishabh Singh"], "categories": ["cs.DB", "cs.PL"], "comment": "To appear in POPL 2018", "summary": "Data integration between web sources and relational data is a key challenge\nfaced by data scientists and spreadsheet users. There are two main challenges\nin programmatically joining web data with relational data. First, most websites\ndo not expose a direct interface to obtain tabular data, so the user needs to\nformulate a logic to get to different webpages for each input row in the\nrelational table. Second, after reaching the desired webpage, the user needs to\nwrite complex scripts to extract the relevant data, which is often conditioned\non the input data. Since many data scientists and end-users come from diverse\nbackgrounds, writing such complex regular-expression based logical scripts to\nperform data integration tasks is unfortunately often beyond their programming\nexpertise.\n  We present WebRelate, a system that allows users to join semi-structured web\ndata with relational data in spreadsheets using input-output examples.\nWebRelate decomposes the web data integration task into two sub-tasks of i) URL\nlearning and ii) input-dependent web extraction. The first sub-task generates\nthe URLs for the webpages containing the desired data for all rows in the\nrelational table. WebRelate achieves this by learning a string transformation\nprogram using a few example URLs. The second sub-task uses examples of desired\ndata to be extracted from the corresponding webpages and learns a program to\nextract the data for the other rows. We design expressive domain-specific\nlanguages for URL generation and web data extraction, and present efficient\nsynthesis algorithms for learning programs in these DSLs from few input-output\nexamples. We evaluate WebRelate on 88 real-world web data integration tasks\ntaken from online help forums and Excel product team, and show that WebRelate\ncan learn the desired programs within few seconds using only 1 example for the\nmajority of the tasks.", "AI": {"tldr": "WebRelate simplifies web data integration for users by learning to generate URLs and extract data from webpages using examples, overcoming the complexity of traditional scripting methods.", "motivation": "Existing methods for joining web data with relational data are complex and require advanced programming expertise, particularly in formulating logic to retrieve data from webpages and extracting relevant information using scripts, which is a barrier for many data scientists and end-users.", "method": "WebRelate decomposes the web data integration task into URL learning and input-dependent web extraction. It learns string transformation programs for URL generation and data extraction programs using input-output examples and domain-specific languages.", "result": "WebRelate achieves high performance on 88 real-world web data integration tasks, learning the required programs efficiently (within seconds) with minimal examples (often just one).", "conclusion": "WebRelate can learn URL generation and web data extraction programs within seconds using only one example for the majority of 88 real-world tasks, addressing the challenge of integrating semi-structured web data with relational data."}}
{"id": "1710.03248", "title": "Synthesizing Bijective Lenses", "url": "https://arxiv.org/abs/1710.03248", "pdf": "https://arxiv.org/pdf/1710.03248", "abs": "https://arxiv.org/abs/1710.03248", "authors": ["Anders Miltner", "Kathleen Fisher", "Benjamin C. Pierce", "David Walker", "Steve Zdancewic"], "categories": ["cs.PL"], "comment": "127 Pages, Extended Version with Appendix", "summary": "Bidirectional transformations between different data representations occur\nfrequently in modern software systems. They appear as serializers and\ndeserializers, as database views and view updaters, and more. Manually building\nbidirectional transformations---by writing two separate functions that are\nintended to be inverses---is tedious and error prone. A better approach is to\nuse a domain-specific language in which both directions can be written as a\nsingle expression. However, these domain-specific languages can be difficult to\nprogram in, requiring programmers to manage fiddly details while working in a\ncomplex type system.\n  To solve this, we present Optician, a tool for type-directed synthesis of\nbijective string transformers. The inputs to Optician are two ordinary regular\nexpressions representing two data formats and a few concrete examples for\ndisambiguation. The output is a well-typed program in Boomerang (a\nbidirectional language based on the theory of lenses). The main technical\nchallenge involves navigating the vast program search space efficiently enough.\nUnlike most prior work on type-directed synthesis, our system operates in the\ncontext of a language with a rich equivalence relation on types (the theory of\nregular expressions). We synthesize terms of a equivalent language and convert\nthose generated terms into our lens language. We prove the correctness of our\nsynthesis algorithm. We also demonstrate empirically that our new language\nchanges the synthesis problem from one that admits intractable solutions to one\nthat admits highly efficient solutions. We evaluate Optician on a benchmark\nsuite of 39 examples including both microbenchmarks and realistic examples\nderived from other data management systems including Flash Fill, a tool for\nsynthesizing string transformations in spreadsheets, and Augeas, a tool for\nbidirectional processing of Linux system configuration files.", "AI": {"tldr": "Optician tool synthesizes bidirectional string transformers efficiently using type-directed synthesis, improving upon manual methods and complex DSLs by leveraging regular expression equivalences.", "motivation": "Manually building bidirectional transformations is tedious and error-prone. Existing domain-specific languages can be difficult to program in due to fiddly details and complex type systems.", "method": "Optician synthesizes bidirectional string transformers by taking two regular expressions and a few examples as input, generating a well-typed program in the bidirectional language Boomerang. The core technical challenge is efficiently navigating the program search space, which is addressed by operating within a language with a rich equivalence relation on types and synthesizing terms in an equivalent language before converting them to the lens language.", "result": "Optician solves the synthesis problem by transforming it from one admitting intractable solutions to one admitting highly efficient solutions, as demonstrated empirically on a benchmark suite of 39 examples, including realistic examples from Flash Fill and Augeas.", "conclusion": "We present Optician, a tool for type-directed synthesis of bijective string transformers, which navigates the vast program search space efficiently using a rich equivalence relation on types and demonstrates empirical efficiency improvements on a benchmark suite."}}
{"id": "1708.06712", "title": "Towards a Holistic Integration of Spreadsheets with Databases: A Scalable Storage Engine for Presentational Data Management", "url": "https://arxiv.org/abs/1708.06712", "pdf": "https://arxiv.org/pdf/1708.06712", "abs": "https://arxiv.org/abs/1708.06712", "authors": ["Mangesh Bendre", "Vipul Venkataraman", "Xinyan Zhou", "Kevin Chang", "Aditya Parameswaran"], "categories": ["cs.DB"], "comment": null, "summary": "Spreadsheet software is the tool of choice for interactive ad-hoc data\nmanagement, with adoption by billions of users. However, spreadsheets are not\nscalable, unlike database systems. On the other hand, database systems, while\nhighly scalable, do not support interactivity as a first-class primitive. We\nare developing DataSpread, to holistically integrate spreadsheets as a\nfront-end interface with databases as a back-end datastore, providing\nscalability to spreadsheets, and interactivity to databases, an integration we\nterm presentational data management (PDM). In this paper, we make a first step\ntowards this vision: developing a storage engine for PDM, studying how to\nflexibly represent spreadsheet data within a database and how to support and\nmaintain access by position. We first conduct an extensive survey of\nspreadsheet use to motivate our functional requirements for a storage engine\nfor PDM. We develop a natural set of mechanisms for flexibly representing\nspreadsheet data and demonstrate that identifying the optimal representation is\nNP-Hard; however, we develop an efficient approach to identify the optimal\nrepresentation from an important and intuitive subclass of representations. We\nextend our mechanisms with positional access mechanisms that don't suffer from\ncascading update issues, leading to constant time access and modification\nperformance. We evaluate these representations on a workload of typical\nspreadsheets and spreadsheet operations, providing up to 20% reduction in\nstorage, and up to 50% reduction in formula evaluation time.", "AI": {"tldr": "DataSpread\u901a\u8fc7\u96c6\u6210\u7535\u5b50\u8868\u683c\u548c\u6570\u636e\u5e93\uff0c\u89e3\u51b3\u4e86\u53ef\u6269\u5c55\u6027\u548c\u4ea4\u4e92\u6027\u95ee\u9898\uff0c\u5e76\u4f18\u5316\u4e86\u5b58\u50a8\u548c\u516c\u5f0f\u8bc4\u4f30\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7535\u5b50\u8868\u683c\u8f6f\u4ef6\u5728\u6570\u636e\u7ba1\u7406\u65b9\u9762\u5177\u6709\u4ea4\u4e92\u6027\u4f46\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\uff0c\u800c\u6570\u636e\u5e93\u7cfb\u7edf\u867d\u7136\u53ef\u6269\u5c55\u6027\u5f3a\u4f46\u7f3a\u4e4f\u4ea4\u4e92\u6027\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDataSpread\u7684\u96c6\u6210\u65b9\u6848\uff0c\u65e8\u5728\u5c06\u7535\u5b50\u8868\u683c\u4f5c\u4e3a\u524d\u7aef\u63a5\u53e3\u4e0e\u6570\u636e\u5e93\u540e\u7aef\u7ed3\u5408\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u7535\u5b50\u8868\u683c\u548c\u4ea4\u4e92\u5f0f\u6570\u636e\u5e93\u3002", "method": "\u901a\u8fc7\u5bf9\u7535\u5b50\u8868\u683c\u4f7f\u7528\u60c5\u51b5\u8fdb\u884c\u5e7f\u6cdb\u8c03\u67e5\u6765\u786e\u5b9a\u529f\u80fd\u9700\u6c42\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u7075\u6d3b\u8868\u793a\u7535\u5b50\u8868\u683c\u6570\u636e\u7684\u673a\u5236\uff0c\u5e76\u89e3\u51b3\u4e86\u8868\u793a\u6700\u4f18\u5316\u7684NP-Hard\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u4e00\u79cd\u5e38\u6570\u65f6\u95f4\u7684\u8bbf\u95ee\u548c\u4fee\u6539\u673a\u5236\u3002", "result": "\u6240\u63d0\u51fa\u7684\u8868\u793a\u65b9\u6cd5\u5728\u5b58\u50a8\u65b9\u9762\u6700\u591a\u53ef\u51cf\u5c1120%\u7684\u5b58\u50a8\u7a7a\u95f4\uff0c\u5728\u516c\u5f0f\u8bc4\u4f30\u65b9\u9762\u6700\u591a\u53ef\u51cf\u5c1150%\u7684\u8bc4\u4f30\u65f6\u95f4\u3002", "conclusion": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u5b58\u50a8\u5f15\u64ce\uff0c\u4ee5\u89e3\u51b3\u7535\u5b50\u8868\u683c\u548c\u6570\u636e\u5e93\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5e76\u80fd\u5728\u5b58\u50a8\u548c\u516c\u5f0f\u8bc4\u4f30\u65b9\u9762\u63d0\u4f9b\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "1709.04553", "title": "MOLTE: a Modular Optimal Learning Testing Environment", "url": "https://arxiv.org/abs/1709.04553", "pdf": "https://arxiv.org/pdf/1709.04553", "abs": "https://arxiv.org/abs/1709.04553", "authors": ["Yingfei Wang", "Warren Powell"], "categories": ["cs.LG"], "comment": null, "summary": "We address the relative paucity of empirical testing of learning algorithms\n(of any type) by introducing a new public-domain, Modular, Optimal Learning\nTesting Environment (MOLTE) for Bayesian ranking and selection problem,\nstochastic bandits or sequential experimental design problems. The Matlab-based\nsimulator allows the comparison of a number of learning policies (represented\nas a series of .m modules) in the context of a wide range of problems (each\nrepresented in its own .m module) which makes it easy to add new algorithms and\nnew test problems. State-of-the-art policies and various problem classes are\nprovided in the package. The choice of problems and policies is guided through\na spreadsheet-based interface. Different graphical metrics are included. MOLTE\nis designed to be compatible with parallel computing to scale up from local\ndesktop to clusters and clouds. We offer MOLTE as an easy-to-use tool for the\nresearch community that will make it possible to perform much more\ncomprehensive testing, spanning a broader selection of algorithms and test\nproblems. We demonstrate the capabilities of MOLTE through a series of\ncomparisons of policies on a starter library of test problems. We also address\nthe problem of tuning and constructing priors that have been largely overlooked\nin optimal learning literature. We envision MOLTE as a modest spur to provide\nresearchers an easy environment to study interesting questions involved in\noptimal learning.", "AI": {"tldr": "MOLTE \u662f\u4e00\u4e2a\u7528\u4e8e\u8d1d\u53f6\u65af\u6392\u5e8f\u548c\u9009\u62e9\u3001\u968f\u673a\u8001\u864e\u673a\u548c\u987a\u5e8f\u5b9e\u9a8c\u8bbe\u8ba1\u95ee\u9898\u7684 Matlab \u6a21\u62df\u5668\uff0c\u5b83\u5141\u8bb8\u7814\u7a76\u4eba\u5458\u8f7b\u677e\u6bd4\u8f83\u5404\u79cd\u5b66\u4e60\u7b97\u6cd5\u548c\u6d4b\u8bd5\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u5b66\u4e60\u7b97\u6cd5\uff08\u4efb\u4f55\u7c7b\u578b\uff09\u7684\u5b9e\u8bc1\u68c0\u9a8c\u76f8\u5bf9\u7a00\u5c11\u7684\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u516c\u5171\u9886\u57df\u3001\u6a21\u5757\u5316\u3001\u6700\u4f18\u5b66\u4e60\u6d4b\u8bd5\u73af\u5883 (MOLTE)\u3002", "method": "MOLTE \u662f\u4e00\u4e2a\u57fa\u4e8e Matlab \u7684\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u8d1d\u53f6\u65af\u6392\u5e8f\u548c\u9009\u62e9\u95ee\u9898\u3001\u968f\u673a\u8001\u864e\u673a\u6216\u987a\u5e8f\u5b9e\u9a8c\u8bbe\u8ba1\u95ee\u9898\u3002\u5b83\u5141\u8bb8\u5728\u5404\u79cd\u95ee\u9898\uff08\u6bcf\u4e2a\u95ee\u9898\u90fd\u5728\u5176\u81ea\u5df1\u7684 .m \u6a21\u5757\u4e2d\u8868\u793a\uff09\u7684\u4e0a\u4e0b\u6587\u4e2d\u6bd4\u8f83\u591a\u79cd\u5b66\u4e60\u7b56\u7565\uff08\u8868\u793a\u4e3a\u4e00\u7cfb\u5217 .m \u6a21\u5757\uff09\u3002", "result": "MOLTE \u63d0\u4f9b\u4e86\u72b6\u6001\u6700\u5148\u8fdb\u7684\u7b56\u7565\u548c\u5404\u79cd\u95ee\u9898\u7c7b\u522b\u3002\u5b83\u5305\u62ec\u4e0d\u540c\u7684\u56fe\u5f62\u6307\u6807\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u5e76\u884c\u8ba1\u7b97\u517c\u5bb9\uff0c\u53ef\u4ee5\u4ece\u672c\u5730\u684c\u9762\u6269\u5c55\u5230\u96c6\u7fa4\u548c\u4e91\u3002", "conclusion": "MOLTE \u63d0\u4f9b\u4e86\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u5de5\u5177\uff0c\u4f9b\u7814\u7a76\u793e\u533a\u4f7f\u7528\uff0c\u4ee5\u4fbf\u5bf9\u7b97\u6cd5\u548c\u6d4b\u8bd5\u95ee\u9898\u8fdb\u884c\u66f4\u5168\u9762\u7684\u6d4b\u8bd5\u3002"}}
{"id": "1709.00362", "title": "An Email Attachment is Worth a Thousand Words, or Is It?", "url": "https://arxiv.org/abs/1709.00362", "pdf": "https://arxiv.org/pdf/1709.00362", "abs": "https://arxiv.org/abs/1709.00362", "authors": ["Gregory Tsipenyuk", "Jon Crowcroft"], "categories": ["cs.SI"], "comment": "12 pages, 4 figures, 7 tables, IML'17, Liverpool, UK", "summary": "There is an extensive body of research on Social Network Analysis (SNA) based\non the email archive. The network used in the analysis is generally extracted\neither by capturing the email communication in From, To, Cc and Bcc email\nheader fields or by the entities contained in the email message. In the latter\ncase, the entities could be, for instance, the bag of words, url's, names,\nphones, etc. It could also include the textual content of attachments, for\ninstance Microsoft Word documents, excel spreadsheets, or Adobe pdfs. The nodes\nin this network represent users and entities. The edges represent communication\nbetween users and relations to the entities. We suggest taking a different\napproach to the network extraction and use attachments shared between users as\nthe edges. The motivation for this is two-fold. First, attachments represent\nthe \"intimacy\" manifestation of the relation's strength. Second, the\nstatistical analysis of private email archives that we collected and Enron\nemail corpus shows that the attachments contribute in average around 80-90% to\nthe archive's disk-space usage, which means that most of the data is presently\nignored in the SNA of email archives. Consequently, we hypothesize that this\napproach might provide more insight into the social structure of the email\narchive. We extract the communication and shared attachments networks from\nEnron email corpus. We further analyze degree, betweenness, closeness, and\neigenvector centrality measures in both networks and review the differences and\nwhat can be learned from them. We use nearest neighbor algorithm to generate\nsimilarity groups for five Enron employees. The groups are consistent with\nEnron's organizational chart, which validates our approach.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790\u90ae\u4ef6\u9644\u4ef6\u6765\u6784\u5efa\u793e\u4ea4\u7f51\u7edc\uff0c\u80fd\u591f\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u4f9b\u66f4\u6df1\u5165\u7684\u793e\u4ea4\u7ed3\u6784\u6d1e\u5bdf\u3002", "motivation": "\u4e3a\u4e86\u5f25\u8865\u4f20\u7edf\u57fa\u4e8e\u90ae\u4ef6\u5934\u4fe1\u606f\u63d0\u53d6\u7684\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\u5ffd\u7565\u4e86\u9644\u4ef6\u6570\u636e\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\u7684\u7f3a\u70b9\uff0c\u5e76\u5047\u8bbe\u9644\u4ef6\u5171\u4eab\u80fd\u66f4\u771f\u5b9e\u5730\u53cd\u6620\u7528\u6237\u95f4\u5173\u7cfb\u7684\u4eb2\u5bc6\u5ea6\u548c\u6570\u636e\u91cf\u3002\u901a\u8fc7\u5206\u6790\u9644\u4ef6\u6570\u636e\uff0c\u65e8\u5728\u66f4\u6df1\u5165\u5730\u63ed\u793a\u90ae\u4ef6\u6863\u6848\u7684\u793e\u4ea4\u7ed3\u6784\u3002", "method": "\u4eceEnron\u90ae\u4ef6\u8bed\u6599\u5e93\u4e2d\u63d0\u53d6\u901a\u4fe1\u7f51\u7edc\u548c\u5171\u4eab\u9644\u4ef6\u7f51\u7edc\uff0c\u5e76\u5206\u6790\u4e86\u4e24\u79cd\u7f51\u7edc\u4e2d\u7684\u5ea6\u3001\u4e2d\u4ecb\u4e2d\u5fc3\u6027\u3001\u7d27\u5bc6\u5ea6\u548c\u7279\u5f81\u5411\u91cf\u4e2d\u5fc3\u6027\u7b49\u6307\u6807\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u4f7f\u7528\u6700\u8fd1\u90bb\u7b97\u6cd5\u751f\u6210\u4e86\u76f8\u4f3c\u5ea6\u5206\u7ec4\uff0c\u5e76\u4e0eEnron\u5458\u5de5\u7684\u7ec4\u7ec7\u7ed3\u6784\u8fdb\u884c\u4e86\u6bd4\u5bf9\u3002", "result": "\u5171\u4eab\u9644\u4ef6\u7f51\u7edc\u5206\u6790\u7ed3\u679c\u4e0eEnron\u7684\u7ec4\u7ec7\u7ed3\u6784\u56fe\u9ad8\u5ea6\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4f7f\u7528\u5171\u4eab\u9644\u4ef6\u4f5c\u4e3a\u7528\u6237\u95f4\u901a\u4fe1\u7684\u8fb9\u7684\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u5bf9Enron\u90ae\u4ef6\u8bed\u6599\u5e93\u8fdb\u884c\u4e86\u5206\u6790\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8fd9\u79cd\u65b0\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u6df1\u5165\u7684\u793e\u4ea4\u7ed3\u6784\u6d1e\u5bdf\uff0c\u5e76\u4e14\u901a\u8fc7\u4e0e\u7ec4\u7ec7\u7ed3\u6784\u7684\u5bf9\u6bd4\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "1708.08731", "title": "Active Learning of Input Grammars", "url": "https://arxiv.org/abs/1708.08731", "pdf": "https://arxiv.org/pdf/1708.08731", "abs": "https://arxiv.org/abs/1708.08731", "authors": ["Matthias H\u00f6schele", "Alexander Kampmann", "Andreas Zeller"], "categories": ["cs.PL", "cs.FL", "F.4.2; F.3.2; D.2.5"], "comment": "12 pages", "summary": "Knowing the precise format of a program's input is a necessary prerequisite\nfor systematic testing. Given a program and a small set of sample inputs, we\n(1) track the data flow of inputs to aggregate input fragments that share the\nsame data flow through program execution into lexical and syntactic entities;\n(2) assign these entities names that are based on the associated variable and\nfunction identifiers; and (3) systematically generalize production rules by\nmeans of membership queries. As a result, we need only a minimal set of sample\ninputs to obtain human-readable context-free grammars that reflect valid input\nstructure. In our evaluation on inputs like URLs, spreadsheets, or\nconfiguration files, our AUTOGRAM prototype obtains input grammars that are\nboth accurate and very readable - and that can be directly fed into test\ngenerators for comprehensive automated testing.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAUTOGRAM\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4ece\u5c11\u91cf\u6837\u672c\u8f93\u5165\u4e2d\u5b66\u4e60\u7a0b\u5e8f\u7684\u8f93\u5165\u8bed\u6cd5\uff0c\u751f\u6210\u51c6\u786e\u6613\u8bfb\u7684\u8bed\u6cd5\uff0c\u5e76\u76f4\u63a5\u7528\u4e8e\u81ea\u52a8\u5316\u6d4b\u8bd5\u3002", "motivation": "\u4e3a\u4e86\u5bf9\u7a0b\u5e8f\u8fdb\u884c\u7cfb\u7edf\u6027\u6d4b\u8bd5\uff0c\u9700\u8981\u4e86\u89e3\u5176\u7cbe\u786e\u7684\u8f93\u5165\u683c\u5f0f\u3002", "method": "\u901a\u8fc7\u8ddf\u8e2a\u6570\u636e\u6d41\u3001\u805a\u5408\u8f93\u5165\u7247\u6bb5\u3001\u5206\u914d\u6807\u8bc6\u7b26\u4ee5\u53ca\u4f7f\u7528\u6210\u5458\u67e5\u8be2\u6765\u6cdb\u5316\u4ea7\u751f\u89c4\u5219\uff0c\u4ece\u800c\u7cfb\u7edf\u5730\u5b66\u4e60\u8f93\u5165\u8bed\u6cd5\u3002", "result": "\u5728\u5bf9URL\u3001\u7535\u5b50\u8868\u683c\u548c\u914d\u7f6e\u6587\u4ef6\u7b49\u8f93\u5165\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0cAUTOGRAM\u539f\u578b\u751f\u6210\u7684\u8f93\u5165\u8bed\u6cd5\u51c6\u786e\u4e14\u975e\u5e38\u6613\u8bfb\uff0c\u53ef\u4ee5\u76f4\u63a5\u88ab\u6d4b\u8bd5\u751f\u6210\u5668\u7528\u4e8e\u5168\u9762\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u51c6\u786e\u4e14\u6613\u4e8e\u9605\u8bfb\u7684\u8f93\u5165\u8bed\u6cd5\uff0c\u5e76\u53ef\u76f4\u63a5\u7528\u4e8e\u6d4b\u8bd5\u751f\u6210\u3002"}}
{"id": "1708.08721", "title": "EntiTables: Smart Assistance for Entity-Focused Tables", "url": "https://arxiv.org/abs/1708.08721", "pdf": "https://arxiv.org/pdf/1708.08721", "abs": "https://arxiv.org/abs/1708.08721", "authors": ["Shuo Zhang", "Krisztian Balog"], "categories": ["cs.IR"], "comment": "Proceedings of the 40th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '17), 2017", "summary": "Tables are among the most powerful and practical tools for organizing and\nworking with data. Our motivation is to equip spreadsheet programs with smart\nassistance capabilities. We concentrate on one particular family of tables,\nnamely, tables with an entity focus. We introduce and focus on two specific\ntasks: populating rows with additional instances (entities) and populating\ncolumns with new headings. We develop generative probabilistic models for both\ntasks. For estimating the components of these models, we consider a knowledge\nbase as well as a large table corpus. Our experimental evaluation simulates the\nvarious stages of the user entering content into an actual table. A detailed\nanalysis of the results shows that the models' components are complimentary and\nthat our methods outperform existing approaches from the literature.", "AI": {"tldr": "\u6211\u4eec\u4e3a\u7535\u5b50\u8868\u683c\u5f00\u53d1\u4e86\u7528\u4e8e\u586b\u5145\u884c\u548c\u5217\u7684\u751f\u6210\u6a21\u578b\uff0c\u5e76\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6210\u679c\u3002", "motivation": "\u6211\u4eec\u7684\u52a8\u673a\u662f\u4e3a\u7535\u5b50\u8868\u683c\u7a0b\u5e8f\u914d\u5907\u667a\u80fd\u8f85\u52a9\u529f\u80fd\u3002", "method": "\u6211\u4eec\u4e3a\u4e24\u4e2a\u7279\u5b9a\u4efb\u52a1\u5f00\u53d1\u4e86\u751f\u6210\u6982\u7387\u6a21\u578b\uff1a\u7528\u5176\u4ed6\u5b9e\u4f8b\uff08\u5b9e\u4f53\uff09\u586b\u5145\u884c\u548c\u7528\u65b0\u6807\u9898\u586b\u5145\u5217\u3002", "result": "\u6211\u4eec\u7684\u5b9e\u9a8c\u8bc4\u4f30\u6a21\u62df\u4e86\u7528\u6237\u5728\u5b9e\u9645\u8868\u4e2d\u8f93\u5165\u5185\u5bb9\u7684\u5404\u4e2a\u9636\u6bb5\u3002\u5bf9\u7ed3\u679c\u7684\u8be6\u7ec6\u5206\u6790\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u7684\u7ec4\u6210\u90e8\u5206\u662f\u4e92\u8865\u7684\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u4f18\u4e8e\u6587\u732e\u4e2d\u73b0\u6709\u7684\u65b9\u6cd5\u3002"}}
{"id": "1707.00144", "title": "On Evidence-based Risk Management in Requirements Engineering", "url": "https://arxiv.org/abs/1707.00144", "pdf": "https://arxiv.org/pdf/1707.00144", "abs": "https://arxiv.org/abs/1707.00144", "authors": ["Daniel M\u00e9ndez Fern\u00e1ndez", "Michaela Tie\u00dfler", "Marcos Kalinowski", "Michael Felderer", "Marco Kuhrmann"], "categories": ["cs.SE"], "comment": "20 pages, submitted to 10th Software Quality Days conference, 2018", "summary": "Background: The sensitivity of Requirements Engineering (RE) to the context\nmakes it difficult to efficiently control problems therein, thus, hampering an\neffective risk management devoted to allow for early corrective or even\npreventive measures. Problem: There is still little empirical knowledge about\ncontext-specific RE phenomena which would be necessary for an effective\ncontext- sensitive risk management in RE. Goal: We propose and validate an\nevidence-based approach to assess risks in RE using cross-company data about\nproblems, causes and effects. Research Method: We use survey data from 228\ncompanies and build a probabilistic network that supports the forecast of\ncontext-specific RE phenomena. We implement this approach using spreadsheets to\nsupport a light-weight risk assessment. Results: Our results from an initial\nvalidation in 6 companies strengthen our confidence that the approach increases\nthe awareness for individual risk factors in RE, and the feedback further\nallows for disseminating our approach into practice.", "AI": {"tldr": "\u4e00\u9879\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u901a\u8fc7\u8de8\u516c\u53f8\u6570\u636e\u8bc4\u4f30RE\u98ce\u9669\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u98ce\u9669\u56e0\u7d20\u7684\u8ba4\u8bc6\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u6709\u6548\u7684\u3001\u9488\u5bf9\u7279\u5b9a\u80cc\u666f\u7684RE\u98ce\u9669\u7ba1\u7406\uff0c\u9700\u8981\u4e86\u89e3\u66f4\u591a\u5173\u4e8e\u7279\u5b9a\u80cc\u666f\u7684RE\u73b0\u8c61\u7684\u7ecf\u9a8c\u77e5\u8bc6\u3002", "method": "\u4f7f\u7528\u6765\u81ea228\u5bb6\u516c\u53f8\u7684\u8c03\u67e5\u6570\u636e\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u652f\u6301\u7279\u5b9a\u80cc\u666f\u7684RE\u73b0\u8c61\u9884\u6d4b\u7684\u6982\u7387\u7f51\u7edc\u3002\u8be5\u65b9\u6cd5\u8bba\u901a\u8fc7\u7535\u5b50\u8868\u683c\u5b9e\u73b0\uff0c\u4ee5\u652f\u6301\u8f7b\u91cf\u7ea7\u7684\u98ce\u9669\u8bc4\u4f30\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8bba\u589e\u52a0\u4e86\u5bf9RE\u4e2d\u5404\u4e2a\u98ce\u9669\u56e0\u7d20\u7684\u8ba4\u8bc6\uff0c\u5e76\u4e3a\u63a8\u5e7f\u5230\u5b9e\u8df5\u4e2d\u63d0\u4f9b\u4e86\u53cd\u9988\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bba\u901a\u8fc7\u57286\u5bb6\u516c\u53f8\u8fdb\u884c\u7684\u521d\u6b65\u9a8c\u8bc1\uff0c\u589e\u5f3a\u4e86\u5bf9RE\u4e2d\u5404\u4e2a\u98ce\u9669\u56e0\u7d20\u7684\u8ba4\u8bc6\uff0c\u5e76\u4e14\u53cd\u9988\u5141\u8bb8\u5c06\u8be5\u65b9\u6cd5\u8bba\u63a8\u5e7f\u5230\u5b9e\u8df5\u4e2d\u3002"}}
{"id": "1707.02833", "title": "Tabula: A Language to Model Spreadsheet Tables", "url": "https://arxiv.org/abs/1707.02833", "pdf": "https://arxiv.org/pdf/1707.02833", "abs": "https://arxiv.org/abs/1707.02833", "authors": ["Jorge Mendes", "Jo\u00e3o Saraiva"], "categories": ["cs.SE"], "comment": "In Proceedings of the 4th Workshop on Software Engineering Methods in\n  Spreadsheets", "summary": "Spreadsheets provide a flexible and easy to use software development\nenvironment, but that leads to error proneness. Work has been done to prevent\nerrors in spreadsheets, including using models to specify distinct parts of a\nspreadsheet as it is done with model-driven software development. Previous\nmodel languages for spreadsheets offer a limited expressiveness, and cannot\nmodel several features present in most real world spreadsheets.\n  In this paper, the modeling language Tabula is introduced. It extends\nprevious spreadsheet models with features like type constraints and nested\nclasses with repetitions. Tabula is not only more expressive than other models\nbut it can also be extended with more features. Moreover, Tabula includes a\nbidirectional transformation engine that guarantees synchronization after an\nupdate either in the model or spreadsheet.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Tabula \u7684\u65b0\u5efa\u6a21\u8bed\u8a00\uff0c\u7528\u4e8e\u7535\u5b50\u8868\u683c\u7684\u5f00\u53d1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\uff0c\u5e76\u80fd\u901a\u8fc7\u53cc\u5411\u8f6c\u6362\u5f15\u64ce\u4fdd\u8bc1\u6a21\u578b\u548c\u7535\u5b50\u8868\u683c\u4e4b\u95f4\u540c\u6b65\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u867d\u7136\u7075\u6d3b\u6613\u7528\uff0c\u4f46\u5bb9\u6613\u51fa\u9519\u3002\u73b0\u6709\u7684\u6a21\u578b\u8bed\u8a00\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u5145\u5206\u63cf\u8ff0\u771f\u5b9e\u7535\u5b50\u8868\u683c\u4e2d\u7684\u5404\u79cd\u7279\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Tabula \u7684\u65b0\u5efa\u6a21\u8bed\u8a00\uff0c\u7528\u4e8e\u7535\u5b50\u8868\u683c\u7684\u5f00\u53d1\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002", "result": "Tabula \u8bed\u8a00\u6bd4\u5176\u4ed6\u6a21\u578b\u66f4\u5177\u8868\u8fbe\u529b\uff0c\u5e76\u4e14\u53ef\u4ee5\u6269\u5c55\u66f4\u591a\u529f\u80fd\uff0c\u8fd8\u5305\u542b\u4e00\u4e2a\u53cc\u5411\u8f6c\u6362\u5f15\u64ce\uff0c\u53ef\u4ee5\u786e\u4fdd\u5728\u6a21\u578b\u6216\u7535\u5b50\u8868\u683c\u66f4\u65b0\u540e\u4fdd\u6301\u540c\u6b65\u3002", "conclusion": "Tabula \u8bed\u8a00\u901a\u8fc7\u589e\u52a0\u7c7b\u578b\u7ea6\u675f\u548c\u5d4c\u5957\u7c7b\u91cd\u590d\u7b49\u7279\u6027\uff0c\u6269\u5c55\u4e86\u7535\u5b50\u8868\u683c\u6a21\u578b\uff0c\u63d0\u9ad8\u4e86\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u80fd\u901a\u8fc7\u53cc\u5411\u8f6c\u6362\u5f15\u64ce\u4fdd\u8bc1\u6a21\u578b\u548c\u7535\u5b50\u8868\u683c\u4e4b\u95f4\u540c\u6b65\u3002"}}
{"id": "1707.01469", "title": "Synthesis of Data Completion Scripts using Finite Tree Automata", "url": "https://arxiv.org/abs/1707.01469", "pdf": "https://arxiv.org/pdf/1707.01469", "abs": "https://arxiv.org/abs/1707.01469", "authors": ["Xinyu Wang", "Isil Dillig", "Rishabh Singh"], "categories": ["cs.PL"], "comment": null, "summary": "In application domains that store data in a tabular format, a common task is\nto fill the values of some cells using values stored in other cells. For\ninstance, such data completion tasks arise in the context of missing value\nimputation in data science and derived data computation in spreadsheets and\nrelational databases. Unfortunately, end-users and data scientists typically\nstruggle with many data completion tasks that require non-trivial programming\nexpertise. This paper presents a synthesis technique for automating data\ncompletion tasks using programming-by-example (PBE) and a very lightweight\nsketching approach. Given a formula sketch (e.g., AVG($?_1$, $?_2$)) and a few\ninput-output examples for each hole, our technique synthesizes a program to\nautomate the desired data completion task. Towards this goal, we propose a\ndomain-specific language (DSL) that combines spatial and relational reasoning\nover tabular data and a novel synthesis algorithm that can generate DSL\nprograms that are consistent with the input-output examples. The key technical\nnovelty of our approach is a new version space learning algorithm that is based\non finite tree automata (FTA). The use of FTAs in the learning algorithm leads\nto a more compact representation that allows more sharing between programs that\nare consistent with the examples. We have implemented the proposed approach in\na tool called DACE and evaluate it on 84 benchmarks taken from online help\nforums. We also illustrate the advantages of our approach by comparing our\ntechnique against two existing synthesizers, namely PROSE and SKETCH.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDACE\u7684\u65b0\u6280\u672f\uff0c\u5229\u7528\u7f16\u7a0bby-example\u548cDSL\uff08\u7ed3\u5408\u7a7a\u95f4/\u5173\u7cfb\u63a8\u7406\uff09\u4ee5\u53ca\u57fa\u4e8eFTA\u7684\u7248\u672c\u7a7a\u95f4\u5b66\u4e60\u7b97\u6cd5\uff0c\u81ea\u52a8\u5b8c\u6210\u8868\u683c\u6570\u636e\u8865\u5168\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86\u7528\u6237\u5728\u7f16\u7a0b\u65b9\u9762\u7684\u56f0\u96be\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u6570\u636e\u8865\u5168\u4efb\u52a1\u4e2d\uff0c\u975e\u4e13\u4e1a\u7528\u6237\uff08\u5982\u7ec8\u7aef\u7528\u6237\u548c\u6570\u636e\u79d1\u5b66\u5bb6\uff09\u5728\u9700\u8981\u7f16\u7a0b\u4e13\u4e1a\u77e5\u8bc6\u65f6\u9047\u5230\u7684\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7f16\u7a0bby-example\uff08PBE\uff09\u548c\u8f7b\u91cf\u7ea7\u8349\u56fe\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6570\u636e\u8865\u5168\u4efb\u52a1\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u7ed3\u5408\u7a7a\u95f4\u548c\u5173\u7cfb\u63a8\u7406\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u6709\u9650\u6811\u81ea\u52a8\u673a\uff08FTA\uff09\u7684\u65b0\u578b\u5408\u6210\u7b97\u6cd5\u6765\u751f\u6210\u4e0e\u8f93\u5165\u8f93\u51fa\u793a\u4f8b\u4e00\u81f4\u7684DSL\u7a0b\u5e8f\u3002", "result": "\u572884\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u6570\u636e\u8865\u5168\uff0c\u5e76\u4e0ePROSE\u548cSKETCH\u4e24\u79cd\u73b0\u6709\u5408\u6210\u5668\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u8be5\u6280\u672f\u901a\u8fc7\u7ed3\u5408\u7f16\u7a0bby-example\uff08PBE\uff09\u548c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8349\u56fe\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u6267\u884c\u6570\u636e\u8865\u5168\u4efb\u52a1\u3002\u5b83\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u7ed3\u5408\u7a7a\u95f4\u548c\u5173\u7cfb\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u6709\u9650\u6811\u81ea\u52a8\u673a\uff08FTA\uff09\u7684\u7248\u672c\u7a7a\u95f4\u5b66\u4e60\u7b97\u6cd5\u6765\u5408\u6210\u7a0b\u5e8f\u3002"}}
{"id": "1705.09276", "title": "Synthesizing Mapping Relationships Using Table Corpus", "url": "https://arxiv.org/abs/1705.09276", "pdf": "https://arxiv.org/pdf/1705.09276", "abs": "https://arxiv.org/abs/1705.09276", "authors": ["Yue Wang", "Yeye He"], "categories": ["cs.DB"], "comment": "The long version of a paper published at SIGMOD 2017", "summary": "Mapping relationships, such as (country, country-code) or (company,\nstock-ticker), are versatile data assets for an array of applications in data\ncleaning and data integration like auto-correction and auto-join. However,\ntoday there are no good repositories of mapping tables that can enable these\nintelligent applications.\n  Given a corpus of tables such as web tables or spreadsheet tables, we observe\nthat values of these mappings often exist in pairs of columns in same tables.\nMotivated by their broad applicability, we study the problem of synthesizing\nmapping relationships using a large table corpus. Our synthesis process\nleverages compatibility of tables based on co-occurrence statistics, as well as\nconstraints such as functional dependency. Experiment results using web tables\nand enterprise spreadsheets suggest that the proposed approach can produce high\nquality mappings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8868\u517c\u5bb9\u6027\u548c\u51fd\u6570\u4f9d\u8d56\u6027\u4ece\u5927\u578b\u8868\u8bed\u6599\u5e93\uff08\u5982Web\u8868\u548c\u7535\u5b50\u8868\u683c\uff09\u4e2d\u5408\u6210\u6620\u5c04\u5173\u7cfb\uff08\u4f8b\u5982\uff08\u56fd\u5bb6\uff0c\u56fd\u5bb6\u4ee3\u7801\uff09\uff09\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u7f3a\u4e4f\u6620\u5c04\u8868\u5b58\u50a8\u5e93\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u7528\u4e8e\u542f\u7528\u667a\u80fd\u5e94\u7528\u7684\u6620\u5c04\u8868\u5b58\u50a8\u5e93\uff0c\u56e0\u6b64\u53d7\u5230\u5176\u5e7f\u6cdb\u9002\u7528\u6027\u7684\u542f\u53d1\uff0c\u7814\u7a76\u4e86\u4f7f\u7528\u5927\u578b\u8868\u8bed\u6599\u5e93\u5408\u6210\u6620\u5c04\u5173\u7cfb\u7684\u95ee\u9898\u3002", "method": "\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u57fa\u4e8e\u5171\u73b0\u7edf\u8ba1\u7684\u8868\u7684\u517c\u5bb9\u6027\u4ee5\u53ca\u51fd\u6570\u4f9d\u8d56\u7b49\u7ea6\u675f\u6765\u5408\u6210\u6620\u5c04\u5173\u7cfb\u3002", "result": "\u4f7f\u7528\u6765\u81eaWeb\u548c\u4f01\u4e1a\u7535\u5b50\u8868\u683c\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6620\u5c04\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6620\u5c04\u5173\u7cfb\u3002"}}
{"id": "1701.04288", "title": "Polynomial-Time Proactive Synthesis of Tree-to-String Functions from Examples", "url": "https://arxiv.org/abs/1701.04288", "pdf": "https://arxiv.org/pdf/1701.04288", "abs": "https://arxiv.org/abs/1701.04288", "authors": ["Mika\u00ebl Mayer", "Jad Hamza", "Viktor Kuncak"], "categories": ["cs.FL"], "comment": null, "summary": "Synthesis from examples enables non-expert users to generate programs by\nspecifying examples of their behavior. A domain-specific form of such synthesis\nhas been recently deployed in a widely used spreadsheet software product. In\nthis paper we contribute to foundations of such techniques and present a\ncomplete algorithm for synthesis of a class of recursive functions defined by\nstructural recursion over a given algebraic data type definition. The functions\nwe consider map an algebraic data type to a string; they are useful for, e.g.,\npretty printing and serialization of programs and data. We formalize our\nproblem as learning deterministic sequential top-down tree-to-string\ntransducers with a single state.\n  The first problem we consider is learning a tree-to-string transducer from\nany set of input/output examples provided by the user. We show that this\nproblem is NP-complete in general, but can be solved in polynomial time under a\n(practically useful) closure condition that each subtree of a tree in the\ninput/output example set is also part of the input/output examples.\n  Because coming up with relevant input/output examples may be difficult for\nthe user while creating hard constraint problems for the synthesizer, we also\nstudy a more automated active learning scenario in which the algorithm chooses\nthe inputs for which the user provides the outputs. Our algorithm asks a\nworst-case linear number of queries as a function of the size of the algebraic\ndata type definition to determine a unique transducer.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5408\u6210\u9012\u5f52\u51fd\u6570\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u53ef\u4ee5\u5c06\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u6620\u5c04\u5230\u5b57\u7b26\u4e32\uff0c\u8fd9\u5bf9\u4e8e\u7a0b\u5e8f\u7684\u53ef\u89c6\u5316\u6253\u5370\u548c\u5e8f\u5217\u5316\u975e\u5e38\u6709\u7528\u3002\u7b97\u6cd5\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u53ef\u4ee5\u9ad8\u6548\u8fd0\u884c\uff0c\u5e76\u80fd\u5728\u4e3b\u52a8\u5b66\u4e60\u573a\u666f\u4e2d\u901a\u8fc7\u8f83\u5c11\u7684\u67e5\u8be2\u6765\u786e\u5b9a\u552f\u4e00\u7684\u51fd\u6570\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u4e3a\u901a\u8fc7\u793a\u4f8b\u8fdb\u884c\u5408\u6210\u7684\u6280\u672f\u5960\u5b9a\u7406\u8bba\u57fa\u7840\uff0c\u7279\u522b\u662f\u9488\u5bf9\u7531\u7ed3\u6784\u9012\u5f52\u5b9a\u4e49\u7684\u3001\u5c06\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u6620\u5c04\u5230\u5b57\u7b26\u4e32\u7684\u51fd\u6570\u3002\u8fd9\u7c7b\u51fd\u6570\u5728\u7a0b\u5e8f\u548c\u6570\u636e\u7684\u53ef\u89c6\u5316\u6253\u5370\u548c\u5e8f\u5217\u5316\u7b49\u9886\u57df\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002\u4f5c\u8005\u5e0c\u671b\u4e3a\u975e\u4e13\u4e1a\u7528\u6237\u63d0\u4f9b\u4e00\u79cd\u4fbf\u6377\u7684\u65b9\u5f0f\u6765\u751f\u6210\u7a0b\u5e8f\uff0c\u53ea\u9700\u63d0\u4f9b\u5176\u884c\u4e3a\u793a\u4f8b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5408\u6210\u4e00\u7ec4\u7531\u7ed3\u6784\u9012\u5f52\u5b9a\u4e49\u7684\u51fd\u6570\uff0c\u8fd9\u4e9b\u51fd\u6570\u5c06\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u6620\u5c04\u5230\u5b57\u7b26\u4e32\u3002\u4f5c\u8005\u5c06\u8be5\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u5b66\u4e60\u5177\u6709\u5355\u4e2a\u72b6\u6001\u7684\u786e\u5b9a\u6027\u5e8f\u5217\u81ea\u9876\u5411\u4e0b\u6811\u5230\u5b57\u7b26\u4e32\u8f6c\u6362\u5668\u3002\u4ed6\u4eec\u8bc1\u660e\u4e86\u5b66\u4e60\u8fd9\u6837\u4e00\u4e2a\u8f6c\u6362\u5668\u7684\u95ee\u9898\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\u662fNP\u5b8c\u5168\u7684\uff0c\u4f46\u5728\u6ee1\u8db3\u7279\u5b9a\u95ed\u5305\u6761\u4ef6\u65f6\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u8fd8\u7814\u7a76\u4e86\u4e00\u79cd\u4e3b\u52a8\u5b66\u4e60\u573a\u666f\uff0c\u5176\u4e2d\u7b97\u6cd5\u9009\u62e9\u8f93\u5165\uff0c\u7528\u6237\u63d0\u4f9b\u8f93\u51fa\uff0c\u4ee5\u786e\u5b9a\u552f\u4e00\u7684\u8f6c\u6362\u5668\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4ece\u4efb\u610f\u4e00\u7ec4\u8f93\u5165/\u8f93\u51fa\u793a\u4f8b\u5b66\u4e60\u6811\u5230\u5b57\u7b26\u4e32\u8f6c\u6362\u5668\u7684\u95ee\u9898\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\u662fNP\u5b8c\u5168\u7684\u3002\u7136\u800c\uff0c\u5728\u6ee1\u8db3\u201c\u6bcf\u4e2a\u5b50\u6811\u4e5f\u662f\u8f93\u5165/\u8f93\u51fa\u793a\u4f8b\u7684\u4e00\u90e8\u5206\u201d\u8fd9\u4e00\u5b9e\u9645\u53ef\u7528\u7684\u95ed\u5305\u6761\u4ef6\u65f6\uff0c\u8be5\u95ee\u9898\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\u3002\u5728\u4e3b\u52a8\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u4ee5\u4e0e\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u5b9a\u4e49\u5927\u5c0f\u6210\u7ebf\u6027\u7684\u6700\u574f\u60c5\u51b5\u67e5\u8be2\u6b21\u6570\u6765\u786e\u5b9a\u552f\u4e00\u7684\u8f6c\u6362\u5668\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u53ef\u4ee5\u6839\u636e\u7528\u6237\u63d0\u4f9b\u7684\u8f93\u5165/\u8f93\u51fa\u793a\u4f8b\u96c6\u5b66\u4e60\u6811\u5230\u5b57\u7b26\u4e32\u7684\u8f6c\u6362\u5668\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\uff08\u4f8b\u5982\uff0c\u8f93\u5165/\u8f93\u51fa\u793a\u4f8b\u96c6\u4e2d\u7684\u6bcf\u4e2a\u5b50\u6811\u4e5f\u662f\u8f93\u5165/\u8f93\u51fa\u793a\u4f8b\u7684\u4e00\u90e8\u5206\uff09\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u3002\u6b64\u5916\uff0c\u8be5\u7b97\u6cd5\u8fd8\u53ef\u4ee5\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u7684\u65b9\u5f0f\uff0c\u7531\u7b97\u6cd5\u9009\u62e9\u8f93\u5165\u5e76\u7531\u7528\u6237\u63d0\u4f9b\u8f93\u51fa\u6765\u786e\u5b9a\u552f\u4e00\u7684\u8f6c\u6362\u5668\uff0c\u6240\u9700\u67e5\u8be2\u6b21\u6570\u4e0e\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u5b9a\u4e49\u7684\u89c4\u6a21\u6210\u7ebf\u6027\u5173\u7cfb\u3002"}}
{"id": "1704.08476", "title": "SpreadCluster: Recovering Versioned Spreadsheets through Similarity-Based Clustering", "url": "https://arxiv.org/abs/1704.08476", "pdf": "https://arxiv.org/pdf/1704.08476", "abs": "https://arxiv.org/abs/1704.08476", "authors": ["Liang Xu", "Wensheng Dou", "Chushu Gao", "Jie Wang", "Jun Wei", "Hua Zhong", "Tao Huang"], "categories": ["cs.SE"], "comment": "12 pages, MSR 2017", "summary": "Version information plays an important role in spreadsheet understanding,\nmaintaining and quality improving. However, end users rarely use version\ncontrol tools to document spreadsheet version information. Thus, the\nspreadsheet version information is missing, and different versions of a\nspreadsheet coexist as individual and similar spreadsheets. Existing approaches\ntry to recover spreadsheet version information through clustering these similar\nspreadsheets based on spreadsheet filenames or related email conversation.\nHowever, the applicability and accuracy of existing clustering approaches are\nlimited due to the necessary information (e.g., filenames and email\nconversation) is usually missing. We inspected the versioned spreadsheets in\nVEnron, which is extracted from the Enron Corporation. In VEnron, the different\nversions of a spreadsheet are clustered into an evolution group. We observed\nthat the versioned spreadsheets in each evolution group exhibit certain common\nfeatures (e.g., similar table headers and worksheet names). Based on this\nobservation, we proposed an automatic clustering algorithm, SpreadCluster.\nSpreadCluster learns the criteria of features from the versioned spreadsheets\nin VEnron, and then automatically clusters spreadsheets with the similar\nfeatures into the same evolution group. We applied SpreadCluster on all\nspreadsheets in the Enron corpus. The evaluation result shows that\nSpreadCluster could cluster spreadsheets with higher precision and recall rate\nthan the filename-based approach used by VEnron. Based on the clustering result\nby SpreadCluster, we further created a new versioned spreadsheet corpus\nVEnron2, which is much bigger than VEnron. We also applied SpreadCluster on the\nother two spreadsheet corpora FUSE and EUSES. The results show that\nSpreadCluster can cluster the versioned spreadsheets in these two corpora with\nhigh precision.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpreadCluster\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u7535\u5b50\u8868\u683c\u7684\u5171\u540c\u7279\u5f81\u6765\u805a\u7c7b\u4e0d\u540c\u7248\u672c\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7248\u672c\u4fe1\u606f\u7f3a\u5931\u60c5\u51b5\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7aef\u7528\u6237\u5f88\u5c11\u4f7f\u7528\u7248\u672c\u63a7\u5236\u5de5\u5177\u6765\u8bb0\u5f55\u7535\u5b50\u8868\u683c\u7684\u7248\u672c\u4fe1\u606f\uff0c\u5bfc\u81f4\u7535\u5b50\u8868\u683c\u7248\u672c\u4fe1\u606f\u7f3a\u5931\uff0c\u4e0d\u540c\u7248\u672c\u7684\u7535\u5b50\u8868\u683c\u4ee5\u5355\u4e2a\u76f8\u4f3c\u7535\u5b50\u8868\u683c\u7684\u5f62\u5f0f\u5171\u5b58\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u805a\u7c7b\u76f8\u4f3c\u7535\u5b50\u8868\u683c\u6765\u6062\u590d\u7248\u672c\u4fe1\u606f\uff0c\u4f46\u7531\u4e8e\u6587\u4ef6\u540d\u548c\u90ae\u4ef6\u5bf9\u8bdd\u7b49\u5fc5\u8981\u4fe1\u606f\u7684\u7f3a\u5931\uff0c\u5176\u9002\u7528\u6027\u548c\u51c6\u786e\u6027\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpreadCluster\u7684\u81ea\u52a8\u805a\u7c7b\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5b66\u4e60\u7248\u672c\u7535\u5b50\u8868\u683c\u4e2d\u7684\u5171\u540c\u7279\u5f81\uff08\u5982\u76f8\u4f3c\u7684\u8868\u683c\u6807\u9898\u548c\u5de5\u4f5c\u8868\u540d\u79f0\uff09\u6765\u805a\u7c7b\u7535\u5b50\u8868\u683c\uff0c\u5e76\u5c06\u5177\u6709\u76f8\u4f3c\u7279\u5f81\u7684\u7535\u5b50\u8868\u683c\u81ea\u52a8\u805a\u7c7b\u5230\u540c\u4e00\u4e2a\u8fdb\u5316\u7ec4\u4e2d\u3002", "result": "SpreadCluster\u5728Enron\u8bed\u6599\u5e93\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5176\u805a\u7c7b\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u5747\u9ad8\u4e8e\u57fa\u4e8e\u6587\u4ef6\u540d\u7684\u6a21\u7cca\u805a\u7c7b\u65b9\u6cd5\u3002SpreadCluster\u5728FUSE\u548cEUSES\u4e24\u4e2a\u8bed\u6599\u5e93\u4e0a\u4e5f\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u805a\u7c7b\u3002", "conclusion": "SpreadCluster\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u7248\u672c\u7535\u5b50\u8868\u683c\u4e2d\u7684\u7279\u5f81\u6807\u51c6\uff0c\u5c06\u5177\u6709\u76f8\u4f3c\u7279\u5f81\u7684\u7535\u5b50\u8868\u683c\u81ea\u52a8\u805a\u7c7b\u5230\u540c\u4e00\u8fdb\u5316\u7ec4\u4e2d\u3002\u7ed3\u679c\u8868\u660e\uff0cSpreadCluster\u6bd4VEnron\u4e2d\u4f7f\u7528\u7684\u57fa\u4e8e\u6587\u4ef6\u540d\u7684\u6a21\u7cca\u805a\u7c7b\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u3002\u6b64\u5916\uff0c\u57fa\u4e8eSpreadCluster\u7684\u805a\u7c7b\u7ed3\u679c\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u6bd4VEnron\u66f4\u5927\u7684\u65b0\u7248\u672c\u7535\u5b50\u8868\u683c\u8bed\u6599\u5e93VEnron2\u3002SpreadCluster\u5728FUSE\u548cEUSES\u4e24\u4e2a\u7535\u5b50\u8868\u683c\u8bed\u6599\u5e93\u4e0a\u4e5f\u8868\u73b0\u51fa\u4e86\u9ad8\u51c6\u786e\u7387\u3002"}}
{"id": "1610.04551", "title": "Tonal consonance parameters link microscopic and macroscopic properties of music exposing a hidden order in melody", "url": "https://arxiv.org/abs/1610.04551", "pdf": "https://arxiv.org/pdf/1610.04551", "abs": "https://arxiv.org/abs/1610.04551", "authors": ["Jorge Useche", "Rafael Hurtado"], "categories": ["cs.SD", "cs.IT", "math.IT", "physics.data-an", "physics.soc-ph", "00A65, 68Q30", "H.5.5; J.5"], "comment": "11 pages, 7 figures. Supplemental material contains 3 figures and 3\n  tables. An spreadsheet .xlsx contains data, fitting parameters, determination\n  coefficients, expected values, and Lagrange multipliers", "summary": "Consonance is related to the perception of pleasantness arising from a\ncombination of sounds and has been approached quantitatively using mathematical\nrelations, physics, information theory, and psychoacoustics. Tonal consonance\nis present in timbre, musical tuning, harmony, and melody, and it is used for\nconveying sensations, perceptions, and emotions in music. It involves the\nphysical properties of sound waves and is used to study melody and harmony\nthrough musical intervals and chords. From the perspective of complexity, the\nmacroscopic properties of a system with many parts frequently rely on the\nstatistical properties of its constituent elements. Here we show how the tonal\nconsonance parameters for complex tones can be used to study complexity in\nmusic. We apply this formalism to melody, showing that melodic lines in musical\npieces can be described in terms of the physical properties of melodic\nintervals and the existence of an entropy extremalization principle subject to\npsychoacoustic macroscopic constraints with musical meaning. This result\nconnects the human perception of consonance with the complexity of human\ncreativity in music through the physical properties of the musical stimulus.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u97f3\u4e50\u4e2d\u7684\u548c\u8c10\u548c\u590d\u6742\u6027\u53ef\u4ee5\u901a\u8fc7\u97f3\u8c03\u548c\u8c10\u53c2\u6570\u548c\u71b5\u6781\u503c\u539f\u7406\u6765\u91cf\u5316\uff0c\u5c06\u7269\u7406\u5b66\u3001\u5fc3\u7406\u58f0\u5b66\u548c\u97f3\u4e50\u521b\u4f5c\u8054\u7cfb\u8d77\u6765\u3002", "motivation": "\u4ece\u590d\u6742\u6027\u7684\u89d2\u5ea6\u7814\u7a76\u97f3\u4e50\u4e2d\u7684\u97f3\u8c03\u548c\u8c10\uff0c\u4ee5\u53ca\u97f3\u4e50\u521b\u9020\u7684\u590d\u6742\u6027\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u662f\u5c06\u97f3\u8c03\u548c\u8c10\u53c2\u6570\u5e94\u7528\u4e8e\u590d\u6742\u97f3\u8c03\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u65cb\u5f8b\u7814\u7a76\uff0c\u4f7f\u7528\u7edf\u8ba1\u7279\u6027\u548c\u71b5\u6781\u503c\u539f\u7406\u3002", "result": "\u65cb\u5f8b\u53ef\u4ee5\u901a\u8fc7\u97f3\u8c03\u548c\u8c10\u53c2\u6570\u3001\u65cb\u5f8b\u95f4\u9694\u7684\u7269\u7406\u7279\u6027\u4ee5\u53ca\u6ee1\u8db3\u7279\u5b9a\u7ea6\u675f\u7684\u71b5\u6781\u503c\u539f\u7406\u6765\u63cf\u8ff0\uff0c\u5c06\u4eba\u7c7b\u611f\u77e5\u4e0e\u521b\u9020\u529b\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u590d\u6742\u97f3\u8c03\u7684\u97f3\u8c03\u548c\u8c10\u53c2\u6570\u5e94\u7528\u4e8e\u97f3\u4e50\u7684\u590d\u6742\u6027\u7814\u7a76\uff0c\u8868\u660e\u97f3\u4e50\u7247\u6bb5\u4e2d\u7684\u65cb\u5f8b\u53ef\u4ee5\u6839\u636e\u65cb\u5f8b\u95f4\u9694\u7684\u7269\u7406\u7279\u6027\u548c\u6ee1\u8db3\u5177\u6709\u97f3\u4e50\u610f\u4e49\u7684\u5fc3\u7406\u58f0\u5b66\u5b8f\u89c2\u7ea6\u675f\u7684\u71b5\u6781\u503c\u539f\u7406\u6765\u63cf\u8ff0\u3002\u8be5\u7ed3\u679c\u901a\u8fc7\u97f3\u4e50\u523a\u6fc0\u7684\u7269\u7406\u7279\u6027\uff0c\u5c06\u4eba\u7c7b\u5bf9\u548c\u8c10\u7684\u611f\u77e5\u4e0e\u4eba\u7c7b\u5728\u97f3\u4e50\u521b\u9020\u4e2d\u7684\u590d\u6742\u6027\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "1704.01802", "title": "Contextual Data Collection for Smart Cities", "url": "https://arxiv.org/abs/1704.01802", "pdf": "https://arxiv.org/pdf/1704.01802", "abs": "https://arxiv.org/abs/1704.01802", "authors": ["Henrique Santos", "Vasco Furtado", "Paulo Pinheiro", "Deborah L. McGuinness"], "categories": ["cs.AI", "cs.CY", "I.2.4"], "comment": "In Proceedings of the 6th Workshop on Semantics for Smarter Cities\n  (S4SC 2015), Bethlehem, PA, USA, October 11-12, 2015", "summary": "As part of Smart Cities initiatives, national, regional and local governments\nall over the globe are under the mandate of being more open regarding how they\nshare their data. Under this mandate, many of these governments are publishing\ndata under the umbrella of open government data, which includes measurement\ndata from city-wide sensor networks. Furthermore, many of these data are\npublished in so-called data portals as documents that may be spreadsheets,\ncomma-separated value (CSV) data files, or plain documents in PDF or Word\ndocuments. The sharing of these documents may be a convenient way for the data\nprovider to convey and publish data but it is not the ideal way for data\nconsumers to reuse the data. For example, the problems of reusing the data may\nrange from difficulty opening a document that is provided in any format that is\nnot plain text, to the actual problem of understanding the meaning of each\npiece of knowledge inside of the document. Our proposal tackles those\nchallenges by identifying metadata that has been regarded to be relevant for\nmeasurement data and providing a schema for this metadata. We further leverage\nthe Human-Aware Sensor Network Ontology (HASNetO) to build an architecture for\ndata collected in urban environments. We discuss the use of HASNetO and the\nsupporting infrastructure to manage both data and metadata in support of the\nCity of Fortaleza, a large metropolitan area in Brazil.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u5229\u7528HASNetO\u672c\u4f53\u89e3\u51b3\u5f00\u653e\u653f\u5e9c\u6570\u636e\u91cd\u7528\u96be\u9898\uff0c\u5e76\u901a\u8fc7\u798f\u5854\u96f7\u8428\u5e02\u6848\u4f8b\u8fdb\u884c\u4e86\u5c55\u793a\u3002", "motivation": "\u8bb8\u591a\u653f\u5e9c\u673a\u6784\u5728\u667a\u6167\u57ce\u5e02\u5021\u8bae\u4e0b\uff0c\u9700\u8981\u516c\u5f00\u5176\u6570\u636e\uff0c\u5305\u62ec\u57ce\u5e02\u8303\u56f4\u4f20\u611f\u5668\u7f51\u7edc\u7684\u6d4b\u91cf\u6570\u636e\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6570\u636e\u901a\u5e38\u4ee5\u7535\u5b50\u8868\u683c\u3001CSV\u6587\u4ef6\u3001PDF\u6216Word\u6587\u6863\u7b49\u5f62\u5f0f\u53d1\u5e03\uff0c\u7ed9\u6570\u636e\u4f7f\u7528\u8005\u5e26\u6765\u4e86\u91cd\u7528\u4e0a\u7684\u56f0\u96be\uff0c\u4f8b\u5982\u6587\u4ef6\u683c\u5f0f\u4e0d\u517c\u5bb9\u6216\u96be\u4ee5\u7406\u89e3\u6570\u636e\u542b\u4e49\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u8bc6\u522b\u6d4b\u91cf\u6570\u636e\u76f8\u5173\u7684\u5143\u6570\u636e\u5e76\u63d0\u4f9b\u5143\u6570\u636e\u6a21\u5f0f\uff0c\u5229\u7528\u4eba\u7c7b\u611f\u77e5\u4f20\u611f\u5668\u7f51\u7edc\u672c\u4f53\uff08HASNetO\uff09\u6784\u5efa\u4e86\u57ce\u5e02\u73af\u5883\u6570\u636e\u6536\u96c6\u7684\u67b6\u6784\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u5e94\u5bf9\u5f00\u653e\u653f\u5e9c\u6570\u636e\u5728\u91cd\u7528\u4e0a\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u4e3a\u798f\u5854\u96f7\u8428\u5e02\u7684\u6570\u636e\u7ba1\u7406\u548c\u5143\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4eba\u7c7b\u611f\u77e5\u4f20\u611f\u5668\u7f51\u7edc\u672c\u4f53\uff08HASNetO\uff09\u6765\u7ba1\u7406\u57ce\u5e02\u73af\u5883\u4e2d\u6536\u96c6\u7684\u6570\u636e\u548c\u5143\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u5e76\u4ee5\u5df4\u897f\u798f\u5854\u96f7\u8428\u5e02\u4e3a\u4f8b\u8fdb\u884c\u4e86\u8ba8\u8bba\u3002"}}
{"id": "1704.01147", "title": "A Conceptual Model for Measuring the Complexity of Spreadsheets", "url": "https://arxiv.org/abs/1704.01147", "pdf": "https://arxiv.org/pdf/1704.01147", "abs": "https://arxiv.org/abs/1704.01147", "authors": ["Thomas Reschenhofer", "Bernhard Waltl", "Klym Shumaiev", "Florian Matthes"], "categories": ["cs.SE"], "comment": "12 pages, 4 figures, 3 tables", "summary": "Spreadsheets are widely used in industry, even for critical business\nprocesses. This implies the need for proper risk assessment in spreadsheets to\nevaluate the reliability and validity of the spreadsheet's outcome. As related\nresearch has shown, the risk of spreadsheet errors is strongly related to the\nspreadsheet's complexity. Therefore, spreadsheet researchers proposed various\nmetrics for quantifying different aspects of a spreadsheet in order to assess\nits complexity. However, until now there is no shared understanding of\npotential complexity drivers for spreadsheets. The present work addresses this\nresearch gap by proposing a conceptual model integrating all aspects which are\nidentified by related literature as potential drivers to spreadsheet\ncomplexity. In this sense, this model forms the foundation for a structured\ndefinition of complexity metrics, and thus enhances the reproducibility of\ntheir results. At the same time, it forms the foundation for identifying\nfurther applicable complexity metrics from other scientific domains.", "AI": {"tldr": "\u7535\u5b50\u8868\u683c\u5e7f\u6cdb\u7528\u4e8e\u5173\u952e\u4e1a\u52a1\u6d41\u7a0b\uff0c\u4f46\u5176\u590d\u6742\u6027\u9a71\u52a8\u56e0\u7d20\u5c1a\u672a\u660e\u786e\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6a21\u578b\uff0c\u6574\u5408\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u7684\u9a71\u52a8\u56e0\u7d20\uff0c\u4e3a\u5b9a\u4e49\u590d\u6742\u6027\u6307\u6807\u548c\u8bc6\u522b\u65b0\u6307\u6807\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u5728\u5de5\u4e1a\u754c\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5373\u4f7f\u5728\u5173\u952e\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u4e5f\u662f\u5982\u6b64\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5bf9\u7535\u5b50\u8868\u683c\u8fdb\u884c\u9002\u5f53\u7684\u98ce\u9669\u8bc4\u4f30\uff0c\u4ee5\u8bc4\u4f30\u5176\u7ed3\u679c\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002\u7136\u800c\uff0c\u76f4\u5230\u76ee\u524d\uff0c\u5bf9\u4e8e\u5f71\u54cd\u7535\u5b50\u8868\u683c\u590d\u6742\u6027\u7684\u9a71\u52a8\u56e0\u7d20\u8fd8\u6ca1\u6709\u7edf\u4e00\u7684\u8ba4\u8bc6\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6574\u5408\u4e86\u6240\u6709\u88ab\u8ba4\u4e3a\u53ef\u80fd\u5f71\u54cd\u7535\u5b50\u8868\u683c\u590d\u6742\u6027\u7684\u56e0\u7d20\u7684 \uac1c\ub150\u6a21\u578b\u3002", "result": "\u8be5\u6a21\u578b\u6574\u5408\u4e86\u76f8\u5173\u6587\u732e\u4e2d\u5df2\u8bc6\u522b\u51fa\u7684\u6240\u6709\u6f5c\u5728\u7684\u7535\u5b50\u8868\u683c\u590d\u6742\u6027\u9a71\u52a8\u56e0\u7d20\uff0c\u89e3\u51b3\u4e86\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u7ed3\u6784\u5316\u590d\u6742\u6027\u6307\u6807\u7684\u5b9a\u4e49\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u7ed3\u679c\u7684\u53ef\u91cd\u590d\u6027\u3002\u8be5\u6a21\u578b\u4e5f\u4e3a\u4ece\u5176\u4ed6\u79d1\u5b66\u9886\u57df\u8bc6\u522b\u66f4\u591a\u9002\u7528\u7684\u590d\u6742\u6027\u6307\u6807\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
