<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 本文介绍表格在LLMs和MLLMs中的重要性，并指出表格理解任务面临的挑战。文章通过分类法和任务介绍来解决这些挑战，并强调了该领域存在的一些关键研究空白。


<details>
  <summary>Details</summary>
Motivation: 表格因其复杂灵活的结构在大型语言模型（LLMs）和多模态大型语言模型（MLLMs）中受到广泛关注。然而，表格格式和用途的多样性导致了专门方法的开发，使得表格理解任务的导航具有挑战性。

Method: 为了应对这些挑战，本文通过表格输入表示的分类法和表格理解任务的介绍来引入关键概念。

Result: 本文强调了该领域的几个关键空白，表明需要进一步研究：1) 以检索为中心的任务，仅需少量数学和逻辑推理；2) 模型在处理复杂、大规模、长上下文或多表格场景时面临的重大挑战；3) 模型在不同表格表示和格式之间的泛化能力有限。

Conclusion: 该领域存在显著的研究空白，特别是在处理复杂表格结构、泛化能力以及超越简单检索的推理方面，需要进一步深入研究。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: 该研究提出了ctdGAN，一种条件生成对抗网络（GAN），通过考虑数据子空间、改进条件采样策略以及引入新的损失函数和聚类尺度缩放技术，有效解决了表格数据中类不平衡导致的机器学习性能下降问题，并在多个数据集上表现出生成高保真样本和提升分类准确性的优势。


<details>
  <summary>Details</summary>
Motivation: 表格数据中的类不平衡问题会导致机器学习任务的性能严重下降。现有的GAN模型在合成不平衡类的实例时，未能充分考虑输入样本的向量子空间，导致数据在任意位置生成；此外，在训练过程中将类别标签与其他分类变量同等对待，使得条件采样效果不佳。

Method: ctdGAN首先执行空间划分步骤，为输入样本分配聚类标签。随后，它利用这些标签通过新颖的概率采样策略和新的损失函数（惩罚聚类和类别误预测）来合成样本。此外，还引入了简单而有效的聚类尺度缩放技术，能够在不影响数据维度的前提下捕获多种特征模式，使ctdGAN能够生成与原始数据分布子空间相似的样本。

Result: 在14个不平衡数据集上的详尽评估表明，ctdGAN在生成高保真样本和提高分类准确性方面表现出优越性。

Conclusion: ctdGAN通过创新性地考虑数据子空间和改进条件采样机制，成功克服了现有GAN模型在处理表格数据类不平衡问题上的局限性，显著提升了合成数据的质量和机器学习模型的分类性能。

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>
