<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows](https://arxiv.org/abs/2509.26557)
*Litao Yan,Andrew Head,Ken Milne,Vu Le,Sumit Gulwani,Chris Parnin,Emerson Murphy-Hill*

Main category: cs.HC

TL;DR: InvisibleMentor是一个系统，它通过分析屏幕录像来识别用户在Excel等工具中的低效工作流程，并提供更高效的替代方案，优于基于提示的助手。


<details>
  <summary>Details</summary>
Motivation: 在Excel等功能丰富的工具中，用户很难发现更高效的工作流程。现有的AI助手需要用户描述目标或问题，这既费力又不精确。

Method: InvisibleMentor采用两阶段管道：视觉语言模型从屏幕录像中重建操作和上下文，然后语言模型生成结构化、高保真度的建议。它直接操作屏幕录像，而非依赖日志、API或用户提示。

Result: InvisibleMentor能准确识别低效工作流程，参与者认为其建议比基于提示的电子表格助手更具可操作性、更具针对性，并且更有助于学习和改进。

Conclusion: InvisibleMentor通过直接分析屏幕录像，有效识别并改进低效工作流程，提供比现有方法更优质的用户体验和学习效益。

Abstract: Many users struggle to notice when a more efficient workflow exists in
feature-rich tools like Excel. Existing AI assistants offer help only after
users describe their goals or problems, which can be effortful and imprecise.
We present InvisibleMentor, a system that turns screen recordings of task
completion into vision-grounded reflections on tasks. It detects issues such as
repetitive edits and recommends more efficient alternatives based on observed
behavior. Unlike prior systems that rely on logs, APIs, or user prompts,
InvisibleMentor operates directly on screen recordings. It uses a two-stage
pipeline: a vision-language model reconstructs actions and context, and a
language model generates structured, high-fidelity suggestions. In evaluation,
InvisibleMentor accurately identified inefficient workflows, and participants
found its suggestions more actionable, tailored, and more helpful for learning
and improvement compared to a prompt-based spreadsheet assistant.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations](https://arxiv.org/abs/2509.26331)
*Berdymyrat Ovezmyradov*

Main category: cs.AI

TL;DR: 本研究通过一个商业游戏模拟器评估大型语言模型（LLMs）在长期战略性商业决策中的表现，以弥补短期基准测试的不足。


<details>
  <summary>Details</summary>
Motivation: LLMs在多步骤、战略性商业决策中的能力尚未得到充分探索，且缺乏评估其长期连贯性的基准。

Method: 研究采用了一个可重现、开放获取的管理模拟器（商业游戏），让Gemini、ChatGPT、Meta AI、Mistral AI和Grok等五种主流LLM为一家模拟零售公司进行为期12个月的每月战略决策。评估指标包括利润、收入、市场份额等量化指标，以及战略连贯性、市场适应性和决策理由等定性分析。

Result: 该框架被用于评估五种主流LLM的性能。

Conclusion: 本方法旨在超越简单的性能指标，用于评估LLMs的长期决策能力，并为研究界提供了一个新的LLM基准测试平台。

Abstract: The rapid advancement of LLMs sparked significant interest in their potential
to augment or automate managerial functions. One of the most recent trends in
AI benchmarking is performance of Large Language Models (LLMs) over longer time
horizons. While LLMs excel at tasks involving natural language and pattern
recognition, their capabilities in multi-step, strategic business
decision-making remain largely unexplored. Few studies demonstrated how results
can be different from benchmarks in short-term tasks, as Vending-Bench
revealed. Meanwhile, there is a shortage of alternative benchmarks for
long-term coherence. This research analyses a novel benchmark using a business
game for the decision making in business. The research contributes to the
recent literature on AI by proposing a reproducible, open-access management
simulator to the research community for LLM benchmarking. This novel framework
is used for evaluating the performance of five leading LLMs available in free
online interface: Gemini, ChatGPT, Meta AI, Mistral AI, and Grok. LLM makes
decisions for a simulated retail company. A dynamic, month-by-month management
simulation provides transparently in spreadsheet model as experimental
environment. In each of twelve months, the LLMs are provided with a structured
prompt containing a full business report from the previous period and are
tasked with making key strategic decisions: pricing, order size, marketing
budget, hiring, dismissal, loans, training expense, R&D expense, sales
forecast, income forecast The methodology is designed to compare the LLMs on
quantitative metrics: profit, revenue, and market share, and other KPIs. LLM
decisions are analyzed in their strategic coherence, adaptability to market
changes, and the rationale provided for their decisions. This approach allows
to move beyond simple performance metrics for assessment of the long-term
decision-making.

</details>
