<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 表格在LLM和MLLM中因其复杂性而备受关注。本文通过表格输入表示的分类法和表格理解任务的介绍，指出了该领域存在的关键空白，包括以检索为主的任务、模型处理复杂表格的挑战以及模型泛化能力的局限性。


<details>
  <summary>Details</summary>
Motivation: 表格的格式和用途多样且复杂，导致了特定方法而非通用方法的开发，使得表格理解任务的导航变得具有挑战性。

Method: 本文通过表格输入表示的分类法和表格理解任务的介绍，引入了关键概念。

Result: 该研究强调了该领域存在的几个关键空白：(1) 以检索为中心的任务占主导地位，除了数学和逻辑运算外，几乎不需要推理；(2) 模型在处理复杂表格结构、大规模表格、长上下文或多表格场景时面临重大挑战；(3) 模型在不同表格表示和格式之间的泛化能力有限。

Conclusion: 上述关键空白表明该领域需要进一步研究，以解决推理能力不足、复杂表格处理困难以及模型泛化能力受限的问题。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: ctdGAN是一种条件GAN，通过空间划分、概率采样和新的损失函数，解决表格数据中的类别不平衡问题，能在相关子空间生成高保真样本。


<details>
  <summary>Details</summary>
Motivation: 表格数据中的类别不平衡问题严重影响机器学习性能。现有GAN模型未考虑输入样本的向量子空间，导致数据在任意位置生成，且条件采样效果不佳。

Method: ctdGAN首先进行空间划分，为输入样本分配聚类标签。然后利用这些标签，通过新颖的概率采样策略和惩罚聚类及类别错误预测的新损失函数来合成样本。此外，还引入了简单有效的聚类缩放技术来捕捉多个特征模式。

Result: 通过对14个不平衡数据集的全面评估，ctdGAN在生成高保真样本和提高分类准确性方面表现出优越性。

Conclusion: ctdGAN通过在与原始数据分布相似的子空间中生成样本，有效地缓解了表格数据集中的类别不平衡问题，并提高了分类准确性。

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>
