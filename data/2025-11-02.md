<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows](https://arxiv.org/abs/2509.26557)
*Litao Yan,Andrew Head,Ken Milne,Vu Le,Sumit Gulwani,Chris Parnin,Emerson Murphy-Hill*

Main category: cs.HC

TL;DR: InvisibleMentor是一个系统，它通过分析屏幕录像来帮助用户发现Excel等工具中更高效的工作流程，并提供改进建议，其表现优于基于提示的助手。


<details>
  <summary>Details</summary>
Motivation: 在Excel等功能丰富的工具中，用户很难注意到更高效的工作流程。现有的AI助手需要用户描述目标或问题才能提供帮助，这既费力又不精确。

Method: InvisibleMentor采用两阶段管道：一个视觉-语言模型从屏幕录像中重建动作和上下文，一个语言模型生成结构化、高保真的建议。它直接作用于屏幕录像，而非依赖日志、API或用户提示。

Result: InvisibleMentor准确识别出低效工作流程。与基于提示的电子表格助手相比，参与者认为其建议更具可操作性、更具针对性，并且更有助于学习和改进。

Conclusion: InvisibleMentor是一个有效的系统，能够基于屏幕录像中的观察行为来识别并推荐更高效的工作流程，相比传统方法具有优势。

Abstract: Many users struggle to notice when a more efficient workflow exists in
feature-rich tools like Excel. Existing AI assistants offer help only after
users describe their goals or problems, which can be effortful and imprecise.
We present InvisibleMentor, a system that turns screen recordings of task
completion into vision-grounded reflections on tasks. It detects issues such as
repetitive edits and recommends more efficient alternatives based on observed
behavior. Unlike prior systems that rely on logs, APIs, or user prompts,
InvisibleMentor operates directly on screen recordings. It uses a two-stage
pipeline: a vision-language model reconstructs actions and context, and a
language model generates structured, high-fidelity suggestions. In evaluation,
InvisibleMentor accurately identified inefficient workflows, and participants
found its suggestions more actionable, tailored, and more helpful for learning
and improvement compared to a prompt-based spreadsheet assistant.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations](https://arxiv.org/abs/2509.26331)
*Berdymyrat Ovezmyradov*

Main category: cs.AI

TL;DR: 该研究通过一个新颖的商业游戏模拟器评估了大型语言模型（LLMs）在长期战略业务决策中的表现，并根据定量指标和战略连贯性进行了比较。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在管理职能方面潜力巨大，但它们在多步骤、长期战略业务决策方面的能力尚未被充分探索，并且缺乏用于评估长期连贯性的基准。

Method: 研究使用了一个新颖的、开放获取的商业游戏管理模拟器作为基准。五种主流LLM（Gemini, ChatGPT, Meta AI, Mistral AI, Grok）被要求每月为一家模拟零售公司做出包括定价、订单量、营销预算等关键战略决策。评估指标包括利润、收入、市场份额等定量指标，以及战略连贯性、市场适应性和决策理由。

Result: 该研究提出了一个可复现、开放获取的管理模拟器，用于LLM的基准测试。它在一个动态的月度模拟环境中评估了五种主流LLM，并设计了一种方法来比较LLM在定量指标上的表现，同时分析它们的战略连贯性、适应性和决策理由，从而超越了简单的性能指标来评估长期决策能力。

Conclusion: 本研究提供了一个新颖的框架和方法来评估LLM在商业环境中长期战略决策能力，并为研究社区提供了一个可复现的开放获取工具。

Abstract: The rapid advancement of LLMs sparked significant interest in their potential
to augment or automate managerial functions. One of the most recent trends in
AI benchmarking is performance of Large Language Models (LLMs) over longer time
horizons. While LLMs excel at tasks involving natural language and pattern
recognition, their capabilities in multi-step, strategic business
decision-making remain largely unexplored. Few studies demonstrated how results
can be different from benchmarks in short-term tasks, as Vending-Bench
revealed. Meanwhile, there is a shortage of alternative benchmarks for
long-term coherence. This research analyses a novel benchmark using a business
game for the decision making in business. The research contributes to the
recent literature on AI by proposing a reproducible, open-access management
simulator to the research community for LLM benchmarking. This novel framework
is used for evaluating the performance of five leading LLMs available in free
online interface: Gemini, ChatGPT, Meta AI, Mistral AI, and Grok. LLM makes
decisions for a simulated retail company. A dynamic, month-by-month management
simulation provides transparently in spreadsheet model as experimental
environment. In each of twelve months, the LLMs are provided with a structured
prompt containing a full business report from the previous period and are
tasked with making key strategic decisions: pricing, order size, marketing
budget, hiring, dismissal, loans, training expense, R&D expense, sales
forecast, income forecast The methodology is designed to compare the LLMs on
quantitative metrics: profit, revenue, and market share, and other KPIs. LLM
decisions are analyzed in their strategic coherence, adaptability to market
changes, and the rationale provided for their decisions. This approach allows
to move beyond simple performance metrics for assessment of the long-term
decision-making.

</details>
