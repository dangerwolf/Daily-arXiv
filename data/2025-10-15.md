<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 表格在大型语言模型（LLMs）和多模态大型语言模型（MLLMs）中因其复杂且灵活的结构而受到广泛关注。本文通过表格输入表示的分类法和表格理解任务的介绍，解决了表格理解任务导航的挑战，并指出了该领域的几个关键研究空白。


<details>
  <summary>Details</summary>
Motivation: 表格作为LLMs和MLLMs的复杂且多样化的输入，其格式和目的的多样性导致了专门的方法而非通用方法，使得表格理解任务的导航充满挑战。

Method: 本文通过表格输入表示的分类法和表格理解任务的介绍，引入了关键概念。

Result: 论文强调了该领域的几个关键空白：1）以检索为中心的任务占主导，只需要最少的推理；2）模型在处理复杂表格结构、大规模表格、长上下文或多表格场景时面临重大挑战；3）模型在不同表格表示和格式之间的泛化能力有限。

Conclusion: 上述研究空白表明，LLMs和MLLMs在表格理解领域需要进一步的研究。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: ctdGAN是一种条件GAN，用于解决表格数据集中的类别不平衡问题，通过在相关子空间中生成高保真样本来提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 表格数据存在类别不平衡问题，这会严重降低机器学习任务的性能。现有的GAN模型没有考虑输入样本的向量子空间，导致数据在任意位置生成，并且在训练过程中对类别标签的处理方式与其他分类变量相同，使得条件采样效果不佳。

Method: ctdGAN首先执行空间划分步骤，为输入样本分配聚类标签。然后，它利用这些标签通过一种新颖的概率采样策略和惩罚聚类和类别错误预测的新损失函数来合成样本。此外，还引入了一种简单而有效的聚类缩放技术来捕获多个特征模式。

Result: 对14个不平衡数据集进行详尽评估，结果表明ctdGAN在生成高保真样本和提高分类准确性方面表现优越。

Conclusion: ctdGAN通过在与原始数据分布相似的子空间中生成样本，有效地解决了表格数据集中的类别不平衡问题，从而提高了分类准确性。

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>
