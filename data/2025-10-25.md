<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations](https://arxiv.org/abs/2509.26331)
*Berdymyrat Ovezmyradov*

Main category: cs.AI

TL;DR: 本研究通过一个新颖的商业游戏基准测试，评估了大型语言模型（LLMs）在长期、多步骤战略业务决策中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多步骤、战略性商业决策中的能力尚未得到充分探索，并且缺乏衡量其长期连贯性的基准。现有的短期基准测试可能无法反映实际性能。

Method: 研究采用了一个可重现、开放访问的管理模拟器（商业游戏），让五种主流大型语言模型（Gemini, ChatGPT, Meta AI, Mistral AI, Grok）为一家模拟零售公司进行为期十二个月的月度战略决策（包括定价、订单量、营销预算等）。决策基于前一期的业务报告。评估指标包括利润、收入、市场份额等量化指标，以及战略连贯性、市场适应性和决策理由等定性分析。

Result: 该框架用于评估五种领先的大型语言模型的性能，旨在比较它们在长期战略决策中的表现，超越简单的性能指标。

Conclusion: 这种方法超越了简单的性能指标，用于评估大型语言模型的长期决策能力，并为研究社区提供了一个可重现、开放访问的管理模拟器以进行LLM基准测试。

Abstract: The rapid advancement of LLMs sparked significant interest in their potential
to augment or automate managerial functions. One of the most recent trends in
AI benchmarking is performance of Large Language Models (LLMs) over longer time
horizons. While LLMs excel at tasks involving natural language and pattern
recognition, their capabilities in multi-step, strategic business
decision-making remain largely unexplored. Few studies demonstrated how results
can be different from benchmarks in short-term tasks, as Vending-Bench
revealed. Meanwhile, there is a shortage of alternative benchmarks for
long-term coherence. This research analyses a novel benchmark using a business
game for the decision making in business. The research contributes to the
recent literature on AI by proposing a reproducible, open-access management
simulator to the research community for LLM benchmarking. This novel framework
is used for evaluating the performance of five leading LLMs available in free
online interface: Gemini, ChatGPT, Meta AI, Mistral AI, and Grok. LLM makes
decisions for a simulated retail company. A dynamic, month-by-month management
simulation provides transparently in spreadsheet model as experimental
environment. In each of twelve months, the LLMs are provided with a structured
prompt containing a full business report from the previous period and are
tasked with making key strategic decisions: pricing, order size, marketing
budget, hiring, dismissal, loans, training expense, R&D expense, sales
forecast, income forecast The methodology is designed to compare the LLMs on
quantitative metrics: profit, revenue, and market share, and other KPIs. LLM
decisions are analyzed in their strategic coherence, adaptability to market
changes, and the rationale provided for their decisions. This approach allows
to move beyond simple performance metrics for assessment of the long-term
decision-making.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [2] [The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows](https://arxiv.org/abs/2509.26557)
*Litao Yan,Andrew Head,Ken Milne,Vu Le,Sumit Gulwani,Chris Parnin,Emerson Murphy-Hill*

Main category: cs.HC

TL;DR: InvisibleMentor是一个系统，它将任务完成的屏幕录像转化为基于视觉的任务反思。它检测重复性编辑等问题，并根据观察到的行为推荐更有效的替代方案。


<details>
  <summary>Details</summary>
Motivation: 许多用户在Excel等功能丰富的工具中难以发现更高效的工作流程。现有的AI助手只有在用户描述其目标或问题后才能提供帮助，这可能费力且不精确。

Method: InvisibleMentor直接在屏幕录像上运行。它使用两阶段管道：视觉语言模型重建动作和上下文，语言模型生成结构化、高保真的建议。

Result: 在评估中，InvisibleMentor准确识别了低效的工作流程，与基于提示的电子表格助手相比，参与者发现其建议更具可操作性、更具针对性，并且更有助于学习和改进。

Conclusion: InvisibleMentor准确识别了低效的工作流程，与基于提示的电子表格助手相比，参与者发现其建议更具可操作性、更具针对性，并且更有助于学习和改进。

Abstract: Many users struggle to notice when a more efficient workflow exists in
feature-rich tools like Excel. Existing AI assistants offer help only after
users describe their goals or problems, which can be effortful and imprecise.
We present InvisibleMentor, a system that turns screen recordings of task
completion into vision-grounded reflections on tasks. It detects issues such as
repetitive edits and recommends more efficient alternatives based on observed
behavior. Unlike prior systems that rely on logs, APIs, or user prompts,
InvisibleMentor operates directly on screen recordings. It uses a two-stage
pipeline: a vision-language model reconstructs actions and context, and a
language model generates structured, high-fidelity suggestions. In evaluation,
InvisibleMentor accurately identified inefficient workflows, and participants
found its suggestions more actionable, tailored, and more helpful for learning
and improvement compared to a prompt-based spreadsheet assistant.

</details>
