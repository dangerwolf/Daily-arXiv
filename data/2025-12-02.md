<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets](https://arxiv.org/abs/2510.19247)
*Ziwei Wang,Jiayuan Su,Mengyu Zhou,Huaxing Zeng,Mengni Jia,Xiao Lv,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: SheetBrain is a neuro-symbolic framework for reasoning over tabular data, improving accuracy in spreadsheet question answering and manipulation.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with complex spreadsheets, lacking accuracy in capturing table structure and ensuring reasoning correctness.

Method: A neuro-symbolic dual workflow agent framework with understanding, execution, and validation modules.

Result: Significantly improves accuracy on existing benchmarks and a new challenging benchmark (SheetBench).

Conclusion: SheetBrain enhances accuracy in tabular data reasoning tasks.

Abstract: Understanding and reasoning over complex spreadsheets remain fundamental challenges for large language models (LLMs), which often struggle with accurately capturing the complex structure of tables and ensuring reasoning correctness. In this work, we propose SheetBrain, a neuro-symbolic dual workflow agent framework designed for accurate reasoning over tabular data, supporting both spreadsheet question answering and manipulation tasks. SheetBrain comprises three core modules: an understanding module, which produces a comprehensive overview of the spreadsheet - including sheet summary and query-based problem insight to guide reasoning; an execution module, which integrates a Python sandbox with preloaded table-processing libraries and an Excel helper toolkit for effective multi-turn reasoning; and a validation module, which verifies the correctness of reasoning and answers, triggering re-execution when necessary. We evaluate SheetBrain on multiple public tabular QA and manipulation benchmarks, and introduce SheetBench, a new benchmark targeting large, multi-table, and structurally complex spreadsheets. Experimental results show that SheetBrain significantly improves accuracy on both existing benchmarks and the more challenging scenarios presented in SheetBench. Our code is publicly available at https://github.com/microsoft/SheetBrain.

</details>


### [2] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: This paper reviews table understanding tasks in LLMs and MLLMs, highlighting challenges and gaps.


<details>
  <summary>Details</summary>
Motivation: The diversity in table formats and purposes has led to specialized methods, making navigation of table understanding tasks challenging.

Method: Introduces key concepts through a taxonomy of tabular input representations and an introduction of table understanding tasks.

Result: Highlights critical gaps: (1) retrieval-focused tasks, (2) challenges with complex tables, (3) limited generalization.

Conclusion: Indicates the need for further research in table understanding for LLMs and MLLMs.

Abstract: Tables have gained significant attention in large language models (LLMs) and multimodal large language models (MLLMs) due to their complex and flexible structure. Unlike linear text inputs, tables are two-dimensional, encompassing formats that range from well-structured database tables to complex, multi-layered spreadsheets, each with different purposes. This diversity in format and purpose has led to the development of specialized methods and tasks, instead of universal approaches, making navigation of table understanding tasks challenging. To address these challenges, this paper introduces key concepts through a taxonomy of tabular input representations and an introduction of table understanding tasks. We highlight several critical gaps in the field that indicate the need for further research: (1) the predominance of retrieval-focused tasks that require minimal reasoning beyond mathematical and logical operations; (2) significant challenges faced by models when processing complex table structures, large-scale tables, length context, or multi-table scenarios; and (3) the limited generalization of models across different tabular representations and formats.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: This paper introduces ctdGAN, a conditional GAN model, to address the class imbalance problem in tabular datasets by generating synthetic data for under-represented classes within the vector subspaces of the original data.


<details>
  <summary>Details</summary>
Motivation: Existing GAN models for tabular data do not consider the vector subspaces of input samples, leading to data generation in arbitrary locations, and treat class labels as regular categorical variables, reducing the effectiveness of conditional sampling by class.

Method: ctdGAN uses a space partitioning step to assign cluster labels to input samples, then synthesizes samples via a novel probabilistic sampling strategy and a new loss function that penalizes both cluster and class mis-predictions. It also includes a cluster-wise scaling technique.

Result: Evaluated on 14 imbalanced datasets, ctdGAN demonstrates superior performance in generating high fidelity samples and improving classification accuracy.

Conclusion: ctdGAN effectively alleviates class imbalance in tabular datasets by generating synthetic data within the vector subspaces of the original data distribution, leading to improved classification accuracy.

Abstract: The tabular form constitutes the standard way of representing data in relational database systems and spreadsheets. But, similarly to other forms, tabular data suffers from class imbalance, a problem that causes serious performance degradation in a wide variety of machine learning tasks. One of the most effective solutions dictates the usage of Generative Adversarial Networks (GANs) in order to synthesize artificial data instances for the under-represented classes. Despite their good performance, none of the proposed GAN models takes into account the vector subspaces of the input samples in the real data space, leading to data generation in arbitrary locations. Moreover, the class labels are treated in the same manner as the other categorical variables during training, so conditional sampling by class is rendered less effective. To overcome these problems, this study presents ctdGAN, a conditional GAN for alleviating class imbalance in tabular datasets. Initially, ctdGAN executes a space partitioning step to assign cluster labels to the input samples. Subsequently, it utilizes these labels to synthesize samples via a novel probabilistic sampling strategy and a new loss function that penalizes both cluster and class mis-predictions. In this way, ctdGAN is trained to generate samples in subspaces that resemble those of the original data distribution. We also introduce several other improvements, including a simple, yet effective cluster-wise scaling technique that captures multiple feature modes without affecting data dimensionality. The exhaustive evaluation of ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating high fidelity samples and improving classification accuracy.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [4] [LinkML: An Open Data Modeling Framework](https://arxiv.org/abs/2511.16935)
*Sierra A. T. Moxon,Harold Solbrig,Nomi L. Harris,Patrick Kalita,Mark A. Miller,Sujay Patil,Kevin Schaper,Chris Bizon,J. Harry Caufield,Silvano Cirujano Cuesta,Corey Cox,Frank Dekervel,Damion M. Dooley,William D. Duncan,Tim Fliss,Sarah Gehrke,Adam S. L. Graefe,Harshad Hegde,AJ Ireland,Julius O. B. Jacobsen,Madan Krishnamurthy,Carlo Kroll,David Linke,Ryan Ly,Nicolas Matentzoglu,James A. Overton,Jonny L. Saunders,Deepak R. Unni,Gaurav Vaidya,Wouter-Michiel A. M. Vierdag,LinkML Community Contributors,Oliver Ruebel,Christopher G. Chute,Matthew H. Brush,Melissa A. Haendel,Christopher J. Mungall*

Main category: cs.DB

TL;DR: LinkML is an open framework that simplifies the process of authoring, validating, and sharing data.


<details>
  <summary>Details</summary>
Motivation: Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult.

Method: LinkML uses a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas.

Result: LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development.

Conclusion: LinkML makes implicit models explicitly computable and allows data to be standardized at its origin.

Abstract: Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult. LinkML (Linked Data Modeling Language) is an open framework that simplifies the process of authoring, validating, and sharing data. LinkML can describe a range of data structures, from flat, list-based models to complex, interrelated, and normalized models that utilize polymorphism and compound inheritance. It offers an approachable syntax that is not tied to any one technical architecture and can be integrated seamlessly with many existing frameworks. The LinkML syntax provides a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas. These key features make LinkML an accessible platform for interdisciplinary collaboration and a reliable way to define and share data semantics.
  LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development. In short, LinkML makes implicit models explicitly computable and allows data to be standardized at its origin. LinkML documentation and code are available at linkml.io.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [5] [To Use or to Refuse? Re-Centering Student Agency with Generative AI in Engineering Design Education](https://arxiv.org/abs/2510.19342)
*Thijs Willems,Sumbul Khan,Qian Huang,Bradley Camburn,Nachamma Sockalingam,King Wang Poon*

Main category: cs.CY

TL;DR: 本研究调查了新加坡科技设计大学一门为期 13 周的基础设计课程中，学生对使用人工智能的反思。该课程为 AI 增强设计课程，旨在培养学生基于 AI 的设计技能。学生需要反思该技术是作为工具、队友还是不使用。通过这种方式，学生学会将 AI 用于创新而非仅仅用于自动化，并反思能动性、伦理和背景。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在设计课程中利用人工智能提升学生的创新能力。

Method: 通过十三份结构化反思电子表格、八份图解简报以及教师和研究人员的笔记，对学生的课程作业成果进行定性编码分析。

Result: 研究结果表明，生成式人工智能的融入带来了加速原型设计、快速技能掌握、迭代提示优化、用户研究期间有目的的“关闭”以及识别幻觉的常规方法。学生不仅利用生成式人工智能来提高速度，而且还学会拒绝其输出，发明自己的幻觉演练，并将节省下来的时间用于更深入的用户研究，从而将效率转化为创新。

Conclusion: 该研究表明，可以将人工智能的采纳转化为可评估的设计习惯；奖励选择性不使用可以培养具有幻觉意识的工作流程；并且，通过工具访问、反思、角色标记和通过竞赛奖励进行公开认可，可以使基于人工智能的教育创新得以扩展，而不会影响责任性。

Abstract: This pilot study traces students' reflections on the use of AI in a 13-week foundational design course enrolling over 500 first-year engineering and architecture students at the Singapore University of Technology and Design. The course was an AI-enhanced design course, with several interventions to equip students with AI based design skills. Students were required to reflect on whether the technology was used as a tool (instrumental assistant), a teammate (collaborative partner), or neither (deliberate non-use). By foregrounding this three-way lens, students learned to use AI for innovation rather than just automation and to reflect on agency, ethics, and context rather than on prompt crafting alone. Evidence stems from coursework artefacts: thirteen structured reflection spreadsheets and eight illustrated briefs submitted, combined with notes of teachers and researchers. Qualitative coding of these materials reveals shared practices brought about through the inclusion of Gen-AI, including accelerated prototyping, rapid skill acquisition, iterative prompt refinement, purposeful "switch-offs" during user research, and emergent routines for recognizing hallucinations. Unexpectedly, students not only harnessed Gen-AI for speed but (enabled by the tool-teammate-neither triage) also learned to reject its outputs, invent their own hallucination fire-drills, and divert the reclaimed hours into deeper user research, thereby transforming efficiency into innovation. The implications of the approach we explore shows that: we can transform AI uptake into an assessable design habit; that rewarding selective non-use cultivates hallucination-aware workflows; and, practically, that a coordinated bundle of tool access, reflection, role tagging, and public recognition through competition awards allows AI based innovation in education to scale without compromising accountability.

</details>
