{"id": "2510.19864", "title": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "url": "https://arxiv.org/abs/2510.19864", "pdf": "https://arxiv.org/pdf/2510.19864", "abs": "https://arxiv.org/abs/2510.19864", "authors": ["Amila Indika", "Igor Molybog"], "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": "14 pages, 5 figures, 4 tables", "summary": "Numerous knowledge workers utilize spreadsheets in business, accounting, and\nfinance. However, a lack of systematic documentation methods for spreadsheets\nhinders automation, collaboration, and knowledge transfer, which risks the loss\nof crucial institutional knowledge. This paper introduces Spreadsheet\nOperations Documentation (SOD), an AI task that involves generating\nhuman-readable explanations from spreadsheet operations. Many previous studies\nhave utilized Large Language Models (LLMs) for generating spreadsheet\nmanipulation code; however, translating that code into natural language for SOD\nis a less-explored area. To address this, we present a benchmark of 111\nspreadsheet manipulation code snippets, each paired with a corresponding\nnatural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini,\nLLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and\nMETEOR metrics. Our findings suggest that LLMs can generate accurate\nspreadsheet documentation, making SOD a feasible prerequisite step toward\nenhancing reproducibility, maintainability, and collaborative workflows in\nspreadsheets, although there are challenges that need to be addressed.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f15\u5165\u4e86\u8868\u683c\u64cd\u4f5c\u6587\u6863\uff08SOD\uff09\uff0c\u8fd9\u662f\u4e00\u9879\u5229\u7528AI\u4ece\u8868\u683c\u64cd\u4f5c\u4e2d\u751f\u6210\u4eba\u7c7b\u53ef\u8bfb\u89e3\u91ca\u7684\u4efb\u52a1\u3002\u901a\u8fc7\u8bc4\u4f30\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u7814\u7a76\u53d1\u73b0LLMs\u80fd\u591f\u751f\u6210\u51c6\u786e\u7684\u8868\u683c\u6587\u6863\uff0c\u4ece\u800c\u63d0\u5347\u8868\u683c\u7684\u53ef\u590d\u73b0\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u534f\u4f5c\u6548\u7387\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6587\u6863\u65b9\u6cd5\uff0c\u963b\u788d\u4e86\u81ea\u52a8\u5316\u3001\u534f\u4f5c\u548c\u77e5\u8bc6\u8f6c\u79fb\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u5173\u952e\u673a\u6784\u77e5\u8bc6\u7684\u6d41\u5931\u3002\u5c06\u8868\u683c\u64cd\u4f5c\u4ee3\u7801\u7ffb\u8bd1\u6210\u81ea\u7136\u8bed\u8a00\u7528\u4e8eSOD\u662f\u4e00\u4e2a\u8f83\u5c11\u63a2\u7d22\u7684\u9886\u57df\u3002", "method": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u8868\u683c\u64cd\u4f5c\u6587\u6863\uff08SOD\uff09\u4f5c\u4e3a\u4e00\u9879AI\u4efb\u52a1\u3002\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b111\u4e2a\u8868\u683c\u64cd\u4f5c\u4ee3\u7801\u7247\u6bb5\u53ca\u5176\u5bf9\u5e94\u81ea\u7136\u8bed\u8a00\u6458\u8981\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002\u8bc4\u4f30\u4e86GPT-4o\u3001GPT-4o-mini\u3001LLaMA-3.3-70B\u3001Mixtral-8x7B\u548cGemma2-9B\u8fd9\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u4f7f\u7528BLEU\u3001GLEU\u3001ROUGE-L\u548cMETEOR\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u51c6\u786e\u7684\u8868\u683c\u6587\u6863\u3002", "conclusion": "SOD\u662f\u63d0\u9ad8\u7535\u5b50\u8868\u683c\u53ef\u590d\u73b0\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u534f\u4f5c\u5de5\u4f5c\u6d41\u7a0b\u7684\u53ef\u884c\u524d\u63d0\u6b65\u9aa4\uff0c\u5c3d\u7ba1\u4ecd\u5b58\u5728\u9700\u8981\u89e3\u51b3\u7684\u6311\u6218\u3002"}}
