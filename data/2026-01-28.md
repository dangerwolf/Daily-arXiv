<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 2]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets](https://arxiv.org/abs/2510.19247)
*Ziwei Wang,Jiayuan Su,Mengyu Zhou,Huaxing Zeng,Mengni Jia,Xiao Lv,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: SheetBrain是一个神经-符号双工作流代理框架，用于在表格数据上进行准确推理，支持电子表格问答和操作任务。


<details>
  <summary>Details</summary>
Motivation: 理解和推理复杂的电子表格对于大型语言模型（LLM）来说仍然是根本性的挑战，因为它们常常难以准确地捕捉表格的复杂结构并确保推理的正确性。

Method: SheetBrain包括三个核心模块：一个理解模块，用于生成电子表格的全面概述，包括工作表摘要和基于查询的问题洞察以指导推理；一个执行模块，集成了带有预加载的表处理库的Python沙盒和Excel助手工具包，以实现有效的多轮推理；以及一个验证模块，用于验证推理和答案的正确性，并在必要时触发重新执行。

Result: 我们在多个公共表格QA和操作基准上评估了SheetBrain，并引入了SheetBench，一个针对大型、多表和结构复杂的电子表格的新基准。实验结果表明，SheetBrain在现有基准和SheetBench提出的更具挑战性的场景中都显著提高了准确性。

Conclusion: SheetBrain在表格数据问答和操作任务上取得了显著的性能提升，尤其是在处理大型、多表和结构复杂的电子表格方面。

Abstract: Understanding and reasoning over complex spreadsheets remain fundamental challenges for large language models (LLMs), which often struggle with accurately capturing the complex structure of tables and ensuring reasoning correctness. In this work, we propose SheetBrain, a neuro-symbolic dual workflow agent framework designed for accurate reasoning over tabular data, supporting both spreadsheet question answering and manipulation tasks. SheetBrain comprises three core modules: an understanding module, which produces a comprehensive overview of the spreadsheet - including sheet summary and query-based problem insight to guide reasoning; an execution module, which integrates a Python sandbox with preloaded table-processing libraries and an Excel helper toolkit for effective multi-turn reasoning; and a validation module, which verifies the correctness of reasoning and answers, triggering re-execution when necessary. We evaluate SheetBrain on multiple public tabular QA and manipulation benchmarks, and introduce SheetBench, a new benchmark targeting large, multi-table, and structurally complex spreadsheets. Experimental results show that SheetBrain significantly improves accuracy on both existing benchmarks and the more challenging scenarios presented in SheetBench. Our code is publicly available at https://github.com/microsoft/SheetBrain.

</details>


### [2] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 表格在大型语言模型（LLMs）和多模态大型语言模型（MLLMs）中受到广泛关注，但其复杂的结构带来了挑战。本文提出了一个表格输入表示的分类法和表格理解任务的介绍，以应对这些挑战。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）和多模态大型语言模型（MLLMs）在处理复杂表格结构时遇到的挑战，并指出现有研究的差距。

Method: 通过表格输入表示的分类法和表格理解任务的介绍来阐述关键概念。

Result: 现有研究主要集中在检索任务，模型在处理复杂表格结构、大规模表格、长上下文或多表格场景时面临挑战，并且模型在不同表格表示和格式之间的泛化能力有限。

Conclusion: 需要进一步的研究来解决表格理解任务中的关键差距，包括需要更强的推理能力、处理复杂和大规模表格的能力以及提高模型在不同表格表示和格式之间的泛化能力。

Abstract: Tables have gained significant attention in large language models (LLMs) and multimodal large language models (MLLMs) due to their complex and flexible structure. Unlike linear text inputs, tables are two-dimensional, encompassing formats that range from well-structured database tables to complex, multi-layered spreadsheets, each with different purposes. This diversity in format and purpose has led to the development of specialized methods and tasks, instead of universal approaches, making navigation of table understanding tasks challenging. To address these challenges, this paper introduces key concepts through a taxonomy of tabular input representations and an introduction of table understanding tasks. We highlight several critical gaps in the field that indicate the need for further research: (1) the predominance of retrieval-focused tasks that require minimal reasoning beyond mathematical and logical operations; (2) significant challenges faced by models when processing complex table structures, large-scale tables, length context, or multi-table scenarios; and (3) the limited generalization of models across different tabular representations and formats.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [IIKL: Isometric Immersion Kernel Learning with Riemannian Manifold for Geometric Preservation](https://arxiv.org/abs/2505.06288)
*Zihao Chen,Wenyong Wang,Jiachen Yang,Yu Xiang*

Main category: cs.LG

TL;DR: 该研究提出了一种名为等距浸入核学习（IIKL）的新方法，用于在非欧几里得数据中学习几何表示，该方法通过在黎曼流形上进行等距诱导来保持数据的内在几何结构，并在下游任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的非欧几里得数据表示学习方法通常将数据映射到欧几里得空间，可能导致关键几何信息的丢失。本研究旨在提出一种新的方法，以在表示学习过程中保持离散非欧几里得数据的内在几何和拓扑性质。

Method: 提出了一种名为等距浸入核学习（IIKL）的新方法，该方法在黎曼流形上构建黎曼度量，并证明了等距浸入等价于流形切丛上的核函数，从而保证了向量内积在任意切空间中的不变性。此外，还引入了一种基于IIKL的参数化学习模型，并使用最大似然估计（MLE）推导了一种交替训练方法。

Result: 实验结果表明，所提出的IIKL方法成功地保持了数据（包括3D和高维数据集）的内在几何表示，并在数据重建和分类等下游任务中显著提高了准确性。与现有最先进（SOTA）的方法相比，该方法可将内积不变性损失降低90%以上，并将下游重建精度平均提高40%，在涉及等距和共形的几何度量方面误差降低90%。

Conclusion: IIKL方法能够有效地保持非欧几里得数据的内在几何结构，并在各种下游任务中取得优于现有方法的性能，证明了其在几何表示学习方面的有效性。

Abstract: Geometric representation learning in preserving the intrinsic geometric and topological properties for discrete non-Euclidean data is crucial in scientific applications. Previous research generally mapped non-Euclidean discrete data into Euclidean space during representation learning, which may lead to the loss of some critical geometric information. In this paper, we propose a novel Isometric Immersion Kernel Learning (IIKL) method to build Riemannian manifold and isometrically induce Riemannian metric from discrete non-Euclidean data. We prove that Isometric immersion is equivalent to the kernel function in the tangent bundle on the manifold, which explicitly guarantees the invariance of the inner product between vectors in the arbitrary tangent space throughout the learning process, thus maintaining the geometric structure of the original data. Moreover, a novel parameterized learning model based on IIKL is introduced, and an alternating training method for this model is derived using Maximum Likelihood Estimation (MLE), ensuring efficient convergence. Experimental results proved that using the learned Riemannian manifold and its metric, our model preserved the intrinsic geometric representation of data in both 3D and high-dimensional datasets successfully, and significantly improved the accuracy of downstream tasks, such as data reconstruction and classification. It is showed that our method could reduce the inner product invariant loss by more than 90% compared to state-of-the-art (SOTA) methods, also achieved an average 40% improvement in downstream reconstruction accuracy and a 90% reduction in error for geometric metrics involving isometric and conformal.

</details>


### [4] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: ctdGAN通过空间划分、概率采样和新的损失函数来解决表格数据中的类别不平衡问题，提高了生成样本的保真度和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的GAN模型在生成表格数据时未考虑输入样本的向量子空间，导致生成样本位置随意，并且类别标签与其他分类变量同等对待，降低了条件采样的有效性。

Method: ctdGAN首先对输入样本进行空间划分以分配聚类标签，然后利用这些标签通过新颖的概率采样策略和新的损失函数（惩罚聚类和类别误预测）来合成样本。此外，还引入了聚类化缩放技术。

Result: ctdGAN在14个不平衡数据集上的评估表明，其在生成高保真样本和提高分类准确性方面优于现有方法。

Conclusion: ctdGAN通过考虑向量子空间和改进的条件采样机制，有效地解决了表格数据的类别不平衡问题，并提高了机器学习任务的性能。

Abstract: The tabular form constitutes the standard way of representing data in relational database systems and spreadsheets. But, similarly to other forms, tabular data suffers from class imbalance, a problem that causes serious performance degradation in a wide variety of machine learning tasks. One of the most effective solutions dictates the usage of Generative Adversarial Networks (GANs) in order to synthesize artificial data instances for the under-represented classes. Despite their good performance, none of the proposed GAN models takes into account the vector subspaces of the input samples in the real data space, leading to data generation in arbitrary locations. Moreover, the class labels are treated in the same manner as the other categorical variables during training, so conditional sampling by class is rendered less effective. To overcome these problems, this study presents ctdGAN, a conditional GAN for alleviating class imbalance in tabular datasets. Initially, ctdGAN executes a space partitioning step to assign cluster labels to the input samples. Subsequently, it utilizes these labels to synthesize samples via a novel probabilistic sampling strategy and a new loss function that penalizes both cluster and class mis-predictions. In this way, ctdGAN is trained to generate samples in subspaces that resemble those of the original data distribution. We also introduce several other improvements, including a simple, yet effective cluster-wise scaling technique that captures multiple feature modes without affecting data dimensionality. The exhaustive evaluation of ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating high fidelity samples and improving classification accuracy.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [5] [To Use or to Refuse? Re-Centering Student Agency with Generative AI in Engineering Design Education](https://arxiv.org/abs/2510.19342)
*Thijs Willems,Sumbul Khan,Qian Huang,Bradley Camburn,Nachamma Sockalingam,King Wang Poon*

Main category: cs.CY

TL;DR: 本研究追踪了新加坡科技设计大学一项为期13周的基础设计课程中，超过500名一年级工程和建筑专业学生对AI使用的反思。课程通过多项干预措施，旨在增强学生的设计技能。研究发现，学生不仅将AI用作工具，还学会了将其视为伙伴，并能在必要时拒绝使用，从而将效率转化为创新。该方法表明，可以将AI的采用转化为可评估的设计习惯，培养对幻觉的意识，并能通过工具访问、反思、角色标记和竞赛奖励等协调措施，在不牺牲问责制的情况下，实现AI驱动的教育创新规模化。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索在设计课程中，学生如何反思和使用人工智能（AI），特别是生成式AI（Gen-AI）。研究旨在了解学生是仅将AI视为自动化工具，还是能将其作为协作伙伴，并探究这种使用方式对培养创新能力、伦理意识以及对AI“代理”的理解的影响，而不是仅仅关注提示工程。

Method: 本研究采用了一种试点研究方法，在新加坡科技设计大学一门为期13周的基础设计课程中，对超过500名一年级工程和建筑专业学生进行。课程中融入了多项AI增强的设计干预措施。要求学生反思AI的使用方式，将其分为“工具”（辅助）、“队友”（协作）或“两者皆非”（刻意不使用）三种模式。研究收集了学生的课程作业、13份结构化反思电子表格、8份图文并茂的简报，以及教师和研究人员的笔记，并通过定性编码进行分析。

Result: 通过对学生作业、反思材料和教师笔记进行定性编码，研究发现了AI融入设计课程所带来的共享实践，包括：加速原型制作、快速技能习得、迭代式提示改进、用户研究中的刻意“关闭”AI，以及识别AI“幻觉”的新出现例程。出乎意料的是，学生不仅利用Gen-AI来提高速度，还学会了拒绝其输出，发明了“幻觉防火演习”，并将节省下来的时间投入到更深入的用户研究中，从而实现了从效率到创新的转变。

Conclusion: 本研究的结论是，通过将AI的使用视为一种可评估的设计习惯，并鼓励学生有选择地不使用AI，可以培养对AI“幻觉”有意识的工作流程。此外，结合工具访问、反思、角色标记和竞赛奖励等措施，能够有效地促进教育领域中AI驱动的创新，同时保持问责制，并实现规模化推广。这种方法有助于学生将AI从单纯的效率工具转变为促进深度设计创新和批判性思维的伙伴。

Abstract: This pilot study traces students' reflections on the use of AI in a 13-week foundational design course enrolling over 500 first-year engineering and architecture students at the Singapore University of Technology and Design. The course was an AI-enhanced design course, with several interventions to equip students with AI based design skills. Students were required to reflect on whether the technology was used as a tool (instrumental assistant), a teammate (collaborative partner), or neither (deliberate non-use). By foregrounding this three-way lens, students learned to use AI for innovation rather than just automation and to reflect on agency, ethics, and context rather than on prompt crafting alone. Evidence stems from coursework artefacts: thirteen structured reflection spreadsheets and eight illustrated briefs submitted, combined with notes of teachers and researchers. Qualitative coding of these materials reveals shared practices brought about through the inclusion of Gen-AI, including accelerated prototyping, rapid skill acquisition, iterative prompt refinement, purposeful "switch-offs" during user research, and emergent routines for recognizing hallucinations. Unexpectedly, students not only harnessed Gen-AI for speed but (enabled by the tool-teammate-neither triage) also learned to reject its outputs, invent their own hallucination fire-drills, and divert the reclaimed hours into deeper user research, thereby transforming efficiency into innovation. The implications of the approach we explore shows that: we can transform AI uptake into an assessable design habit; that rewarding selective non-use cultivates hallucination-aware workflows; and, practically, that a coordinated bundle of tool access, reflection, role tagging, and public recognition through competition awards allows AI based innovation in education to scale without compromising accountability.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations](https://arxiv.org/abs/2510.19864)
*Amila Indika,Igor Molybog*

Main category: cs.SE

TL;DR: 该论文引入了电子表格操作文档（SOD）这一AI任务，旨在为电子表格操作生成人类可读的解释，以解决电子表格缺乏系统文档的问题。


<details>
  <summary>Details</summary>
Motivation: 电子表格缺乏系统文档阻碍了自动化、协作和知识转移，并可能导致重要的机构知识丢失。

Method: 创建了一个包含111个电子表格操作代码片段及其对应自然语言摘要的基准。评估了GPT-4o、GPT-4o-mini、LLaMA-3.3-70B、Mixtral-8x7B和Gemma2-9B五种大型语言模型（LLM）在该任务上的表现，并使用BLEU、GLEU、ROUGE-L和METEOR等指标进行评估。

Result: 研究表明，大型语言模型能够生成准确的电子表格文档，证实了SOD作为提高电子表格可复现性、可维护性和协作性工作流程的先决步骤的可行性。

Conclusion: SOD是一个可行的任务，可以提高电子表格的可复现性、可维护性和协作性，但仍存在一些挑战需要解决。

Abstract: Numerous knowledge workers utilize spreadsheets in business, accounting, and finance. However, a lack of systematic documentation methods for spreadsheets hinders automation, collaboration, and knowledge transfer, which risks the loss of crucial institutional knowledge. This paper introduces Spreadsheet Operations Documentation (SOD), an AI task that involves generating human-readable explanations from spreadsheet operations. Many previous studies have utilized Large Language Models (LLMs) for generating spreadsheet manipulation code; however, translating that code into natural language for SOD is a less-explored area. To address this, we present a benchmark of 111 spreadsheet manipulation code snippets, each paired with a corresponding natural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini, LLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and METEOR metrics. Our findings suggest that LLMs can generate accurate spreadsheet documentation, making SOD a feasible prerequisite step toward enhancing reproducibility, maintainability, and collaborative workflows in spreadsheets, although there are challenges that need to be addressed.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [7] [LinkML: An Open Data Modeling Framework](https://arxiv.org/abs/2511.16935)
*Sierra A. T. Moxon,Harold Solbrig,Nomi L. Harris,Patrick Kalita,Mark A. Miller,Sujay Patil,Kevin Schaper,Chris Bizon,J. Harry Caufield,Silvano Cirujano Cuesta,Corey Cox,Frank Dekervel,Damion M. Dooley,William D. Duncan,Tim Fliss,Sarah Gehrke,Adam S. L. Graefe,Harshad Hegde,AJ Ireland,Julius O. B. Jacobsen,Madan Krishnamurthy,Carlo Kroll,David Linke,Ryan Ly,Nicolas Matentzoglu,James A. Overton,Jonny L. Saunders,Deepak R. Unni,Gaurav Vaidya,Wouter-Michiel A. M. Vierdag,LinkML Community Contributors,Oliver Ruebel,Christopher G. Chute,Matthew H. Brush,Melissa A. Haendel,Christopher J. Mungall*

Main category: cs.DB

TL;DR: LinkML是一个开源框架，用于简化数据的创建、验证和共享，它通过提供标准化的模式描述语言，减少数据异构性，提高数据互操作性和可复用性，并支持FAIR数据标准。


<details>
  <summary>Details</summary>
Motivation: 现有科研数据存储格式（如自由文本、非标准化电子表格）缺乏结构化，阻碍了数据的互操作性、集成、验证和重用。LinkML旨在解决这一问题。

Method: LinkML提供了一个易于使用的框架和语法，用于描述数据结构（从简单列表到复杂规范化模型），并支持多态和复合继承。它不依赖于特定的技术架构，可以与现有框架集成，并允许模型定义模式、类和关系，支持模式的导入和导出，并可选择性地与本体对齐。

Result: LinkML已被多个领域采用，包括生物学、化学、生物医学、金融、工程等，成功减少了数据模型中的异构性和复杂性，同时支持了FAIR数据标准，使隐式模型变得显式可计算，并在数据源头实现数据标准化。

Conclusion: LinkML是一个易于使用的平台，促进了跨学科协作，并为定义和共享数据语义提供了一种可靠的方式，从而提高了数据的标准化程度和互操作性。

Abstract: Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult. LinkML (Linked Data Modeling Language) is an open framework that simplifies the process of authoring, validating, and sharing data. LinkML can describe a range of data structures, from flat, list-based models to complex, interrelated, and normalized models that utilize polymorphism and compound inheritance. It offers an approachable syntax that is not tied to any one technical architecture and can be integrated seamlessly with many existing frameworks. The LinkML syntax provides a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas. These key features make LinkML an accessible platform for interdisciplinary collaboration and a reliable way to define and share data semantics.
  LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development. In short, LinkML makes implicit models explicitly computable and allows data to be standardized at its origin. LinkML documentation and code are available at linkml.io.

</details>
