{"id": "2508.11715", "title": "Benchmark Dataset Generation and Evaluation for Excel Formula Repair with LLMs", "url": "https://arxiv.org/abs/2508.11715", "pdf": "https://arxiv.org/pdf/2508.11715", "abs": "https://arxiv.org/abs/2508.11715", "authors": ["Ananya Singha", "Harshita Sahijwani", "Walt Williams", "Emmanuel Aboah Boateng", "Nick Hausman", "Miguel Di Luca", "Keegan Choudhury", "Chaya Binet", "Vu Le", "Tianwei Chen", "Oryan Rokeah Chen", "Sulaiman Vesal", "Sadid Hasan"], "categories": ["cs.SE", "cs.AI"], "comment": "Accepted at the KDD workshop on Evaluation and Trustworthiness of\n  Agentic and Generative AI Models", "summary": "Excel is a pervasive yet often complex tool, particularly for novice users,\nwhere runtime errors arising from logical mistakes or misinterpretations of\nfunctions pose a significant challenge. While large language models (LLMs)\noffer promising assistance by explaining formula errors, the automated\ncorrection of these semantic runtime errors remains an open problem. A primary\nchallenge to advancing models for such scenarios is the severe lack of\nhigh-quality, comprehensive datasets for training and rigorous evaluation. This\npaper addresses this gap by introducing a novel approach for constructing a\nbenchmark dataset specifically designed for Excel formula repair. We propose a\ndata generation pipeline, which leverages a small set of curated seed samples\nfrom online forums to synthetically expand the dataset. Our pipeline integrates\nfew-shot prompting with LLMs and employs a robust \\textit{LLM-as-a-Judge}\nvalidation framework, combined with execution-based checks to ensure the\ncorrectness and semantic fidelity of the generated data. This process produced\na benchmark dataset of 618 high-quality samples, covering common runtime\nerrors. Furthermore, we propose a context-aware baseline technique for Excel\nformula repair that utilizes LLMs to leverage both the faulty formula, and\nrelevant spreadsheet context. We evaluate the performance of various LLMs\n(GPT-4o, GPT-4.1, Phi-3, Mistral) on our newly generated benchmark using\nexecution-based metrics. Our analysis demonstrates the dataset's quality\nthrough manual annotation and provides insights into error and function\ndistributions. The proposed generation methodology is highly scalable and can\nbe readily adapted to create evaluation benchmarks for similar code repair\ntasks in other low-resource programming languages.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6784\u5efa\u9ad8\u8d28\u91cfExcel\u516c\u5f0f\u4fee\u590d\u57fa\u51c6\u6570\u636e\u96c6\u7684\u65b0\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528LLM\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684Excel\u516c\u5f0f\u4fee\u590d\u57fa\u7ebf\u6280\u672f\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u79cdLLM\u5728\u6b64\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "Excel\u65b0\u624b\u7528\u6237\u5728\u5904\u7406\u8fd0\u884c\u65f6\u9519\u8bef\u65f6\u9762\u4e34\u6311\u6218\u3002\u5c3d\u7ba1LLM\u80fd\u89e3\u91ca\u9519\u8bef\uff0c\u4f46\u81ea\u52a8\u4fee\u590d\u8bed\u4e49\u8fd0\u884c\u65f6\u9519\u8bef\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u5229\u7528\u5c11\u91cf\u5728\u7ebf\u8bba\u575b\u7684\u79cd\u5b50\u6837\u672c\u6765\u5408\u6210\u6269\u5c55\u6570\u636e\u96c6\u3002\u8be5\u7ba1\u9053\u7ed3\u5408\u4e86LLM\u7684\u5c11\u6837\u672c\u63d0\u793a\u548c\u201cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u201d\u9a8c\u8bc1\u6846\u67b6\uff0c\u5e76\u8f85\u4ee5\u57fa\u4e8e\u6267\u884c\u7684\u68c0\u67e5\u4ee5\u786e\u4fdd\u6570\u636e\u6b63\u786e\u6027\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u7684Excel\u516c\u5f0f\u4fee\u590d\u57fa\u7ebf\u6280\u672f\uff0c\u5229\u7528LLM\u7ed3\u5408\u9519\u8bef\u516c\u5f0f\u548c\u76f8\u5173\u7684\u7535\u5b50\u8868\u683c\u4e0a\u4e0b\u6587\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b618\u4e2a\u9ad8\u8d28\u91cf\u6837\u672c\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e86\u5e38\u89c1\u7684\u8fd0\u884c\u65f6\u9519\u8bef\u3002\u4f7f\u7528\u57fa\u4e8e\u6267\u884c\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u8bc4\u4f30\u4e86\u591a\u79cdLLM\uff08GPT-4o, GPT-4.1, Phi-3, Mistral\uff09\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002\u5206\u6790\u7ed3\u679c\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u7684\u8d28\u91cf\uff0c\u5e76\u63d0\u4f9b\u4e86\u9519\u8bef\u548c\u51fd\u6570\u5206\u5e03\u7684\u89c1\u89e3\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u53ef\u6269\u5c55\u6027\uff0c\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u9002\u7528\u4e8e\u4e3a\u5176\u4ed6\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u4e2d\u7c7b\u4f3c\u7684\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u521b\u5efa\u8bc4\u4f30\u57fa\u51c6\u3002"}}
