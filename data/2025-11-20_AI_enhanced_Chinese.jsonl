{"id": "2511.06973", "title": "Oh That Looks Familiar: A Novel Similarity Measure for Spreadsheet Template Discovery", "url": "https://arxiv.org/abs/2511.06973", "pdf": "https://arxiv.org/pdf/2511.06973", "abs": "https://arxiv.org/abs/2511.06973", "authors": ["Anand Krishnakumar", "Vengadesh Ravikumaran"], "categories": ["cs.LG", "cs.CV"], "comment": "5 pages, 2 figures, Accepted to EurIPS'25: AI for Tabular Data Workshop", "summary": "Traditional methods for identifying structurally similar spreadsheets fail to capture the spatial layouts and type patterns defining templates. To quantify spreadsheet similarity, we introduce a hybrid distance metric that combines semantic embeddings, data type information, and spatial positioning. In order to calculate spreadsheet similarity, our method converts spreadsheets into cell-level embeddings and then uses aggregation techniques like Chamfer and Hausdorff distances. Experiments across template families demonstrate superior unsupervised clustering performance compared to the graph-based Mondrian baseline, achieving perfect template reconstruction (Adjusted Rand Index of 1.00 versus 0.90) on the FUSTE dataset. Our approach facilitates large-scale automated template discovery, which in turn enables downstream applications such as retrieval-augmented generation over tabular collections, model training, and bulk data cleaning.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-flash-preview-05-20 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
{"id": "2507.13558", "title": "Why Isn't Relational Learning Taking Over the World?", "url": "https://arxiv.org/abs/2507.13558", "pdf": "https://arxiv.org/pdf/2507.13558", "abs": "https://arxiv.org/abs/2507.13558", "authors": ["David Poole"], "categories": ["cs.AI", "cs.DB", "cs.LG"], "comment": "10 pages (6 pages + references + appendices). To appear AAAI-2026", "summary": "Artificial intelligence seems to be taking over the world with systems that model pixels, words, and phonemes. The world is arguably made up, not of pixels, words, and phonemes but of entities (objects, things, including events) with properties and relations among them. Surely we should model these, not the perception or description of them. You might suspect that concentrating on modeling words and pixels is because all of the (valuable) data in the world is in terms of text and images. If you look into almost any company you will find their most valuable data is in spreadsheets, databases and other relational formats. These are not the form that are studied in introductory machine learning, but are full of product numbers, student numbers, transaction numbers and other identifiers that can't be interpreted naively as numbers. The field that studies this sort of data has various names including relational learning, statistical relational AI, and many others. This paper explains why relational learning is not taking over the world -- except in a few cases with restricted relations -- and what needs to be done to bring it to it's rightful prominence.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-flash-preview-05-20 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
{"id": "2209.14457", "title": "Consensus-Free Spreadsheet Integration", "url": "https://arxiv.org/abs/2209.14457", "pdf": "https://arxiv.org/pdf/2209.14457", "abs": "https://arxiv.org/abs/2209.14457", "authors": ["Brandon Baylor", "Eric Daimler", "James Hansen", "Esteban Montero", "Ryan Wisnesky"], "categories": ["cs.DB", "cs.SE"], "comment": null, "summary": "We describe a method for merging multiple spreadsheets into one sheet, and/or exchanging data among the sheets, by expressing each sheet's formulae as an algebraic (equational) theory and each sheet's values as a model of its theory, expressing the overlap between the sheets as theory and model morphisms, and then performing colimit, lifting, and Kan-extension constructions from category theory to compute a canonically universal integrated theory and model, which can then be expressed as a spreadsheet. Our motivation is to find methods of merging engineering models that do not require consensus (agreement) among the authors of the models being merged, a condition fulfilled by our method because theory and model morphisms are semantics-preserving. We describe a case study of this methodology on a real-world oil and gas calculation at a major energy company, describing the theories and models that arise when integrating two different casing pressure test (MASP) calculation spreadsheets constructed by two non-interacting engineers. We also describe the automated theorem proving burden associated with both verifying the semantics preservation of the overlap mappings as well as verifying the conservativity/consistency of the resulting integrated sheet. We conclude with thoughts on how to apply the methodology to scale engineering efforts across the enterprise.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-flash-preview-05-20 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
{"id": "2503.12345", "title": "General Table Question Answering via Answer-Formula Joint Generation", "url": "https://arxiv.org/abs/2503.12345", "pdf": "https://arxiv.org/pdf/2503.12345", "abs": "https://arxiv.org/abs/2503.12345", "authors": ["Zhongyuan Wang", "Richong Zhang", "Zhijie Nie", "Hangyu Mao"], "categories": ["cs.CL", "cs.AI"], "comment": "work in progress", "summary": "Advanced table question answering (TableQA) methods prompt large language models (LLMs) to generate answer text, SQL query, Python code, or custom operation, which impressively improve the complex reasoning problems in the TableQA task. However, these methods lack the versatility to cope with specific question types or table structures. In contrast, the Spreadsheet Formula, the widely used and well-defined operation language for tabular data, has not been thoroughly explored to solve TableQA. In this paper, we first attempt to use the Formula as the executable representation for solving complex reasoning on tables with different structures. Specifically, we construct \\texttt{FromulaQA}, a large Formula-annotated TableQA dataset from existing datasets. In addition, we propose \\texttt{TabAF}, a general table answering framework to solve multiple types of tasks over multiple types of tables simultaneously, which decodes answers and Formulas with a single LLM backbone. Extensive experiments demonstrate the versatility and generalization of \\texttt{TabAF}. Under the same model size, \\texttt{TabAF} achieves new state-of-the-art performance on the WikiTableQuestion, HiTab, and TabFact.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-flash-preview-05-20 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
{"id": "2502.09787", "title": "TableTalk: Scaffolding Spreadsheet Development with a Language Agent", "url": "https://arxiv.org/abs/2502.09787", "pdf": "https://arxiv.org/pdf/2502.09787", "abs": "https://arxiv.org/abs/2502.09787", "authors": ["Jenny T. Liang", "Aayush Kumar", "Yasharth Bajpai", "Sumit Gulwani", "Vu Le", "Chris Parnin", "Arjun Radhakrishna", "Ashish Tiwari", "Emerson Murphy-Hill", "Guastavo Soares"], "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": null, "summary": "Spreadsheet programming is challenging. Programmers use spreadsheet programming knowledge (e.g., formulas) and problem-solving skills to combine actions into complex tasks. Advancements in large language models have introduced language agents that observe, plan, and perform tasks, showing promise for spreadsheet creation. We present TableTalk, a spreadsheet programming agent embodying three design principles -- scaffolding, flexibility, and incrementality -- derived from studies with seven spreadsheet programmers and 85 Excel templates. TableTalk guides programmers through structured plans based on professional workflows, generating three potential next steps to adapt plans to programmer needs. It uses pre-defined tools to generate spreadsheet components and incrementally build spreadsheets. In a study with 20 programmers, TableTalk produced higher-quality spreadsheets 2.3 times more likely to be preferred than the baseline. It reduced cognitive load and thinking time by 12.6%. From this, we derive design guidelines for agentic spreadsheet programming tools and discuss implications on spreadsheet programming, end-user programming, AI-assisted programming, and human-agent collaboration.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-flash-preview-05-20 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
{"id": "2506.05587", "title": "MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark", "url": "https://arxiv.org/abs/2506.05587", "pdf": "https://arxiv.org/pdf/2506.05587", "abs": "https://arxiv.org/abs/2506.05587", "authors": ["Junjie Xing", "Yeye He", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Lingjiao Chen", "Dongmei Zhang", "Surajit Chaudhuri", "H. V. Jagadish"], "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "comment": "Included additional benchmark results covering 24 LLMs", "summary": "Tables and table-based use cases play a crucial role in many important real-world applications, such as spreadsheets, databases, and computational notebooks, which traditionally require expert-level users like data engineers, data analysts, and database administrators to operate. Although LLMs have shown remarkable progress in working with tables (e.g., in spreadsheet and database copilot scenarios), comprehensive benchmarking of such capabilities remains limited. In contrast to an extensive and growing list of NLP benchmarks, evaluations of table-related tasks are scarce, and narrowly focus on tasks like NL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks that professional users face. This gap limits our understanding and model progress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 30K questions across 25 real-world table tasks, designed to comprehensively evaluate models ability to understand, reason, and manipulate real tables at the expert-level. These tasks are drawn from decades' worth of computer science research on tabular data, with a focus on complex table tasks faced by professional users. We show that MMTU require a combination of skills -- including table understanding, reasoning, and coding -- that remain challenging for today's frontier models, where even frontier reasoning models like OpenAI o4-mini and DeepSeek R1 score only around 60%, suggesting significant room for improvement. We highlight key findings in our evaluation using MMTU and hope that this benchmark drives further advances in understanding and developing foundation models for structured data processing and analysis. Our code and data are available at https://github.com/MMTU-Benchmark/MMTU and https://huggingface.co/datasets/MMTU-benchmark/MMTU.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-flash-preview-05-20 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
{"id": "2507.22391", "title": "Knowledge engineering for open science: Building and deploying knowledge bases for metadata standards", "url": "https://arxiv.org/abs/2507.22391", "pdf": "https://arxiv.org/pdf/2507.22391", "abs": "https://arxiv.org/abs/2507.22391", "authors": ["Mark A. Musen", "Martin J. O'Connor", "Josef Hardi", "Marcos Martinez-Romero"], "categories": ["cs.DL"], "comment": "22 pages, 7 figures", "summary": "Scientists strive to make their datasets available in open repositories, with the goal that they be findable, accessible, interoperable, and reusable (FAIR). Although it is hard for most investigators to remember all the guiding principles associated with FAIR data, there is one overarching requirement: The data need to be annotated with rich, discipline-specific, standardized metadata. The Center for Expanded Data Annotation and Retrieval (CEDAR) builds technology that enables scientists to encode metadata standards as templates that enumerate the attributes of different kinds of experiments. These metadata templates capture preferences regarding how data should be described and what a third party needs to know to make sense of the datasets. CEDAR templates describing community metadata preferences have been used to standardize metadata for a variety of scientific consortia. They have been used as the basis for data-annotation systems that acquire metadata through Web forms or through spreadsheets, and they can help correct metadata to ensure adherence to standards. Like the declarative knowledge bases that underpinned intelligent systems decades ago, CEDAR templates capture the knowledge in symbolic form, and they allow that knowledge to be applied in a variety of settings. They provide a mechanism for scientific communities to create shared metadata standards and to encode their preferences for the application of those standards, and for deploying those standards in a range of intelligent systems to promote open science.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-flash-preview-05-20 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
{"id": "2408.08068", "title": "The Paradox of Spreadsheet Self-Efficacy: Social Incentives for Informal Knowledge Sharing in End-User Programming", "url": "https://arxiv.org/abs/2408.08068", "pdf": "https://arxiv.org/pdf/2408.08068", "abs": "https://arxiv.org/abs/2408.08068", "authors": ["Qing", "Xia", "Advait Sarkar", "Duncan P. Brumby", "Anna Cox"], "categories": ["cs.HC"], "comment": "8 pages", "summary": "Informal Knowledge Sharing (KS) is vital for end-user programmers to gain expertise. To better understand how personal (self-efficacy), social (reputational gains, trust between colleagues), and software-related (codification effort) variables influence spreadsheet KS intention, we conducted a multiple regressions analysis based on survey data from spreadsheet users (n=100) in administrative and finance roles. We found that high levels of spreadsheet self-efficacy and a perception that sharing would result in reputational gains predicted higher KS intention, but individuals who found knowledge codification effortful showed lower KS intention. We also observed that regardless of occupation, users tended to report a lower sense of self-efficacy in their general spreadsheet proficiency, despite also reporting high self-efficacy in spreadsheet use for job-related contexts. Our findings suggest that acknowledging and designing for these social and personal variables can help avoid situations where experienced individuals refrain unnecessarily from sharing, with implications for spreadsheet design.", "AI": {"tldr": "Unexpected Error", "motivation": "Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-flash-preview-05-20 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]", "method": "N/A", "result": "N/A", "conclusion": "N/A"}}
