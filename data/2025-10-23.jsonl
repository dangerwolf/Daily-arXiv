{"id": "2510.19342", "title": "To Use or to Refuse? Re-Centering Student Agency with Generative AI in Engineering Design Education", "url": "https://arxiv.org/abs/2510.19342", "pdf": "https://arxiv.org/pdf/2510.19342", "abs": "https://arxiv.org/abs/2510.19342", "authors": ["Thijs Willems", "Sumbul Khan", "Qian Huang", "Bradley Camburn", "Nachamma Sockalingam", "King Wang Poon"], "categories": ["cs.CY", "cs.AI"], "comment": "to be published in IEEE TALE 2025", "summary": "This pilot study traces students' reflections on the use of AI in a 13-week\nfoundational design course enrolling over 500 first-year engineering and\narchitecture students at the Singapore University of Technology and Design. The\ncourse was an AI-enhanced design course, with several interventions to equip\nstudents with AI based design skills. Students were required to reflect on\nwhether the technology was used as a tool (instrumental assistant), a teammate\n(collaborative partner), or neither (deliberate non-use). By foregrounding this\nthree-way lens, students learned to use AI for innovation rather than just\nautomation and to reflect on agency, ethics, and context rather than on prompt\ncrafting alone. Evidence stems from coursework artefacts: thirteen structured\nreflection spreadsheets and eight illustrated briefs submitted, combined with\nnotes of teachers and researchers. Qualitative coding of these materials\nreveals shared practices brought about through the inclusion of Gen-AI,\nincluding accelerated prototyping, rapid skill acquisition, iterative prompt\nrefinement, purposeful \"switch-offs\" during user research, and emergent\nroutines for recognizing hallucinations. Unexpectedly, students not only\nharnessed Gen-AI for speed but (enabled by the tool-teammate-neither triage)\nalso learned to reject its outputs, invent their own hallucination fire-drills,\nand divert the reclaimed hours into deeper user research, thereby transforming\nefficiency into innovation. The implications of the approach we explore shows\nthat: we can transform AI uptake into an assessable design habit; that\nrewarding selective non-use cultivates hallucination-aware workflows; and,\npractically, that a coordinated bundle of tool access, reflection, role\ntagging, and public recognition through competition awards allows AI based\ninnovation in education to scale without compromising accountability."}
{"id": "2510.19247", "title": "SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets", "url": "https://arxiv.org/abs/2510.19247", "pdf": "https://arxiv.org/pdf/2510.19247", "abs": "https://arxiv.org/abs/2510.19247", "authors": ["Ziwei Wang", "Jiayuan Su", "Mengyu Zhou", "Huaxing Zeng", "Mengni Jia", "Xiao Lv", "Haoyu Dong", "Xiaojun Ma", "Shi Han", "Dongmei Zhang"], "categories": ["cs.CL"], "comment": null, "summary": "Understanding and reasoning over complex spreadsheets remain fundamental\nchallenges for large language models (LLMs), which often struggle with\naccurately capturing the complex structure of tables and ensuring reasoning\ncorrectness. In this work, we propose SheetBrain, a neuro-symbolic dual\nworkflow agent framework designed for accurate reasoning over tabular data,\nsupporting both spreadsheet question answering and manipulation tasks.\nSheetBrain comprises three core modules: an understanding module, which\nproduces a comprehensive overview of the spreadsheet - including sheet summary\nand query-based problem insight to guide reasoning; an execution module, which\nintegrates a Python sandbox with preloaded table-processing libraries and an\nExcel helper toolkit for effective multi-turn reasoning; and a validation\nmodule, which verifies the correctness of reasoning and answers, triggering\nre-execution when necessary. We evaluate SheetBrain on multiple public tabular\nQA and manipulation benchmarks, and introduce SheetBench, a new benchmark\ntargeting large, multi-table, and structurally complex spreadsheets.\nExperimental results show that SheetBrain significantly improves accuracy on\nboth existing benchmarks and the more challenging scenarios presented in\nSheetBench. Our code is publicly available at\nhttps://github.com/microsoft/SheetBrain."}
{"id": "2508.00472", "title": "A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces", "url": "https://arxiv.org/abs/2508.00472", "pdf": "https://arxiv.org/pdf/2508.00472", "abs": "https://arxiv.org/abs/2508.00472", "authors": ["Leonidas Akritidis", "Panayiotis Bozanis"], "categories": ["cs.LG"], "comment": null, "summary": "The tabular form constitutes the standard way of representing data in\nrelational database systems and spreadsheets. But, similarly to other forms,\ntabular data suffers from class imbalance, a problem that causes serious\nperformance degradation in a wide variety of machine learning tasks. One of the\nmost effective solutions dictates the usage of Generative Adversarial Networks\n(GANs) in order to synthesize artificial data instances for the\nunder-represented classes. Despite their good performance, none of the proposed\nGAN models takes into account the vector subspaces of the input samples in the\nreal data space, leading to data generation in arbitrary locations. Moreover,\nthe class labels are treated in the same manner as the other categorical\nvariables during training, so conditional sampling by class is rendered less\neffective. To overcome these problems, this study presents ctdGAN, a\nconditional GAN for alleviating class imbalance in tabular datasets. Initially,\nctdGAN executes a space partitioning step to assign cluster labels to the input\nsamples. Subsequently, it utilizes these labels to synthesize samples via a\nnovel probabilistic sampling strategy and a new loss function that penalizes\nboth cluster and class mis-predictions. In this way, ctdGAN is trained to\ngenerate samples in subspaces that resemble those of the original data\ndistribution. We also introduce several other improvements, including a simple,\nyet effective cluster-wise scaling technique that captures multiple feature\nmodes without affecting data dimensionality. The exhaustive evaluation of\nctdGAN with 14 imbalanced datasets demonstrated its superiority in generating\nhigh fidelity samples and improving classification accuracy."}
{"id": "2508.00217", "title": "Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges", "url": "https://arxiv.org/abs/2508.00217", "pdf": "https://arxiv.org/pdf/2508.00217", "abs": "https://arxiv.org/abs/2508.00217", "authors": ["Xiaofeng Wu", "Alan Ritter", "Wei Xu"], "categories": ["cs.CL", "cs.DB", "cs.LG"], "comment": null, "summary": "Tables have gained significant attention in large language models (LLMs) and\nmultimodal large language models (MLLMs) due to their complex and flexible\nstructure. Unlike linear text inputs, tables are two-dimensional, encompassing\nformats that range from well-structured database tables to complex,\nmulti-layered spreadsheets, each with different purposes. This diversity in\nformat and purpose has led to the development of specialized methods and tasks,\ninstead of universal approaches, making navigation of table understanding tasks\nchallenging. To address these challenges, this paper introduces key concepts\nthrough a taxonomy of tabular input representations and an introduction of\ntable understanding tasks. We highlight several critical gaps in the field that\nindicate the need for further research: (1) the predominance of\nretrieval-focused tasks that require minimal reasoning beyond mathematical and\nlogical operations; (2) significant challenges faced by models when processing\ncomplex table structures, large-scale tables, length context, or multi-table\nscenarios; and (3) the limited generalization of models across different\ntabular representations and formats."}
