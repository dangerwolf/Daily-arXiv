<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets](https://arxiv.org/abs/2510.19247)
*Ziwei Wang,Jiayuan Su,Mengyu Zhou,Huaxing Zeng,Mengni Jia,Xiao Lv,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: SheetBrain是一个用于处理复杂电子表格的神经-符号双工作流代理框架，能够支持电子表格问答和操作任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在理解和推理复杂电子表格时存在挑战，难以准确捕捉表格结构和确保推理的正确性。

Method: SheetBrain框架包含三个核心模块：1. 理解模块：生成电子表格的全面概述，包括表格摘要和基于查询的问题洞察。2. 执行模块：集成Python沙盒、预加载的表格处理库和Excel助手工具包，以实现有效的多轮推理。3. 验证模块：验证推理和答案的正确性，并在必要时触发重新执行。

Result: SheetBrain在多个公开的表格问答和操作基准测试以及新的SheetBench基准测试（包含大型、多表格、结构复杂的电子表格）上显著提高了准确性。

Conclusion: SheetBrain能够显著提高在现有基准测试和更具挑战性的复杂电子表格场景下的准确性。

Abstract: Understanding and reasoning over complex spreadsheets remain fundamental challenges for large language models (LLMs), which often struggle with accurately capturing the complex structure of tables and ensuring reasoning correctness. In this work, we propose SheetBrain, a neuro-symbolic dual workflow agent framework designed for accurate reasoning over tabular data, supporting both spreadsheet question answering and manipulation tasks. SheetBrain comprises three core modules: an understanding module, which produces a comprehensive overview of the spreadsheet - including sheet summary and query-based problem insight to guide reasoning; an execution module, which integrates a Python sandbox with preloaded table-processing libraries and an Excel helper toolkit for effective multi-turn reasoning; and a validation module, which verifies the correctness of reasoning and answers, triggering re-execution when necessary. We evaluate SheetBrain on multiple public tabular QA and manipulation benchmarks, and introduce SheetBench, a new benchmark targeting large, multi-table, and structurally complex spreadsheets. Experimental results show that SheetBrain significantly improves accuracy on both existing benchmarks and the more challenging scenarios presented in SheetBench. Our code is publicly available at https://github.com/microsoft/SheetBrain.

</details>


### [2] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: LLMs在处理表格数据时面临结构复杂性、多样性和推理能力不足等挑战，需要进一步研究以实现跨格式的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 表格数据在LLMs和MLLMs中因其复杂性和灵活性而受到关注，但其二维结构和多样性带来了挑战，导致缺乏通用方法。本研究旨在通过分类和任务介绍来解决这些问题。

Method: 本研究通过引入表格输入表示的分类法和表格理解任务来解决表格数据处理的挑战。

Result: 当前研究主要集中在检索任务，模型在处理复杂结构、大规模、长上下文或多表格场景时遇到困难，且模型在不同表格表示和格式之间的泛化能力有限。

Conclusion: 现有研究在表格理解方面存在关键差距，尤其是在推理能力、处理复杂表格结构和大规模数据、以及跨不同表格表示和格式的泛化方面，这些都需要进一步的研究来弥补。

Abstract: Tables have gained significant attention in large language models (LLMs) and multimodal large language models (MLLMs) due to their complex and flexible structure. Unlike linear text inputs, tables are two-dimensional, encompassing formats that range from well-structured database tables to complex, multi-layered spreadsheets, each with different purposes. This diversity in format and purpose has led to the development of specialized methods and tasks, instead of universal approaches, making navigation of table understanding tasks challenging. To address these challenges, this paper introduces key concepts through a taxonomy of tabular input representations and an introduction of table understanding tasks. We highlight several critical gaps in the field that indicate the need for further research: (1) the predominance of retrieval-focused tasks that require minimal reasoning beyond mathematical and logical operations; (2) significant challenges faced by models when processing complex table structures, large-scale tables, length context, or multi-table scenarios; and (3) the limited generalization of models across different tabular representations and formats.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [3] [To Use or to Refuse? Re-Centering Student Agency with Generative AI in Engineering Design Education](https://arxiv.org/abs/2510.19342)
*Thijs Willems,Sumbul Khan,Qian Huang,Bradley Camburn,Nachamma Sockalingam,King Wang Poon*

Main category: cs.CY

TL;DR: 本研究追踪了新加坡科技设计大学一个包含500多名一年级工程和建筑学生的为期13周的基础设计课程中，学生对人工智能使用的反思。该课程是人工智能增强型设计课程，并包含多项旨在为学生提供人工智能辅助设计技能的干预措施。通过“工具”、“队友”或“两者皆非”这三种方式，学生们学会了将人工智能用于创新而非仅仅是自动化，并着重于能动性、伦理和背景的思考，而非仅仅关注提示词的制作。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索如何在基础设计课程中有效利用人工智能（AI），引导学生从仅仅依赖AI自动化转向利用AI进行创新，并反思AI使用的能动性、伦理和背景。

Method: 通过对13周课程中的课程作业、13份结构化反思电子表格、8份图文并茂的简报以及教师和研究人员的笔记进行定性编码，分析学生在使用AI作为工具、队友或两者皆非时的反思和实践。

Result: 研究发现，学生们不仅利用AI加速原型制作、快速学习技能、改进提示词和识别AI幻觉，还学会了拒绝不合适的AI输出，发明“幻觉应对机制”，并将节省的时间用于更深入的用户研究，从而将效率转化为创新。

Conclusion: 研究表明，可以将AI的采纳转化为可评估的设计习惯，奖励选择性“不使用”AI可以培养具有幻觉意识的工作流程。通过提供工具访问、反思、角色标记和通过竞赛奖励相结合的协调方法，可以在教育中规模化AI驱动的创新，同时不损害问责制。

Abstract: This pilot study traces students' reflections on the use of AI in a 13-week foundational design course enrolling over 500 first-year engineering and architecture students at the Singapore University of Technology and Design. The course was an AI-enhanced design course, with several interventions to equip students with AI based design skills. Students were required to reflect on whether the technology was used as a tool (instrumental assistant), a teammate (collaborative partner), or neither (deliberate non-use). By foregrounding this three-way lens, students learned to use AI for innovation rather than just automation and to reflect on agency, ethics, and context rather than on prompt crafting alone. Evidence stems from coursework artefacts: thirteen structured reflection spreadsheets and eight illustrated briefs submitted, combined with notes of teachers and researchers. Qualitative coding of these materials reveals shared practices brought about through the inclusion of Gen-AI, including accelerated prototyping, rapid skill acquisition, iterative prompt refinement, purposeful "switch-offs" during user research, and emergent routines for recognizing hallucinations. Unexpectedly, students not only harnessed Gen-AI for speed but (enabled by the tool-teammate-neither triage) also learned to reject its outputs, invent their own hallucination fire-drills, and divert the reclaimed hours into deeper user research, thereby transforming efficiency into innovation. The implications of the approach we explore shows that: we can transform AI uptake into an assessable design habit; that rewarding selective non-use cultivates hallucination-aware workflows; and, practically, that a coordinated bundle of tool access, reflection, role tagging, and public recognition through competition awards allows AI based innovation in education to scale without compromising accountability.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [IIKL: Isometric Immersion Kernel Learning with Riemannian Manifold for Geometric Preservation](https://arxiv.org/abs/2505.06288)
*Zihao Chen,Wenyong Wang,Jiachen Yang,Yu Xiang*

Main category: cs.LG

TL;DR: 通过等距浸入核学习（IIKL）方法，在非欧几里得数据表示学习中保持了数据的内在几何结构，提高了下游任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将非欧几里得离散数据映射到欧几里得空间，可能丢失关键几何信息，因此需要新的方法来保持数据的内在几何和拓扑性质。

Method: 提出了一种新颖的等距浸入核学习（IIKL）方法，构建黎曼流形并从离散的非欧几里得数据中诱导出黎曼度量。将等距浸入等同于流形上切线丛中的核函数，确保了向量内积在任意切线空间中的不变性。引入了基于IIKL的参数化学习模型，并使用最大似然估计（MLE）推导出交替训练方法。

Result: IIKL方法成功地在3D和高维数据集的内在几何表示，并显著提高了数据重建和分类等下游任务的准确性。与现有SOTA方法相比，内积不变性损失减少了90%以上，几何度量（等距和共形）的误差减少了90%，下游重建准确性平均提高了40%。

Conclusion: IIKL方法有效地保持了离散非欧几里得数据的内在几何结构，并在各种下游任务中取得了显著的性能提升，为非欧几里得数据表示学习提供了一种新的有效途径。

Abstract: Geometric representation learning in preserving the intrinsic geometric and topological properties for discrete non-Euclidean data is crucial in scientific applications. Previous research generally mapped non-Euclidean discrete data into Euclidean space during representation learning, which may lead to the loss of some critical geometric information. In this paper, we propose a novel Isometric Immersion Kernel Learning (IIKL) method to build Riemannian manifold and isometrically induce Riemannian metric from discrete non-Euclidean data. We prove that Isometric immersion is equivalent to the kernel function in the tangent bundle on the manifold, which explicitly guarantees the invariance of the inner product between vectors in the arbitrary tangent space throughout the learning process, thus maintaining the geometric structure of the original data. Moreover, a novel parameterized learning model based on IIKL is introduced, and an alternating training method for this model is derived using Maximum Likelihood Estimation (MLE), ensuring efficient convergence. Experimental results proved that using the learned Riemannian manifold and its metric, our model preserved the intrinsic geometric representation of data in both 3D and high-dimensional datasets successfully, and significantly improved the accuracy of downstream tasks, such as data reconstruction and classification. It is showed that our method could reduce the inner product invariant loss by more than 90% compared to state-of-the-art (SOTA) methods, also achieved an average 40% improvement in downstream reconstruction accuracy and a 90% reduction in error for geometric metrics involving isometric and conformal.

</details>


### [5] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: ctdGAN是一种条件生成对抗网络，通过空间划分和概率采样策略来解决表格数据中的类别不平衡问题，提高了生成样本的保真度和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的生成对抗网络（GAN）模型在处理表格数据类别不平衡问题时，未能考虑输入样本的向量子空间，导致生成数据位置任意，并且条件采样效果不佳。

Method: ctdGAN首先执行空间划分步骤为输入样本分配聚类标签，然后利用这些标签通过新颖的概率采样策略和惩罚聚类及类别预测错误的新损失函数来合成样本，从而在与原始数据分布相似的子空间中生成样本。此外，还引入了聚类感知缩放技术来捕捉多特征模式。

Result: ctdGAN在14个不平衡数据集上的广泛评估证明了其在生成高保真样本和提高分类准确性方面的优越性。

Conclusion: ctdGAN通过考虑数据子空间和改进的条件采样机制，有效解决了表格数据类别不平衡问题，提高了生成样本的质量和下游机器学习任务的性能。

Abstract: The tabular form constitutes the standard way of representing data in relational database systems and spreadsheets. But, similarly to other forms, tabular data suffers from class imbalance, a problem that causes serious performance degradation in a wide variety of machine learning tasks. One of the most effective solutions dictates the usage of Generative Adversarial Networks (GANs) in order to synthesize artificial data instances for the under-represented classes. Despite their good performance, none of the proposed GAN models takes into account the vector subspaces of the input samples in the real data space, leading to data generation in arbitrary locations. Moreover, the class labels are treated in the same manner as the other categorical variables during training, so conditional sampling by class is rendered less effective. To overcome these problems, this study presents ctdGAN, a conditional GAN for alleviating class imbalance in tabular datasets. Initially, ctdGAN executes a space partitioning step to assign cluster labels to the input samples. Subsequently, it utilizes these labels to synthesize samples via a novel probabilistic sampling strategy and a new loss function that penalizes both cluster and class mis-predictions. In this way, ctdGAN is trained to generate samples in subspaces that resemble those of the original data distribution. We also introduce several other improvements, including a simple, yet effective cluster-wise scaling technique that captures multiple feature modes without affecting data dimensionality. The exhaustive evaluation of ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating high fidelity samples and improving classification accuracy.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [6] [LinkML: An Open Data Modeling Framework](https://arxiv.org/abs/2511.16935)
*Sierra A. T. Moxon,Harold Solbrig,Nomi L. Harris,Patrick Kalita,Mark A. Miller,Sujay Patil,Kevin Schaper,Chris Bizon,J. Harry Caufield,Silvano Cirujano Cuesta,Corey Cox,Frank Dekervel,Damion M. Dooley,William D. Duncan,Tim Fliss,Sarah Gehrke,Adam S. L. Graefe,Harshad Hegde,AJ Ireland,Julius O. B. Jacobsen,Madan Krishnamurthy,Carlo Kroll,David Linke,Ryan Ly,Nicolas Matentzoglu,James A. Overton,Jonny L. Saunders,Deepak R. Unni,Gaurav Vaidya,Wouter-Michiel A. M. Vierdag,LinkML Community Contributors,Oliver Ruebel,Christopher G. Chute,Matthew H. Brush,Melissa A. Haendel,Christopher J. Mungall*

Main category: cs.DB

TL;DR: LinkML是一个开放框架，用于简化数据的创建、验证和共享，它通过提供一种标准化的方法来描述数据结构和模式，从而减少异构性、复杂性，并促进FAIR数据标准的合规性。


<details>
  <summary>Details</summary>
Motivation: 目前科学研究中的数据存储格式多样且缺乏标准化，例如自由文本的实验记录本、非标准化的电子表格或数据存储库，这给数据的互操作性、集成、验证和重用带来了挑战。

Method: LinkML 提供了一种易于理解的语法，不依赖于任何单一技术架构，可以与许多现有框架无缝集成。它允许描述从扁平的、基于列表的模型到复杂的、相互关联的、利用多态和复合继承的规范化模型。LinkML 模式可以导入到其他 LinkML 模式中，并提供了一种描述模式、类和关系的标准方法，使建模者能够构建定义良好、稳定且可选的与本体对齐的数据结构。

Result: LinkML 减少了异构性、复杂性和一次性数据模型的泛滥，同时实现了对 FAIR 数据标准的遵从。它已被生物学、化学、生物医学、微生物组研究、金融、电气工程、交通和商业软件开发等多个领域采用。

Conclusion: LinkML 使隐式模型显式可计算，并允许数据在源头进行标准化，从而成为跨学科协作的可访问平台以及定义和共享数据语义的可靠方式。

Abstract: Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult. LinkML (Linked Data Modeling Language) is an open framework that simplifies the process of authoring, validating, and sharing data. LinkML can describe a range of data structures, from flat, list-based models to complex, interrelated, and normalized models that utilize polymorphism and compound inheritance. It offers an approachable syntax that is not tied to any one technical architecture and can be integrated seamlessly with many existing frameworks. The LinkML syntax provides a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas. These key features make LinkML an accessible platform for interdisciplinary collaboration and a reliable way to define and share data semantics.
  LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development. In short, LinkML makes implicit models explicitly computable and allows data to be standardized at its origin. LinkML documentation and code are available at linkml.io.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations](https://arxiv.org/abs/2510.19864)
*Amila Indika,Igor Molybog*

Main category: cs.SE

TL;DR: 电子表格缺乏系统性文档方法，阻碍自动化和知识转移。本文提出“电子表格操作文档”（SOD）AI任务，旨在生成人类可读的电子表格操作说明。我们构建了一个包含111个电子表格操作代码片段及其对应自然语言摘要的基准，并评估了五种大型语言模型（LLMs）的表现。结果表明，LLMs可以生成准确的电子表格文档，使SOD成为提高电子表格可重复性、可维护性和协作流程的可行前提步骤，但仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 现有电子表格缺乏系统性的文档方法，导致自动化、协作和知识转移受阻，并存在重要机构知识丢失的风险。

Method: 提出“电子表格操作文档”（SOD）AI任务，并构建了一个包含111个电子表格操作代码片段及其对应自然语言摘要的基准。评估了GPT-4o、GPT-4o-mini、LLaMA-3.3-70B、Mixtral-8x7B和Gemma2-9B这五种大型语言模型（LLMs）的性能，使用了BLEU、GLEU、ROUGE-L和METEOR等评估指标。

Result: 评估结果显示，大型语言模型（LLMs）能够生成准确的电子表格文档，证明SOD是提高电子表格可重复性、可维护性和协作流程的可行方法。

Conclusion: 大型语言模型（LLMs）能够生成准确的电子表格文档，使SOD成为提高电子表格可重复性、可维护性和协作流程的可行前提步骤，尽管仍面临一些挑战需要解决。

Abstract: Numerous knowledge workers utilize spreadsheets in business, accounting, and finance. However, a lack of systematic documentation methods for spreadsheets hinders automation, collaboration, and knowledge transfer, which risks the loss of crucial institutional knowledge. This paper introduces Spreadsheet Operations Documentation (SOD), an AI task that involves generating human-readable explanations from spreadsheet operations. Many previous studies have utilized Large Language Models (LLMs) for generating spreadsheet manipulation code; however, translating that code into natural language for SOD is a less-explored area. To address this, we present a benchmark of 111 spreadsheet manipulation code snippets, each paired with a corresponding natural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini, LLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and METEOR metrics. Our findings suggest that LLMs can generate accurate spreadsheet documentation, making SOD a feasible prerequisite step toward enhancing reproducibility, maintainability, and collaborative workflows in spreadsheets, although there are challenges that need to be addressed.

</details>
