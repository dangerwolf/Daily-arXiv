<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 该论文讨论了大型语言模型（LLMs）和多模态大型语言模型（MLLMs）中表格处理的挑战，并提出了一个分类法和任务介绍来解决这些问题，同时指出了该领域存在的关键研究空白。


<details>
  <summary>Details</summary>
Motivation: 表格由于其复杂和灵活的结构在大型语言模型中受到关注，但其多样化的格式和目的使得表格理解任务充满挑战，缺乏通用的方法。

Method: 论文通过表格输入表示的分类法和表格理解任务的介绍来阐明关键概念。

Result: 研究强调了当前领域的几个关键空白：1) 主要集中于检索任务，推理能力有限；2) 模型在处理复杂结构、大型表格、长上下文或多表格场景时面临显著挑战；3) 模型在不同表格表示和格式上的泛化能力有限。

Conclusion: 表格理解领域需要进一步的研究来解决当前存在的关键问题，特别是在提升模型的推理能力、处理复杂表格结构和增强泛化能力方面。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: ctdGAN是一種條件GAN，用於處理表格數據中的類別不平衡問題，它通過空間劃分、新的概率採樣策略和損失函數，在接近原始數據分佈的子空間中生成高質量樣本，並顯著提高分類精度。


<details>
  <summary>Details</summary>
Motivation: 表格數據存在類別不平衡問題，導致機器學習任務性能下降。現有GAN模型沒有考慮輸入樣本的向量子空間，導致數據生成位置隨意，且類別標籤在訓練中被視為普通類別變量，使得條件採樣效率低。

Method: ctdGAN是一種條件GAN，首先執行空間劃分步驟，為輸入樣本分配聚類標籤。然後，利用這些標籤通過新的概率採樣策略和一個新的損失函數來合成樣本，該損失函數懲罰聚類和類別的錯誤預測。它還引入了聚類縮放技術，可在不影響數據維度的情況下捕捉多個特徵模式。

Result: ctdGAN在14個不平衡數據集上的綜合評估表明，它在生成高保真樣本和提高分類準確性方面表現優越。

Conclusion: ctdGAN通過考慮數據的向量子空間和改進條件採樣，有效解決了表格數據中的類別不平衡問題，生成了高質量的合成數據，並提升了分類性能。

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>
