<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations](https://arxiv.org/abs/2509.26331)
*Berdymyrat Ovezmyradov*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在多步战略业务决策中的能力尚未被充分探索。本文提出并分析了一个基于商业游戏的管理模拟器，用于对五种主流LLMs（Gemini, ChatGPT, Meta AI, Mistral AI, Grok）在模拟零售公司的长期决策能力进行基准测试，评估其在利润、收入、市场份额以及战略连贯性、市场适应性等方面的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言和模式识别任务中表现出色，但其在多步、战略性商业决策中的能力仍未得到充分探索。现有短期基准测试（如Vending-Bench）可能无法充分反映LLMs在长期时间范围内的表现，并且目前缺乏用于评估长期决策连贯性的替代基准。

Method: 本研究采用一种新颖的商业游戏作为基准，构建了一个可重现、开放获取的管理模拟器，用于LLM的基准测试。研究选取了五种主流LLMs（Gemini, ChatGPT, Meta AI, Mistral AI, 和 Grok），让它们为一家模拟零售公司进行决策。实验环境是一个动态的、逐月的管理模拟，以电子表格模型透明呈现。在每个月的模拟中，LLMs会收到一份包含上一时期完整业务报告的结构化提示，并被要求做出关键的战略决策，包括定价、订单规模、营销预算、招聘、解雇、贷款、培训费用、研发费用、销售预测和收入预测。

Result: 本研究将根据利润、收入和市场份额等定量指标以及其他关键绩效指标（KPIs）来比较LLMs的表现。同时，还将分析LLMs决策的战略连贯性、对市场变化的适应性以及它们做出决策所提供的理由。

Conclusion: 这种方法使得评估超越了简单的性能指标，能够深入评估LLMs在长期决策中的能力。本研究通过提出一个可重现、开放获取的管理模拟器，为LLM基准测试研究做出了贡献。

Abstract: The rapid advancement of LLMs sparked significant interest in their potential
to augment or automate managerial functions. One of the most recent trends in
AI benchmarking is performance of Large Language Models (LLMs) over longer time
horizons. While LLMs excel at tasks involving natural language and pattern
recognition, their capabilities in multi-step, strategic business
decision-making remain largely unexplored. Few studies demonstrated how results
can be different from benchmarks in short-term tasks, as Vending-Bench
revealed. Meanwhile, there is a shortage of alternative benchmarks for
long-term coherence. This research analyses a novel benchmark using a business
game for the decision making in business. The research contributes to the
recent literature on AI by proposing a reproducible, open-access management
simulator to the research community for LLM benchmarking. This novel framework
is used for evaluating the performance of five leading LLMs available in free
online interface: Gemini, ChatGPT, Meta AI, Mistral AI, and Grok. LLM makes
decisions for a simulated retail company. A dynamic, month-by-month management
simulation provides transparently in spreadsheet model as experimental
environment. In each of twelve months, the LLMs are provided with a structured
prompt containing a full business report from the previous period and are
tasked with making key strategic decisions: pricing, order size, marketing
budget, hiring, dismissal, loans, training expense, R&D expense, sales
forecast, income forecast The methodology is designed to compare the LLMs on
quantitative metrics: profit, revenue, and market share, and other KPIs. LLM
decisions are analyzed in their strategic coherence, adaptability to market
changes, and the rationale provided for their decisions. This approach allows
to move beyond simple performance metrics for assessment of the long-term
decision-making.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [2] [The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows](https://arxiv.org/abs/2509.26557)
*Litao Yan,Andrew Head,Ken Milne,Vu Le,Sumit Gulwani,Chris Parnin,Emerson Murphy-Hill*

Main category: cs.HC

TL;DR: InvisibleMentor是一个通过分析屏幕录像来帮助用户发现Excel等工具中更高效工作流程的系统，它能够检测重复操作并推荐改进方案，并且比基于提示的助手更实用。


<details>
  <summary>Details</summary>
Motivation: 许多用户在Excel等功能丰富的工具中难以发现更高效的工作流程。现有的AI助手需要用户描述目标或问题才能提供帮助，这既费力又不精确。

Method: InvisibleMentor直接操作屏幕录像，采用两阶段管道：一个视觉-语言模型重建动作和上下文，一个语言模型生成结构化、高保真度的建议。

Result: InvisibleMentor准确识别了低效工作流程，参与者认为其建议比基于提示的电子表格助手更具可操作性、更具针对性，并且更有助于学习和改进。

Conclusion: InvisibleMentor提供了一种更有效、更实用的方法，帮助用户在复杂软件中学习并提高工作流程效率。

Abstract: Many users struggle to notice when a more efficient workflow exists in
feature-rich tools like Excel. Existing AI assistants offer help only after
users describe their goals or problems, which can be effortful and imprecise.
We present InvisibleMentor, a system that turns screen recordings of task
completion into vision-grounded reflections on tasks. It detects issues such as
repetitive edits and recommends more efficient alternatives based on observed
behavior. Unlike prior systems that rely on logs, APIs, or user prompts,
InvisibleMentor operates directly on screen recordings. It uses a two-stage
pipeline: a vision-language model reconstructs actions and context, and a
language model generates structured, high-fidelity suggestions. In evaluation,
InvisibleMentor accurately identified inefficient workflows, and participants
found its suggestions more actionable, tailored, and more helpful for learning
and improvement compared to a prompt-based spreadsheet assistant.

</details>
