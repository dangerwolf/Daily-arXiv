<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows](https://arxiv.org/abs/2509.26557)
*Litao Yan,Andrew Head,Ken Milne,Vu Le,Sumit Gulwani,Chris Parnin,Emerson Murphy-Hill*

Main category: cs.HC

TL;DR: InvisibleMentor是一个系统，它通过分析屏幕录像来识别用户在Excel等工具中的低效工作流程，并推荐更高效的替代方案。


<details>
  <summary>Details</summary>
Motivation: 在Excel等功能丰富的工具中，用户很难发现更高效的工作流程。现有的AI助手需要用户明确描述目标或问题，这既费力又不精确。

Method: InvisibleMentor采用两阶段管道：首先，一个视觉-语言模型从屏幕录像中重建动作和上下文；然后，一个语言模型生成结构化、高保真的建议。它直接作用于屏幕录像，而非日志、API或用户提示。

Result: InvisibleMentor准确识别了低效工作流程，参与者认为其建议比基于提示的电子表格助手更具可操作性、更具针对性，并且更有助于学习和改进。

Conclusion: InvisibleMentor通过分析屏幕录像，能有效地识别并推荐更高效的工作流程，相比现有的基于提示的方法，提供了显著的改进。

Abstract: Many users struggle to notice when a more efficient workflow exists in
feature-rich tools like Excel. Existing AI assistants offer help only after
users describe their goals or problems, which can be effortful and imprecise.
We present InvisibleMentor, a system that turns screen recordings of task
completion into vision-grounded reflections on tasks. It detects issues such as
repetitive edits and recommends more efficient alternatives based on observed
behavior. Unlike prior systems that rely on logs, APIs, or user prompts,
InvisibleMentor operates directly on screen recordings. It uses a two-stage
pipeline: a vision-language model reconstructs actions and context, and a
language model generates structured, high-fidelity suggestions. In evaluation,
InvisibleMentor accurately identified inefficient workflows, and participants
found its suggestions more actionable, tailored, and more helpful for learning
and improvement compared to a prompt-based spreadsheet assistant.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations](https://arxiv.org/abs/2509.26331)
*Berdymyrat Ovezmyradov*

Main category: cs.AI

TL;DR: 该研究通过一个为期12个月的商业游戏模拟器，评估了领先大型语言模型（LLM）在多步骤战略业务决策中的表现，比较了它们的利润、收入和市场份额等指标。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自然语言和模式识别方面表现出色，但它们在多步骤、战略性商业决策制定方面的能力，尤其是在长期一致性方面，仍未得到充分探索。现有基准可能无法反映长期性能。

Method: 研究使用了一个新颖的、可复现的、开放获取的管理模拟器（商业游戏）。五种领先的LLM（Gemini, ChatGPT, Meta AI, Mistral AI, Grok）被要求每月为一家模拟零售公司做出关键战略决策，为期12个月。决策基于结构化提示和上一期的业务报告。评估指标包括定量指标（利润、收入、市场份额和KPIs）以及战略一致性、市场适应性和决策理由等定性方面。

Result: 该研究将利用此框架评估五种领先LLM在上述模拟环境中的表现，并分析其决策的战略一致性、对市场变化的适应性以及决策理由。

Conclusion: 这种方法超越了简单的性能指标，用于评估LLM的长期决策能力，并为研究社区提供了一个可复现的、开放获取的管理模拟器，用于LLM的基准测试。

Abstract: The rapid advancement of LLMs sparked significant interest in their potential
to augment or automate managerial functions. One of the most recent trends in
AI benchmarking is performance of Large Language Models (LLMs) over longer time
horizons. While LLMs excel at tasks involving natural language and pattern
recognition, their capabilities in multi-step, strategic business
decision-making remain largely unexplored. Few studies demonstrated how results
can be different from benchmarks in short-term tasks, as Vending-Bench
revealed. Meanwhile, there is a shortage of alternative benchmarks for
long-term coherence. This research analyses a novel benchmark using a business
game for the decision making in business. The research contributes to the
recent literature on AI by proposing a reproducible, open-access management
simulator to the research community for LLM benchmarking. This novel framework
is used for evaluating the performance of five leading LLMs available in free
online interface: Gemini, ChatGPT, Meta AI, Mistral AI, and Grok. LLM makes
decisions for a simulated retail company. A dynamic, month-by-month management
simulation provides transparently in spreadsheet model as experimental
environment. In each of twelve months, the LLMs are provided with a structured
prompt containing a full business report from the previous period and are
tasked with making key strategic decisions: pricing, order size, marketing
budget, hiring, dismissal, loans, training expense, R&D expense, sales
forecast, income forecast The methodology is designed to compare the LLMs on
quantitative metrics: profit, revenue, and market share, and other KPIs. LLM
decisions are analyzed in their strategic coherence, adaptability to market
changes, and the rationale provided for their decisions. This approach allows
to move beyond simple performance metrics for assessment of the long-term
decision-making.

</details>
