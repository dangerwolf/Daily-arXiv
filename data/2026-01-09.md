<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Tabularis Formatus: Predictive Formatting for Tables](https://arxiv.org/abs/2508.11121)
*Mukul Singh,José Cambronero,Sumit Gulwani,Vu Le,Gust Verbruggen*

Main category: cs.DB

TL;DR: TaFo是一个创新的方法，能够为表格自动生成条件格式（CF）建议，解决了用户在创建CF规则时遇到的复杂性问题。它通过结合符号推理和神经模型，并利用值和语义信息，实现了比现有系统更准确、更多样化和更全面的格式化建议。


<details>
  <summary>Details</summary>
Motivation: 现有的电子表格软件虽然广泛用于数据管理和分析，但创建条件格式（CF）规则对于用户来说仍然是一个复杂且需要技术知识的任务。用户常常不了解CF功能，难以创建规则，并且现有用户界面不够理想。

Method: TaFo采用一种神经符号方法，借鉴了组件化合成系统的思想，并结合了语言模型的语义知识和一个能够保持规则多样性的排序机制。它专注于值（value-based）格式化，自动学习触发规则的条件以及相关的视觉格式属性，解决了以往仅关注结构化格式化的问题。TaFo消除了对用户提供格式化示例或自然语言指令的依赖，实现了完全预测性和自动化。

Result: 在对180万个包含CF和手动格式化的公共工作簿进行的评估中，TaFo的表现优于多种用于或改编用于表格格式化的符号和神经网络系统。TaFo生成的格式化建议在准确性、多样性和完整性方面均优于现有系统，并且在匹配用户添加的真实规则方面，其性能比现有系统提高了15.6%--26.5%。

Conclusion: TaFo通过其独特的神经符号方法，成功地实现了表格条件格式化建议的自动化和智能化，显著提高了格式化建议的质量和用户体验，为电子表格数据分析领域带来了重要的改进。

Abstract: Spreadsheet manipulation software are widely used for data management and analysis of tabular data, yet the creation of conditional formatting (CF) rules remains a complex task requiring technical knowledge and experience with specific platforms. In this paper we present TaFo, a neuro-symbolic approach to generating CF suggestions for tables, addressing common challenges such as user unawareness, difficulty in rule creation, and inadequate user interfaces. TaFo takes inspiration from component based synthesis systems and extends them with semantic knowledge of language models and a diversity preserving rule ranking.Unlike previous methods focused on structural formatting, TaFo uniquely incorporates value-based formatting, automatically learning both the rule trigger and the associated visual formatting properties for CF rules. By removing the dependency on user specification used by existing techniques in the form of formatted examples or natural language instruction, TaFo makes formatting completely predictive and automated for the user. To evaluate TaFo, we use a corpus of 1.8 Million public workbooks with CF and manual formatting. We compare TaFo against a diverse set of symbolic and neural systems designed for or adapted for the task of table formatting. Our results show that TaFo generates more accurate, diverse and complete formatting suggestions than current systems and outperforms these by 15.6\%--26.5\% on matching user added ground truth rules in tables.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows](https://arxiv.org/abs/2512.13168)
*Haoyu Dong,Pengkun Zhang,Yan Gao,Xuanyu Dong,Yilin Cheng,Mingzhe Lu,Adina Yakefu,Shuxin Zheng*

Main category: cs.AI

TL;DR: Finch是一个包含172个复合工作流和384个任务的基准，旨在评估AI代理在真实的、企业级的金融和会计工作流中的表现。


<details>
  <summary>Details</summary>
Motivation: 评估AI代理在真实世界、企业级专业工作流中的能力，这些工作流涉及数据输入、网页搜索、跨文件检索、计算、建模、验证、翻译、可视化和报告等多种任务。

Method: 通过LLM辅助发现和专家注释来构建工作流。具体包括：1. 从真实的邮件和电子表格历史记录中提取工作流；2. 由领域专家进行详细注释，耗时超过700小时。该方法生成了172个复合工作流，包含384个任务，涉及1710个电子表格（2700万个单元格）以及PDF等文件。

Result: 评估了包括GPT 5.1、Claude Sonnet 4.5、Gemini 3 Pro、Grok 4和Qwen 3 Max在内的前沿AI系统。GPT 5.1 平均每个工作流花费16.8分钟，但仅完成38.4%的工作流；Claude Sonnet 4.5的完成率仅为25.0%。

Conclusion: 现实世界的企业工作流对AI代理构成了严峻挑战，即使是最先进的模型也难以高效率和高准确性地完成。

Abstract: We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.
  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.
  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 16.8 minutes per workflow yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.

</details>
